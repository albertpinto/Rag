 All right, so I'll just give a basic overview. We do have certain textbooks. They are mentioned in this orientation document, which you all should have received. Please read the orientation document carefully. If you have not subscribed to the Slack discussion channel, please do. It's important because i wouldn't have the luxury of posting or sending emails all the time and other people would like to chime in into the discussion it's much better to do it over a discussion group rather than through emails so please do subscribe to the slack those of you who haven't must do this is what this is anyway our stuff that we did last time if you remember we went over the basics of machine learning and so on and so forth we talked about a workshop will include the following features what are the features we talked about a workshop to include uh let me go back we'll have lab work we'll have projects we'll have quizzes and data science interview prep we will have polls guys the less than half of you only a third of you fill the polls it just takes 10 seconds can I please request that if you haven't filled the poll after the last lecture you have an invite to that please do complete the polls it's it's important that we take the polls and participate likewise discussion groups if you haven't joined please do join it now I wanted to announce and then YouTube we have a YouTube channel now why is that important? This Sunday on YouTube actually we'll be doing two broadcasts. One of them is a slightly technical topic. It's on word embeddings, a simple understanding of word embeddings. It's a very interesting topic in machine learning. You guys are all ready to understand it. So think of it as an additional You guys are all ready to understand it. So think of it as an additional content besides the workshop. It is at noon on Sunday. Watch our YouTube channel and certainly do, if you subscribe it, you'll get notifications about it. The second is, I'm going to give, for those of you who are not very familiar with Python or would like a bit of extra help, I'll give a hands-on walkthrough of Python through a notebook. That will happen around 1.30 or 2 o'clock. I'll be giving it on YouTube and I'll take questions in the YouTube's live chat and provide explanations so for that reason if you have not subscribed to the YouTube channel I would strongly suggest that you do are you together that's that likewise we have a Facebook and Twitter channel so what I'm doing is notifications I try to push out to each of the channels but not everything am I able to push out some Jay Shah, Dr. So that is that. Now today I expect us to finish a few things guys. Let me mention what I expect we do. I would like us to do the following. I'll talk about Kaggle. We will set up Colab. colab in GCP sorry GCP we will set up for those of you who have good powerful machines or who are willing to pay for in GCP itself I will show you how to set up Jupiter notebooks or notebooks in notebooks notebooks in GCP that is if you want to do faster computation will need more memory and so on and so forth are we together and for local setup I'll give you an idea of local setup so this is the scope of what we are going to do we'll talk about homeworks and projects speaking of projects so homeworks the way it will work is every week a homework is due you this homework you will post directly togle so I've created a data set a private data set where you can submit your homework so one thing that I need from all of you right away is go to Kaggle if you haven't registered in Kaggle by the way you can register to Kaggle using your Gmail accounts once you do that, confirm that you are registered in Kaggle. Then I will show you a data set, a simple data set that we have. This week I'm making the assignments rather simple. The homework the assignments rather simple. The homeworks are rather simple, but going forward it's going to be a bit more involved because the whole idea is that this class is about a lot of practice. We'll continue the tradition hereafter. Mondays will be theory and Wednesdays will be a review of labs, walkthrough of of code and walkthrough of the projects so let me start by first sharing my screen and talking about cattle is there anybody who is not familiar with cattle or what cattle is if you're not familiar I'm not familiar with Kaggle. Okay, so then I will talk a little bit about what Kaggle is. So are you guys seeing my screen? Yes, we see your screen. I can change the settings for automatically admitting everybody. I don't know why I have to enable people to join this. I don't know. Anyway, that's some setting. All right, if you're seeing this caggle, let me give you a background. Yeah, Asif. Asif Srinivas here. So this has been the security setting from the Zoom because the Zoom moments in the past. So if you could make somebody else on the host like Prachi or some other idea that will help you get over this issue all right i will do that let me do that prachi you are you're the host now yeah i can say that And if you notice anybody in the waiting room, please do it. Yeah, thanks Explain to me. This is very interesting. So people random people come and join your zone, is it? Yeah, that's true. And then people can share whatever right so that especially with the kids enough Some people have got some nice not so nice pictures on the meetings have got some nice not so nice pictures on the meetings all right that explains so cattle is a site which has been very influential in data science the reason uh i am emphasizing this is because if you if you want to be considered seriously in this field you have to you have to have a presence on cable I mean together I'm making a pretty strong statement here well having said that I am I belong to a generation that used to not be very active in Kegel and myself have not been active in cable for for reasons that now in hindsight I can't explain because I've been very busy with work or whatever it is but I wish I had time if I was younger I would certainly be very active on Kaggle if you're joining data science as a field you aspire to have a career in it I would strongly suggest that you do have a presence on Kaggle. What they do is they post a lot of data sets. They are a curator of data sets. I believe the total number of data sets they have is, if we go here, do you notice that what they have done is they have collected data sets, all publicly available data sets from everywhere, and they are hosting it. There are many other sites that are doing that, but Kaggle is certainly the most influential these days. Most of the things that people talk about are here. Now when you have a data set, do you notice that today we are in the middle of a COVID situation? Today we are in the middle of a COVID situation. So if you go home and you look at what is happening here into the data sets, you will realize that the COVID challenge is this. There is this data set. Government has said it's a challenge. Let us all try and solve the COVID's research or at least facilitate research into COVID. The moment you do that, you can post your datasets in Kaggle and then, and these are massive datasets as you can see 13 gigs of dataset, you can then specify what do you want people to do. So you notice that the researchers have said these are all useful things they want the data science community to do or help them help make possible. So these are the tasks you give certain tasks. Then there is a discussion board associated with a particular data set. A lot of people are discussing all sorts of things here and it's a conversation you know about the data. You have a fairly large amount of activity it shows how much people are engaged with it and from where. Clearly people from the United States and India are dominant in this particular challenge and this is by the way an emerging trend uh india is emerging as a data science powerhouse and it's quite quite interesting actually but you find so much talent emerging in india in this new field so and then you have the kernels so what kernels kernels are notebooks that people have posted in this space and you can look at the kernels by how much votes they got so for example here is a person who has created a kernel I'll just take the most popular kernel it seems to have been voted on 1094 times what it means is if you are here look at the beautiful way this is a what is called a notebook in science in data science now most of you who have done something are familiar with it but roughly speaking in programming you write code and maybe you put some comments or you don't put some comments in the world of data science there is something called literate programming. The idea is that when you code typically in C or Python or some language, let's say Python for general purpose coding, you're trying to make the machine understand your code. Whereas in data science, there is a difference. When you write code, to a large extent, your audience is other data scientists. You're trying to explain your code to other data scientists. And that's a huge differentiator. So the way you do it is comments dominate. What you would consider comments in code, it actually dominates. Are we together? Right? And so most of these notebooks are full of comments. By the way, I don't know, yes, they're full of comments. And you can clearly see this notebook has pictures and descriptions and so forth. They usually don't call it comments, they call it documentation or text or something. But in the language of programmers, you would say a lot of comments or documentation. But very neatly, this person has documented everything, what it is, what data he's working with. He's doing exploratory data analysis and so on and so forth. And it's a pretty long textbook notebook. If you notice in this notebook he has used a lot of features. You know he has colored the columns as he's looking at the data. He has given the top end. Those of you who did exploratory data analysis with me before know what I'm talking about I expect these things to you so for example if you go back to the let's do this compare these methods with what I've been teaching you support vectors comm if we go here and by the way, it is there in your slack, but I'll just go through this website support.com if you search for for example I think I gave a page Are you focusing this? So when you look at this and this is the notes from the previous workshop. Those of you who took the introductory workshop with me. And those of you, if you have had exposure to basic data analysis somewhere else, this is it. Those of you who have not, who are completely new to any data science or statistical analysis, do please attend the extra session that I'm giving over the weekends. So this is it and I want to give you a sense since we covered these things, those of you who have been familiar with this I suppose, do you notice that we went through a systematic process of data analysis? Yeah. Yeah, so this whole data analysis that we went through and for example by the way what you're looking at are chapters from my emerging textbook in due course of time I would like to finish it and get the volume one out which I hope will be before this month ends. So Asif, can you maximize the screen? Can I maximize the screen? There we go. Is that better? Yes. So I take an example of the Irish data set, for example, which is the quintessential example that everyone starts with. We do exploratory, basic exploratory analysis. We draw graphs and plots and so forth. We do bar charts, correlations, pair plots. Then likewise the California dataset, you do all sorts of visualizations and so forth. As you can see, we do different sorts of visualizations of the data, correlations and so on and so forth. As you can see, we do different sorts of visualizations of the data, correlations, and so on and so forth, and missing value analysis. So I'll just stop here at some of these plots and compare them to what you see now happening. Let's see, looking at this COVID data set. So what do you see? Do you see a similarity? People go about the data in a systematic way. This notebook is well done. It has studied the data. It has done a very good job of exploratory data analysis, explored the data. And you can see that if you systematically do the data the way I have taught you guys, my feeling is that you will get quite a lot of recognition in the field. Generally, highly voted people in Kegel, it becomes very easy for them to have job conversations with companies because they can their work is already showcased and the way we will do this workshop is I want to make sure that you all right away create kernels in Kegel a high quality curtains and of course I'll guide you in improving those curtains so that you you create a set of assets which you which you can showcase in your interviews or in your or Talk about with your future employers So you notice that there's a lot of descriptive statistical analysis done by here now, what does it take? How do you do all that? It's very easy. This is nothing but sort of a Jupiter notebook Those are who are familiar with jupiter notebooks you can do it now kegel has one limitation it accepts notebook only notebooks only in python and r it doesn't accept notebooks in julia but in this workshop i will expect you to do also your notebooks in julia give me one second guys i'm getting the sun directly in my eyes yes so we'll also do that anyway so that is the kegel aspect of it let's go back to home so what you should do uh what we will do is we will take a few data sets as homeworks and a few data sets as your projects. For projects, it's important that you find your partners as soon as possible. And just to get you practiced with the new way that you need to do, this time around, I will take submissions only as Kaggleel submissions. Are we clear guys? And I will leave it to you to decide at the end whether you want to make those notebooks public. In the beginning, your notebooks will be private. I hope only we can see it, but gradually they will start becoming public. So what are the data sets we are going to talk about? The data sets that we will talk about are, if you search for something called the river data set, river data set for classifiers. I have sent a link on slack to all of you for this data set are you guys able to see this page yeah that's right so this page and you can see it as a string stranger etc if you see it as an anonymous person it will look to you like this let me go into the anonymous mode. This. Oops. You can't see it. We can't find this dataset. That's not very encouraging. So let's see if you can even see this. Yeah, so you need to, at this moment, you need to, yes, it will not even show up in Slack. So in other words, you have to be logged will not even show up inside so in other words you have to be logged in as a user and I have to give you access to it what this data set is about is it had fields x1 and x2 and there is a target variable T P is categorical it has values of either 0 or one you can see that right here it has only two values most of the values are one some of the values are zero uh x1 and x2 are numerical fields your first assignment is a very simple assignment just write in either r or in python create a classifier right now the way you have to do that is depending upon your level of expertise if you're completely sort of entering this field do at least this much pick up enough so that you can do an exploratory data analysis now remember guys this analysis is all due before Monday. As if the text is not visible. As if people click on the link which you have shared on Slack, I think you don't need to sign in. You can still see the data set. Oh, because I've given a shareable link. All right. Yeah. Yeah, go to Slack. Yeah, I see the data set. You do see the data set oh because given a shareable link oh yeah yeah go to slack I see the data set you do see the data set wonderful wonderful let me also try that just to see how it looks to looking to you at this particular moment. Does it look like this? Yes. Yes. So I've given the instructions here. You need to do exploratory data analysis. By now, you know what exploratory data analysis is, univariate statistics, mean, median, modes, and all of that. do some visualization of the data it's a very simple data two-dimensional data with a with some data belonging to one class and some data belonging to the other class then you have to create classifiers and first task is you need to create an effective classifier using only logistic regression don't use anything else first in your notebook there should be a section that says using logistic regression. It is this you're allowed to do feature extraction. Vaidhyanathan Ramamurthy, So before you do logistic regression regression as part of your exploratory data analysis. If you can extract a few features from the data. That would be absolutely marvelous. See if you can do that. And you try to get a better model using logistic regression. Now, Let me just mention that just with logistic regression, you can achieve accuracy is in the 90% So the trick is how do you get there? Initially, I thought I'll make it just as a competition, but then I thought, let all of you see each other's notebooks and learn from it. Then what do you do? Try, if you know any of the classifiers, and we'll talk about other classifiers today, go use those classifiers to train on this data and do that. But logistic regression, you must somehow achieve 90 close to 90% accuracy using just logistic regression. And the assignment is to be able to do that. The bonus is go use other classifiers and try to get those results. Obviously, today I'll talk about the other classifiers. For many of you, this may be the first time you're creating a notebook for for kegel now how do we do those notebooks there are two ways that you can do that uh first what i would suggest is you can go and create your notebooks uh like sorry when you go and do that you can well obviously you can't see the notebooks here so i will come to the view that is using when you log in so do you notice that you have these kernels i put just a starter kernel here and this starter kernel doesn't have much it just shows that there is a bit of code and it produces this output it is a boilerplate kernel that gets created when you hit create new kernel so obviously i wouldn't put the solution here yet i want all of you to contribute your files and do that so any feedback guys before we move on this is a basic homework i expect you to do as of before monday we have to submit it right? Yeah before Monday try to have something in each one of you. Yeah okay. So individual. Individually. This is an individual project. I am willing to like if you want to if you find too intimidating to do individually you can do it in pairs. Preferably individually but if you can't pair up because if you feel the learning curve is too steep pair it with some pair up with somebody you have a choice of languages r and python for this and bonus for doing it also in julia but then julia you won't be able to post here you'll have to uh send it to me in Jupiter as a by email And I'll be very happy to look at your Julia submissions If you say I don't know Python I remember this weekend. I'm giving a free introduction to Python for data science Questions guys You should we have to use this notebook from Kegel or we can use our own Jupyter? Yeah, what I would suggest is you can do both ways. See, you can do it first in your Colab, Google, or on your local machine and then post it here. That is easy to do. Or you can post it here. That is easy to do or you can create the notebook directly in Kaggle. It's up to you. Generally, the Kaggle platform is quite slow. So it may be much better if you do it locally. I mean locally means on your either laptop or in your own Jupyter in Google Cloud and then bring it in here but i would like to see the submission here eventually so that you know everybody can benefit from everybody else's submission now one thing i would suggest if you do it or in the interest of making sure that others i mean see here's the thing guys it's an honor system no point in just seeing other people submit and just repeating what they have done I would suggest that try to do it on your own it's a very simple problem try to do it on your own and once you have done it then look at other people's notebooks and when you say submit it here what does it mean like copy paste the code here or how do you submit it to you for example here is a notebook right here it is a new notebook I say and save it yes exactly sure advanced settings you can do that and that is it you can paste your code here that is one way of doing it uh there may also be a way to just directly upload it see if you guys can find that that would be good okay you got it that's easy enough thank you so after that and a lot of these homeworks I'll put it here for you guys your projects will be here so let me tell you what your project is the first project is there three projects that you will have to do actually first let me finish with the homeworks this is one homework the other homework is there is a data set here called breast cancer do you see breast cancer prediction the breast cancer data set so Wisconsin data set so if you go to this breast cancer data set and I'll by the way put everything in email and post it to Slack and so forth. This is a famous data set. It is also a classifier problem. At this moment, use whatever you know. If you only know logistic regression, first homework is just apply logistic regression and do it now that homework I wouldn't advise you to post it to this public place because you know you may you may feel awkward you're making an attempt so here is what I would suggest I'm going to clone this data and make it available under the just like the river data set under support vectors AI lab. So once it is available under this, I'll send you guys an email saying it is available. So post your kernels, not in the public space, but here. Once you have posted it, it's very easy to migrate it later on. If you feel really proud of your kernels, you can always migrate it to the public space or we can make this space itself public space. Hey, Asif. Yes, go ahead. Hey, the link you sent on the slack, right, for the reward dataset, when you click on it, you go to Kaggle, right, and you're in a signed in page already. How did you get to that new notebook? Where is that link? I have to add you to this. signed in page already now how did you get to that new notebook where is where is that link I have to add you to this so as a user I have to add you to this oh okay then I will get the new notebook and so which is why it is important that today guys before we finish the class because today it's all about hands-on all of you have an account on cablegle. And as you create account on Kaggle, please put it on our Slack discussion group. As you know, we have a Slack discussion group here, the Data Science 2020. If you don't find your name here, you should be concerned. Let me know let Prachi know actually she'll keep adding you to this But put your Kaggle account here if it is just your gmail address I Would highly encourage you to just use your Gmail then put it there so that I can keep adding you guys as users to this private data set and Then you're ready to get started with your work. Are we together? started with your homework. Are we together? So just like that, we'll do the breast cancer data set and there is a third data set of which you will do. It is the California housing data set. Do you see that there's this housing data set for California? So this housing data set, once again, I'll post it onto a private support vectors channel so that your kernels remain your kernels. Now, these two data sets, because they have been heavily studied by others, you may be very tempted to just go and read other people's submissions. I would strongly suggest don't do that yet. First, try to solve it on your own. And then your solution may not be as great as the best solutions, because the people who are highlighting or showcasing their thing, they have worked on it for weeks and weeks to perfect their notebooks, right? That's why they're so high up in the leaderboard and so forth. So you don't have to because I'm giving you time only till Monday. So you have limited time. Your notebook may not be that great, but the advantage is I'll give you feedback on what you have done and I'll help you improve it. And the whole idea is that by the time you finish this workshop, you will be producing world-class notebooks, right? Or data science notebooks. So this is your third homework. I'll itemize it. So the three homeworks are analyze the river dataset, analyze the breast cancer dataset, California dataset. There are two more datasets actually. One of them is called the FLAG dataset and other is called the HIL dataset. So you will have a total of five. Three of them you would not have seen anywhere else except here because they are support vectors created datasets. Breast cancer and California housing are public datasets. You are going to, you can sort of do something and then see how others have done it and so forth and also in the book here in those of you who did the who have access to the ml-100 who took ml-100 they have access to it you of course remember that those data sets are heavily studied in my book the the the dataset at least is, I don't remember if I added the breast cancer here, but I think I have by now. So both of these datasets are heavily studied in my textbook, so those of you who had, who have taken ML100 of course have this. Those of you who are repeating this class would also have analysis of those two things from the past. So but those of you who are new, of course, you can benefit from the public data sets available. So that's what is the name of this book is on your support vector.com right? Yeah. So if you registered for ml 100 this time, or this time, okay. I registered in the past, but okay. So then you would have had, it's called data explorations. Literally you're seeing the cover of my book. Oh, data explorations. It will be, I mean, obviously those are, I mean mean hopefully I'll finish it those of you who haven't taken my previous course and would nonetheless want to buy a copy of it I'll be happy to give it to you but at this moment it's work in progress as you can see it's a draft I'm trying to finish it within three four weeks now the first one then you guys can all buy it I'm giving it at cost in other words I'm not making a profit or anything whatever the printer charges sit on the printers charge a lot of money for us for doing color printing but so be it whatever the cost is I let you know if you want to pop you can purchase at price so well that's that then there are three projects, guys, that we're going to do. The projects are, you will analyze a dataset, which is, hang on set of, well, this is a smaller data set for natural and physical sciences, acknowledgements. So this contains all the papers that were published in our field of machine learning. So what is archive? Would anybody like to mention what archive is? That where university researchers publish their research and... That's right. It is not just university. Everybody these days, if you have any new research, you don't wait to publish it in a journal. You instead go and publish it in archive. So to show what I mean by that, let me see. If you want to see what I published many, many years ago, I would go and search for myself so these are the two and there are other papers I have not posted to our cave but this is an example right so well this is little outside machine learning but so it wouldn't mean much but this is a place where the best research are published every time a new research comes not only best all research is published so people have these different fields and all those fields publish here and this is heavily studied most of the great works are first published here as preprints for example this last Sunday I talked about the paper attention is all you need remember that attention is all you need and that paper is somewhere here attention is all you need yeah all you need you see this this paper is again just to give you an idea it has eight thousand five hundred and seventy four citations why because in the field of machine learning especially natural language processing it was a game changer the the field of machine learning, especially natural language processing, it was a game changer. The whole field of natural language processing changed right after this paper was published at the end of 2017. And early 2000, from 2018, we do everything differently. Language translations and summarization and everything is now done using something called transform. So this is the place where you go and find serious work. So what is our work? What we will do is, this data set is manageable, 69 MB. You will find, and the project here is in this this project by the way you can do in groups of five and today I want you to as you guys are here in the break form your teams and let me know which are those teams and in Kegel you can go create groups of fiber so form your team let me know what the name of your team is register it in Kegel and your job is, I will explain what it is. This data set, we will analyze from text perspective, we will do descriptive stat, who are the most published authors, who are the most cited authors. We will do basic descriptive statistics, you know, top end. If I ask you you who is the author in the in these fields or in each of these fields who is the most cited which paper is the most cited you realize that those are easy questions to answer right you just have to count the citations and so forth we will start with that and we'll build that project up. We'll make a graph of citations. This author cites that author and so forth. We'll create a citation network. We will also create from paper to paper citations and so forth network. All of that we'll do and then we'll do link prediction. Vaidhyanathan Ramamurthy, Right. So what is the likelihood that this author is going in his next paper is going to cite those other authors. Those are the researchers, so we will do it as a machine learning. It is all very interesting and Vaidhyanathan Ramamurthy, This is a project as you notice this project is not something you can do in three, four days. It will take you the better part of six weeks. So form your teams, get started and engage with me. I'll be available all the off hours, evenings, nights, weekends to guide you through your project. How many of you, I hope you guys are not feeling that this is a lot of work. If you feel it's a lot of work, let me know. I hope you guys are not feeling that this is a lot of work. If you feel it's a lot of work, let me know. But this would be one project worth doing and I'll write the detailed instructions for it. The other project has to do with COVID. We all live in the world of COVID. Right, so We need to do the data. So when we go to the data sets, search for COVID data set. Yeah. And topics data sets. The COVID-19 data set. Now, the big one obviously is from the world challenge, COVID-19 challenge. So we will start with this dataset and I'll give some, maybe a subset of it. We'll do the same thing. We'll do exploratory data analysis. We'll do all sorts of things on COVID dataset. I'll post it as a project. And the last dataset that we do, so why is COVID good? It has a lot of things to do, you know, descriptive statistics, modeling, and so forth, making machine learning models. It's a project. The reality of COVID is in front of you. So it will guide you in what to look for in data. You can ask interesting questions in the data and try to answer those questions on your own it may be that other people have answered those questions doesn't matter you're not trying to make a breakthrough but you can certainly use these data sets to learn machine learning and techniques so we'll do that in the last data set that you will do is something to do with Higgs boson. So Higgs boson was, there is this data set. We don't care about the challenge. We only care about this data set. And this data set is also reasonably small, 54 MB. You have to start by doing descriptive statistics and then we'll make progress beyond that I don't try to immediately go and start doing a major challenge there just start by doing basic descriptive statistics and then we'll see what we can make out the data set I'll guide you guys through it so guys are we clear this week's homework is quite simple you start with see what we can make out of the data set. I'll guide you guys through it. So guys, are we clear? This week's homework is quite simple. You start with the river, the flag, the hill, the breast cancer and the California housing data set. Start and do as much as you can based on what you know. It will also help me establish what exactly it is that you know at what level you are so for example if you're just starting out you may not be able to make much progress if you have really been in this field for some time you'll be able to do much more complete analysis and there are five tasks a picket the river is something that you absolutely must do. The other ones, try to finish it. And then the project, of course, you don't have to finish or do anything by this, by this coming week. It is a six weeks project. I expect it to be done by end of the six weeks. Are we together guys? So now you can post it at kegel but let's go and see where else we can do your labs where it is advantageous to do your labs by the way whenever you submit your notebooks people tend to put pretty pictures you can go to unsplash this website called unsplash it gives you freely usable images. So you can search for anything. So for example, if you want to look for an image of COVID-19, you can see all sorts of freely posted images of COVID-19. People wearing masks, firstly. Those images may not be the best images but they're reasonably good I guess for you to just stick it in your notebook and jazz it up a little bit so use this website and splash if you want then the next thing I would like to do is go to collab so this one before we take a break guys I want you guys to do along with me visit this website called colab research that google.com right well because I have some things here tell me if you have reached this place. If you're seeing something like this, then all of you. I can't hear you. Yeah, I see my some of the notebooks getting pulled in. Yeah, perfectly fine. Yeah, that would just the basic ones getting started. Because they're getting started notebook. What is collab? Which notebook? Welcome to Collaboratory. Yeah, welcome to Collaboratory. Okay. Okay. And when you do that, welcome to Collaboratory. Do you see that there is text again and this data sections right the data sections are the sections that you can run these are executable sections so a notebook is divided into some english text explaining what you're trying to do and then doing it right this is an example of some Python code that generates a graph. If you write this code, then you can click on it. You don't like the color green, let me just make it red. And now I click on this. You notice that the graph became red. So you can do whatever it is you can do let's see if it recognizes yeah the color change to Indian red and so forth and you can change the code and you can do all sorts exercise for today is guys i want all of you to go and just visit collaboratory and obviously those people who have done ml100 and so forth may find it a little bit basic but let's start with the basics today today is the lap. And what I want to do is study this properly, like study how to code, write new code, just create a new notebook. How would you do a machine learning exercise, for example? There are lots of tutorials. For example, there's a course on introduction to pandas, just as a notebook here. You can learn about pandas just as a quote you know as a notebook here you can learn about pandas just by running through this of example this notebook if you want to run it what can you do you can go and say run all or you can run individual segments and when you run all these things will start running now as you run your notebook at the top you notice something you can what all things can you connect to you can first of all this is free free is great for the purposes of learning you can create your notebooks in collab you must become familiar with collab guys it's a it's a de facto standard people use collab to create their work these days the data science notebooks in collab so get used to collab try to what I would suggest is create your solutions in collab and then later on you can go and post it to you know some of them to the to kegel so that you're familiar with both of them now here do you notice that there is a drop down which says you can connect to a hosted runtime. So in other words, if you have a more powerful machine, you can connect to it. At this moment, it just connected to a basic machine, you can connect to a local runtime when more powerful thing is if your home workstation is quite powerful. You can actually connect it to your local machine so for example here it is a back-end URL you can start connecting it to your local machine and so your code will be executed on your local machine again a very powerful thing you get the benefit of collab but you're using your own hardware rather than using the hardware from from Google so it's it's very interesting that transparently you can move between local machine and the cloud issue and do your work makes a difference and then become familiar with writing things in collab let's get a solution in collab so once you have run all of these things in Colab. Let's get a solution in Colab. So once you have run all of these things in, executed it, you see the results of each of the execution, like for example, of the city, et cetera, et cetera. What is Pandas? Pandas is the data frame. And we'll talk a little bit about the theory after the break, but Colab is one thing. The other thing that I want you guys to do, so two we did kegel we did collab the last thing we I want you to do and whether this session is recorded so you can go back and look at it so is go to Google console individually go to your Google console then once you are in your Google console let me switch over to Google console then in the Google console you can go to you can scroll down and you will notice a section called artificial intelligence do you see that do you see that yes so when you go to this there are many things for example data labeling their data sets and so forth so here is where you can upload it or keep your data sets and so forth. But then you can go back to the same thing. Where is my artificial intelligence. AI platform right under artificial intelligence. Do you notice that there is AI platform has something called will. Okay, okay, let me first go to the dashboard. It may be worth going to the dashboard. When you go to the dashboard, there are many things you can do. There are prediction models and auto ML and all of that. But the only thing that we will use is notebooks. So you can create notebooks here. You can go to your AI hub and you can do a lot of things. People have created notebooks and so on and so forth. I would say that your assignment for today and till the end of this week heavily is to just make yourself familiar with these things. It's very important that you do. This is a whole lot of new information for many of you for most of you i would imagine become familiar like you know know the lay of the land so that you don't feel so lost it's a vast space you can't pick all of it up in a day right so because you and but you don't have to you don't really have to pick all of that in just one day and let me just take a particular thing and then you can go to your notebooks in your AI platform dashboard you can go to your notebook and see you can create a notebook instance do you see these guys at the top you can create a new notebook instance mm-hmm yeah now remember collab is free it's important collab is free but when you create a notebook here you have to be careful this can get you into a lot of bills and so remember to stop it so here you see you can do our here right along with Python's kick it learn etc you can do a Python 2 & 3 you can do your TensorFlow 1.5, TensorFlow 2.1, 2.2, PyTorch. Generally, what I advise you to do is pick between one or the other. Pick either, my feeling is, if I have to give you an advice, I would say pick PyTorch. Because it contains everything for Python that we need. It contains Secret Learn, Pandas, NLTK. And in this workshop, we will just touch a little bit of PyTorch. You can do it with GPU. GPUs make your code run faster or without it. I would say without GPU in the beginning, for a large part of this workshop, you won't need the GPUs. You need the GPU for the next workshop. So you can go, let's say, without GPU. So I can say PyTorch test notebook. I'll pick a region for this. Now comes the interesting part. You you can change you can customize it don't do it right now start with very basic at this moment but if you customize it you go to a page where you can control just about everything about it so for example you can pick what sort of machines you need. For example, you can take high, say a high CPU machine, right? You can go with, as an example, you can go up to 96 vCPUs and 86 gigs of RAM. If you were to select something like this, you realize here it tells you what bill you'll incur if you leave this notebook running forever, you don't shut it down. So this is the danger, don't do that. But just below that you see the price per hour, $2.38. That is not much of a price to pay if all you're using it is for half an hour. Suppose you have a big computation and you get tired of running it on your Colab or on your local laptop. You feel that you're wasting hours and hours doing it. One thing you can do, you can suddenly go reserve a big instance like this run it on that most likely your computation will finish in 15 minutes so long as you remember to shut it down for 15 minutes how will you how much will you pay maybe 50 maybe 50 60 cents for the computation isn't it now paying 50 60 cents is not a big deal at all right you can pay it and you got the results in your notebook and once the results are there those results don't disappear there the output is there in your notebook right but the worst thing you can do is reserve a huge notebook like this like a huge machine and run it for a notebook and then not really do anything just go to sleep and a few weeks later realize that your instance is still running don't do that you'll you'll you end up creating a huge bill for yourself so that is the danger that I would say on the other hand if you are the kind who says that you know why not take a small machine dedicated to me let it run all the time I don't care you can go with something like this you know to take this like 8 or 15 gigs of RAM I wouldn't take that actually I would take a standard let me see by default what was it machine type you can go with n1 standard for CPU you know the n1 standard for if you look at it it's 100 a month right again even if you forget to shut it down the worst that you will do is pay 100 a month right um so but hopefully you'll remember to shut it down when you're not using it. So you can do something like that. Are we together? Right? So when you create a machine like this, see what happens. You create a machine like this. So Asif. Yes. Just one question. So just to give, get an idea, right? So the other one you said it will take most probably 15 minutes. this one if you take how much you said what what's how much time typically see for the sort of things we'll do in our lab work you will write the notebook and you'll run it see you'll write the code for quite some time and then you'll turn it we are using those things only to run it maybe half an hour or something like that here and there at the end of the day if you're careful you'll get a like four dollar bill at the end of the month that is for the high power on the 96 one no no no for this one oh for this one okay standard one all the time you'll pay 100 a month but most of the people from experience, right? When they write their code, it costs them like they end up with a bill of four, eight, 12, $15 per month. Very low bill. Because even if you're coding straight here, see the advantage of this is it's a bit more powerful than your collab, then basic collab. So can you run collab from here or you have to bring Colab copy paste here? There is no way to do that. You don't have to go into that. We'll research it here. It's a complicated way. I don't know why at this moment Google hasn't solved the problem. But they're trying to, I'm sure they'll bridge it over. So see here's a thing I have this at this moment have I started this instance I have not started this instance isn't it it is just allocated I have not given it any GPUs right if I want to give it this so it is sorry this is live at this moment what do I do if I want to stop it select that and then stop it exactly I can go in there and then if I go here dismiss fail to get the server rooted sector at sector in the beginning it will create some things like that what do you want to do you want to create a notebook let's go ahead and there's some tutorials here's here's a notebook there There you go. You have a notebook. You can change the name of the notebook, right? And you can get started. So suppose you say import numpy as np. And then import, these are the basic imports into pandas as PD import at there you go you notice that you ended up running some codes and so on and so forth you want to then what do you want to do let's go rename this let's call it starter you have it here now you can do some basic things you can uh one thing that i would suggest is your notebooks you should commit it to git or somewhere so that you don't lose your work it's always a basic good idea then you can you can do shut down what did I do I shut down this notebook I can go back all my sessions are terminated I can go here and so this is it you know I can go back to my notebooks if I were to refresh this and then you were using pie chart there by torture that was tried wrong if I purchase something will use for our deep neural networks. So suppose I do, and this label, you can add all sorts of labels, et cetera. You can stop it. This is the most important thing. Once you are done, you stopped it. So now we have used this notebook for a few minutes. I'm sure I will get some bill for this but it will be in sense so i'll say one question i have so in this case you went there and you wrote actual code but in real world what will happen is is there a way to kind of copy paste from somewhere oh yes yes definitely that that's what we'll most probably do because we'll write the code outside right yeah you do it outside and in fact you know depends upon how deep you go see at this moment you guys are in the learning phase so you can write your code here once you start writing a lot of code it is much more customary let me see see this windows machine i use only for teaching so it cannot have this a pie oh yeah here it is pie charm professional so usually what i do is write elaborate code in pie charm then copy paste it here for my licenses so pie charm is anaconda right is it no no no pie charm is a yeah pay for it so it's a like let me show you what my charm is if you guys are interested by charm this is spy charm id it helps you it's just a elegant like it's just a full-fledged a code development environment integrated development environment oh it's just a full fledged code development environment integrated development. Oh, it's an ID for Python. So I will you think of it as the J developer for Python. Oh, but will you be able to import all the libraries and everything will be there? Yes. So see what happens is once you become good at it, and you're writing a lot of code, you write it as libraries and then you bring your libraries into your Jupyter notebook. You don't pollute your Jupyter notebook with very complicated Python code. You keep it outside as libraries or as Python scripts, Python classes and files or modules, and then you just use them in your GPTL. So guys let me recap before we take a break what are the things we learned about from basics we learned about Kaggle we are going to take a can seriously there's a river data set I've posted I want all of you to come give me your email so that I can add you guys all here it's important that you put that on slack the second thing we learned about is collab this is cool app your assignment today actually the last hour I won't be teaching I'll just be there to field questions as you guys try this out I want you guys to try all this out before you go get off this session go to collab make yourself familiar see try to run this right overview like this thing see what happens when you run this for example you see the run button here right do that you must become familiar with cola by the way do you notice i have this little docs's run down that you may not have that is just some for fun stuff you can do this by the way you can team it also do you see I have a team adaptive you may prefer a light team if you do a light team now the whole page has become light colored. You can do this, Collab Pro. You can go get more runtime, more memory and so on and so forth. That is one. But remember guys, now you're talking about paying money. So before you try to go and start paying the money don't do it for most of this workshop you don't need it only for the projects that you guys are doing as a group you need it and you can share suppose your total bill comes out to be $25 five of you doing the project together can share the $5 amongst yourself but don't waste money thinking that you can reserve a very powerful machine and because of that your code will run much better sometimes it will run at the same speed because a lot of the homeworks that we are doing are simple homeworks are we together right the editor and you can change a lot of things here as you can see right the editor and you can change a lot of things here as you can see you can see the indentation guide cold folding in the editor so for how much indentation you like some people like an indentation of two some like it of four a vertical rule 80 is the default these days more like people go with 120 so you can put 120 here what kind of a key binding do you like? Do you prefer default VIM? Those of you who are used to VIM, you can type as though it is VIM and so forth. You can do your github and other things and miscellaneous this is remember this koji mode is where i enable dogs if you if you put kittens also now kitty will also start showing it's just a fun thing it's a joke hopefully they are not charging for it yeah no so so long will you stay away from the collab pro mode you're not okay if you start going to the collab pro then you and of course you can share these notebooks with each other you can take each other's help I read together font size actually one thing I realized that the the customizability is very limited or you can't change the font and other things the teaming is also fairly basic but for what it is it is there if you want to go pro you can upgrade to $10 a month I would say that before you start reserving your own jupiter notebooks on massively powerful machines go go the simpler route just pay ten dollars a month see if that works if that also doesn't work then you can keep on upgrading to more and more are we together in this one uh second collab pro not sure if you have used it the output of notebook can be a word document or is that always pdf yeah we can we can try that so depends upon it uh let's go and do it suppose i have this same as html yeah I go here and I say save a copy in github etc etc download I Python okay so I can download this I Python notebook now I can run it in my local jupiter okay this is upload notebook if you have done something locally or you have done it in your other fancy machine that you reserved in the cloud, then you can upload that, bring it into Collab and so forth, open notebook and so forth. So bring this down and then of course you can do everything. Okay, got it. Thank you. So guys, I'm going to take a small break of 5-10 minutes. In this, what I explain after that, I'll just give an hour to field your question. Today, we are not doing any real lab. Next time, next week, of course, I will walk through the solutions of those exercises. We'll take a break. After that, I'll field questions. And then I will start walking through libraries. Today I'll walk through pandas and skikit learn for Python before we end the session today will it be possible for you to summarize again like what exactly are the assignments so and what all we have to do oh yeah sure definitely I'll do that okay thank you all right guys let's take a five minutes break, 10 minutes break and I'll be back. Or would you prefer doing it all locally? I'd rather do some mix and match, Asif, just to get a hands on, right? Use some of the local, I like that idea where you can back to use your local host and still use the company itself. Yeah, so then you benefit from the collab collab notebook japan collab notebook is generally considered improvement upon Jupiter because it gives you auto completions much better so for example let me do that suppose I go to the bottom and you want to add a code let's say at the Rachel you can you want to add a code section. So suppose I do input numpy. Do you see that? It is giving you auto completions and so yes, it's doing import matplotlib as pipeline. So most of the statements you get auto completion and then it gives you keeps giving you these are the things you would use pandas profiling pandas profiling you would remember from the ml100 they intro to ml so you we have all of this so suppose you start saying X is equal to NP. Do I have to download this library again and again every time I start a notebook? Which library? The NumPy and MATLAB. Yes. No, you just have it once imported in your thing. Okay. You know, you see your collab will stop after 24 hours yeah I think yeah then you just have to rerun it but you don't have to like a download or anything nothing to download here I see you know import when you say import right do I import it again and again every time I write a new notebook or yeah yeah every new notebook you have to do import for sure okay Asif yeah can you let Kamiya and I suppose I think i've lost the permissions to grant entry let me certainly do that let me see where is that uh oh there is no waiting room she should already be in there i'll ask her to try again in there i'll ask her to try again by the way do ask her to also send me her phone number yeah i say i tried to reach her today his number has changed yeah so has she been able to join now i don't know i've told her to try again should i enable meeting room i just you have enabled the waiting room and i'll make you prachi yeah once again what do i need to do make course yeah host where do i do that from from From the settings view options. Okay, let me stop sharing my desktop so I can see the whole UI properly. More okay makers host All right, I made you the host again and now you can do Yeah. All that is necessary. Yeah. Okay. Asif, Prachi, it was mentioned that, Asif, you mentioned you wanted to see everyone's emails. Is there a Slack channel, specific Slack channel you want us to type our emails? Yeah, Data Science 2020. Data Science 2020 is it. Okay. And so let me go... Oh, I see. A lot of people have done that. I'll take that. That is for the Slack or Kaggle purposes, right? You just want email address. Okay. Asim, why do we need email addresses to add in Kaggle? I suppose you can still view the data sets, right? No, not really. This data set is private. Oh, okay. See, the whole idea is that this particular notebook, at this moment, you may not feel comfortable exposing your notebook till you feel it is polished which is i have created some privacy here okay so got it thanks also so guys i know that this is a hassle compared to doing it on the laptop doing it in the cloud it's a bit of a hassle doing it in kaggle and all of that collab but believe me this is the future yeah yes so we need to move with the practical times uh by the way i'll also give her today if you want we can give some time to setting it up locally but uh maybe maybe i'll do that i'll help you set it up locally also in the next few minutes i'll do that i'll help you set it up locally also in the next few minutes i'll give those instructions so kernels Okay, guys, I'll get started now. Let me share. Are we all back? I hope we are. Let me start sharing my screen again. Oh, host disabled participant screen sharing? Raji, you'll have to give me. Yeah. Give me, yes. It's still disabled. Yeah. I'm just checking where can I give you back the permissions so guys remember that in Sunday there's a free session on word embedding after that there's a free session on Python for those of you who want some experience in doing notebooks in Python and getting started with Jupyter and so forth and after that i'll keep some time open so you can ask for any help you want so all of sunday afternoon i'll be available for that uh as if in the support section can you request for control again i suppose it should work oh control again I suppose it should work let me see who can share is only host so should I do it all participants? All participants, yeah. Okay, yeah, done. So now I'll try to share the screen. So Asif, what time is the session on Sunday? It starts at noon. So let me write it down so all of you can have these things with clarity so what we have talked so far is this homework all of these things I'll send it to you by email I I will send instruction, actually may not be email, but I'll put it on Slack at least. What we have is the river dataset on Kaggle. It is set on cable. Likewise the There is a flat data set. Data set. There is the hill data set. Hill data set. These two are classifications. This is regression Exercise then We have then two publicly available datasets are Wisconsin Breast cancer dataset It's a famous data set in your career at some point you have to analyze it. And California housing dataset. California housing and so this is your homework guys now you may not be based on your level of expertise you may not be able to do all of it if you are able to do all of it that's most wonderful but I would say that at least do this one try to do this one and then try to do this one and then if you do this one the second one becomes easy these ones become easier but a pace yourself out then the the instruction is that do it in so jupiter etc you can do it in R or Python R or Python is there anybody in this group who would rather do it with Julia any Julia enthusiasts here yeah I'm sorry who said yes me Kate and Dennis we might give it a try how'd you get in Dennis right sure definitely give it a try this is it our Python and if you're if you have time if you're highly dedicated or motivated but do it in both because if you do it in both you'll have a lot of learning it also means that you won't have much of a life from now till Monday. You'll be busy. So this is your homework. What is your project? Project is not due now. At this moment the only deliverable is form teams. forms teams less than equal to five five members now guys is there any teams that have formed so far if not I would strongly advise you that form the teams and come back to me and give me the list of team members so for each team pick a name pick a name and mascot right the name could be i don't know tiger or whatever it is tiger you can have a picture of a tiger. Whatever it is. Pick your name and mascot, 90 Higgs boson, the Higgs boson and the archive. These three datasets, they will form the context of your project. So these are biggish things. You have six weeks to deliver on now one thing I will give you guys in return if you put in the hard work you do the homework and you deliver on a solid project I will be willing to be your job reference usually I'm not willing to be the job reference I do it only if I know that there is proven competency so you do all of this you would have developed proven competency I will help you so that's the project there will be a quiz on we haven't taught much but if you want to just check if you remember your basics quiz on the basics of ML it's an optional session you can attend or skip it as you wish optional session attend or skip it as you wish optional session so I'm going to hold this quiz sometime on Saturday Saturday afternoon and I'll send out a notification to that those of you who are interested come there this is all part of the interview preparation if you can right some of you may need to mute yourself I can hear you're typing. I suppose getting recorded. Asit, the interview is on Saturday afternoon. It's Saturday afternoon. So I'm giving a session on Saturday, one session on Saturday afternoon and two sessions on Sunday afternoon. All of those are optional and anytime you can reach out to me if you are getting stuck with your collab and so on and so forth are we together now what I would like to do is walk you through one particular library Skinkit learn in Python next time around maybe I'll walk over our libraries at this moment I will do a particular Python library and show you what it offers but today is very general guys we are not walking over the labs we are not doing solutions and so forth it's because I'm setting the framework for you guys to do enough lab before we start walking through solutions and code walkthroughs practical code also we haven't done enough theory so I'm just getting this week was just getting people started so in that spirit let me now go and share the main screen again so So, in machine learning, there are a few libraries which are very important. Most of those libraries I have mentioned, actually those of you who already have access to my book from the first workshop know that I mentioned at the end of it I've given a pretty long bibliography but here what I'll do is I will just walk through so skip it learn yes I think you'll use for the rest of this class yes yes go ahead so for this Jupiter notebook do we have to install that by charm on anaconda oh no no no no you don't have to do that anaconda so okay all right why don't we start with that if you're locally doing your homeworks or see if you're doing it in the cloud widget you don't need to install anything everything installed collab comes with that built-in oh yeah okay that's fine that's fine then but if you want to do a local install then what you would do is you would go to anaconda.org on your local app it's still a good idea to install it locally also go download anaconda you see this anaconda your data download this I will do it like actually why don't I do it and show how to do it so this is Python version 3.7 wait for Windows this machine from which I'm presenting is Windows now usually I work from Linux so when I'm walking you guys through the solution I might be on the Linux machine. So but for all the three major operating systems you have a you have this here it's very slow it says 1.4 MB out of 366. Yes. For whatever reason is downloading very, very slowly at this moment, but it's a one click install. Once you get, yeah, I've already installed it. And when you do that, I'll show you what it looks like. And once you have installed it it will open up a shell something like this so what you do is you either pick Jupiter lab or Jupiter I would say in the beginning start with just launch it when you do it it will you'll be in a situation like this. You can go there and you can sort of start creating kernels or so-called notebooks. Notebooks are often called kernels. You can do that. For example, I'll take a note. Well, this is code. You can write code or you can write notebooks. Let me take a basic one not even this let me take Python classic players here it is so when you do it is again the same thing everywhere you have notebooks you do the imports you you take in data you run the data you do some basic analysis and so forth so these things those of you are not familiar with python i'll get you a walkthrough over the weekend just wait for that but most of you may be familiar or in fact you're coming from your ml100 most of you have taken that so I don't want to waste time here repeating all this does this all look familiar to you guys anybody would like to say that this is the classifier data set classic one of the classifier data sets yeah yep yeah yep so there we go we won't go into that more so this is the way to do it locally now this anaconda environment also gives you some other good things it gives you the R studio to write your code in R so So for example, if I were to start this. So on this machine, because I use it only for teaching, most of the things may not be properly set up a little bit. Then you have spider. Spider is sort of like the R studio for Python once again, you can do You can write your code here So these are all the different development environments But these days by and large the mind share is taken by notebooks jupiter or collab notebooks and pie chart if you want to do cs work you do it in pie chart long long bits of programming in pie chart okay so this is it this is how you would do it locally now if you're doing r i would suggest that instead of using the anacondas R, you should go download it it's very easy here you can pick any one of them download for Windows these are auto install situations nothing very complicated base download this you can imagine that it will start downloading it and let you go through the r installation for a moment if you do that it's a straightforward install you don't have to do anything just click through your way create a desktop with a quick join starter So once you install R, by the way, those of you who are interested in getting a copy of the book, I already have a list of some people who showed interest. The new ones who have joined or who haven't signed up for getting a copy of the book, just drop me a line that you are interested with a slack or send it to me by email then you go to our studio which these days is owned by Microsoft we can go here once again it's free you can click on that obviously get the free one don't don't get an expensive something that you don't need for development purpose the free one is good now once again just download the R studio and I go through the install for a moment and the versions don't matter right you get the latest you always learn the latest if you do that where is it yes I generally tends to be much faster than see then Python so the ship runs over quickly the RStudio I mean it's to come Anaconda console. Just a Go ahead Is PyTorch a part of Anaconda too? No, no, no, I will. Okay, you can see PyTorch is a library. Once you're in Anaconda, you can select and install it optionally see I see I see like like an umpire and any other like anything so I got your environments in this it's a lot and so all you have to do is check for Python by talk it's not installed so it means that all you have to do is go get it so you see that by touch all you have to do is click it and go ahead and install it it's not a notebook it's a library it's a library thank you and when you install the R studio you can bring it up and you can create a new notebooks I'll create a simple notebook in our our notebook our markdown you call it typically and it's creating one and the first time you run it it will go install a few things so guys have a local setup both of our and Python and Julia and I'll show you how to do it for Julia also. So suppose you create a document, you can do your presentation or document or whatever you like. You can even create Beamer slides directly from that. But yeah. Oh wow, they have PowerPoint in your machine you can do that We have done that. So what it will do is it will create a sample little notebook for you here. And all you need to do is just run it. So run all. Once you run it, you see the output right here. So now do you notice that your output is right there in your notebook. And then you want to export it. Let's say here. put right here so now do you notice that your output is right there in your notebook and then you want to export it let's say here you want to export it to powerpoint you say nick to powerpoint let's see what happens uh file name let me just say oh sorry first of all we need to save this file itself. Save as example. It's an example notebook. I save this file. Then I save it to PowerPoint. Look at it. Your PowerPoint is produced. Do you see this, guys? This is a PowerPoint. And you can go into the presentation mode. Are you guys able to see my screen with the PowerPoint? Yeah. Yes, I see. Even your graphs show up automatically in your PowerPoint. So these environments of data science are very powerful these days. You can see how powerful it is. Now suppose I want to instead, if I'm the kind of person who likes the PDF part and latex style, once again, you'll see that it will come up well on this machine latex is not installed I think so it won't work on latex fail to compile because we are not installing it let me try to do it too slidey this is a web format of doing powerpoints some of you are familiar with that sliding so here it is a pure web native presentation is if you are familiar with slightly nervous so this is it you could from there also export it to knit to HTML I or slides that I'm not familiar with but I learned something there it is this is so powerful and free very powerful these things are extremely powerful unit is there you can please the entire web presentation just like that and it just the maturity of the tools is just amazing actually these days the nice way these tools work it's really entering a new tradition data science is really the golden age of data science data is plentiful applications are plentiful as far as I can see almost all AI companies are becoming the startups are becoming, startups are becoming successful. Literally, the moment you put AI or something like that, people are ready to find you these days. And it's a wonderful subject to learn from. So guys, this is that. Now what I would like to do in the second part is walk you through some this key library, which is the skicket like So one thing that you should start studying is this psychic Psychic is the machine learning library in Python Our comes fortunately with the whole thing built in So you don't need an external library. Now we will take classification because I've given you a classification task in the river data. Suppose you go to classification. Do you notice that for classification you have so many, many algorithms here. Logistic regression, it's a classifier. I can go with that. Support vector machines will give you classification. For every large algorithm, so this is the names, what you see in bold are the names of algorithms so linear models are linear things if you want to look for classification paradoxically the classifier has the word regression built in which is misleading so this is your logistic regression if you click on this this is what I've asked you to do. You go to the documentation, then some of the math, the way they put it is very succinct. It's meant for people who have taken theoretical machine learning courses. You can ignore all this to understand it. You don't need all of this in the beginning. you can go directly and straight away go to your what you need examples do you see how to use this you just go straight to the examples and the documentation so for example I would go to logistic yeah this is the section on Yeah, here we go. This is the section on logistic regression. And suppose I want to see it with examples. I can see these things with examples. It'll also tell you which books to go and read. You can go click on this. And there is a lot of code examples that are given here. Do you see this code examples? And not only are the code examples given, you can download these examples. They're usually very well written code. You can launch it on something called Binder. Binder is another magical thing that you have. It will spin up a Dockercker instance on the binder website so for example here it is doing that and amazing thing is it is all just free here we go this entire thing showed up right on the web you see that this is a Jupiter notebook that has showed up on the web right and so the sample code are all ready to run i can just go and click on run you see this now it is running and the results are right here in front of you beautiful so the kind the the level of documentation and help that you get in data science libraries is unparalleled I've not seen it there for normal computer science at all most libraries are poorly documented I am very poorly done frankly so this is it you can these guys make money binder days yeah I mean at this moment you are running it for free but they hope that you will use the binder functionality so if you go to binder at all they can just go to binder Oh sorry, what was the address? Okay, I went to the wrong website. Binder. That itself is not very good. Binder. My binder, okay. Jupyter Notebook, MyBinder, okay. Let's go to MyBinder. Yeah, turn a Git repository into it. So what you can do is you can just point it to your Git repository and work it into a lovely notebook that you can execute straight on the web like this. So all these examples for example a plot logistic thing beautiful all you have to do is just go run the code what do you see you run the example code that you found on the web and it just runs it the web and it just runs it you can do any one of these code examples that you find in scikit-learn you can learn and so you learn how to do this beautiful visualizations and you you quite often use the code because the creators of those libraries have thoughtfully created examples made sure that those examples are best practices and you could directly just sort of look at the code, take it from there and adapt it to your use. And that is how you pick up this field very rapidly. You can learn this field if you follow these examples. It's just amazing. I'll go back to it so I could learn and so the point that i'm mentioning it is and for regression let's say that you want to do regression here we go so for any of these now what i want to do is i haven't taught you these algorithms we haven't done the nearest neighbor we haven't done uh support vector machines we haven't done a lot of these things, decision trees, ensemble, all of these things we'll do in this workshop in the theory part of it. But my point is, see if you can start using it in practice, even before you master the theory. And you can. So for example, to classify the river dataset using a decision tree, what could you do? You can just go to the classification example you see it here and you notice that to use it is just two lines of code I hope you can see that guys that you instantiate the classifier and you ask and you try to fit it to the data and once you have into the data you can see the entire decision tree emerge on that are we are we seeing guys how easy it is to be able to use these things and the whole question is that isn't it dangerous to use algorithms without knowing it is indeed it is much better we understand it properly but that's the purpose of this workshop you start using it and then in the theory part will understand each of these things and so for example you can use random forests are very popular these days what does it take to do random for is exactly two lines of code and you can do it so use this to do your homework for this weekend guys Are you seeing this how easy it is you just go to the list and pick something up wherever you see in every major Algorithm, you will see classifier there multiclass and multi-level algorithm that then you can go to Pick something a naive bias Gaussian naive bias, etc All right, you can go do that. would you do it here we go and the theory may look a little bit intimidating but the whole point is we are going to do the theory also as part of this workshop so get started guys and I would say that at least if you want to try it out use the knife bias decision tree random forest the gradient boosting support vector machines all of these just start using k nearest neighbors and the only thing I would say don't bother using is the neural networks of scikit-learn the scikit-learn's neural networks is not used in practice because it's very primitive it doesn't use the GPU at this moment it's a very primitive implementation we will do that in pytorch okay so that is it guys I'll now open up to questions and reach out to me as you need help through the week. But on Monday, do come back with the video notebooks. and in collab if you feel like it pay that 10 a month and get the collab pro it will make your life a little bit easier things run faster then when the workshop is over in one and a half months you can just stop it any questions guys do you guys feel now that you have a good idea how to get started yes I can't hear you it's very dim the data sets can you hear me now yes the data sets that you're going to share we'll see see that in Kaggle, right? Once you- Kaggle, yeah. Yes, yes. I'll send you the links to all of them after tonight. By tomorrow morning, I'll send you detailed links to all of them. Okay. In the meanwhile, if you want to give some time today, make yourself familiar with all of this, Colab and Kaggle and so forth. Make sure you can log into kaggle then go create your accounts in kaggle then let me know your id and i'll keep adding you guys yeah save to in anaconda if you have to install the package right where you sold in that environment app yes is that you have to sign in to install the package or maybe i'm missing a no you don't have to sign an action i don't know it says sign in but i don't usually sign in i just go and oh yeah this is very interesting so when you when you enter that you got that list for me i'm not getting this list you know or the least time okay see here you you see the environment okay see on this laptop I've not set up the whole environment properly maybe I'll show it to you on the Linux if you guys have time or maybe on this Saturday night and walk. Yeah This machine is just for teaching so it's not really powerful. Yeah, that's right We'll do Anything else guys? Yeah, that's it. Just a quick question if you go to that Psychicarn, right? Yeah, website. The website you had opened. Before you go there, just in Anaconda Navigator itself, if you go to the learning section, you will see all these enormous amounts of resources for learning things here. Do you see all of these documentations and videos and trainings and whatnot, right? That you can do. Of course, not to mention that Coursera, Udemy, et cetera, are filled with a lot of helpful hints. The only thing is that they end up eating a lot of your time. So my own personal favorite has been that I spend more time reading a book and trying to code it myself and I refer to videos only if I hear that some video is very good and I need to refer to it so now what was the question that you asked? So I said, right, maybe it's a basic question. Let's say go to logistic regression, right? For example, it can be supervised or unsupervised. Oh, no, no. Logistic regression is always a supervised learning. And where is supervision part in that? Supervised learning just means that there is a target variable. It's a prediction. that word is very misleading. So learning simply means that it's a it's a classifiers and regressors are both supervised learning because you make a prediction on a target variable. Clustering is an example of unsupervised learning. There is no target variable, you just look for clusters. Look for clusters. So my understanding, okay, and that's confusing because I thought that there's a way to train it by your supervision, regression, logistical. A lot of people think that actually, that terminology, that's why I hate that supervised unsupervised language because it makes it appear as though the supervised algorithms are not as powerful as unsupervised which can learn on their own it's not me yes yes okay yeah thanks for that clarification asset for the data sets you mentioned that the river data set is classification they would allowed a piece river data set is now this classification yeah they were data set and the flag data set will be classification Hill will be regression breast cancer is and a California housing is regression and so guys it's a lot I'm not saying that you'll be able to do all of it a pick and choose which one you want to play within the homework if you can do all of them that's really good for those of you who have been doing workshops at me um I would like to see you do all of it because I have trained you to that level if you are joining my workshops without doing other things then you will need help do at least one definitely one if possible more do one in regression and one in classification as a minimum. And get into the habit of using the web, the cloud technologies like Google Cloud Platform and so forth. At the end of this workshop, what I would like to see is each one of you have a fairly respectable... See, each of these homeworks that you are doing with me it isn't that you're just doing this homeworks to learn if you do it well you can show it in your interviews that's how past students have got jobs there is a lot of value to that doing it well is your ticket to a good job at a good company all right guys and any other questions but can you ask if can you just show us some Julia part as well? Oh yes, thank you for reminding me. Julia. So Julia. Julia language. So this is Julia. Let me actually do it because this laptop is new. I don't have anything installed, so we can go through the process of installing it. Let us install the latest one. Here we go. You download it. Just as simple. We'll install Julia. And you download it just as simple will install Julia and Julia by the way is the fastest of all this between R and Python both of them it beats by a factor of ten to thousand something sometimes it's ten times faster sometimes hundred times faster sometimes thousand times faster it's just amazing but it's a young language they're not the ecosystem of libraries are like three thousand libraries where is the ecosystem for libraries for our in Python will be like fifty thousand hundred thousand or something like that or something like that so we have installed Julia Julia comes with extensive documentation as you can see again in the tradition of it getting started how do we get started you can just bring up Julia do you see this julia shell right you can take treat the julia shell for just that so suppose you want to say x or 10 you can just use it as a calculator to begin with and then gradually build your way away through it and you can follow this uh there's a lot of documentation here how do you declare variables so actually let me do this basic i would suggest that just follow the documentation it will take you about four to five hours to become comfortable with julia and start doing it right so it feels like any other language so suppose you have that and then you do X plus 1 do you realize that this could be either R or Python you would get the same effect isn't it so not very different where the some come in is when you try to create complicated data types and so on and so forth or functions so how do you do functions one one thing that you find very interesting is it has a native support for complex numbers a Python also has but here you have it directly you notice that right so you can do complex number multiplication you know what complex numbers I hope most of us know 5 plus 4 plus 2 imaginary right and you can it So it is the upside. What did I do wrong? One plus. Oh, sorry. Okay, there you go. So this is the multiplication of those two complex numbers. Then how do you create multidimensional arrays and so forth? So all of that, you you have examples you just look at the examples now most of these examples will look very similar to Python so it it is very very similar to RN Python so that's why people say that it works like Python but runs like C the performance of this language is comparable to C right so that is the beautiful thing and you can call C functions from within you can see you can directly call C functions etc there's a very good integration it also has integration with Python so you can call Python from this so it's a new language it's lovely language you have to give it time though three four hours will make you comfortable but it will take you a couple of weeks to master it and the way the see for example you look at this function how our functions define do you see this guys I just put it here I want to take an example from here. Base, essentials, constants. By the way, it has pretty rich iterator and support, array support and so forth. But more importantly, I want to show the functions. functions so you can actually do let me just write a function copy paste a function here and you will see so you can write a function let's say I'm not able to paste it here so I'll just write it there X X Y then sorry well I'm not able to write it i would typically do it in an editor but just look here what it helps you do is if you look at the syntax of it does it remind you of fortran some of you would be reminded of fortran you know ending the functions or routines with end and so forth and then the wording is so straightforward we use the word function not only that look at this one in the function names you can have Sigma it is such a easy way to let me just put it this way well here I can't put Sigma because Sigma is not there in the keyboard. But imagine writing code like this. The one that you have highlighted here. If you're summing up numbers, isn't this Sigma XY as a function name very illustrative of what you're trying to do? These things you can only do in, as far as I know, only do in Julia. Wow. these things you can only do in as far as i know only do in julia wow it's just amazing that you can write so expressive mathematically expressive functions and things like that so so yeah go ahead now how do you write sigma here? Like, you know, it's not on the keyboard. It is a Unicode. So in your editor, you have to enable Unicode and insert Sigma. Nice. It's doable. It's nice actually that you can do that. I mean, you know, you can put character names, you can put whatever, Hindi or Chinese or whatever it is because it's Unicode so you can name your functions much more broadly than you will do in RN Python or Java where everything must be alphanumeric it's a wonderful language it's a future but it's a young language it'll it is on the rise it hasn't become dominant yet if you pick it up now by the time other people learn about it you would be a guru of it alright guys so before I close I just wanted to mention this weekend. The talk is on Sajeevan G. Word embeddings. Sajeevan G. This topic of what what our word embedding syntax, of course. Sajeevan G. It's a broad topic. Sajeevan G. Obviously these spaces don't explain it well. We will talk about word to actually when one good thing that i may recommend is there is a website called towards data science that has very good articles you can go and search for good articles there so for example word embeddings may have here we go word to whack and so forth exploration explanation with code and python explanation except that yeah so read these things if you want or come to the top if you come to the talk in a very simple way we can explain you in half an hour or one hour and then after that you can come back and read these articles and these articles will then feel very easy to understand. That's it guys. I don't have anything else for today. We couldn't do code walkthroughs because we haven't done anything in practice yet. And theory also, the real thing will start next week if you don't have any other question in the meeting thanks as if this has been very helpful yeah have a good night thank you thank you guys And we can let other people know about the embedded word seminar. Yes, yes. In fact, I posted it to our Facebook, Twitter, and LinkedIn. So every week I'll be posting to the social media sites and on YouTube, of course, I'll be doing live. Excellent. I'll see if you will be posting the recording and your notes also. Today's recording? Yeah, definitely. It's important to refer back to this. All right guys, anything else?