 Today, we will learn about only one classifier, which is called logistic regression. Are we together? Logistic regression. Now, when people teach teach this word has a whole bag of problems associated with it first of all the name is a misnomer it is called logistic regression so if you look at the name what does it look like an algorithm that does what regression but actually it's not regression it is actually this is a classifier this is the first thing you need to remember right so by the way this is a very nervous error people they always if you look at the people in the data science community who do interviews almost everybody has a joke of meeting a candidate who in the list of regressors said linear regression logistic regression and so on and so forth right so that would not really be a very well and they of course point out that logistic regression is a classifier well yes or no it is a classifier we'll start about it but there is actually a generalized way of looking at regression which which I will teach you at some point. I'll do an extra session for you. It's called generalized linear regression, which uses a link function. Should you start thinking about that, then there is a way, then the situation gets a little bit more, let's say, interesting. We'll talk about that later. Go ahead. Premjit, are you asking a question? No. Okay. So this is logistic regression. That is the topic for today. It's a long topic. We're going to cover it in the next two, three hours. It's a long theory class and it's a very long lab class. And today I'll really expect you to finish your homeworks if you haven't done that, guys. So just but anyway, I'll talk about that at lunch. We'll have a very brief lunch today. So we won't start here, we will get here slowly. But let us craft a problem. We won't use cows and ducks. We will use a little bit more complicated problem or amiable to this. So I'll create a toy problem and the biologists and the farmers would laugh at it. So I'm taking a lot of liberties with reality here but go along with it. The point is to create a toy problem that will help us understand. Suppose we are trying to distinguish between blueberries and cherries. So let's say that our axes are weight and size, two axes. so x1 is way and x2 is size right size is size and now let us project the blueberry points you would agree that blueberries are small they would be somewhere like this and i will deliberately oversimplify the situation. Remember, this is a toy example, motivating example. And then you have strawberries. Oh, no, did I say cherries? Cherries. So let's say cherries. Maybe occasionally. These are our cherries. This is a cherry. And then of course some blueberries can be a little bit bigger. And there's some region of overlap and i ask you how would you tell an arbitrary point x is it a blueberry or a strawberry so let me ask this question let's look at point a there is a fruit whose weight and volume and size puts it here. What would you guess? Is it a blueberry or is it a strawberry? Sorry definitely a cherry. Right. These two are very clear. C. So C is likely a blueberry. And what about, what about D? Likely cherry. Now, why is it that you are sure of A but not of C? A and B you are sure of and C and D you are not sure of. Rantik? Because they're close to the kind of outlier, right? On the basis of weight and the size. No, they're not outliers. Outliers are away from all data points. Yeah. See, the moment you look at this data and I i ask you to guess the points what your mind begins to do is it begins to draw imaginary something like this it is beginning to conceive of is this correct right and it basically says in your mind you begin to draw a line like this and you begin to say this side. Is blueberry. Right. Let me use the right colors yeah you begin to say that in this line this side is. say that in this line this side is blueberry and on this side it is cherry isn't it that's how your mind is deciding isn't it when i ask you that so because a and c fall on the blue side of that, the lower side of this line, you call it a blueberry. The things that fall on the other side of it, you call it a cherry. But you also notice that the further away you are from the decision, by the way, this thing has a name, it is called the decision boundary. And this is a very important term they see is decision boundary in fact it is the crucial term in classifiers decision boundary decision boundary would you agree that if i have to create a classifier that tells whether a point is a blueberry or a cherry the problem is equivalent to finding the decision boundary because if you find the decision boundary then you can tell on one side is blueberries another side is cherries do you agree with that point guys yes isn't it the problem is equivalent so to create a successful classifier is the same as to discover geometrically the decision boundary. And so that is a very crucial observation. Remember the pursuit of a classifier is the pursuit of a decision boundary in the feature space. In which space? The feature space, data space. So let us find that decision boundary now the question is what is this decision boundary some observations associated with decision boundary the further we are we are from the decision boundary decision boundary boundary the the more sure or unsure we are the more sure we are conversely the closer we are to a decision boundary, the less sure we are, isn't it? Why are we less sure? It could be both blueberry and the cherry. Right, because data is not so clear cut. There's always noise in the data. So there are some blueberries here and there are some strawberries all over the place here. Isn't it? So all we know is that if we are sitting on, if we are sitting on the decision boundary itself, then what happens? What would you say it is? Is it a blueberry or a cherry? Either way. You could go equally either way, isn't it? So the way you would say it probabilistically is that the probability of it being a blueberry, probability of a blueberry of that point X, let's say this is X, right, of the point X of blueberry. So here's the language in the mathematical language given point if we are sitting on the decision boundary at x right you say that blueberry probability of blueberry given probability of blueberry given at the point x given x is at is also 0.5, 50-50. Would you agree with that? On the other hand, what would you say? Now let's develop our language a little bit more carefully. Much of this math language is very elementary to get. Probability of blueberry. Let me just look at the probability of blueberry because cherry would be the converse of it, one minus blueberry. Would you agree? If the probability of something being a blueberry is 70%, probability of it being strawberry is 25 percent. So this is it. So we go here at point A. Let's go back to point A and see what it was. Look at point A. At point A, what is the problem? What would you say? Probability that it's a blueberry. Almost sure. Right. So let us say that it is approximately equal to one right hundred percent probability right at the same time the probability of its being probability of its being a blueberry blueberry given Blueberry given point B is closer to zero, isn't it? This is the way we write the language. So now let us go this. We will only look at the probability of a blueberry because probability of a cherry is this. What do you observe? What is the mental intuition you have the distance from that decision boundary isn't it do we agree distance from the decision boundary so now i'm going to use this tiny bit of space i seem to be going circular in my diagram let me take a point. A point, this was a point X. Let me take, actually, let me not call that point X. Let me call that point, just say P. And in my hair also, I will change my name because I'm going to use X for something else, guys. I hope I'm not confusing you by changing the name of this point. Probability is p and this is q. That will be terrible. Let me call it q. Probability at the point q. Do we agree? We are still on the same page. Now I'm going to take an arbitrary point x from the origin. Let us say I take this point this right this point given by the vector x remember every point can be represented by a vector x isn't it this point and i ask you intuitively what is it you would you would say let me do one thing let me find the distance of this point from the decision boundary this is your distance distance of x this is distance from where the origin no it is the distance from the decision boundary and you can tell now i'm going to say a statement which is tell me true distance of x greater than greater than zero means probability of blueberry actually let me change the language i will look at the Actually, let me change the language. I will look at the probability of instead the cherry because that will align with the language. Cherry is approximately one, isn't it? If the distance is much greater than zero, means you're really far from the decision boundary in the positive direction. It is this. If the distance is less than less than zero, means you're far inside like point A, this point, right? If you're on the lower side of it, distance is negative, right? Because you take one distance to be positive on the upper side, downwards, you take it to be negative distance. So here, you would say that the probability of cherry is probability of a cherry is what? Close to zero, zero is close to zero. Right? So then, now let's carry this intuition forward. Let me summarize it. Because if you get this intuition, all we have to do is use a little bit of simple mathematics to develop some very elegant formulations. Go ahead, Rantik. that at this moment we are purely at the level of intuition right in fact that is what we are going to do with the next time but so far you're clear with the intuition isn't it what we're saying is we need a decision boundary it's very intuitive geometrically you can look at it and say classifiers are nothing but machines that discover the decision boundary once you have the decision boundary the only question is how far you are from by the way this is for the linear situation but Raja Ayyanar?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre?nilre and if the distance is zero oh gosh you're not sure at all 50 50 right it's a toss of a coin at that moment so that is the intuition we'll carry now we'll simplify this notation mathematicians see what we are looking at is probability of a cherry at a point x isn't it so we will say this is what we are looking for we will simplify the notation to to p just x we'll assume cherry are we together we assume we are talking of cherries right we'll just assume so we'll use this the reason is that see here's the thing more formally we should use the notation on the left, but more commonly people use the notation on the right. In fact, your textbook uses the notation on the right. So we'll just use that simpler notation. But remember that we're always talking about probability of cherry. Probability of blueberry is just one minus probability of cherry. So now let's think about it in terms of one graph in our mind. Let's think about it in terms of one graph in our mind. This is zero. This is d. d is distance from the decision boundary, right? So you realize that when you are really far away, let me take this. When you are really far away, let me say that this value is zero. This value is, this is the probability, probability of a point dx. dx is here. Probability x. What is the maximum probability something can have? so this is one this is a one value what is the lowest probability something can have zero okay so at very large values of d very large values of d what is the probability that it will have that it's a cherry pretty yeah pretty high right so we can say that at in at it will be like you know very very high yeah close to one right at very negative values of the d means in the other direction in the lower direction if you go very far from the if you go back to this you go very far down compared to the decision boundary, far down from the decision boundary. What is the probability that it's a cherry? You know it's zero. It is zero. So we are here. Now what happens as you come closer to the decision boundary at this at the distance zero what is the value here at half when you are literally sitting when dx is zero what is the probability that it is a cherry 0.5 0.5 right this is this is a 0.5 so we know know three points, the answer to. Now what happens? Let's think about it. This probability, you know, rises up, isn't it? And you know that. So first thing is, is there any distance from the decision boundary where we will not know the answer? No. There'll always be a probability, isn't it? That speaks to the fact that this probability is a continuous function. Is there any reason to believe when you look at this thing, that the probability as you go along, as you go in the perpendicular direction to the decision boundary, like along this direction, as you go, any reason that the probability will make a very discrete jump like from 25 percent to like 45 percent suddenly any reason to believe that no no no no reason right probability is a slow increasing function right it's a slowly increasing function the way you say it is that probabilities rise smoothly slowly the word for that is probability more mathematically you say probability px is a differentiable function it's a smooth function px we will say now we say say based on our intuition, visual intuition, that Px is is a continuous smooth continuous continuous function it's a smooth continuous curve now what is the smooth continuous curve which doesn't have pointy edges that you can draw which goes through or which agrees to the two things these are called the upper asymptotes upper the word i'm just throwing in the words upper asymptote third and this is the lower asymptote means the value such if you go too far down the value saturates at zero isn't it saturation points and so what is the one curve that you can draw can i go like this is this okay no as the distance increases, and there is one more quality that I need to address. The closer I come to the decision boundary, the more the probability, right? If I'm going from negative to positive direction, right? You would agree that the closer I keep coming, probability will increase. There's no reason for probability to take a dip. Would you agree or not? Isn't it? that brings us to the last quality of this function so we cannot have this this is not possible so i'll erase this not this it has to be yes the word is it has to be a monotonically increasing function or curve that is monotonically increasing. So what is the monotonically increasing function that you can draw? Well, this hardly looks monotonic in my... Just imagine that if I was a better artist I would have drawn something like let's see. Does this look better guys. I just make this. Fat. Yes, lovely color. Yes, go ahead. I need to go ahead. Hi, I think yes, indeed. So all such functions which have so now it's so you just jump the gun a little bit so guys look at this logically can you convince yourself that there is no other possibility the shape of the function must look like this isn't it there is a cl these functions so what does this function looks like? There is an intuition. It turns out it looks like a stretched S, isn't it if you take this s so imagine you take an s and you keep stretching it out does it begin to look like this right and that is why this stressed s are called sigmoid sigmoid sigmoid now contrary to popular belief there are actually many functions many mathematical functions that have the shape many many, many functions. All such functions are called sigmoid. So I give you a homework. Go discover as many sigmoids as you can by searching on the web and so forth. I will tell you one sigmoid, a couple of them we'll talk about today. one of them is of course the logistic function because the name of the logistic regression but there are many right there at least at least half a dozen are well known but there are many right so hold that thought in your mind we'll take again a five minute break and then we'll go ahead and take take again a five minute break and then we'll go ahead and take yes we can and we'll come to that they come to that in other words how do you not only that you can translate it and you can flatten it right so there are two parameters that you that you have actually three parameters because you can even instead of rising up to one it could have been rising up to two in a different situation probability can of course only go to one right so what is the amplitude how where is the center where is it hitting 0.5 mark or mid mark and is it very steep steeply rising or not that's why this particular thing is almost like what is often called a three parameter model and things like that. So there is a lot going on here. We'll talk about that. Let's take a five minutes break. Livestream on YouTube. Oh goodness. So guys, this YouTube thingy, where is is anil it might be a nuisance because every time i have to do this yeah i think youtube really not required i don't know yeah it's hard slows us down okay all right i'll do it or what i can do is not pause it just let it run all the time do it or what i can do is not pause it just let it run all the time those of you who are remote shows us done okay all right i'll do it or what i all right uh what i will do now is restart where we left off. But before I do that, a quick, a couple of quick checks. So you guys are able to hear me in the classroom clearly because of the amplification. Those of you who are remote, are you able to hear me clearly? Yes. Is the screen clearly visible? Is it legible what I'm writing? Yes. Yes. That too is there. Thank you for for the feedback and are you able to see me clearly or am i completely out of the screen out of the camera no we can see you but if you could move it so that the doorway behind you is not in sight that's a little bit better isn't it hang on let me take care of that yeah why not another thing can you lower the camera a little so we can see we only see your head moving this side that side so my head bobbing up and down yeah so if you could make it a little lower yes so we can do that sometimes when you show the bowl examples we're unable to see because when it's touching your hand, it doesn't cover the bowl. Oh, yeah. Oh, thank you. Thank you. Yes. Okay. How about now? Are you able to see me more clearly? And yes, I can. I think the thing that you're saying is turn you away from the door. Now you're not seeing the door, I hope. No, you're not. It's good now. OK, and now let me see where I kept my writing pen. Here we go. All right, right guys so we will start so this class of functions that have this shape of a stretched out s are called sigmoid functions right now there are many sigmoid functions but amongst them for classification by far the most commonly used is the logistic function by far the most commonly used is the logistic function. Now, this word logistic is rather strange. Logistics, when we talk about, we think in terms of trucks and shipping and whatnot, isn't it? The logistic companies, they are the trains and the trucks and the shipping and moving things here and there and the logistics of a project and so on thing so what is a logistic function it has its history actually surprisingly it is in in i believe it had something to do with world war one i forget what but it has it has a military background or maybe even before that it has a military background it was for the moving of food and other things to armies in that context it became famous, but it's a simple function and I'll motivate it in a way that I hope you will get it easily. Let me go back to the simple decision boundary. I will remove everything else, just draw the decision boundary. else, just draw the decision boundary. And I will say that for a point x, this is d of x, right? Simplified way. You realize that d, now let's look at the characteristic of this function we know that when x very large p of x probability that it's a cherry is equal to one approximately when dx is very large negative px is equal to 0. In other words, the probability associated with this, with d, let me just make a column here and tell me if this agrees with your intuition. Suppose I make a column here, D of X, and this is P of X. When this is infinity, D is infinity, what is PX? One. When D is minus infinity, what is P? Zero. Zero. When D is zero, what is p? 0. 0. When d is 0, what is p? 0.5. 0.5. 0.5. So now let's build through this intuition. And just to recap, the shape of it is like this, right? This is d of x. This is p of x. This direction is p of x this direction is p of x right this is one right this is zero so with this intuition in mind let's think of what you go what you see is something very interesting when you look from a mapping from d to it's very interesting. When you look from a mapping from D to, it's very simple actually, when you look at a function, think of a function, F, that maps from D to P, right, to probability. Literally, that is the P of D of d so actually let me see that this function p itself is mapping to this p of d so it is mapping minus infinity to infinity this interval it is somehow able to map to zero to one isn't it guys it is able to squish an infinite thing. It is able to squish it down to 0 to 1 in such a way that you have a smooth rise up. Isn't it? In the y direction. So let's think what function can do that. First of all, let's solve half the problem. And I'll motivate you. Suppose there is a function that goes from zero to infinity. Look at this interval, something that goes from zero to infinity. Now, anything that's defined in the domain zero to infinity, what happens if you take the log of x log of x will go from where to where has to be an open boundary on the side you have to have an open boundary on the left yeah yes it will go from minus infinity to infinity in the asymptotic limit that it goes to zero it's minus infinity right log of x would go like this now this begins to look very promising isn't it oh boy maybe we need to somehow bring in a log of d somehow isn't it log of d but there is a catch to it d goes from zero to infinity log will go from minus so minus infinity if you go like this direction it is easy if b is the log it's like this right so you realize that whatever it is this is the relationship now how do you bring something that goes from zero to infinity to zero to one suppose you could do one more step and you you could go from zero to one right so this is the progression guys imagine that what what is it that we need to do? To go from here to here, all you have to do is, suppose this was x, right? Or this was d. You know that you could do e to the d. It would go from 0 to infinity, isn't it? What is e to the minus infinity? 0. So this step will take you there. What is that operation, e to the minus infinity? Zero. So this step will take you there. What is that operation, e to the d, let me write it here. What is that operation that takes zero to infinity to zero to one? So there is something very interesting actually. You can go sort of backwards. You can say that if I want to go this direction, there is a common word that people use. They call it the odds. Suppose you have the probability of success is probability that your team is going to win a particular football or soccer or cricket or whatever it is. The probability is 0.7. What do you call call the odds have you heard the word odds the betting people don't use the word probability they use the word odds what is that that is the probability of success over probability of failure right that is 0.7 over 1 minus 0.7. That is 7 over 3, isn't it? So they will say that there is more than twice the odds that your team will win. Are we together? You say that there is more than twice the odds that your team is going to win, right? So the word for odds is odds is probability of X of an event. One minus probability of that event. Odds goes from what odds can be zero to infinity. Odds is zero to infinity. Do you see this, guys? Right. Do you see this, guys? Right? And so, suppose your probability of it being strawberry is this. Right? Then, if you write the probability of it being strawberry, you convert it to odds. Odds will become what? Zero to infinity. You go this direction odds will take you here and what takes you back to this zero to infinity how do you convert to minus infinity to infinity by taking the So log odds. Log odds. We'll make it what? Log px, 1 minus px. This will go from what range to what range now? This will go from minus infinity to infinity, isn't it? Do you see this, guys? I'm saying very simple thing. If probability goes from 0 to 1, odds goes 0 to infinity. We are halfway there. We just need to bring in minus infinity here because the distance goes from minus infinity to plus infinity, isn't it? I take the log of odds and now I'm looking at one transformation of probability that has the same range as what? The distance function. Do you see this mathematical trigger is a simple mathematical fact so we say what if what if and so we are at this moment trying to invent a theory right we say what if what if we posit that log odds of px of the probability of x which goes to which actually belongs to minus infinity infinity is basically proportional to or y proportional let's just say it is the same as is equal to the distance function up you can put a proportionality constant but it doesn't matter right what you you realize that this also goes from minus infinity to infinity so what if you pose it that this is true we could do that right it would make sensible think about it when you're really far in the positive direction probability is close to one d is infinity and log odds would also be infinity isn't it when you're literally d is minus infinity right probability is zero when probability is zero log odds would be minus infinity so it all seems to agree and if you make this statement you have essentially discovered rediscovered I should say rediscovered logistic regression right in fact this is logistic regression this is Right? In fact, this is logistic regression. This is logistic, actually, logistic equation. And if you take distance to be the, d to be the distance from the decision boundary, in fact, this becomes regression. So let's write it down. Log of, natural log by the way, log is always natural, p of x, 1 minus p of x is equal to the distance from the decision boundary dx. By the way, distance is often also written as z, right? Some literature often, Right? Some literature often, often, this is not often, often, ML textbooks, right? So, but I'll call it, this actually so now what is d now the same equation hold hold your thought one second if i write it if i do the inverse guess what it will be p 1 minus p x is equal to e to the d would you agree this is true right And now let me make it into a more traditional form. I could say P of X is equal to, now if you just work out, so what you do is you add PX to the denominator. So it will become E to the DX, one, then of course, this is one plus E to the DX. Now divide numerator and denominator by E to the DX. It will become 1 over 1 plus e to the minus dx, right? Or also often written as. So probability of x is equal to 1 plus e to the minus dx, often also written as 1 plus e to the minus z. Are we together? It is often written as 1 plus e to the minus z. Are we together? It is often written as that. This is the logistic regression. But it solves one part of the problem. The second part we still have to work out is what in the world is d in terms of our x1, x2 axis? The part that remains to be solved. But before we go there, guys, is this reasoning simple? You saw, we just made a theory. Hey, you know what? I need to convert probability into something, somehow do transformations to probability, such that its values go from minus infinity to plus infinity. Why would I do that? Because d goes from minus infinity to plus infinity. Do you see that? If I could do that, then I could minus infinity to plus infinity do you see that if i could do that then i could posit a theory i would say this is the same as this right the transformation of the probability is log odds so log odds is the same as the distance from the decision boundary right that is the basic i that is all there is to it guys so I'm giving you this intuition because um most I don't know how many textbooks actually explain this like this usually most machine learning textbooks give was it this equation as a God-given fact logistic regression this is the fact right so I thought I would explain where all of this magic comes from. It's a very beautiful reasoning. It leaves one last topic there. Distance function d of x. We still need to evaluate d of x. What is it? Isn't it? We haven't found d of x. We are going to do that the next time. But before I do that, guys, the odd logs business business and probability is that self-evident is that easy right now we'll just solve this last problem so let's look at this we have this where goes here is our decision boundary decision boundary now let us take an arbitrary point let's take a point. Which point should I take? I'll take this point X, an arbitrary point X, right? And I will draw. Actually, might as well draw this vector. I drew this vector. Right? Actually, this point looks so orthonormal to the thing. I don't want to take this point. I take this back. Let me take another point where the geometry is more visible. Let me take a point. Let's take I got my point right. Now, what is the distance of this point from the decision boundary? What matters in reality is this. This distance is the real d of x, isn't it? Now, given the x vector, how do I get to the d of x? So, one thing you realize, if I had, now we'll bring in a vector, which I will call the unit vector. For whatever mysterious reason, I will use the symbol beta. You don't have to use beta. You could use theta, unit, whatever. This is the unit vector. And these axes are x1 and x2 axes. I'm not using x, y, because y in machine learning is just for the target variable. These are the two, feature space. So you would agree that this beta vector would be something like, it would go something like this. At any given point, it would be, so just draw a perpendicular bisector from here. You know, something that will hit at 90 degrees this is 90 degrees let me call this distance for whatever reason let me just call this distance give me a symbol guys what do you want to call this distance let me call this distance t right no rhyme or reason you could pick whatever you want right i'll do this let us take this unit you realize that this line that perpendicularly hits is the line that is perpendicular a vector that is in this direction this vector is the vector orthogonal or perpendicular to the line do you see that it is perpendicular to the line any doubts about it guys it's a very self-evident fact now this unit vector if i make it unit vector means unit vector so such that beta one beta two the beta the the components beta 1, beta 2 are such that beta dot beta is equal to 1. What do I mean by this? The unit vector dot product with itself is 1. The magnitude of the unit vector is 1. But what is the direction? The direction is what we are seeing here, beta hat, right? So now look at this vector and observe that if I just extend this line and I finish this curve, tell me one thing. What is the dot product? Let's ponder over this fact for a bit. What is the dot product of x dot beta unit vector? Right. What is the unit vector in this direction? What is the dot product of this X in the beta hat direction? It is, would you agree that that would be, again, let me use a different color. Would you agree that this is, isn't it? Dot product is nothing but the projection on the ground in the direction of beta, isn't it? So this red direction, this distance is that, right? And so how much is dx? Would you agree? Now observe the relationship of dx to this entire thing and you will observe something at the most remarkable and simple fact it's it's a beautiful beautifully simple idea guys you will see that d t plus dx is equal to x dot beta hat right x of course being x being made up of x1 and x2 components would you agree guys is this self-evident right d plus t is the total length x dot beta anybody anywhere has doubts i can repeat it but to me i hope it i hope i've explained it very simple simple right right so if this is true now see the magic guys and you'll be absolutely love it so you would say that dx is equal to x dot beta minus t right so now let's work it out what is this x is x1 x2 right dot product of like how do you do the dot product transpose you know in matrix notation anyway i'll just leave it to you you guys know that the dot product of this would be beta 1 x1 plus beta 2 x2 minus t this is the distance isn't it t being the distance of the line from the origin the shortest path shortest distance of the line from any point basically the orthogonal distance of the line from the origin this now you notice that these are all betas suppose we call this by definition we call this to be by definition beta naught then what does this equation become this equation becomes beta naught plus beta 1 x1 plus beta 2 x2 feels like magic isn't it simple very simple equation that's all it is so what we are saying is that the distance function is basically saying that it is given distance from the decision boundary of any point is given by this we just need to know the orthonormal vector and we need to know the distance of the line from the this origin now you say wait a minute wait a minute why in the world is orthonormal business we are all taught that equation of a line is mx plus b isn't it why why why this strange way of writing it so the thing is we can of course reformulate it in terms of mx plus b and so on and so forth. We don't do that. Here's a reason why. See, a line is given by mx plus b. But when it comes to a plane where mx, m is the slope, but when it is a plane or a hyperplane of higher dimension, now what? But you would agree that even if it is a plane or a hyperplane, Now what? But you would agree that even if it is a plane or a hyperplane, still a vector, orthonormal vector, captures a hyperplane of any dimensions. It is a more general idea, isn't it? A hyperplane, an orthonormal vector to a hyperplane, along with the distance of the hyperplane from the origin, these two things will uniquely quantify a hyperplane in any dimensions right it's very easy and geometric to state it like that that is why actually in much of mathematics except of course high school you always call a plane you identify a plane by its orthonormal vector here we call beta hat but people call it u hat or whatever it is. The n hat, normal vector, orthonormal vector, and the distance from the origin. If you don't give the distance from the origin, there will be infinitely many planes parallel to each other. Isn't it? But the moment you fix the distance from the origin, even it will just collapse it down to only one possible plane now right and if you only give the distance from the origin they can again be infinitely many planes tilted at different angles which would still be at the same distance from the origin right you can imagine a unit circle or circle at that distance and all tangents to that circle would be a plane that is at distance from the origin right so uh you but when you give both the distance function the origin distance and the orthonormal vector you can quantify a hyperplane and now you think of regression we have now bring it to machine learning we are doing machine learning with many features, isn't it? So we are actually searching for a decision boundary in a feature space, in a data space, which is of arbitrary many dimensions, p-dimensional space. And we are searching for the hyperplane that separates the decision boundary as the hyperplane. So it is best to quantify that hyperplane using the orthonormal vector and this and so let us summarize all this if d is this then you agree let's plug it into our probability equation remember we said probability of it being a cherry is equal to or can i write it in a more formal language rather than the subscripts and so forth let me say probability of cherry given x at a point x in the feature space x is a point in the feature space is equal to remember we did that one plus e to the minus dx this is where we were last isn't it and that is equal to one plus e to the minus beta naught plus beta one right minus beta naught plus beta 1 x1 plus beta p xp. Right? D, whatever. Let me just say beta n, n dimension. Suppose you have n features. Do you see this equation? Now, what happens is in your textbooks, you... What is it? Oh, sorry. Yeah, yeah, yeah. And close in the bracket. You're right. So in your book, you typically see it in a more abbreviated form. People often write it just as PX, even though it's a conditioned probability. They just sort of write it as 1 plus e to the minus beta naught minus beta 1 x1, right? Minus beta 2 x22, and so forth. Right? And what this probability looks like, of course, we know that this is a sigmoid. It has a sigmoid shape. So what happens is that it has a shape like this. dot one asymptote zero right d is equal to this is uh this is where x probability is given as are we together this is how you see it so now there is a bit of abuse of notation they will often call people often call this the sigmoid function but this is actually wrong even though books call it sigmoid is a whole class of s shaped functions there are many this is specifically the logistic function what you just discovered is the logistic function and it is everywhere guys this logistic function and sigmoid functions in some form or the other any one of the sigmoid functions they dominate nature, right? If you look at the, in some sense, we think the fact that I'm talking, we are exchanging ideas, we are thinking, our nerves are firing. The firing of the nerve across the synapses, if you look at the electrical potential, the sodium-potassium balance rising, what is the shape of the activation? It the sigmoid right if you look at a transistor firing it is the sigmoid right it is shaped like the sigmoid if you look at the population growth suppose you take every everywhere you look you look at the population growth in an ecosystem suppose there's a lot of resources and you have just two people one couple couple there, they create and so on and so forth. And, you know, they have children, some children died, and so they have support, they have more children, and so forth. At the end of it, what happens, the population is limited by the total amount of resources available, isn't it? Because after sufficiently high population, people will have just enough to survive. and population will start saturating right so population growth has a sigmoid structure wherever you look you'll find sigmoids in nature logistic is by far one of the most commonly used sigmoids to model such behavior population dynamics and many many things and in fact it is one of the this is the logistic regression what i just taught you is logistic regression are we together so you take data and then you do that now the question comes well that is fine but what is the loss function how do you optimize how do you find the decision boundary how do you find the best beta naught beta one? So one may be tempted to say, well, we all know the sum squared error, right? The trouble is we don't have the notion of residual. It's not the gap. Remember, it's the confusion matrix, that matrix in which how well the child was able to tell the cows and the ducks, right? Let's go back to our cows and ducks. You don't have the notion of it is wrong by this much. What you are wrong by, suppose you predict a probability of it being a cow. And it was a cow. So what is the ground truth? 100% sure it's a cow. You predicted that it is 70% it's a cow. Now your it is 70 percent it's a cow now your probability because you are predicting a probability now so you can't look at the gap between 0.7 and 1 and try to square that there is a reason for it but the reason for that has to do with something called emily with something called Emily, right? There's a word in, there's a whole thing, concept called MLE. But if I were to choose to be mischievous, let's call her Emily, right? So we will all become friends with Emily after lunch. I noticed it is one o'clock, so I will let you folks go. So Emily, we may do today or we may do perhaps next time. Why we don't take, what is the nature of the last function? We have a choice, guys. We can take a short break and continue for one more hour, but that will really push out your lunch. Or we can do lunch and then do this. But we also have a choice, guys. We can take a short break and continue for one more hour, but that will really push out your lunch. Or we can do lunch and then do this. But we also have a lot of lab. Or we can do lunch and come back and do the labs only, because we have a lot of labs, and push this to the Emily part, the last function part to next week. What would you like? Do you think this is enough theory for today? I think function part to next week what would you like do you think this is enough theory for today that is it then then that will bring me to emily last function is emily based any any feedback from those of you who are remote are you in for more theory i i think we should do lab and then we can do the emily next week next week okay any other voice that's a good feedback send you any other feedback anybody who would want to have emily next week next week okay any other voice that's a good feedback any other feedback want to have emily today nobody so why are you trying to do the emily now because it would close the topic of uh classifiers end-to-end thing that's it but it's a long journey i think we should stop here it will take more than an hour it will easily eat us no no i don't want to do only of theory there's a lot of labs we don't want to fall behind on labs today is a very very long lab very long lab right labs today is a very very long lab very long lab right you should switch to lab let's let's switch to lab in the afternoon all right guys so we will do the question what what what sachin is asking is in this particular logistic function what are the degrees of freedom like what uh what changes the shape of the sigmoid, of the logistic function? So the answer to that is quite simple. The beta naught controls whether, see there are beta naught and beta 1. They control whether the sigmoid is like this or whether the sigmoid is like this. In general, they control the shift typically. like this in general they control the shift typically and beta one and beta the other thing they control is whether the sigmoid is like this or whether the sigmoid is smooth right so these two factors they control that right uh then the one parameter that we don't need to worry about is the amplitude is fixed at 1. But if the amplitude also has to change, right, then it becomes a three parameter model, which we don't show here. Because I thought it was the curve also, it becomes like this, right? Yeah, yeah, that is it. So you control with this, beta naught, beta 1, right? so you control with this beta naught beta one right so with these parameters you can control how strongly it goes up and down but that's with the logistic but the family of sigmoids will control even the angle at that curve no no no no no no no see the families are all very similar so i'll give you an example so let me just say the two thing one is that see am i going like this or am i going like this to this right this is this there's actually there is a word for this they're very um what is the in for example i deal with education so one of the questions we are so let me tell you something about where, one more location where these functions are used. It is called item response theory. So see, when you ask in a test people questions, the most obvious way to grade is to each question give one mark. If they answer the question correctly, one mark, right? So that that is not true. Some questions are harder than others. Giving only one mark per question is not good. In our quiz, I tend to do that, but it's not good. So that reminds me of a king in India. There's a saying, , right? Because There was an ignorant king in his kingdom, everything was priced the same. Simple food and delicacies were all the one. One repeat. So it is like that. What you want is some questions are harder, you need to give more weightage to that. So then the next step of evolution is, you notice people do professors do in the exam, they will give what teachers do, they will give more marks to harder questions, and less marks to easier questions. But then the question is, how did they determine that? It is their gut check, you know, that it's not reliable, sometimes a five mark question will be easy and a two mark question will be hard. They get it right. So the thing is, how do you make sure that questions are truly a differentiator or ability to tell a person's talent? Right. And so the answer to that is, what you do is if you say that the ability, right, Ability is this is the ability score, the actual ability on that particular thing, let's say calculus or something like that, ability at calculus, I'm just taking it, right? And you plot it against the probability that the person will answer it. So you know that at high ability, the person should be able to answer it. At low ability, the person should not be able to answer it. Zero, right? So you want a curve that goes like this. But what happens is that a badly designed question will take like this. But a well-designed question will have this in other words between not having an ability and having an ability right the probability rises very fast so in other words if you did answer this question right the people who did answer this question they all certainly have at least this minimum amount of ability. Very quickly it can tell. So these things are literally controlled by the beta not beta ones itself. But a separate question is why did I use the logistic function? Here I use logistic. So I'll jump the gun, I'll tell you a solution. There are many other functions that you could use. One of them is the, so there's the's the logic there is the posit right but you know what i shouldn't say that because then you won't go and discover the other sigmoids right but when you discover the sigma yes you could do that one of the reasons people don't like to use some of those other things is not because you can't logistic is famous because of some very simple reason. As you will see, if you take this function, logistic function, it has some beautiful mathematical properties. Amongst its good properties is the derivative of logit, right? dp dx is actually p1 minus p, right? And other sigmoids also, some other sigmoids also some other sigmoids also well i'm now tempted to tell you all the answers which i'm not going to because this is your homework let me erase this also because this derivation 2 was your homework at some point so there are error functions and other things which also have exactly the same shape but in a error function is let me okay let me get the cat out of the bag for one of them only one of them error function is related to sigmoid sorry the bell curve the bell curve has how many parameters mu and sigma do you see how these things develop right now there are many more sigmoids i won't tell you about go go go and find it out let's lunch. Because I'm going to announce a homework, which is literally for you to go discover. I mean, I have announced. Go discover all the sigmoids and observe their properties. Right? So that is that. Do that.