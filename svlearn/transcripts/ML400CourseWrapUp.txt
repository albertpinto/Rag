 Today we finished the lab of GAN. This is the week of Generative Adversarial Networks. In this workshop I've been trying in many ways to compensate for the fact that I can't see your faces. I'm usually a very interactive person and most of you have been in my classroom and you know that, that I don't look at the board. I instead look at people and talk. And I know when people are understanding and not understanding. So it's a very interactive process not having that interactive process means that i have to find ways to compensate you know get something back or something like that and it's unfortunate that i can't see into your eyes and tell whether you caught it or not so i supplemented this course with these quizzes and these extra sessions and help sessions and so forth i hope they are proving useful I'll send you guys a survey you can let me know the relative usefulness of these things because it does take some effort to create these collaterals but it's been fun you guys are like see it's a good batch we have and my hope is that whatever your individual goals are to apply deep learning to your workplace existing job to become an entrepreneur and apply to some new ideas or to change job or whatever your goals are now is a good time I hope I can take you towards that my timeframe was that by early Jan if you are looking for a shift, smaller, big shift, you should be ready. Many of you have been taking this with me since summer when we started the ML 100, 200 journey. We have taken almost everything. The one thing that we missed this year was the mathematics of data science. And I can see that effect as I was explaining in this class People would ask could you explain this again and things like that and so there's a little bit of a difference when people have taken the math of data science and if people have not taken This is perhaps the first batch that will go out from support vectors that has not taken the math of data science we would have run out of time by end of this year why did we not do the math of data science we didn't get enough enrollment as many of you know we didn't reach a quorum so be that as it may try to compensate for it in the class resource portal I have I have put a link to the book the math of data science and it's a wonderful book the author has very generously made the entire book freely available as a PDF what I would suggest is the book is certainly I my general I have a basic rule if I like a book and especially if the author has made it freely available as a PDF I sort of reward that behavior by promptly going and buying a hard copy version of the book if it is available, or at least a paperback copy. Because I feel that it takes a tremendous amount of effort to create these notes and these books, far more effort than it takes to just read a book. And great books should be treated with reverence so the books that I have referred you to in this workshop the ISLR the deep learning and the other books and these lab books they are all very good and when people produce them when they write them they have given a part of their life to do that not only they are just pouring their knowledge, the world is filled with people who are extremely knowledgeable. You see them around in your workplace every day. So geniuses in Silicon Valley are as common as dirt. But the willingness The willingness to share and the ability to share with clarity is a much more rare quality. So my own, and this is a little bit of a personal reflection, whenever I see a book that is well written, I invariably treat it as a gem and acquire it. That makes me a little bit of a hoarder of books. I am a bookworm, but it's worth it. That makes me a little bit of a hoarder of books. I am a bookworm. But it's worth it. Now, the books that I refer to you in this workshop, a deep learning textbook and the two lab books, I don't know if you are making progress with this book, Spice. Please do make progress. I haven't been pointing out that go read chapter this, that, because you guys are all grownups. You can relate what i have uh taught you in the lectures and then review it from the books so one feedback i wanted to give you is those of you who are reading the book are you finding it easier to read the main textbook after the sessions yes yes yeah it is much more easier easier. It gets easier. I have some doubts in the book. Book time with me. I'll explain it to you. You can say this page I don't understand and I'll be happy to explain that page to you. There are a lot more pages which can need a little bit more explanation. I can share the page numbers later. Yeah, sure. So long as it is what we in the scope of what we covered, I'll be happy to explain that. That book is a little abstract, it is indeed. But once you see, if you read, it is not a book, like many textbooks. It is written to exactitude and perfection in some sense. Statements are well thought out, correct, absolutely correct. And it is a senior researcher talking to other senior researchers explaining it. So from a pedagogical perspective, from a learning perspective, something is lacking. I mean, the whole idea is that textbooks are usually coupled with people who can teach you and they guide you through the textbook, which I suppose was my purpose. This workshop is that, it takes you through that. But it is important guys that you make progress through the textbook. There are very very few people who have actually done the entire textbook. Because these days it is so easy to pick up 10 lines of Python and claim you're a deep learning expert. It is much harder to learn these things properly. And right from the beginning, all of you have been with me and I keep emphasizing that I not only care about the coding, I also care about understanding it. Because these coding libraries will come and go, I guarantee you 10 years later, there won't be any PyTorch or may not be TensorFlow, PyTorch. I mean, they may be there, but I'm sure something else would come up and something else would come up and newer libraries, they mushroom. Like they seem to be growing like mushrooms. There is so much creativity in the field. But the one thing that never changes is mathematics there's something there's an eternal quality to mathematics you know the pythagoras theorem is as much true today once proven as it was true when pythagoras proved it so and to this to the extent that deep learning is nothing but applied math it's very simple mathematics it is the mathematics of basic statistics probability linear algebra that is playing around with matrices and multiplying matrices and a bit of calculus right and mostly differential calculus and so forth so it's not a very hard subject. It's a very limited part of applied mathematics. For example, in much of deep learning, at least in reading a research paper, etc., you are not solving partial differential equations with boundary conditions and things like that. So it is nothing like that. Today Shankar is not, but he used to solve the ocean dynamic equations. Those are hard and in fact analytically unsolvable. But we are in a domain that is relatively straightforward once we get used to the lingo. Therefore, I would strongly suggest read the book guys. The second thing is do the labs now lab in a way I've been deliberately very soft in the first part of the lab because given time given the fact that you guys have day jobs you have to sleep you have to socialize give time to your family and here in this workshop itself there is a trade-off between understanding the concepts and becoming very fluent with the coding. Time is limited. And I knew that people are, they have reached out to me and say, I'm not getting time for both. In part one, we did labs, but it was sort of the emphasis was on getting the fundamentals in place. We are going to change that. It is, if you have reached this far and if you have been reading the textbook you are strong now with the field or at least let's put it this way you were stronger you're stronger now than before and fundamentally you have an idea of the field at this moment the point or the thing that is probably needing most attention is practice part two in part three will focus on multiple areas they'll focus a lot on transformers transformers are great to read about and all those papers are great to see the magic happen but can you solve a problem in small groups for which it is not an academic problem it is not cookie cutter it is not something that you'll find on kegel but if I give you guys a problem with words and I pose a few I will give you guys some records some things and I will ask you to do text classification I'll ask you to do text summarization I'll ask you to do text summarization. I'll ask you to do study many, many aspects of readability, look for hate speech in it and many, many things. These are things that, for example, I do in my day to day life. So I would like to bring day to day experience to bear upon or give you guys a window on what happens in day toto-day life in deep learning so what I would like to do is I'll give you guys some you know little bit of a warm-up problems and labs to do but then I would give you longer labs in which it is open-ended do it in small groups do it alone if you wish if you have the bandwidth but do it and as we make progress solve that you would be breaking new grounds I'll deliberately give you some data sets that have never been explored before and I'll craft a problem in such a way in which even I would not know whether you'll succeed or not. Would you guys like that sort of challenge? Yes, Rasif. Yes, Rasif. Yeah, that'll be good, Rasif, yeah. That is, yeah. And you know, it's very confidence building when you solve a problem nobody has solved. You move the needle forward. It's not just an academic dataset, let's say. You know, one of these datasets, but to be very real-world centered. So, and there is also a standing principle, as you know, in this workshops, bring your own data. You are working, one easy way to save time is, why not have overlaps? Or talk to your employer, if the data is sufficiently non-proprietary, for example, it's a general research data, then with the proper non-disclosure agreements and so on and so forth, you can include your team members. And I'll be happy to guide you through, also sign your NDAs. People have done that in the past quite often with me so i'll respect the nda and sign the legal document and then that will give me allow me visibility to the data and then of course i wouldn't work on the project you guys will work but i'll certainly guide you so the bring your own data byod is certainly on the table. Bring your domains data so that you in the in the course between now and January you solve a real problem for your workplace or any other data. Kaggle has 35,000 data and growing data sets and growing. Most of them are untouched because if you look at the learning curve. Most people learn or analyze those data set the majority of them, not all of them. Sajeevan G. They do it as a pedagogical exercise. They want to create notebooks. They want to show it. They want to get a job and then they hope to get real data in the workplace. Sajeevan G. What I'm seeing is that let's not do such shadow learning let's take some non-trivial data sets so we will start now after this break we have a one-week break after that we'll start we will start a with two sort of projects one is longer term for you to think it is a lung cancer data it is to do with computer vision and it is a continuation of some of the things we're talking today. But the other is natural language processing. We will first do natural language processing and a lot of it. You will go very deep into the transformer using the transformer, not so much at this moment of the theory you are not the theory actually transformers when I explained it to you I explained it does this and it does that and so on and so forth to a certain level we understand but actually we don't understand truly deeply in an analytical equation manner mathematical manner the dynamics of these transformers or any any sufficiently rich neural networks we really don't understand there is a lot of research that is happening to create better understanding interpretability to it see if we can write it as equations see if you can figure out the dynamics it's one of the things that will recur when we do it we look at saliently we look at interpretability and there are many things sometimes to interpret a complicated model you build a model that predicts the behavior of this model you build a meta model and that is more interpretable and you do all sorts of interesting games with that we will do that in this workshop we'll do language translations we will do for example we will we will take specific sounds and we will see whether a cnn can detect or a very rare sound a very specific sound and distinguish it from other sounds and things like that so we'll do some very good labs so the exciting things going forward are not more neural architectures for the duration of this workshop. I think we have done enough. The only two more concepts. One more concept actually Vaidhyanathan Ramamurthy, Well, let's say to that I'll bring back at some point I'll introduce them, but they're smaller ones. They are auto encoders and there are many kinds of auto encoders in particular will learn about basic auto encoders and then variation auto encoders particular we'll learn about basic autoencoders and then variational autoencoders. We'll learn about restricted Boltzmann machines which have a lot of applicability. But besides these two new concepts, broadly we are done with concepts, we are done with fundamentals. Time is now and the fun is now in lab work. So mentally ready for more fun labs you know so towards that make sure that you have you understand the code that i've given you read it line by line if you get stuck ask me become very familiar with the pie torch see pie torch is very straightforward you build a neural net what do you do you subclass the module class. It has a init and it has a forward. If you don't really care about debugging specifically line by line, you can create it the Keras style. You can create nn.sequential and in the constructor, in the function, sequential function itself, you can layer out comma separated list of all your layers linear followed by relu activation followed by batch normalization followed by dropouts again followed by the next layer linear and so on and so forth you can do it in a single line now so that being as it is it will become very familiar to you and make sure it does see if you read the code and it looks like I have to sit and understand it it means you are not familiar with it enough by now if you go and look at the various classes I created you will see that they follow a pattern it's a pretty common pattern I follow but each of them will have small variations and things like that. It is representative of the industry. You create a neural architecture but once you figure out how to create a neural architecture and you understand the theory, it is a matter of just doing it. Like for example, GAN theory is very subtle and interesting, right? It's fun to do, to figure out how GANs work but once you have figured out you see that you bring that theory back to code and the code makes a lot of sense then isn't it in fact code looks like the most logical way to lay out that theory so that thing we need to do you folks please take this week and I will be available during this break to help you guys This Saturday we will especially in particular is a remediation day. Please bring reach out to me We'll start with the quiz reviews multiple quiz reviews are pending We will do all of those quizzes reviews. I will be releasing the Gann quiz today. Let's do the Gann quiz I will be releasing the GAN quiz today. Let's do the GAN quiz along with the previous quiz, Condulations quiz and the Transformer quiz. So we'll spend a few hours doing that. Maybe we'll take a break and then after that we'll have the one-on-one sessions to help you guys whatever lab issues you're having. So and take help from each other. So, for example, Harini, you know, the Colab, just two lines that I gave with the Colab to upgrade Python to Python 3.8, she has it running successfully. So if your Colab notebook is not working, all you have to do is reach out to her and just take her help or just wait for my help. But if you wait for my help, it will be on Saturday because I stay busy during the weekdays. If you take her help, she'll help you right away. Isn't it, Harini? Sure, sir. Nice. And thank you for that. Isn't it Harini? Nice. And thank you for that. And also it is a time when I want to start the practice of presenting your notebooks. So this is what we'll do in lab two, in the part two, part three, but I would like to initiate it. Harini has also been doing an internship with me and she has created a notebook on on breast cancer patterned after our notebooks that we have the california data set that we covered in the past so and she has done a very good job so i would like her to be the first participant to have a presentation session on that so we'll fix the time I was thinking this Saturday but maybe this Saturday is getting very crowded we can do this Sunday or maybe next Sunday or one of these days next Saturday one of these days we should pick maybe next Sunday because I I am not planning to present a paper next Sunday I'm presenting again this so would you like to take next Sunday, Harini? I can't hear you. That could be okay. Next Sunday. Thanks. And guys, if you have any things to present, we should get into a cycle in which every week there is a presentation from at least one participant. It helps. It helps. Collaborative learning helps. So that is our roadmap going forward. I will send you guys a survey. This is, as you know, in the Western hemisphere, in the US, it is customary to end courses with surveys. I know that you guys are busy and surveys are the, everybody hates filling out surveys, but you can help this workshop, you can help the next generation of students who come, next batch of students who come next year by giving your feedback on this workshop, part one, which was much more about fundamental ideas. So please do fill out that survey i would say the other bookkeeping thing is i haven't yet created the registration page i will create the registration page for part two right and part three so you guys when i post it on slack then you guys can all go register for that and the moment you register there is another course portal for part two this course portal that you guys are logged into it is for part one the deep learning fundamentals now part two course page is ready if you want to get a early head start then you can register and then you will get access to that and you can continue on from there. You can try to do some early reading. Rajiv Gill When the part two course page comes up, what will be the user experience for folks who are looking at part one and part two? Will that be a union or they'll be different no no no it is not because there are people who only are doing part one so unless they register for part two they'll forever have access to this page but they won't have access to the next page now in two case and a few others there are about half a dozen people or more who have registered for all three at one go so there you you obviously right away will have access to part two okay and part two is more practical practice focus guys. More practice focus. We'll go deeper into theories, but much more will focus in practice. Asif, so when we did the bootcamp last year, so like we uh do the time series data uh that time we said like because we ran out of time and we had to choose that like uh whether the time series can be done and that time it was recommended that when we have the next time that the course will include that so can we have that as a like one of one week session certainly certainly instead of being an optional like like one week dedicated to the time series using whichever approach you want to do like the non deep learning, deep learning, like combination of both. Yes, time series is certainly a part of this series. Yeah, because for enterprises, that is where like the lot of values will come for the commercial businesses yes like images and NLP yes but for enterprises like still like you have like lot of structure and the time series data you have it and if you want to do some early reading and getting ready for it so that in the when we do the class we can move a little bit forward one of the things I'm thinking is now I'll give you a visibility. I mean, obviously this time it was all fundamental. So we all knew what we are going to do. A CNN, CNN, Transformers, Gantz, right? But in the next one, you guys will have visibility at least a couple of weeks in advance of what's coming. So time series in particular, for example, if you know your Foyer transform and what does a Foyer transform do, at some point, all of you must have studied it. What is a Foyer transform? We can go back and look into it. Time series analysis has multiple approaches. One is in the time domain, one is in the frequency domain one is in the frequency domain and of course then comes deep neural network and the whole game becomes more complicated but you can do some early readiness by understanding those things before you transform and so forth you guys must have done for you transform at some point do you guys remember that actually I have not done like I didn't study electronics so I didn't do signal for your transfer Oh anybody anybody who has done it so It was a while back. Yeah. Fourier transforms are very easy. It is one of those, see there are this bunch of integrals, Fourier transform, Laplace transform. They are mathematical lenses. They are ways of fishing out. out imagine that you have a way of looking at a lake with polarized glasses you start seeing into the lake you see the pebbles and the fishes in the water but if you don't put on those glasses all you see is reflection of sunlight the shimmering sunlight isn't it so these these these transforms are very magical sort of colored glasses a polarized glasses you can wear and the moment you do that what happens is that you're looking at a signal you're looking at any time series data and it begins to reveal its periodicity its patterns its driving frequencies behind it and the fact that it can do that is absolutely amazing. That's what Fourier transform does. It also gives you a visibility into the energies behind it. The power, the spectral energy in the wave, in the pattern that is there. And what is even more remarkable, when you extend the idea to Laplace transform, it gives you the attenuation also. How is the whole wave pattern over time? Not only has periodicity, but it is showing the appropriate decays and so forth. So to be able to just fish it out is almost like, and those transforms are very simple. It's just an integral. You take a function, multiply it with another function, a probe, right? And when you multiply it by a probe and then you sort of add over or integral over it, suddenly it probes the entire data and extracts these meaningful harmonics out of it and it's just amazing to see these harmonics and energies allowed with something so simple as a magical power of mathematics actually most of mathematics is frankly elementary once you get used to it and as mathematicians call it they say that everything in mathematics is trivial The point is to reach the point at which you can see see that it is trivial So, is there a book you can take a min for this like to get an early start or Or some research paper we can look at see the only two books that I would suggest One is the mathematics of data science is are freely on our course portal. I really mean it. It's a wonderful book. Print it out, read it. I can't over emphasize. That book has recently been published. Before that, the book that I used to recommend and I still recommend was my own engineering when I was, it was the textbook that I went through in college. It is the Irwin Krasick's Advanced Engineering Mathematics. Many of you have taken the workshop with me on that in engineering math. So if you want I can post the link to Irwin Krasick's Advanced Engineering Mathematics. The book is prohibitively expensive. It's like $200 or something like that. But the good news is that math is eternal. So Jay Shah, Dr. of the book and those those portions are available for like $9 $7 $10 it's a massive book weighing in it no less than 1200 pages or something like that but each chapter is self-contained so if you go and look at the chapter on foyer transforms or the chapter on Laplace transforms they are pretty self contained and very well done the other thing that I could suggest is the three brown three blue one brown portal that I've given a reference to in our course portal that YouTube channel is just absolutely excellent their explanation of Fourier transform is just absolute gold just go and watch that 15 minute video you will learn the intuition of Fourier transform right away that is very good and they also have a video on the Laplace if I remember right but the four year they have explained very very well yeah I have white that that's really good it's really and in general the linear algebra is also I mean oh yes really really good they have put tremendous amount of energies in doing it obviously now I hear that they are very well funded for all of this work and there's a pretty pretty substantive team helping make all those videos it's a great thing I mean I wish I wish I could do, I had the time or the ability to create such wonderful visualizations. Asif, do we have like syllabus for part two and part three? Yes. So I can mention that here verbally. We'll do a lot of natural language processing. We'll do computer vision. When I go into computer vision, though the difference would be, is that this is lightweight computer vision. It's completely focused on deep learning because we are doing a deep learning workshop. See, computer vision when you take, like grad school level, there is a lot of mathematical theory there I won't be covering that As I mentioned before I if there is enough interest I will be happy to give a workshop on computer vision and deep learning together in which we go very deeply into computer vision But computer vision is a deep well of knowledge very much like deep learning in its own right and people who just do computer vision without knowing computer vision just by applying CNN's they actually hit a wall they don't go further because if all you have to do is apply a CNN there's an army of 1 million people who can write the same 30 lines of Python code. So it doesn't help. You have to know as you know, and you have, you went into the computer vision course, right? Yeah, I'm doing open CV course. Yes, open CV course. Yes, that is an excellent course. So so when we do it, we'll do it along those lines. So we'll see how many people are interested, but we'll do computer vision anyway. So a lot of word, natural language processing, computer vision, we'll do DADs, deep anomaly detectives. It's a big topic. We'll do graph neural networks, which unfortunately I didn't cover in part one. I was hoping I'll give you guys a taste of it, but I couldn't. Then we'll do time series. There's one more topic we'll do. So I did computer vision, natural language processing, anomaly detection, time series. And then XA. AI that's a big thing because it is not just fluff it is a lot of very interesting and emerging cutting edge algorithms on how you can get a sense or interpretability out of deep learning so those are your five topics guys those each part two and three will be six week each there will be six weeks and the timings will be same right as if monday and wednesday absolutely the same guys and i i don't i am not i mean maybe somebody will want to join the second part the third part who hasn't joined the previous one there may be occasional one or two people and by all means bring your friends if they are interested in natural language processing. We'll start with NLP first. The topic that we'll take up is NLP, text processing. So if there's anybody interested, he is welcome. But for you guys, the thing is, you guys, we are following exactly the same patterns in SAMA, Monday, Wednesday. So we'll continue to follow that pattern we'll continue to have the quiz we'll continue to have the paper reading nothing will change we're just taking a one week break and if you guys feel you don't need a break we can skip it entirely a break we can skip it entirely what do you say i think week break is good you need to be ready for the election okay sorry are there any external certifications that you know your exams or something oh i will be i've been remiss actually i'm still yet to send out the ml200 certificate I will be giving you a nice beautiful certificate but more to the external certificate and by the way I was pleasantly surprised some people have put the support vector certificate on their linkedin and recently i heard chatter somebody some recruiter was saying that he didn't know that uh support vectors is something i'm associated with he was they were he was talking about certificates and then he says yes we we we get candidates from support vectors who have the certificates I think they are good so it doesn't mean much maybe it's just one guy saying but for what it is worth maybe the certificate is beginning to gain some some traction hey yeah that's good the brand is building yes the gradually the brand is printed and I don't give it to people easily they have to take the whole workshop so I will be giving it to you guys it will have the elephant to the balloon on it that's all I have guys so thank you for being part of this workshop we are the end of it remember we are not done with the week will release the quiz tomorrow please take time to do the quizzes guys we are all busy people we are all parents and we are all breadwinners life will never be will never have time however much you may hope the future always seems as though it's empty and we can do things in the future but you know new things come and crowd the day so you have to take time right now review the book do the labs do the quizzes and we'll discuss the quizzes on Saturday and we'll do the all the lab remediations also on Saturday Sunday we'll do the paper reading and we'll end the week there six weeks will be over end of it six weeks thank you guys yeah one thing as if after your course right so if you go online and check for any blog or video right it will be much easier you're finding that much easier yeah I've seen a lot of videos comparing like active functions right and all those stuff are like pretty hard even for Andrew unique right so Directly, it's first time. It's very difficult to understand once after your course right so all those things I find it very easy. Nice. Is there anybody in the class who feels that we went too fast? We need to really slow down. I think the week break will help us catch up on labs. At least that's where I'm behind. But I got my GPU working finally. Oh, that's really nice it was quite the Linux adventure and is there anybody in the class of use we went too slow we were excessively slow or something so anyway you won't speak up publicly in the survey you can express those opinions I would like to know if there are polar views like that because I because if it is too slow I can challenge you with more interesting and more more labs and more interesting labs that you can do I think that's if you are at a right speed. Yes, because the amount of material we are doing, even this should have been a little bit of a stretch. If you're actually reading the book, you'll realize that in every week we cover large sections of the book. These are pretty big areas of the book we have covered. In fact, part one of the book is over. The book isn't part one and part two, the textbook. Part one, if you realize, is over. We have covered just about everything there. Are we going to go over the later parts in the next workshop? Come again? The later parts, yes, certainly. Autoencoders in restricted Bolton machines are certainly there. And that book is an excellent book, but it's likely dated because this field is moving so fast that things have come about after that. Many, many things have come about after the book was written. And obviously those researchers are great people. I don't think they'll get time to update the book if they do it will be a wonderful wonderful gift but yeah we'll do more than that Alright guys, that's all I have for today.