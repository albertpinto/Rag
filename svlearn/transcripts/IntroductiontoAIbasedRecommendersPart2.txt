 . This is our second session on the recommender systems, AI-based recommender systems. In the first session, we had an overview of the various ways of doing recommendations. Just to summarize, we have, let's see if I have those notes here so we can quickly go over it directly. Is that part one? Yes, this seems to be the notes from the first one. All right. Ah, it seems that I started more with the business motivation. I pointed out that in the e-commerce world, which was one of the drivers of the early recommendation systems and the Netflix and so forth, there's an interesting phenomenon, which is the long tail, long and heavy tail phenomenon. Most books, for example, if you take books, which is how Amazon started, or just items, there are very few bestsellers, and those bestsellers have a huge amount of sale. Then there is a long tail. So these are your bestsellers. This is items ranked ranked by numbers sold. How many did you sell? So everything is ranked in the decreasing order ranked by that. So the top rank, one rank is obviously your best seller. Then after that comes two, then three, et cetera, et cetera. And there are different items. And you all know that this is true of movies some movies which are absolutely blockbusters everybody wants to see but there are movies and there are things for example something might be a blockbuster movie 10 20 years ago but now has a small audience of people still seeing it occasionally going back and seeing it there are situations where for example the indian dias in the US, they consume a lot of the Bollywood movies, but the Bollywood movies are not likely to show up in the bestseller list globally and so forth, or Netflix bestseller list. So, in other words, and for books it's definitely true, I took the example of one of my favorite science fiction writers, Ursula Le Guin. She wrote, in my view, is one of the most beautiful and poignant science fiction. She never was a bestseller, never made it anywhere close to it. But on the other hand, she never faded. She is one of those authors who was an all-time favorite for a very small group of people, not a vast amount, actually not a very small group of people, but not enough momentum to bring her to any sort of bestsellers list that I know of. Or maybe she was at some time, but I don't know. But when I got introduced to her, she wasn't considered a bestseller, but still she's excellent and you learn about them through references to each other and so forth so there is a there is a huge amount of mass in the so-called long tail if you look at the area under the curve of this graph you will realize that most of the time there is a wealth of things that you can do why was that important the reason it was important was a brick and mortar shop is limited to only the top end simply because of the amount of shelf space they have if you think of books. But in the Blockbuster case it's the videos. In the case of Netflix on the other hand because they are either streaming or in those days sending it to you by postal mail, they can have an unlimited inventory of almost unlimited inventory, Amazon, Netflix, etc, could have of contents of items, even items that are only only has a small following that people used to and those items bring a lot of value, a lot of revenue to the company to these companies. So now when you look at the long tail though, this long tail represents a zone of opportunity. So that is how I pose the business problem. But the whole question comes, the long tail has so many items. Amazon, someone told me that they now have close to a much more than 100 million unique items. 100 million unique items is an excess, it's an extraordinarily large amount of items. In there somewhere are things that you would really love to buy, if only we knew that they existed, right? In there are things that we know we want, but we want to know how good, I mean, are they aligned with our budget, our purchasing habits, our taste, and so on and so forth. Likewise for movies, there's so many, many movies we don't know that would perhaps be movies that we would like. And songs, Spotify and so forth. So the crucial problem therefore becomes that when you have a vast inventory nearly unlimited inventory of items and you also have these days because of the network if you vast amount of following you see like the more people know about netflix or purchase from netflix the more other people become aware of netflix i mean sorry amazon i meant a purchase from Amazon. And Amazon has a huge, huge following now, which also I'm told is in the order of 100 to 300 million users, unique users. So for each user, how would you know what you should, what they would like to buy, what you should recommend to them? And that is the recommender system problem so when you do the recommender system problem the fundamental problem is you have users along this axis and you have items along this this is by the way the classic way of putting it it's called the user user item rating matrix or user rating matrix or sometimes people just say rating matrix or just urm a user item rating matrix or more briefly user rating matrix this is it so what does it contain each user is a row each item is a column so items are columns and users are rows at the intersection of a user and an item is what rating the user gave to the item now if you think about it a user may have purchased a few hundred things from Amazon, different kinds of things. So when you look at 100 million and even if he has purchased let's say a hundred different kinds of things and given ratings on those, on all those 100 items let's say, still you have data about the user which is very sparse. Most of the user role, most of these things are empty. In fact, at the typical point, you would say the question that arises, the fundamental question is, should I or should I not recommend this item to the user? Would the user really like it? Would the user have preference for it or taste for it? That's the fundamental question that we are trying to answer so this user rating matrix is very sparse the sparsity typically is like very very small like for example the 0.001 right 0.0001, I believe, or very, very low values that you find in this sparsity level. By sparsity level, what do I mean? Let's see, how many values can this matrix have? Suppose the number of users is NU times the number of items is NI. If you had all of these ratings let's say that every user had bought every item and rated it you this is the maximum value you can have now the actual number of data points so if you look at the data points number of data divided by item this number it turns out is very, very small. It's just like, let me put a word, epsilon, very small. And so the question is, it's a pretty interesting game. You're basically asking, can I populate just from that tiny little bit of data, can we infer the rest of the value in this matrix? Because if I could infer the rest of the values in the user rating matrix, so for example, ahead of time, if I could tell that if the user was shown this item, they are asked to rate this item or shown this movie, what is the rating the user would give or to the song and so on and so forth. If you could guess, and if your guess is good enough that has massive business implications because now you can rank all the items by how much the user has a preference for and give the top end items as things as recommendations to the user and you could turn the other way around you could just go to items and say who are the users who are most likely to like those items right you can go by the column and sort by sort the values in any given column and you would know which users are likely to purchase that item so for example if you're doing a marketing campaign or something like that you could pick the top end users and send them a personalized emails recommending this item to them. So both ways, it has a lot of value. And there's a lot that people do. They find groups of users. They look for patterns and clusters and whatnot. So a lot goes on in this particular field. And this is a field of, essentially, recommendation system. Its main point is, how do you recommend something to the user so how would people do before ai the way they would do it is that they would for example you would look at the item characteristics so they used to be this matrix which is called the item content matrix you in here the the axes are different. This is the items. Items are the rows and their characteristics item. These are traditionally called item content matrix. Or you can think of them as item attribute matrix. So this thing is the attributes. So for example, one example that could be given is, suppose it is about food, right? Or does it or does it not contain salt? At this particular moment, suppose this attribute is salty. You may have an amount, a number between zero and one, how salty it is. You may have another attribute here saying how sweet it is, and it will have a number on zero to one, or whatever scale that you want to give, some scalar, some real valued number belonging to real, you could have. Or you could even make it Boolean. You could just say either it has that property or it doesn't have that property, right? So just a Boolean kind of attribute. And then, of course, you can generalize. You can do categoricals, which you'll have to burst out and all of that. So this is a notion of attributes. So traditionally, what people did is they would look at item characteristics, and then they would do sort of similar the moment they noticed that you're searching for a computer you looked at dell computer they would immediately start showing you other computers that are similar that have similar attributes before you have purchased it's very useful to get those right the other thing you could do is a market what used to be called market segmentation. Market segmentation would do like group the users into certain segments by demographics, by income, by this or that, and then sell, you know, just use basic marketing techniques to sell to different things to different segments. For example, if you go to a car shop, you know that the same car manufacturer will have different brand names. They would be Toyota and then there would be Lexus, right? And quite often the car is fundamentally the same. The chassis are almost the same, not quite the same, but almost the same, the engine and the plumbings. But the upscale variety, it would have a few extras you know slightly better parts here and there but the interior would be completely different it would be far more luxurious right and much more gadgety whereas the the the more consumer brand would have compared to the luxury brand the more mainstream brand would have basically a car what you think of as a car so that is segmentation of the market you're addressing different market segments then people also have a niche for example the subaru is often associated with people who like outdoorsy life so they have really optimized the car from what understand, for safety and from not slipping and being very safe and handling slippery roads, curves, uphill, downhill, and so on and so forth. So that is market segmentation. You find your niche and then you build products specific to that. But when you sell it, you do the same thing. You find a product that you figure out what market segment you should address it to and you sell it you do the same thing you you find a product that you figure out where what market segment you should address it to and you address it it changes in our case in the case of ai we have to ask the fundamental question given a user given an item what is the relation what is that function we need this function f that predicts that gives given a user i given a item j item j you need from this tuple you need a function that goes to a rating right and the rating can be just boolean or zero one one of these two right either it is a number or it is just zero one boolean but you need some function that does it accurately. Now always in machine learning when you make prediction, the question comes how do you improve the prediction? So you can start with some prediction, then look at the data, train, learn from the data, and then you can improve your predictions. And now one example that I gave why this sort of thinking is more important is that, what was I said, that if you have just, and many things affect you, like one simple intuition is, suppose you have, you ask, what is the likelihood that a random person visiting a store would buy a printer? would say probably very low right very low but on the other hand let us say that you knew that the user has just bought a computer now you know that the probability that he would buy a printer begins to climb up the a post your probability is much higher. And so people have done things like market basket analysis and so on and so forth. So that kind of things that we are going to do is much more involved here. It's sort of these days quite a bit, we still do market basket analysis, a priori and so forth, very effective, but this is a slightly different set of techniques. Content-based, so they are fundamentally two kinds of approaches that people use to do this one in from an ai perspective you can use what is called content filtering approach or it is content based approach which i show here on the left hand side of the screen this what it says is that given the user, either use the user's characteristic or the item's characteristic to make a prediction on whether, what would be the rating of this user on that item, right? So you could have essentially, in some sense, it is a classifier problem, right? You're taking all the characteristics of the user and the characteristics of the items and you may choose only one or the other if you wish and you're looking you're creating a function of this x vector which is a your feature vector is made up of the features of the user and features of the item and you are now making a function that gives you the prop either as a regression problem or as a you know logistic or whichever, it gives you the probability of a likelihood or score of purchasing or liking that item or having a preference for that item. So these have been around. Then the other approach which is sort of the dominant and very heavily used are the collaborative filtering approach. Collaborative filtering itself comes in two classifications, the memory-based approach and the model-based approach. Memory-based is item-based and user-based. I won't review a lot of it, but basically it looks at the interaction matrix and looks at similarity between columns of items to see which items are rated pretty similarly by different users or what you know or what you given a user what other users have rated whatever they have purchased very similar to this user so you're looking for k nearest neighbor and once you get the k nearest neighbor then you can take the or take the take that and build up a recommendation system by saying, okay, these are your nearest neighbors. Whatever they have purchased, just prioritize that, rank that, and give it as a recommendation to the user. Here, the problem is performance because finding a nearest neighbor for every user, every pair of users, I mean, you'll have to do pairwise comparison. So first you need a similarity measure, a smart similarity measure, and then you have to solve the nearest neighbor problem, which is quadratic, right? Because every user I needs to be compared to every user J, and that's a quadratic computation. So people have come up with all sorts of approximation techniques, very clever ideas of how to not have to do exact comparison, this order n square problem with considerable success. So this model based approaches are here to stay, they are effective to consider. Then the other approach which we focused on a bit more is the under collaborative filtering is the model based approach. The model based approach takes away a different way of looking at things. It says that if you look at this interaction matrix, and you say that a user and by the interaction matrix, I mean the user, the user rating matrix, user rating matrix, if you take a user Xi has rated, so user I, actually let me stick to the standard convention, user I has rated an item J, item J, we are not rated and we want to predict this. So one way to do that in model is model always builds a hypothesis. The hypothesis that you build here is that there is a latent space, there's an underlying space. And of taste and traits. So items have traits and users have taste. So one way to say that is if you look at a, for example, a kitchen, your own kitchen or people's kitchen, you would have in terms of spices and grains and beans and vegetables and fruits and so on and so forth, you would have a finite number you would have a finite number of real ingredients, underlying ingredients. But out of these ingredients, you can manufacture practically an infinite number of dishes. Let's say that you can, suppose, for the sake of argument, let's say that you have 100 ingredients in your kitchen. And how many dishes can you make let us say that you know how to make uh about 10 000 dishes which is a pretty large number but for the sake of argument we'll continue with this 10 000 dishes now let's say that you you have a restaurant your kitchen serves food to a lot of people right and there are people there let's say another 50 000 people who occasionally or frequently visit your kitchen visit your restaurant for food now one of the questions that appears is suppose you can make 10 000 items they will come and say give me this you can sort of obviously up by saying, I know something else that you would like very much. You can recommend some other dishes. So how would you recommend some other dishes to the user? So that is one frame of reference I use to think about it. So, you know, but here is one crucial thing you know, underneath all of those dishes are these basic ingredients so soon you figure out that this person likes salt like things that has high salt and you know what in India you call Namkeen and so for snacky food but this person likes sweet this person like things with chili in it this person likes you know things with you ingredients. Rice-based dishes are this person's favorite, and so on and so forth. And this person is very heavy, veggie heavy, and this person likes jams, that kind of things, fruit-based things. as the ingredients every dish will have a certain amount of it and let me use that as a as a starting point and i will recap some of the things that i mentioned last time so so the basic hypothesis is that there is there are hidden ingredients in each dish that affect user preference. So would you agree with this example from experience? If you just look around this is true right and it's a hypothesis we it's a hypothesis you you take this hidden right there's a fancy mathematical term for it you call it the hidden the hidden matrixes has given been given a fancy name your hidden main ingredients is called latent factors, latent factors. I always, whenever I want to be, the mental picture that I always carry in my mind are the spices, the spices or things like that, that build up the dish. or things like that that build up the dish. Are we together? And so you can say that every dish, let dish be I, J, some dish. You can represent it as a vector. So suppose you have how many? 100. Let's say 100 spices. We agreed that our kitchen has 100 spices. We agreed that our kitchen has 100 spices. Number of spices in our kitchen. So you can represent every ingredient or ingredients, let us say, as you would say that ij belongs to a vector space of 100 dimensions. Would you agree, guys? So far, so good. Is this straightforward? And this is your straightforward and this is your dimensionality the the more formal word is dimensionality of the latent factors space latent factor space so far so good guys and now what can you do our hypothesis in this model is that let it let a user be so these are called the traits this is the trait vector ij ij is the rates vector this is the terminology people use quite often. Trait vector in the, and you can also use, add the word latent sometimes. You say latent traits vector in the latent space. Or the item. Okay. Right? So this is it. So far so good guys. In the same way, you hypothesize that users, they buy or they like or dislike an item purely based on the spices it contains. Suppose you make that hypothesis. It's an oversimplified hypothesis. Let's make it, let's simplify life and say that the taste of a user, the preference for a dish of a user is completely dictated by these ingredients, by these spices and other ingredients in the food. So you can therefore say that this also is, suppose it is, so for example here, the first one could be spicy, I mean salty. For example, here, the first one could be spicy, I mean salty. So some dish would be very salty, let's say one. And this user may have 0.3. He has some liking for salty but not too much. Then suppose this one is sweet, which is it 1, 2, 3 three four and let's say the user absolutely loves sweet right and let's say that this item is zero point let me call it seven right it's 0.7 oh my goodness it can't be both salty and sweet let's let's decrease the saltiness a little bit just to be realistic 0.4 and the sweet is 0.7 right and this person absolutely loves it to be let's say sweet or is likely to has a strong taste for the sweet as a sweet tooth simply put right so likewise you can create this vector and you would agree that in a similar way you would say this belongs to our hundred also the same space and now it is and to write it down is the taste vector in the latent in the latent space for the user. So far, so good, right? And so with these two assumptions, the next step only remains is to make the hypothesis, which is that, so what is the remaining part of the hypothesis? So let me call it part one. And from here, we go here. Let me call it part one. And from here we go here. Okay. B and part C is simply to say that the rating prediction, the rating that the user will give, let me make it wear a hat as a prediction. Rating that the user will give to, user I will give to item J is basically given by the dot product of these two vectors u i i j and you must be familiar we always we tend to use this angle brackets just to make it and then you can write it in matrix notation or u i transpose you, I J and so on and so forth. Use the transpose notation if it so suits you. But basically it's a dot product. You just multiply element by element, cell by cell. You multiply the two and you will get a rating. Now you get this rating here and whatever that number comes out to be you say that this is hypothesis is that this is the predicted rating so it now i must say that just for the for the time being and we will get into the details later it has biases one thing to remember is, we'll leave it as that. Now what happens? We have a user rating matrix. Let's just call it interaction matrix because rating may be in the case of implicit recommendation, all you know is that the user did listen to the song but didn't leave a rating right most much of the data these days is implicit and so the emphasis to a quite a bit is more these days as far as i can see on implicit recommenders quite a bit of that so this is the users this is once again the items now this is your item recommended matrix and what we are saying is at the intersection of user i and item j this particular thing this is the if a value exists this is the actual r i j right this is your target variable isn't it this it? This is the actual seen value. If a value is present, that is the value that was seen. But your model predicts that. Now the question is, how do we train this model to make very accurate predictions of the rating? That becomes the learning, the machine learning part of it. How do you make the machine learn? All the usual techniques, you can already see one way or the learning, the machine learning part of it. How do you make the machine learn? And all the usual techniques, gradient, you know, you can already see one way or the other, we have to map it to some standard thing and apply a gradient descent and so on and so forth to it. So that's the journey we'll do. But one question that arises, how do you know that there is such a latent space? How do we know that such a space exists? It turns out that that comes from a bit of mathematics that is well established. It is called and so how do we discover the latent space and because it has dimensionality is low people often call it the low rank low ranked latent space how do we know that there are many ways of doing it and in in the course of ml 400 if you remember we we have used many things to reduce dimensionality or go to lower dimensionality. And I won't recap that, but two of the powerful techniques, for example, you're familiar with principal component analysis, and you're familiar with autoencoders and so on and so forth. And then we had other techniques. So we wouldn't do that, but we know that data can be projected to lower dimension. The way you do that here is you take this matrix m and you can write m as u a diagonal matrix v transpose. Now what this is at this moment, this is called singular value decomposition and we have covered this many times. I won't go too much into it today because I want to focus on the regression part of it. So this is singular value decomposition. It guarantees that this matrix can be decomposed. And this is a rectangular matrix. This is a matrix and singular value decomposition is a sort of one of the crown jewels, a crown jewel in linear algebra. It is a very interesting result and we won't unpack it too much but just to say that here the values will be all the diagonal matrix would be matrix in which there would be values like sigma whatever k right and what happens is that when you do this kind of a thing these singular value these diagonal values they, they tend to have a relationship. It can be sorted like this. Sigma 2 is greater than equal to sigma 3, et cetera, et cetera, sigma k. But what you notice is if you plot these values, they tend to decay quite often. So you can take a very quick cutoff or say here and say beyond this the we won't consider so you can chop this matrix to a much smaller value k in the case of spices we took k is equal to 100. so for example it is telling you what spices like if there are many many attributes in the user space what is the real ingredient space of that and so when you can do that this u u it looks like this each user is represented by a k so u i is a k dimensional matrix we remember that right k is equal to in this example k is equal to 100 user i this is the this you have this matrix right user i is represented by the taste let's call it the taste user taste matrix matrix right then there is a this diagonal matrix the k by k by k diagonal matrix and then there is a item matrix which is like this right this is interesting actually the you typically think of the items also has having see you know so this is actually this is why is it this this is the matrix v transpose so what is v v is also just like this v is what are these these are your K is equal to 100. And for this, it's the same space, but you use the word traits. The traits of an item. So item J, this is the traits vector that we created a little while ago. And these are the traits. And you are basically saying that you can break this matrix up into two parts. saying that you can break this matrix up into two parts. On one side are the users and their taste and here is the items and their taste. And of course, what would we transpose do? It will turn it around and make it horizontal instead of vertical and so you have this we transpose here. you have this v transpose here, v transpose is here, right? And so you can break up a matrix into this form. The fact that you can do that is the heart of the statement that you can find. You have that lower dimensional, low rank space in which you can do that. The first paper, this particular paper used exactly this technique. But now comes the question, all right, this is all very good, but now let's find the values. How do you find these optimal values that agree with, how do you train a machine to come up with values, right? That are accurate predictions of user preference, you know, or the rating the user will give. So there we need to create a loss function. So now we will go into the business. As you know, if you train machine learning, the first thing of learning is quite often learning comes down to two steps. Create a good loss function. a good loss function function b created to gradient descent do we remember that guys this is as simple as that, isn't it? Now let's create a loss function. I will start. Typically, for example, this paper has this result. Now let's go back to this paper and see if we can step through this. What is this person trying to say? Is it legible? Can you guys read it? Yes. Yeah, okay. So this is the famous Netflix prize competition winning paper. I mean the explanation of how they did it and the crucial idea, just the crucial idea they gave. They say that, see, look here, Joe watches a lot of movies and then, for example, the user-oriented neighborhood methods. Okay, this is other methods. We'll just ignore it at this moment. We'll come to the matrix factorization method. What he's saying is, suppose your traits of the item are two things, that it is geared towards male or the opposite geared towards female. So some movies are geared towards men and some are towards women. So every movie could be put on this axis somewhere. Then likewise, you can take movies which are serious, every movie could be put on this axis somewhere. Then likewise, you can take movies which are serious, like documentaries, or very serious movies, historic significance and so forth, or value-based movies and so forth. Or you can take movies whose main point is to take you to a dreamland or give you a lot of humor or fun and so on and so forth. So that is the serious versus escapist. And these are only two traits they're taking just to illustrate the point. And by the way, in reality, the traits that get discovered are not as simple as this. They are more sort of abstract, but for the sake of argument they use this and so you can project all the movies in your in your collection onto this space then all you have to do is project also the users onto this space right so for example uh if you have a user this user let's take uh if you have a user this user let's take this particular user right what would this user like this user would like which movie if you had to just guess let me call this guy alex what would Alex like? Just from this picture guys, could you name a few movies that Alex is likely to like? Anyone? Lethal Weapon. Yeah, Lethal Weapon, Braveheart, sort of like this, right? You pretty much have something to recommend to Alex. On the other hand, look at, oh, they have actually given names, Dave. Dave is here, but this person is not named. But what would Gus like? Gus, it turns out that he would probably like these two very much and maybe this. Does this seem reasonable? Gus tends to like male-oriented escapist movies. So you can put different people as in different places. This person, let's say Jane, just give a name to that. Clearly, Jane would like this movie and the next closest thing that seems to be is this movie. Isn't it? Sense and sensibility and so forth. So that is the main intuition, what I explain in terms of spices is here. Now, let me give this a little bit of explanation. So in this one, what I call user I, they call QI in this paper. I prefer user and item, a little bit more intuitive to me. PJ, they use PJ, product, user, I, item, J. That is the way to map this paper to the way we are discussing at this moment. And so what is this? R, U, I is basically this. Well, in this case, they're using this. What I would consider this is the way we wrote it is in our notation, the data says, this is this. The predicted value is user I item J in our notation, but it is exactly the same thing. This is a dot product, right? And they are saying, and so the original method this is a dot product right and they are saying and so the original method was using a singular value decomposition from there onwards uh you say that you can easily solve for this by minimizing this you see you do admin of q and p for all users such that this the optimal q and p you figure out the optimal taste values in the print and traits of items and users taste says that your predictions are always right once you figure out users taste you figure out item states from that matrix somehow and so this is your minimization problem what i will do is do you notice that this looks somewhat like some squared right does this look like a least square problem regression somewhat like least square isn't it this term the first term do you agree guys uh no one is responding. Is anybody still there? Let me see. Or has everyone dropped off? Oh, you are? Yes, Asif. Yes, it is, right? And this is quite reminiscent, if you remember, of this looks like a regularization term, right? Ridge regularization. Do you remember the lambda squared? The squared of the weights, ridge regularization. So now let's connect how in the world did this thing come about? We seem to be getting the intuition that that's what is going on. I'll just unpack it a little bit because it's very simple actually to unpack it but i have um but actually partly i looked at that and it took me a few minutes actually almost half an hour to come up with the intuition when i read this paper long long ago long time ago so maybe it is obvious to you guys it wasn't so to me. So I'll just write the explanation of how I did that. And sorry, this is the gist of the, this is where the problem comes. Let me take another color now. So how to solve that? Great. Thinking, unpacking the the loss function so product minus so this is the prediction so let me put it this way let me write it in simpler terms so that we it makes sense in the way we think about it the predicted rating minus the actual rating right right, squared. So this is your least squared error, or some squared error. And you know that you have to effectively minimize it, but with a constraint, and the constraint seems to be lambda. And here you have, again, there's a summation here user i user i squared plus item j squared now this looks like regularization term i'll just give you a simple intuition of how it is and that will also be and so this thing we can in this written as and this is your there's an overarching here the way you would do that is you would write this as user I item J this is your dot product minus our I J the actual this is, let me put words here, actual value, the Y in quotes, you know, Y in our notation. And this is the predicted value, which we often call Y hat. Remember in a regression notation, we used to call this y hat. So, or the modeling in the prior. And so this is what is going on here. You write it like this and you have this square plus lambda. And again, the rest of it is the same. This i, j. By the way, is it a plus or minus? I always tend to get my regularization screwed up. Okay, yeah, it's just, I don't know. So this is it. We got our parts right. Now what do we need to do? We need to find the minima this is a loss function and the problem statement is argmin min optimal so u i star then i j star across across all possible values of ij for this loss function. Isn't it? Find the optimal test vector for all the users. So in words, find the optimal test vector for each user find the optimal optimal traits vector for each item as simple as that now the question is, how in the world do we do that? So the method that is proposed is the alternating least square. So actually even before I go there, okay, let me go there. Alternating least square. to mating least square. By the way, now we don't just do this. We add some more terms. We'll get to that a little bit later. So suppose you have alternating least square method. What does it do? It just says... Suppose alternating least square says, and maybe i should use a different color just we are changing topics i'll take this color whatever color it is you already knew to a reasonable extent to an item ij's trait vector so you know that this is part you have so far like you're in the middle of the learning process and you have so far figured out that this is ij right so now look at your loss function. Your loss function would be given, so what is the data that you have? You have data, your equation is that user i item j, right can think of every user user one user two as far as item j is concerned it can be written as for this particular thing you can write it as um u i user i call zero user i call zero item j zeroth you know the zeroth basically uh let me just write it as that some alpha one alpha one and item j's j's zeroth component whatever it is item zero j zero plus alpha two or maybe not even alpha weight weight 1 or beta 1 remember in the in the standard regression notation that we use beta 1 beta 2 beta 2 and the value item j 1 and so on and so forth right so and what you say is that this dot product is equal to the rating of the user one with respect to item J. We are just looking at item J. Do you see this problem, guys? This is your X1 or let me just call it X1, X2, Xn. So what we have is an equation for the user one of our user i let me just use the word user i i1 x1 plus beta i2 x2 plus beta i3 x3 is equal to the data rij which is basically your y i right given the fact that j is fixed it is basically your y i what are we looking at guys solving this problem is a problem of just regression isn't it does this make sense guys this is simply a problem of regression so what would you do you would take one step to find to improve your betas by gradient descent you would try to improve your beta you you would think of your loss function to be again this term uh rating ij minus rating ij the predicted rating squared this would be your term and then what would be your This would be your term. And then what would be your what are your weights, your weights, your these are the betas that you need to regularize. So this would be over I beta I right. Beta I squared. beta i squared do you see that this is your standard here regression ridge regression that we did in ml100 it is basically coming i just reduced to that so what you do is now for each of the users assuming that items all the items value are fixed, you are basically taking one step. descent to find better beta i right beta i let's say better this is your standard this thing is equal to the previous value of beta i minus some learning rate alpha times the gradient of the loss function with respect to the the gradient with respect to the beta right you do that so you found a better and then what you do is now you have improved your taste a better guess of the taste let me put that sentence here now you have now you have a slightly better estimate of the user taste vector taste vector isn't it and what is phase two now phase two let me pick one more color. Let me pick this. These are the colors I see in the palette of phase two. You do the opposite. You assume that you know the user's taste and try to improve or estimate the items trace, right? So what you would do is you would say, given user i, what is my equation for item j? So it again becomes like this. Suppose this is your user i's taste vector is basically your vector. It becomes the beta vector now. Or let me call it the beta prime vector so you can write the rating r i j basically your y j is for this item j it is basically beta like how should i put it item j one item j one beta prime one plus item j two beta prime two etc is equal to this rating and so for this the least the regression regularized regression equation would be again the same i now we are doing over j because there are j items in your inventory and so you're doing r i j the same thing minus r i j the the prediction minus reality squared this term remains the thing and here your regularization term would be j and a beta j like you know the the beta of the j right so this is it this you are regularizing so when you take this is the phase two so here what you're saying is now keeping taste user taste values fixed we can improve we can now improve the item trade estimation we can we can do a better job of doing that and so what you do is you keep now you keep moving you keep cycling between phase one and phase two you go here and then you come back here then you go here again and then you come back here so one two three four and so forth you know or five and then likewise you keep on doing it and so forth so keep alternating between the two phases. Just to recap, phase one, improve user taste estimate. The second part is phase two, improve item rate estimate. So this is that, this is it. And so now when you put these two, the two loss functions together, the loss function, let me call it phase one and loss function phase two together, the net loss function is of course, the net loss and loss function phase two together the net loss function is of course the net loss total loss function by which is just adding the two total loss function is the quadratic term r i j hat minus r i j squared plus lambda you know the the weights of the item so item uh user i well the which was just user i square the the taste the quadratic of all the taste values just to regularize it and the quadratic of all the taste values right item j right which is the same as i j this thing is missed user i item j the dot product here minus the actual value squared plus lambda this whole term i wouldn't go over this term again maybe i'll do that u i squared plus i j squared and this is your loss this is your net loss function it is as simple as that guys so let us recap what we are saying is, there is this equation, long equation that's there on the paper. It is there on page 44 in the article. It is equation number two. And I just sort of give you an argument. It looks pretty much simple, ridge regression, but I unpacked it a little bit and I broke it up into the two phases by which this paper suggests we do it. it up into the two phases by which this paper suggests we do it. Phase one, phase two. First update. So you can start with random values and then first improve the taste a little bit, then improve the traits a little bit, then improve the taste a little bit, improve. And this whole thing converges because this is ultimately a ridge regression in a different form. And so it does converge. That is why in the early days, a lot of people used to think of recommenders as an adaptation of the regression problem. So that is that. Spark, for example, most of you are familiar with Spark and then it has a Python implementation also, PySpark is also there. You can do it in Java, Python, Scala, whatever you want. So this provides the airl it in Java, Python, Scala, whatever you want. So this provides the airless recommender literally as one of its core recommenders. So now comes a couple of questions. Some enhancements are required. Suppose you have, now I'm going a little bit beyond this paper, now there are, there is more happening, there's a question of bias and so on and so forth. Now, remember this thing needs some thinking. This point needs some thinking. See, do we want to feed in the user's rating for an item? The problem with the user's rating for an item is some users are very generous. They tend to rate items very positively. Even if they don't like it, they'll give it a three star, four star. But generally, if they even have a slight liking, they'll give it a five star. Some users are much more strict in their rating unless if they give three star to something it means it's quite good and if they get four star it means it's exceptional and so forth right so people's ratings differ not only that some items historically like the average rating they get is very high. So getting a four on an item whose average is four doesn't tell you much about the user, isn't it? So we need to remove those biases. So we will talk now, and this is, I don't know, is this, it is, I think mentioned in the paper, this is an old paper but i'll cover it yes somewhere in there is talk about biases yes there is a bias conversation yeah it is very much there equation four equation four and equation three and four do talk about biases so i'll just talk about bias a little bit so what is about bias a little bit. So what is the, hang on, let me just look at what he has here. Rating R U minus, yes, yes, yes. So the basic idea is we need to go from R I J to unbiased rating unbiased rating of some sort right rating let me just call it our IJ till day so we will go there in six steps and this six steps are important so remember those so what will we do first thing we notice step one there is global bias let us say the average rating of all the products is three out of on a scale of five it is probably not much use to remember four or five you might as well subtract three from it so that you get negative numbers saying didn't like it, positive numbers saying you liked it. Do you see the value, guys? So you can compute the average rating, the global bias, mu typically is signified as. This is equal to, for every item and for every user, you find the rating, Rij, and you divide it by n, total number of ratings the matrix that was the size of the data so this will give you is the simple, this is just the average, a simple average. You take the average of all the ratings. Step two, what you do is step two, you say rating IJ, let's say it goes, you replace it with the initial rating minus the average. So now it is centered, your values are centered. So now values are centered around the mean, zero. You make it a zero mean if you take the mean now it will be zero right because the mean of this will become mu mu minus mu will become zero so the next thing you notice that you have users now which one do you first users or items let me think through it. Let me keep that. Okay. So let's look at the item bias. Item, step three. Suppose you do item. So given an item, let's look at this, RIG prime. Every, some items are highly rated, some are less rated. What you want to know is given the average of that item is the user's rating higher than that or not or lower than that so something that everybody on average rates as four if somebody reads it as three it's relatively less like than you would expect so from that perspective you find the bias term for the item you say across all uh bias term for this for i like for all users you find the number of the number of users who have rated that item and then what you do is you add a shrinkage term what you do is you add a shrinkage term. Let me explain what this is. See what happens is suppose you have a book. It's a very popular book. So it has gotten ratings like five, five, five, four. And there is another book and so on on and so forth a book two and it has only one rating five right so do you realize that there is a problem here the problem is this rating book one's rating would be average rating would be a 19 over 20 and this sorry if you take the average rating uh one two three four five is it is a times five uh why am i getting this wrong divided by four sorry 19 divided by four by four which is less than 5 a little bit less than 5 right because 20 would have made it 5 on the other hand this is divided by 1 if you just divide by the number of ratings the average rating here would be average without average without shrinkage would be five. So which book would it rate higher, book two or book one? Clearly book two is getting rated higher as average rating. You don't want that. So what you do is you add a shrinkage term. It's just a mathematical trick and it works. What you do is, if you take C, let's say C is equal to 1. Now what happens? Here, you would say 5 plus 5 plus 5 plus 4 is equal to 19, divided by how many of those are there? Four items are there, plus 1, right? Divided by 5, right? And what about this guy book one so this would come to uh something close to let's say four i'll take an example book two becomes what five divided by one plus one and this becomes 2.5. And so we tend to like it because now, a four looks greater than 2.5. And so you say that you have taken care sort of how often a book is rated or an item is rated. You have sort of suppressed that, shrink the effect of that. So it is step two. You do step two. What you do is you find the item bias. And now what do you do now that you have the item bias? Once again, step four, as you can imagine, four is you take your previous already centered rating, let me just call it Rij double prime is equal to Rij prime minus VI the item bias you remove item bias item bias removal right this is terrible spelling removal item bias removal step now comes well that takes care of the item bias there is one more thing there somewhere in there is now we in the in a same way where is step book one book two step three you realize that we can do the same thing for um user bias for user bias. Bias of the user would be what? It would be the same thing. And now let's deal with this, R, I, J, double prime, and summed over every item for a given bias for J. User's bias. The user has rated god knows how many items and so for every item j you just go and find that and this will give you a sort of shrinkage with respect to and you just put it like this uh to get the biased term the average bias you know the some some users they tend to be very generous. The average rating is four. Some users tend to have average rating of two. So what you want to do is you want to adapt. You want to take care of that bias also. And thus you end up with the final rating, Rij, which is Rij prime minus the bias of the user. So the next thing is, effectively, what you're doing is you're doing Rij, the modified is Rij minus item bias minus user bias minus global bias, right? So you correct for all of these small biases in the rating. And this sort of a connected rating is what you train the matrix factorization method or any method after that. It doesn't matter if it is matrix factorization or neural networks and so on and so forth, right? You can train. Now, there is something else to this we have a loss function here this is a loss function one extension that we have to think about oh i notice that we have gone in for some time now i'll finish in 10 minutes so some extensions what about implicit implicit rating What about implicit? Implicit rating. What happens in an implicit rating matrix? You either know that the user did or did not listen to the song. That is it. Here is a one, here is a one that the user listened to the song. Others are all just empty or missing right so here how would you zero just means it's not there you don't have a value for it so here what you do is because it's a boolean and you know you're predicting a zero or one whenever we are trying to do that of course one trick one extension that you do is you don't just do the user i item j right but you take the logistics of this typically you apply a function that converts this dot product into a 0 1 scale it belongs to 0 1 interval typically it is the logistic function you apply the logistic function on it and it will it will then then you can extend it also to implicit rating the next aspect that comes in is what do you do this is one loss function that you have are there other methods that you can use to solve this to solve this loss function? And the answer to that is yes. You can actually use some, based on this idea, you can use, ultimately you have this, right? The Rij hat minus Rij. This is your gap. So a lot of powerful neural network techniques have emerged that we will cover in the subsequent talks. For example, autoencoders and many, many things, very rich literature that we have of recommenders that people have come. In fact, this literature in this space is so vast, I always look at it and I feel every time I look at the literature, I feel that I probably know just a very tiny little bit of the subject. There's so much and so much happening and they have so much brilliance from so many people that it's just spectacular, you know. You just try to, every time I get some time, you try to catch up to a little bit more. So that is it guys and that's it for today. If you have any questions, please ask. Was this useful uh yes as if it's useful thank you so i'll just recap what we did what we did today is one particular method we went deeper into alternating least square we ended last time with alternating least square and today i went deeper into it i said the the the basic initial netflix paper price paper was or article was it said that it based on three a hypothesis in three parts it said first that there are hidden ingredients or hidden traits that you can associate with items. In the example of a kitchen and food, I think that items are food, those hidden ingredients are the spices, right? Which the user can't see. Then all you have is the data. They said this user like this dish. Can you therefore somehow infer this hidden space of spices? Can you write a user's taste vector as a degree of taste for each of the spices? And likewise, any dishes traits as the degree to which it contains those ingredients. That's a basic intuition. This latent factor space is a lower dimensional space. Obviously in your kitchen, you have about 100 ingredients or 100 spices or so forth. And you're serving thousands of users and you can make thousands of dishes and so on and so forth. So that is the basic idea. Based on that, you have the user rating matrix, the user gifts rating. By the way, rating can be implicit or explicit you know it could be a number or it could be just zero one as we talked about so now we say that given these two the dot product of this this is the crucial point part c that the dot product of the user taste and the item um trade is basically the rating. In very simple terms, it is the, let me go back to the PowerPoint, not the PowerPoint, the actual article, which explains it very, very nicely. See what happens is that here, let me take this vector. Is there a very easy way for me to change color? I don't know. I'm scared of clicking it because I am not too familiar with the powerpoint tool here i mean sorry this adobe tool oh no i just managed to screw it up what about now okay i don't know what i did anyone who is good at adobe one of these days please do educate me how to properly use the pen tool here. But anyway, what I would say is, I wish I could do it. All right, let me do it in the writing pad in the OneNote. See, the basic intuition of Rij, when we say that it is equal to the dot product of ij, what we are saying is that that let us say that the user is here ui vector and there is some point some other point this is item j right and item let me just k k uh this is item k ik you would agree that these two points are near each other, right? So UI item J is greater than, in this example, UI item K, right? These are practically perpendicular to each other. Isn't it, guys? Are we seeing the point? Right. And what about item l or item m, which is just the opposite of what the user's taste is? You would agree that the user's preference would be IJ likes IJ, maybe neutral on IK and doesn't like I am. Perhaps, this is it. And this relationship, this nearness is captured by dot product. That's it. And that's a basic intuition for this and then leveraging that the rest of it is creating the loss function in steps and once we have the loss function we move forward and i this last function mentioned in the paper i sort of unpacked in two parts for you but by saying first keep the the taste fixed and then or maybe traits fixed improve the user's taste estimate then keep the taste estimate fixed and improve the items a trait estimate and keep moving back and forth between the two and as you do it gradually you'll converge and the equation is a very reminiscent of ridge regression because it's quite literally the ridge regression equation in two parts and that is it guys next topic we cover is removing the bias from the rating there's global bias there is user bias and there is item bias all these three biases you want to remove this is mentioned i think in the equation to the first approximation. It is mentioned in the equation three and four, right, and five as a consequence of that. That is it. It's a very simple. I hope you now find this paper, this elegant and remarkably influential thing that started a lot of personalized recommendation, you know, activity everywhere to be now easy to understand. With that, I'll conclude. I'll stop the recording and you guys can feel free to ask me more questions.