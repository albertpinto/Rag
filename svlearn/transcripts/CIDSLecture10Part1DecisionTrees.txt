 The best way that I can motivate a decision tree is with a story, which happens to be real. is with a story which happens to be real. At one time, this is a story about my friend and I'll just deliberately exaggerated for humor. So at one time, the US decided to invade some island kingdom. I believe it was Grenada or something like that the bat the entire battle lasted the war i suppose lasted okay so the entire war lasted for perhaps an hour and the idea was that u.s forces went in aeroplanes over the island they parach down, and they took over the country. So it so happened that a friend that I actually know, who was in the US, I suppose, he was airdropped. He ended up landing in a tree. And he stayed stuck there hanging from the tree till he was rescued by the time the battle was over apparently. So I will use that as sort of an example. Suppose you have this following situation. You have this, let's say that this is a region with trees and then this is fields This is fields. You would agree that in the simple example, the nature of the, like literally if this line was not there, I ask you, what are good places to drop, to parachute down to? You would agree that it is a terrible idea to drop your soldiers, if you're flying a plane, to drop your soldiers in the middle of the tree, right? They will essentially get impaired, right, in the ability to fight. On the other hand, if you drop them somewhere in the field, it's a much better choice. So if I were to ask you to make a decision, what are good places versus bad for dropping, you would say well it is very simple just go ahead and make this split right trees field and here the data is quite simple isn't it what you have done is you have created a classifier a decision boundary that splits the region simple decision boundary that splits the region, simple decision boundary, that splits the region into two halves, one for trees, one for fields, isn't it? And it need not be a perfect split. It so happens that there may be a lone tree sitting there in the field after a good friend ended up in that tree. So that is all right you tolerate a little bit of error but this is still a pretty good split this decision boundary right so what you have done and just motivating this example you have taken the entire feature space region r0 and split it into two regions R1, R2. Isn't it? Do you notice that? You have taken the entire region, which was R0, and split it into two regions, R1 and R2. So far, so good? Right. Now, it is not perfect, but how did you decide on this pink line? If you were a machine, how would you decide on this pink line? You could have said, why did I not choose, or sorry, whatever line color it is, why did I not choose this point? Or why did I not choose this as the decision boundary? If I were to ask you this question to distinguish between tree region and fields you would say now wait a minute i need some measurable way to tell that this big red line here is the best line so you could say well here is a simple measure i can just look at I can just look at, so let me take this line. Let's call this line A and this pink line B, pink decision boundary B, right? For A, I can count how many mistakes were made. sorry for a in region r1 the number of mistakes is zero proportion of mistakes is zero isn't it so the majority class is three right so proportion of the majority class is one and mistakes a proportion of the minority class is zero so you would say error rate which is the proportion of the non-majority class one minus proportion of the majority of class right in this region is whatever it is and it turns out to be zero. Likewise for region R2, which is this region R2, R1. Region R2, well there seems to be one mistake. Right? Let us say that you had 100 data points. Right? So you would say error rate is 1 minus 99 points you got right. You called it field. And a proportion of the majority class would be 0.01. So if you were to look at the total error rate, you could say the total error rate is 0.01. Isn't it? The cumulative error comes out to be, in fact, half of this because you're taking two regions, let's say. But I'll just leave it at 0.01. On the other hand, if you take the pink line, the B, the pink line, Now let's look at R1. The R1 for the pink line is, let's say this, and this, this is R2 for the pink one, decision boundary. So far so good. Now you would imagine that this would be a disaster.5 isn't it and here also r2 the error rate will be approximately 0.5 isn't it so you have come upon a metric a suitable metric to help tell you which split, which decision boundary is better, which way to split the region, the feature space, or not into two regions. I'm allowing you to split it into just one line and to split it into two. So clearly, by looking at the error rate, you can find out which is your best way to split this region. Are we together? Do we use gradient descent to arrive here? No. So how do we go from B to A? So what you do is, well, let's keep gradient descent aside. We won't get into the mathematics of it. let's just use your intuition you slide this line you slide this line start from here and you keep sliding this line all the way here right for all values of this split along the x-axis and let me just mark these axes as x1 x2 and split along the x2 axis for each of them you have to make a table of errors error rate total error rate and then find the minima pick the minima okay yeah now how do we do that so let's not let's not at this moment assume that we know no mathematics and we are just doing it by brute force. Right. Okay. Yeah. So you find it and so you'll find your perfect split so far. So once you find your perfect split you see. So now, a few things what did we do do you notice that to split the region you had to search for the split point along each of the axis both x1 x2 right so if i were to generalize it to p features of a p dimensional feature space i will have to search along each of the p axes so computationally brutal isn't it and because these are continuous variables it's a very computationally intensive you know little little dots i'll have to do i'll have to take discrete points along these lines and do the split along them and do the split so obviously this takes a lot of effort but we are not done yet now let me go to another situation it's not just error rate there is a concept of something to do with that area and the error right no so at this moment keep it simple just go with the intuition here that error rate it turns out that rate, I mean go ahead is not the best metric for variety of reasons we come to other more important metrics. Just the other way. The line will not be there to be just after the second. You mean that the line of pink one should not be the red line. Just after the second three here. Oh, on this side oh on this side as soon as you reach there the error rate on this side versus this side you already maximize no no no the look at this the moment you come to this side there are a lot of points here the lot of field points here that you are getting wrong. Okay. Yeah. So that is it. Approximately, let's stick with the basic intuition here. So I want us to draw some conclusions. So let us generalize from that. We need the following to following to a measure of error. Prediction errors. A measure of errors. Isn't it some measure then a we need scan each of the axes feature directions feature directions to find the split line remember perpendicular to one of the perpendicular to one of the axis and parallel to the rest. So if you make a line perpendicular to X1 axis, then by definition is parallel to X2, isn't it? So it's a given. You need a measure of error. And then what you need to do is scan each of the axes and then what you need to do is scan each of the axes and then see, split a region into sub regions. But then you can split those regions again, recursively you can go on. There has to be a criteria to know when to stop and we'll come to that like intuitively you look at this region and say at least on the left hand side the tree regions i don't need to split it's all trees i probably should stop isn't it but uh maybe i can further split here and box out this region further, and then I will have a better, more accurate model. So we won't get there. Now comes a third part. Since we took this as a classification problem, we can ask this question. How do you make a prediction part d in classification if i take a point let's say i take a point here let me use another color blue suppose i take a point here x1 how would you make a prediction here what would you tell this place is trees or fields here what would you tell this place is trees or fields trees and how do you say trees because in this region the majority class is trees so you just take the majority class right for classification and so i'll write the rule for classification take the majority class right as prediction, as the prediction in a region. Whatever the majority class is, it's your prediction. So that's a basic intuition. Now comes the recursive step. Let's take a slightly different example. Suppose the same region had things like this. Like I wouldn't draw this out. Suppose the trees were all over the trees, all over here. And this is all fields. This is all trees. So now, first thing you do is, and this is how you go, you find the classification error. So you start out with the region R0, base region, once again, and of course, base region will, if you, let's say that there are more trees than field points, data instances. So what would be the prediction for the entire region? Tree, right? Your y hat every time for every point x would be tree, isn't it? And this will have a certain amount of error rate, right? The error rate will come because of this region, rate right the error rate will come because of this region which is not trace let us say that this is 40 percent of the space so you will have a 40 percent error rate right so let's say 40 percent region so error error rate will be approximately 40 percent makes sense guys now let us do this exercise again with a little bit more precision this time again you find that this is the best split point the first split right and let's draw this out this is our r naught it got split into This is our R naught. It got split into R1, R left, R right. This is the left, this is the, well, right region, isn't it? It got split. When you do that, will the overall error go down, prediction error go down? It will go down because this place will be trees always, and this place will be regions, will all be planes. So the only error now that will come will be from this jump of trees, right? Little jump of trees. And let us say that this is about 15 percent of the space right so your error rate came down to so when you do it you get r left r right r left error rate is zero r right error rate is let's say maybe 10 percent okay, if you say, is approximately about 10% or so. 10% is the error rate, isn't it? Much smaller error rate. So you say the split was worth doing. Then you say, well, is there something else you can do to improve your situation? Is there something very tempting that you can do to improve your situation? Is there something very tempting that you can do staring at this picture? Top and bottom. You could do one more split this way. If I do this split. So in other words, the right hand part, if I split it in the region r right upper and r right lower this part is r right upper upper and this part is right lower this region then what will happen in this idealized situation you have this situation so now this goes, this is split here into two parts. So right upper error rate is zero, right lower error rate is zero. So is this total error rate, which is the addition of all of them, is it going to be better now? Right, naught went away you had r r left r right but now r right goes away you split it into two parts so how many regions are you left with the regions you are left with is this the leaf nodes these three error here is zero error here is zero error here is zero right so we have a perfect prediction model did you this is the journey that we went through now it did not have been perfect there may have been let's say a little bit of a tree here and little sandy spots here plain fields here it could be so there will be residual error but you would all agree that this drawing these two decision boundaries, these two splits has vastly improved your prediction model classification model, isn't it? And that is the gist. We can keep on doing it further, right? And further, I've just done it for two steps. You can keep on splitting it till you have a model where you have all these regions the prediction for any of the regions is simply the majority class in the region right so now we learned a step that you can continue splitting d is e is continue the splits keep splitting the region till it keeps going down. So what will happen is you'll end up with a tree that is pretty deep after some time. Well, in this case, it stops here. But in real data situations, you can keep making a tree that goes pretty deep. So now let me refine this. What was intuition? Let me refine it a little bit more. See, I used error rate as a measure. Error metric was? In this intuition, we always assume one dimension at a time. Yeah, one dimension at a time, always. So what happens in this is, think of it almost as your loss function right your loss that you look at sort of like loss well i wouldn't use the word loss losses are well it is related but let me just do that let me just call it the e error you need a measure for error here we literally took the most naive or the most intuitive measure literally what is the error rate in a region what proportion you got wrong isn't it it turns out for a variety of reasons and we'll see it in the in the lab notebooks why that it is not such a good measure to split on you don't want to find the place the split point which max which most decreases the error rate you instead look for another two factors so i'll just write write it down the three varieties of it one is simply the error rate right the second is goes by the name of ginini, named after a great Italian mathematician named Gini, who came up with a mathematical expression. I will write it without indices. It is p 1 minus p. We'll come to that. And there are subscripts mk,, mk, summation over mk. I'll explain what the summation is. But just error times 1 minus the error. Simply put, proportion error, right? We'll come to that, what this means. And then there is a third one, which is more information theoretic, which is the entropy. one which is more information theoretic which is the entropy right which roughly speaking is p log p right and once again the mk mk summations right and then of course a minus sign here entropy comes with a minus sign let me just put one sigma here that's what i put sigma over mk now what is this mk let me explain uh so their data will come in k classes like for example here k is equal to here k is equal to two tree versus field equal to two. Tree versus field. Isn't it? Tree versus field. But then each of the regions, you know, now we have three regions, right? One, two, three. These regions you index with m. m is the number of regions. So what you're saying is that for each region, so for each region, So for each region, region M, right, you will have data points belonging to the two classes, trees and fields, right? class compute compute either the genie or the any one of the three. But let me take genie. Genie, you realize for any class K now this term makes sense. Proportion of a K let's say K is tree at this particular moment. The proportion of trees in the region M we can compute now the moment you find that now multiplied by one minus p mk right and so the total error would be summation of it so you don't call it uh error this genie is called that there's a nice technical word for it it is the purity index genie purity index genie purity index let's take it further what does it mean so we'll study the genie purity index uh for a moment let us say that there is a region i'll just take one region m region m right let us say that we are talking about trees and fields field points suppose this was suppose case a suppose Suppose this was, suppose case A, suppose a P of tree, M tree, so K is tree, is equal to 1, you know, as in it's all tree. Right? So proportion in this region of field is, field points are 0. So now let's compute Gini. Gini for this, only for this region is 1, 1 minus 0, isn't it? Plus 0, sorry, 1 minus 1, sorry, 1, 1 minus 1, 1 minus 0. What does it look like? Both the terms have a 0, right? So you will get a 0, right? And conversely, if you had a region which was all just field points so what would be the genie purity index once again zero isn't it case a case so case a okay is the case a b and then let's take case c where let us say that you have uh 50 50. right 50 50 right so then what would be the pmb kc p m tree would be a half p m field would be a half isn't it and so uh this genie would be for this region would be for genie of c uh would be equal to a half one minus a half plus half one minus a half and that is equal to one fourth plus one fourth is equal to a half isn't it so now the word that is used genie The word that is used is Gini purity index. It is an interesting index. When a region is pure in the sense that it has members of only one class, its purity is zero. But when it is a 50-50 mix, the opposite extreme, then the Gini purity index is a half. So this is the range. It goes from zero to a half. Right. So you can say that if you take, let's say that the proportion of trees, as it goes from zero to one, this is one, this is 0, the Gini of this region, of this region M, will go as, would you agree? Achieving its maxima at a half. So its maxima is when there's most impurity. In other words, the things are mixed up, you have half of one and half of the other. Isn't it? So which is why while the name is purity index, as a mental picture, at least I tend to in my mind, add in impurity index, it actually measures the impurity rather than the purity means the more impure the more it tends towards half isn't it so this is the genie purity index formally with i often refer you'll often see me uh refer you use the non-standard word genie impurity index me uh refer you use the non-standard word genie impurity index it's a measure of the impurity in a place go ahead please can you do some intuitions it's very easy see in india now it is no more true because India has become a much more prosperous country. When I was growing up, the food scarcity was a genuine problem. Femines were known. They were still there when I was young. I don't think your generation has known about femines in India. India has prospered a lot. has known about famines in India. It has prospered a lot. So what would happen is, one, you could quantify how much famine the country was suffering from by a very simple measure. Go and buy wheat or rice and the proportion of stones in it that are mixed in and dirt that is mixed in with the wheat would be a very good indication of famine right you see that so the proportion of dust in it let's say that suppose the wheat is wheat then what is the genie index zero it's pure but the more stones that you find in that mixed up, the more you know that it is impure, right? Up to a limit because nobody would be so blatant as to make 50% stones, right? It wouldn't sell. So people had certain degree, the businessman had certain sense of reasoning that up to one fourth or whatever they could make stones. I don't know if anybody remembers the history of or has experienced this. Anybody here? You have? Yeah, I remember my mother used to buy the bags of the used to have a helper who would come and saw that. Yeah, shifted through the stone and the wheat right and that is it so that is your intuition for a genie index right is it like variance uh there is no variance uh when when all when all the data points are of the same class but no no no uh yeah you know see the word in the literal english sense is true mathematically variance is for real variables no continuous variables here we are talking discrete variables okay you just reminded me of bernoulli variable and its variance it is very close to that right it's somewhat related to that but but not that. It is actually a simpler concept, proportion of basically impurity. Suppose it's supposed to be mostly wheat. How many stones are mixed into my wheat when I buy it? That is a very basic intuition of the Gini impurity index. All right. Okay. yeah. So in other words, how annoyed will you be when you bring that beet home into your kitchen and have to look at, stare at it and realize you have a homework to clean it up. Right, yeah. That's it. So did we miss a step in the two steps you mentioned that . Go up, huh? Yeah. Okay. in the two steps you mentioned that go up okay over here um the b1 you said scan each of the axes to find the split line for the nuclear spread and take the classification right yeah over here don't you have to go through each of the axes yes yes that is why yes that's why i said scan each of the axes? Yes, that is why. That's why I said scan each of the axes. Keep on finding the best split along each of the axes and compare the best of the best. Compare the best of the best, then you go to the next one. Yes, that is it. So that is implied. That is implied. Yes, that is it. So guys, did you get the idea of that? So just to reiterate this point, and now we'll go to other one, Ginny. So there is another index, which is the entropy. Let's look at what entropy behaves. For a region that is pure, so this is summation over mk, but since we are looking at m is fixed here for the same abc what is the entropy of a a is pure trees so proportion it is again minus sum of so a proportion of trees proportion in the region of tree times natural log of proportion of m tree right minus proportion of fields points log of p m field right now in region a how many what is the proportion of tree one so this becomes if i may here write it of field points zero zero times log of well zero now log of zero is of course minus infinity but unfortunately is multiplied by zero you multiply anything by zero you get zero so this goes away what is log of of 1? 0. So this also 0. It goes to. So entropy of A, 0. Isn't it? Likewise, if it was all fields, entropy, likewise, you can argue that entropy of B is also 0. entropy of B is also zero. Is also zero. On the other hand, when it is 50-50 mix, right? As mixed as it can be, entropy of C. Let's figure that out. out entropy of c is equal to minus a half times log a half minus a half again because tree is half right for trees for fields isn't it and now it's interesting log of a half is a half times plus log of two plus a half log of two and so this becomes nothing but log of two natural log of 2 right so e to the power what is equal to 2 i believe it's 0.8 or something would somebody please do that for me natural log of 2 is 0.893 0.690 0.7 okay so this is approximately 0.7 right so what happens is and once again if you look at this if you look at the function x log x you realize that x this is again a smooth function and when you plot plot it out, it also looks, guess what it looks like? Isn't it? Right? And this will achieve it at your, this value is 0.7. This is a half. This is zero. This is one. So Gini and entropy, they are very similar behaving, isn't it? They are more robust measures than just the error rate, but they look very similar. And actually, numerically, when you build a decision tree, you have a choice of using GINI or entropy. It becomes a hyper parameter of the model, which impure it, which error metric you take isn't it a pick an error metric. The older software used to have preferentially Ginny as the default. Scikit-learn I don't know which one has it as a default, or for whatever reason, if I tend to use entropy as a default. But I don't think it terribly matters. You can always cross-validate and check which is the best hyperparameter here, Gini or Empiri. The differences are very small. Most situations, the differences won't matter. So now comes the interesting part. One question we left unanswered is, when and how do you stop splitting because in theoretically you can keep splitting till each point is a region when each point is a region what is the impurity zero right but surely you don't want to get down to that point you need a stopping criteria and there are many stopping criteria out there you need one of the common stopping criterion is to say when the number of points in a region so let's write it down stopping criteria split So let's write it down. Stopping criteria, split stopping criterion. What all it could be? Well, since it is plural, I'll just make it criteria. It could be, the simplest criterion could be make a tree of depth less than equal to some d. You can say that as you go r0, it becomes r left, r right, and then r right. This further becomes r right upper, r right lower. What you do is you stop. what is the depth of this tree? Depth is two. In other words, the maximum edges that you need to traverse to reach a leaf node, the maximum number of links in a chain that takes you to a leaf node is the depth. Here the depth is true. So one simple thing is just don't split after you have reached a depth of say two or three or five or ten or whatever it is. You limit the depth. It's a pretty common strategy that is used the other thing another good criterion could be the number of data instances in sub region rm right the number of rm is lower bounded number of RM is lower bounded. So in other words, number is greater than, equal to some threshold, say 10, 10 points, let's say, say 10 points. So if a region has less than 10 points or 10 points, don't split it. That is it. You must have 10 or more points in every region. So that's a very simple stopping criteria. The other criterion that people use is they say that every time you split, see, your net error is decreasing. Suppose you're using Gini. The overall Gini of the model is decreasing, is becoming purer. The impurity is going down. Or if you're using entropy, the entropy is going down. But after a little while, what will you see? A point of diminishing returns. In the beginning, the initial splits will cause a big improvement in Gini or entropy. But after that, there'll be like small, small improvements in that. So point of diminishing returns. What do you do when you reach point of diminishing returns? Remember your Elbow method? Kicks in. reach point of diminishing returns remember your elbow method kicks in so see stop splitting when you reach a point of diminishing returns diminishing improvements on further splits it should be reminiscent of the elbow method right the end result of all of this, you can pick your path to build a decision tree like this. At the end of it, you'll end up with a tree. This entire thing is a tree tree T. Right? Tree T. The number of nodes in the tree, so there's some convention, number of nodes in the tree, in the tree, is denoted as T. R is denoted as T, parallel bar, like a T wrapped up in parallel bar. So the number of nodes in a tree is often a measure of how big a tree you have built. Alternatively, you could just go and count the number of regions you have ended up with. It's more like how many sub regions that you have created. Very complex trees will lead to very fine grade little regions. So this is the process. Now for those of you who have a background in machine learning, you would realize that this is a greedy algorithm, right? This is a greedy, re, right? Why is it a greedy algorithm? Anybody would like to volunteer an answer? Why do we consider it a greedy algorithm? Come again? Short- Short- Short- Exactly. Very good. See, every time you're looking for a split, you're making a locally optimal decision. At that level of the tree, at that level of modeling, what is the best possible split? You're not asking for those splits which would be globally best. You're not saying, what is the partitioning of this entire space that would truly give me the lowest error, right, or metric or Gini or whatever it is. You're asking at each step that which reduces it now. Now, greedy algorithms always have a problem. A whole series of local optima decisions do not necessarily yield a global optima decision. Let me say that again. Greedy algorithms have a problem. A whole series of local optima decisions, based decisions, do not necessarily lead to a global optima decision. In particular, in the case of decision trees, there is no guarantee that the splits that you did into whatever number of regions that you built or notes here that you have in the tree you could not conjure up another tree with that many or lesser number of nodes which would have the same uh guys just wait a minute there's somebody here could somebody check why what he wants if you could just step out and ask him car wash he's gone okay they're doing a car wash a little strange that somebody would just enter this place without warning. But anyway, so greedy algorithms have this property. You don't know that you can't create a tree with that many nodes or lesser number of nodes, but with a different topology, different way of splitting the regions, that would not actually give you a better global minima. And I will end here with the note that actually, very, very often, you can find another tree with that many or lesser number of nodes, a different way, a different region, geometry of regions and sub regions that would actually give you a better predictive model with less error, less errors, prediction errors. So that brings us to the question, how do we find that? How do we find that? You cannot just randomly try out every single possible combination, randomly go about splitting the space and doing things. That is not practical. So there has to be a systematic way to at least strive towards getting to what may be a globally better solution than the one that you arrived at by just the greedy algorithm. To do that is to use a process called pruning. You prune the tree systematically. And when you prune the tree, you prune it in such a way that now you're not using the greedy algorithm or sort of using a different approach, but it basically prunes the tree, and you end up with a combination of regions that is generally better. And one of the things that happens when you prune the things is, remember, when you go down, everything is boxes. You don't have L-shaped boxes. You don't have regions that are, for example, merged in such a way that their shape is anything but a rectangle. But imagine that there is one box like this and one box like this, and you erase the boundary between them. You merge these two. Now you'll, for example, have an L-shaped box and different shaped boxes like that, U-shaped box, whatever it is. So there is a potential that you'll come up with a completely different geometry of splits when you do the pruning of a tree, right? So let's take a five minutes break. I noticed it's break time. Again, let's limit it to exactly five minutes and no more. Come back and learn about the pruning of trees. So we now move to the topic of pruning. Why prune? Pruning of trees. Pruning of trees. The purpose of pruning is to address the fact that the tree construction was a greedy algorithm. Greedy algorithms have, they end up with often globally suboptimal solutions. You need to do that. So pruning has many, many ways of doing it, what you do is and we won't go into how it is done in too much detail. Vipul Khosla, Ph.D.: But i'll just mention the fact that it needs to be done in decision trees, what you do is suppose you have found the total error he, this is your Jimmy or whatever it is, he can take it, then you put a regularization term which basically says alpha is the pruning tuning a pruning tuning parameter parameter so for different value what happens is that the way this machinery grinds itself and we won't get too much into detail is for different value, what happens is that the way this machinery grinds itself, and we won't get too much into detail, is for different values of alpha, different nodes, and what you do is you find the weakest nodes. So you say that suppose I have a region here, and these two split nodes are there. these two split nodes are there if it turns out that if you split this note and your total error actually uh does not it has the weakest like the least increase right or the best uh the the best benefit that you get in this then then you go and do that. You keep removing the weakest link. So I'll just keep it as a very high hand waving arguments because I don't want to go into technical details. Why I don't want to go into technical details, you'll see shortly. So there is a way to prune the tree, but when you do that, what can happen is suppose that you have a region like this and you erase this too, and you erase this. So what have you ended up with? You have ended up with a region that is now like this. Do you see that? You can end up with regions that are not shaped like rectangles. Go ahead, Premjit. So how do you, so you're using a two-dimensional plane for description. And there was some kind of an adjacency which is visible. Right. But if you're using a two-dimensional plane for description and there was some kind of an adjacency which is visible right but if you're in n-dimensional space adjacency is always yes yes adjacency between rectangulars splits is always guaranteed right those would be rectangular cuboids right solid regions they're connected through one of the dimensions. That is right. They will always have a joining hypersurface. They go right up and down the . One example that I often think of is Tetris. When you play Tetris, you often colored blocks and then there'll be another block of the same color and you'll see that they have joined themselves and so on and so forth so somewhat like tetris you do a pruning of them yeah and dimensional tetris so you do that you prune the tree and ultimately you end up with a more optimal tree it isn't that you'll necessarily know the global optima or maybe but it generally improves the tree quite a bit the The prune tree is supposed to be better. Now, when you prune the tree, you don't use the same metric that you use to split down. If you use Gini to split down, use something else to prune it back up. You have to change the method. That's right. So remember I said that while while going down while splitting it is better to use genie or entropy they somehow work better than just the error rate it turns out that when you go back up pruning the simple error rate is actually a better way to prune the tree. Using error rate as a metric, you're much better at pruning the tree. So this is one thing to keep in mind. So it's just the machinery of it. And there's some details about it, which you won't go because we have a lot to cover. Why am I not worrying too much about building the optimal decision tree the reason you'll learn shortly so when decision trees were created you realize that computationally it's a bit of a beast you have to go scanning every see at one step you can only split one of the regions so suppose you have 10 regions and the data is in 15 dimensions you have to do for each of the 10 regions, you have to go along each of the 15 axes to find the best split point. So you're finding the best split point along 150 sort of lines or surfaces, isn't it? It's just pretty computationally heavy. And that is just doing one step, right? One split, and then you split again and split again, and you keep on splitting. And so what happens is that decision trees traditionally lead to very complicated, right? Partitioning into sub regions. Just the visualization of it looks complex. So that is something to be aware of. There's a computational cost to that, right? The other problem with it is that it tends to overfit the data. Even after pruning, it tends to still overfit the data. Between the bias variance trade-off, if you try to reduce the variance too much, like the complexity too much, you end up with buyer-sellers, right? So it's a little hard to just, you know, deal with that problem of high variance or overfitting with decision trees. It's always been a problem. And a couple of other aspects, but principally the major advantage of a decision tree is the sheer simplicity of the model look at it would you agree that you can explain this model to just about anybody right you are saying hey if your values are here it's it's all trees if it is here it's all trees if it is uh in the in that field region it's field and why just look at it so far so good but you have to explain to somebody why those bricks were done the left and right yes you can explain that you can explain that you can just visualize it sometimes and just show that look look here this is mostly trees you can explain to somebody and then you can say mostly field but further split it out and you say lower all trees all field so people know why your point which happens to land here happens to land here why are you predicting it to be a field isn't it the interpretability is very high in theory in practice what happens is when you build a decision tree that's very fine-grained you look at it and you go, ah, right? It's gotten too complex, but still some people like it. So that is one advantage of. Just using the loan application to, they need this level of application to show why a loan was accepted or denied. See, I'm not very familiar with the loan industry, but if you happen to know it is like that, I would say that is correct. Using a decision tree is sensible. It's a very interpretable model. You also know, by the way, the unfortunate reality is loan giving is very biased. Just so much as walking in with a brown color or a dark color decreases your chances of getting a good interest rate right so i mean reality is slightly different from the theoretical stuff but i would imagine that a decision tree would be a good case interpretable model for giving loans so all right so you say all of this is wonderful we can do classification with decision tree, what else can it do? Well, it turns out we can do regression to the same arguments that we use for classification, we can use for regression. How so? Let's think about it. For regression. regression regression so suppose you have a region so let me take a similar situation and change it a little So imagine that you are it's winter right and it's very cold, and you are being dropped somewhere, and let's imagine that there is there is a forest here. here, a chump of houses, one house or more house, which has heating inside it. And then there is an open field. Let's take an approximation. And it's a windswept land. And this is dense forest. Imagine a tundra or a tiger forest close to Alaska or Canada. So let's look at the heat, the temperature. Our target variable is temperature, right? And this is your x1 axis, this is your x2 axis. These are the two directions you can go to. Would you agree that this would be the hottest region, the house? There is a nice good heart going on, hottest, warmest region. This would be maybe moderately warmer than the, this will be the coldest plain open field windswept filbert's now terribly cold isn't it and deep in the dense forest where things are decaying and you know humus and so forth and wind doesn't penetrate through let's say that it's a bit warmer so you would agree that y is a function of the x vector at every point y you can predict the temperature isn't it so you're supposed you're supposed to build a model that predicts temperature in this area everywhere right so how would you do that the The first thing is, you would say, all right, let's have an error measure. For regression, the most obvious error measure is some squared error, isn't it? So what do you do? So let's take this region R0, which is the entire, this field, this entire land with forest and houses and fields. this entire land with forest and houses and fields. And one easy prediction is you take the all the data points that you have, you to the average of all the y i in the region R0. Take the average. This would be a pretty good prediction, isn't it? For the region R0. Would you agree? Just take the average temperature of all the data. And that is the only sensible prediction you can make for the entire region. And when do that it turns out that oh goodness is minus 20 degrees fahrenheit or something right and those of you who have lived in northeast close to the canadian border will attest to that right it's very very cold then you say well you know we can can we improve upon this prediction model we can right what can you do how can you improve upon this prediction model split it so the most obvious split is this because if you split it here what happens this is the rss of let me just write it, RSS. So let me just use this. So let me just use the word E. What is the error of this? It is yi minus this yi hat, right, squared for the region r0. Isn't it? This is your error. Would you agree that if I split it and let's say that the average here is Y average for forest, Y average for open area, right? And let's say open area plus house, because at this moment, you haven't split in the open field in this. That the, if I want to point, find the value here, I'm much better off using the split value, the value of the open field, isn't it? So if I use this red line, then I would get an error. Let me call this region now. R1, R left and R right is equal to yi minus yi in the yi average of the left region square plus. square plus and of course the summation over i summation over j y j minus y j of the right region the forest region squared all the points in the forest right so the prediction the this is basically the error total error in making predictions isn't it because what's your prediction your prediction is just the bar the average in those regions right and so that is your error and you would agree so this is the error after r1 r r left r right after the first split i will call it the error after let me just call it error one let me just call it error zero this is after the first split would you agree that e1 is less than e0 substantive substantially when you look at this figure you can say well that is good now what can i do once again you can go scanning the axis and you might come to the conclusion that guess what? One further split might do even better. Let us do this split. Right. And then you may have better predictions in this region. Let me take this point X at X. The prediction would be better if I add the second split also. But then you realize you're still far from the heart, the house, maybe two more splits are called for. You see that right? And so you can keep on splitting and so long as your net sum squared error, the total errors of all the errors added up, it keeps on decreasing right but soon you'll reach a point of diminishing returns you would know that now is a good time to stop you can use one of the various stopping criteria criteria one criterion can be no you cannot have less than 10 points let's say whatever number of points min points or the other is you don't want to make a tree deeper than a certain depth, right? And so on and so forth. So I won't go further into it, but I hope you agree that what we did for classification, the same activity we can do for regression, is just that our error, the quantity that we are minimizing has changed. It has become some squared error, isn't it? has changed. It has become some squared error. Isn't it? And that is why decision trees are often called classification and regression tree. It can classify as well as regress for you. Do regression for you. And the word is cart. This is a very coarse grain regression. What I mean by coarse grain is like, I'm trying to estimate, you'll say, the average income of a person using things like his race, educational background, and all that to get to the average income. That is true. See, ultimately you box a data point in, a person in, into a neighborhood. And you're basically saying that neighborhood is a region and you're taking the average of that region. That is what you're doing. And that's what decision trees are. They're basically that. But unlike a K-nearest neighbor, you don't have a model. You keep all the data points in memory and you find the shortest neighbors here you don't you pre-compute your regions and so all you ask is which region does this point belong to right whichever region it belongs to you just take the average there average prediction there and you don't need to just do average you could do median like for example if there's q in the data you could take media and you could take something else but pick a measure right picks pick some aggregate stat to do that so this in sum is decision trees decision trees are great highly intuitive their main problems is they overfit right they have high variances this has traditionally been hard to get rid of people People have tried all sorts of tricks. And then came a radically different idea that we will discuss. That idea said, if one tree is good, more trees are better. But the idea goes beyond trees. It goes to all algorithms actually. And that brings us to a completely new topic called ensembles. The ensembles. Ensemble method. ensemble method people also call it the committee methods right or often people colloquially say that basically the intuition comes from the wisdom of crowds Wisdom of crowds. So I'm going to take a small digression into the wisdom of crowds. It's sort of not directly related, but just humor me. The wisdom of crowds, I always feel tempted to talk about it in this context of ensembles, what could argue that ensembles are something very specific, but I still like to bring it in the story. So what is the wisdom of crowds? We have all heard this phrase at some point. There was a lovely book actually, whose title is literally Wisdom of Crowds. I believe it's 2006 or sometime it was published. If you get a chance, do read that book. It's a lovely book, absolutely lovely book. And it tells many, many stories. Among the stories that it tells, and I'll start with that and you'll see why it's sort of somewhat related to what we are going to learn. So Galton, remember the Galton of the regression towards the mean, Galton? The great Galton of the regression towards the mean? Galton, the great scientist whose work we studied. He used to go to country fairs. Now country fairs in England were quite common and very much like the country fairs in India, what are they called? Mela or heart. In Northeast they're called heart and usually use the word Mela. When you go to those country fairs or Melas, you often find lots of things to eat and lots of things to have fun with, enjoy rides and whatnot. But you also see people selling, at least in England, selling livestock. Farmers would sell each other sheep, hens, chicken, goats, whatnot, cows, whatnot. So in England, apparently there was a custom to, there was a butcher shop that would be trying to sell meat. I don't know which animal it is. I would hazard because England is very beef heavy. It could be a cow or maybe a pig or a goat or whatever it is. So let's take some animal, that four legged animal that is heavily consumed in England. So the butcher used to, sheep, let's take sheep. Sheep is also very common in England. This is sheep. I forget the exact details. very common in England. This is sheep. I forget the exact details. So the sheep, the butcher used to obviously wanted to market his shop. So he came up with the ingenious trick. He created a lottery and he said that whosoever can predict the dry weight of the sheep after it has been butchered and cleaned out and who can make the best prediction of the dry weight, would get a prize. So we'll create a jackpot. Everybody would contribute, let's say a shilling, right? In US terms, let's say a dollar or something like that. Lots of people would contribute. Then, well, obviously after the sheep has been slaughtered and cleaned and all of that and hung, dry weight is what is the weight that you can actually sell, the meat that you can actually sell. But then whatever that, whosoever's prediction is most accurate, will get that, will get that jackpot. Obviously it's a great marketing trick because now everybody is interested in your shop and wants to bet, right? Galton did something quite interesting. He would go in at the end of the day when the lottery was over, he would pick up those little chits in which people had put their names and the predictions, guesses, he would pick it up and then he would make tables of that data, true data scientist spirit at the end of it. And when he did that, he observed something quite remarkable. He observed that pretty much the average of those values was often uncannily close to the best prediction. Right? Uncannily close to the best prediction. And sometimes it even beat the best prediction, right? Uncannily close to the best prediction. And sometimes it even beat the best prediction, right? So he thought about it, why it happens. And then he realized that what happens is we all carry in our mind some information when we make a guess. That guess is a composite of the information, the experience that we have, a place of bias that adds error. Somebody is too optimistic, he'll exaggerate the weight, some will underestimate the weight. Right. But what happens to errors? Errors have a bell curve distribution, roughly speaking, isn't it? Gaussian distribution around zero. So gradually the errors will begin to cancel each other out. The average error will be 0 roughly. But the true information that is there in everybody's guess that will stay isn't it? It's a very intuitive way of when you take the wisdom of crowd, when you take the word of, you take the answers of a committee, you're often very right. Right? Are we together? In fact, people have often made this as one of the arguments in favor of democracy. There is a this, by the way, is a mathematically established, you can establish it, you can prove it. It is called the theorem of this mathematician, I'll forget it. Anyway, it's there in one of our Jupyter notebooks notebooks i'll be handing out to you um it is a proven that committee vote generally beats generally beats uh individual predictions tends to beat individual predictions because of the fact that errors cancel out and signal stays so we'll leave it as that now this has a long history you may not believe often say, have you ever heard in politics people saying that countries should be ruled by some bright people, wise bright people, right? But it never works. People have tried that. You cannot create governments where all the decision making power is concentrated in the hands of some people who are deemed to be smart or wise or something like that. Generally it fails. In fact, the converse is true. Gibbons wrote, spoke about the, he wrote a big set of volumes, decline and fall of the Roman empire, in which he gives many reasons why the great Roman empire failed. It is a case study of power emergence of umpires and the decay one of the reasons that he tellingly speaks about he said in the roman empire at the end of the day power was concentrated into the hands of very few decision makers and therefore the decisions that began and you could see the decisions that began to come forth, were not the wisest or the best decisions. And it began to, the empire began to crumble after that. So it's the opposite of wisdom of crowds. It's the folly of a few. Because their biases then rule the thing. thing comes in have you heard the word group think sometimes very dubious facts become uh self you know they're assumed as self-evident in a group of people right in management it's a big problem of course any uh well-established group that you go to sooner or later that you'll find that that group of people in the company believe something which is actually can't be proven. And they strongly believe that. Grip thing comes in and then it screws things up. So wisdom of Kraut says, what if everybody could make independent decisions and you take the average of those decisions, free thinkers. The important thing is free thinkers. So to this, I'll add another story also from that book. So it has to do with losing things. So I'm a master of losing my keys. Today morning, I spent the better part of 25 minutes, 20 to 25 minutes, searching all over the house for the keys to support vectors in my car, right? So it's a nuisance. I tend to lose keys practically every day or something every day. My cell phone, I lose every day. And so I started using tile, but what happens when, is it? Tile is the same thing. Tile is the same thing, yeah. So what happens is cell phone can find keys, keys can find cell phone, but I tend to lose both at the same time, right? So then I get into trouble. trouble so you know uh losing things is a nuisance we all lose little things and uh deal with it yes right but one fine day apparently the u.s navy managed to lose something a little more important they managed to lose an entire submarine right now how in the world do you lose an entire submarine? Of course, and that was in the white Pacific Ocean. It so turned out that the submarine got into some technical problem and the last signal that was received from the submarine could have put it in anywhere in a few thousand square mile area. It's very hard to tell. Now, if you look at the Pacific, especially the deep end of the Pacific, forget about a few thousand square miles of area, even a few, even a thousand square meters, or even a few hundred square meters of space is hard to find things in. Because you have to, it's very expensive to go down deep and visibility is poor and at the end of it you better strike what you're looking for it'd be visible very nearby you can't see it so the experts were searching for it everywhere and they couldn't find it so then it turns out that in one of the ships a sailor sailor, who also had a background in mathematics, he had an idea. Now, what do sailors do? What do Navy sailors do? If you ask the common man, they say, those brave people are defending our country, which definitely they're doing, the great patriots. When you ask actual Navy, so Navy, Navy fellow, which I have asked asked i have some in my family in the extended family they'll say it gets boring so so so we keep placing bets either playing games or gambling and and of course the booze right so uh so he he called up a little game. He said, let everybody predict where that submarine has gone down. And whosoever's answer comes out to be right when the submarine is actually found will get the jackpot. It is immediately enticing to, if you're a sailor, you'll immediately fall for the bet. And you will, of course, like every sailor, always knows the correct answer. We have strong opinions, so you would put some prediction there. He took everybody's prediction and he did an analysis of that. And he came up with a location, went to the admiral or somebody and said that, okay, look here. They actually pooh-poohed him. They said, forget it. We have deep experts looking for it, big experts at finding things at sea who are searching for it. And so they actually ignored the prediction from the way the story, I remember it. After a long, long time, the submarine was found. And in the vast stretch of thousands of square miles of the Pacific, it was found a few hundred feet from where the prediction was. Isn't that amazing? So if they had actually gone down there, they would have seen the submarine straight on. So this, again, is the uncanny power seen the submarine straight on. So this again is the uncanny power of the wisdom of clouds. So to illustrate that I will illustrate that with a real example, an experiment here. I did this experiment with almost every batch and I'm going to do it with you guys. I want you to guess who is this jar of stones well the number of people in the class is very small so there will be some statistical error but here is a jar of stones you cannot count it but i want you to guess exactly how many stones there are you can call it you can call it spend as much time as you can then pass it to the next person and guess the number of stones in it and with at the end of the session you will find the right answer so we'll start with you know them but those of you who have taken this class with me before, just to let you know, I've changed the number of stones. All right. So those of you who are remote, we are doing an experiment. There is a jar of stones. Everybody is getting a chance to touch it, feel it and find the right answer. Guess the right answer and then we'll see whose answer is closest. Show us the jar once they are seen all of them are seen it yeah sure in fact i can show the jar to you right now sachin would you please show the jar to people for a moment in the camera and guys you also can guess please all of you who are remote try to guess here is the jar of stones all of you who are remote try to guess here is this jar of stones nobody can open it it's full with stones let me give you the height this total height is about six inches it is square base right and yeah four five inches square and about six inches five six inches high this is it and it's filled with nice pebbly stones your job is to guess how many stones there are in this jar all right so i will come up with the number right remote people are entering in chat. Yes. And one of you, could you please? Kyle, could you please take down the answers that are coming through in the chat? If you could get them. Yeah, sure. Oh, good. Apparently, the aux, it was out by a bomb in the story yeah in the story yeah so anyway so that's the wisdom of crowd so what it tells you is that you should trust the wisdom of crowds it is a known thing today that it is better to take the opinion of a group of experts than to listen to one super expert. Super experts will be opinionated, they'll lead you astray. Don't. Create a committee and take a committee vote and it's mathematically rigorous that you'll get a better decision, right, generally. Now it doesn't always work see what happens is uh for example if you took galileo and a committee of other astronomers and asked does the earth go around the sun or does the sun go around the earth right it would fail because except for galileo everybody else would say well the sun goes around the earth isn't it so you have to be careful what is it that you are doing don't don't have blind faith in it right there is another way that it fails and that is crucial to the discussion we are taking if the people are correlated their opinions correlate their answers get correlated then instead of wisdom of crowds you have the madness of crowds you have the hysteria of crowds right that's how rights come about example let me illustrate that with the point. See, if you look at elections, democracy is premised on the fact that it's wisdom of crowds. Let's find the best guy. And everybody's opinions counts. Right? So if all of us were given facts and we would go and the same thing and we sat down and thought about it and we came up with the independent opinion and voted, it would be lovely. What really happens is, what happens before an election? All the candidates, they go on a massive campaign, political campaign, right? What do they do? They show TV ads, they show this, they show that. What are they trying to do? They're trying to give a selective presentation of facts so that obviously good part is that they are trying to make people aware of political issues. They may not be interested, but the other aspect is that they're biasing them, giving them a set of information or a perspective so that a whole group of people will have the same opinion, and presumably the opinion to vote for the candidate, isn't it? So there what happens, you lose the independent thinker criteria, which is central to it. This doesn't work, wisdom doesn't work, if all the members of the crowd are not independent thinkers. Now they have become all correlated because they have been exposed to a certain set of facts and opinions, isn't it? And you deliberately bias them, you make sure that they all come to essentially the same decision which is to vote for them right and the other party will do a similar thing right so somewhere along the way the truth becomes a casualty and then wisdom of crowd doesn't quite work and the evidence of that is look at the clowns people are bringing to power all around the world right so you see that uh putting it very bluntly so then it doesn't work right so it doesn't always work all the time ask this question are the people's decisions uncorrelated they must be uncorrelated if they are correlated it fails immediately right And the other is, do they have sufficient data to make the right decision? That is the other criteria. So for example, in the case of Galileo and his peers, if they were truly making an opinion from data, from data, they presumably would have agreed with Galileo. Isn't it? But they chose not to see the data or interpret it, or they were scared of the Pope and the government or whatever it is in those days, early Renaissance days. So that is important. So each person therefore has to be a learner has to learn from data are we together has to learn from data and learn independently or i'll put it this way each of the learners must be independent learners from data they must learn from data not just have an opinion because they have an opinion right that has no meaning you must learn from data and the then the wisdom of crowd works let us bring that down to machine learning now see the way you do is that you take a committee or a lots of learners you take a decision tree you give it some data you have it learn you take a committee or lots of learners, you take a decision tree, you give it some data, you have it learn. You take another decision tree, you give it another sample of data and you let it learn. And so you keep on doing this process. So we are making baby steps there. So what will happen? You know that decision tree has a problem it learns hard means it just goes and overfits to whatever it sees if you don't prune it if you just let it just go down it will make a nice deep tree and just go and fit hard to the data right so it is not able to distinguish between what is signal and what is noise. But you let it do that. But guess what the other decision tree, the other learner would have fit to the data differently, because there, the noise would be different, isn't it? The data hopefully is representing the same underlying reality. But those fluctuations, those noise would be different. And so it is almost like one is pointing this way another is pointing this way and when you take the average they're pointing here right something like that in a very hand waving way what happens is once again each of these decision trees which are fit both of the signal and the noise if you treat it as a learner and now you start taking the average of their values. It becomes the wisdom of crowds, isn't it? Are we all together? The crowd being the crowd of trees, decision trees, right, or the learners. Because the signal part will sort of accumulate and amplify, the noise part will hopefully cancel each other out. So each decision tree will exhibit considerable variance means two two decision trees one fit to this sample of the same data another fit to another sub sample of the same data a bootstrap sample of the data will will have different decision boundaries let's say for a classification problem. isn't it right, they will market very differently, so what will happen is, if I may take a illustrative example and let's go back to our grapes and not grapes blueberries and cherries example that we keep going to. Suppose you have blueberries. Just a small correlation here like is there something to do like a chaos theory kind of a concept instability part yes but not much see chaos okay since you raised that in a colloquial way maybe there's a there's something to it let me explain that see are you familiar by the way with the theoretical foundations of kiosk theory no i don't but i just have like a bad idea of what it is yeah so i will i will drill down into it a little bit more because you raised an interesting point right see what happens is that when we think of instability right now the physicists who study kiosks they actually use two different words randomness kiosks and stable systems right i will illustrate that with a point. See, have you? So this is a fact. Take it as a fact. If you ever look at snow, snow that falls on the ground, and we think of snow as snow and snow is made up of snow water from snowflakes geometrically snowflakes so there's some remarkable things about snowflakes that you may enjoy you know that you can't make snow on earth You know that you can't make snow on earth. It can only be made at high altitudes. You can make ice in your fridge. But if you just look, notice the fact nobody has a snowmaker in their fridge. Right? People have ice makers. is something that only comes into existence either in high altitudes in the sky or of course in a physicist's laboratory where you recreate those conditions when you do that you observe that the shape of a snowflake is extraordinarily, extraordinarily sensitive to the physical conditions producing the snow. Very slight changes of temperature, pressure, etc. leads to completely different snowflake geometries. And people have been fascinated by it and they have devoted their entire life photographing snowflakes. If you want, Google up snowflakes and photography and so forth, and you'll find stunningly beautiful pictures of snowflakes that all look different. So now you ask this question, see the initial conditions for the snowflake to nucleate and form. Very small changes led to vastly different outcomes. Those outcomes are not kiosks. I mean, not random. Like for example, a snowflake has a beautiful structure. It's a fractal structure. The word is, those shapes are called fractals. They have a fractal structure they come about right but so it is it is completely different from randomness it is actually beautiful structure but the emergence of the structure what structure will emerge from the multitude of structures that can come about completely depends is very very sensitive to the initial conditions completely depends is very very sensitive to the initial conditions right and that is chaos when initial conditions lead to vastly different minor perturbations of the initial conditions lead to vastly different outcomes you say that your dynamic system is exhibiting chaos right it is slightly different from the popular meaning of chaos. So obviously this is a digression, but because you asked me and I happen to be a physicist, I thought I'll give you- Exactly. Very nice. Idea of a, of a, so now, so the way connecting the dots, the reason you mentioned it is in some sense, you're saying with just a different sample connecting the dots, the reason you mentioned it is in some sense you're saying with just a different sample of the data, the decision tool looks vastly different. I would say not vastly different, but quite a bit different. That is the commonality between the idea of kiosks and what you're getting at. So your basic intuition was right. Thank you. Yeah. So now coming here, let's do this. So see what can happen is one tree could see some data. Let us say, I will deliberately erase some points here in the boundary. Let me go randomly erase some point. And if you make a decision boundary here, you would agree that at this moment, the tree that sees this data may end up and let me just remove this point here may end up making a decision boundary that is like this. Would you agree that this would be the decision boundary that the first tree would make? Isn't it? Then comes the other tree would make, isn't it? Then comes the other tree, which sees more points and the other tree sees what were the points that I forgot. I wish I remembered that, a couple of here, here, and a few red points across, right? So there is another tree and that doesn't see these points, but it sees a different reality of points. I'm just making a few such decisions. And let us say that it doesn't even see these points. It sees this other point. I've given it a different set of points, right? Do you see this, right? And maybe it doesn't see this point also. So now, and what are the points can I erase? right do you see this right and maybe it doesn't see this point also so now and what are the points can i erase let me erase this point also this tree what would be the decision boundary that this tree comes up with let's see it would also start here it would go like this, like this, then this, this, and this, all the way across this, and then it would just go across like this, would you agree that this would be the decision boundary that this tree would draw. isn't it, and so you can keep drawing a lot of decision boundaries, but if you had to take the average of such decision boundaries. of such decision boundaries without drawing more of them because it's getting tedious for me would you agree that the decision boundary if you just average the votes of all of these you would end up with a decision boundary that would be roughly like like this the average decision boundary that you would come up with. Does this make sense guys? Right? Yes. And therefore the intuition, you literally see the wisdom of crowds here, isn't it? Each learner is making its own decision boundary, but it is learning. It doesn't know it is learning both from the signal as well as the noise so so the final result is what the max the yellow the yellow line the average of all the decision what do you mean by max average yeah yeah yeah you take the max for classification you mean by max average? Final when you like, everybody has given their results. Yeah, yeah, yeah. You take the max for classification, you take the max, right? And then when you draw the decision boundary, you'll notice that. So the variance has gone away. The variance has gotten suppressed, isn't it? Two trees having entirely different realities, or to use somebody's example of sort of qr study initial samples commit you to entirely different decision boundaries right but when you average them out you get a decision boundary but now the good thing is decision boundaries decision trees have inherently low bias their main problem is variance so your bias is not increasing but your variance is decreasing when you take the wisdom of crowds, when you take the ensemble of them, or the committee vote of them. So another way to put it geometrically is the small perturbations in the decision boundary disappear, and the main signal line remains, right? The main high order term remains. And therefore the value of doing it. The process that we did, the wisdom, the way, it is called bagging. Bagging comes from bootstrap aggregation. What I did from classification, would you agree that I can generalize it to regression also? The value at a point is the average of the value predicted by each of the decision trees. Now, why decision trees? Can we generalize it to any learner? Go ahead. No, no. Ensemble means wisdom of crowds. How do you harness it? Ensemble means committee. A simpler word for ensemble is a crowd or a committee, committee of learners. And now the question is, how do you synthesize their predictions to get the right prediction? So let me emphasize the point ensemble or committee are is or the wisdom of crowds is basically the big philosophy that we are going to or approach or theme we are on bagging that i will talk to you about is one specific way of doing it we will learn many specific ways of doing it in particular we will we will do four ways, three, four ways, bagging, boosting, stacking. And even with decision trees, we'll do a decision tree, random forest, gradient boosting, XG tree. XG boost, for example, is the implementation of it. Gradient boosting and BART. example is the implementation of it gradient boosting and bach right but so instead of taking bach to go home we'll learn bach as a prediction algorithm but vrt part so we'll learn about all of these things you know in a little bit right but i hope before we go into specific methods, the intuition is clear why it outperforms any one decision tree, isn't it? So that is the great intuition. Now I would like to take a lunch break. Today there is no lab. We have a lot of theory to cover. We'll continue to cover that theory. And remember, next time is the opposite. It's nothing but lab projects. For those of you who joined late, we have decided that we are not making sufficient progress on the practical part. And it's important to do that. So the project that I gave big three data sets, one for regression, one for classification, one for clustering. Please, guys, form your teams and do that. So that when you come here, and next time, I don't ask you guys to be here all the time. But this time, I will request that as far as possible, please humor me and come back, assuming that you're fully vaccinated. If you're not, then don't of course come. So it's an honor system. But if you are fully vaccinated, which I believe all intelligent people are, right? So then come and let us do that one day brain like full work in a boot camp mentality it will be a long day we'll start at 10 a.m and we will end whenever you get thoroughly exhausted from the experiences of the past people have been here till midnight you will be making presentations each of your teams will be making presentations in our lobby there is a vast theater there with the actual theater grade projector high intensity theater grade projector and a 200 inch screen it's designed for presentations many of you have participated in that how many of you here have participated yeah praveen you and sachin hope you would agree it's fun to present there right and a state-of-the-art audio video system you will have fun you will it will think of it as you as a budding data scientist your first exercise in doing a rigorous analysis and presenting it so next saturday is all boot Please, please take it very seriously because I noticed that the one weakness that we have had, thanks to pandemic and everything, if you were here, we would have been using all of these conference rooms, the vast number of conference rooms here for doing the projects. Because you're not here, you haven't, and we are lagging behind in our labs and projects. It is important to do it here. Study the labs. There are about 33 or so labs here. I will be adding another six, seven labs this week. All of those labs you can use as examples. Use them, but go analyze the new data. Pick it up from the awesome data sets website or pick it up from anywhere whatever your team likes be very careful don't bring proprietary data of your company because that would be considered intellectual theft intellectual property theft do not do that it can get you into a lot of legal trouble absolutely avoid it safest take public. Form your team and come by with those values, come by with those data sets. If you can start on the analysis, do that. Otherwise, come here and do it. Reality is you all are very busy. You may not do that. I would strongly urge you that before you start on your projects or before next Saturday, in the very minimum, please study the labs collectively. There's a lot of labs that we have posted on the website. Review that. How many of you have been studying all the labs? Some of them. So you have been studying all of them. Nice. Some of them. Now study all of them, guys. See see let me put it this way it takes me 10 times the effort to produce a lab that it takes you to read right these labs are not just labs that you do in the workplace they are designed for teaching purposes i have written the lab specifically to teach you one point or two points in each of the lab. So it's part of the learning, part of the pedagogical experience. Please do go through it. Do the labs come to the class? Finish your quizzes before you come here. It is important that you finish your quizzes. So we will continue to delve deeper into the ensembles. After lunch, it is lunchtime. I would reserve the last 10 minutes, seven minutes or eight minutes, whatever it is, to taking questions. So far guys, is it simple? Do you get the basic concept of ensembles? Like a wisdom of Christ. It is very remarkable, isn't it? In hindsight, you ask, why didn't we think of it before? And so the basic thing is generalized method. It has nothing to do with decision trees it's very commonly used with decision trees but it actually can be used with anything with neural networks with any kind of algorithms and in fact it's preferable to use that right to do it yeah one question on that before we break right so the demand planning product that I worked on long ago. It had a concept of a kick test. What was done in iTunes demand planner was there are multiple forecasting techniques you had all of them are time series forecasting because that was basically the problem statement. So you because the spreadsheet where you can insert any of those techniques. Yeah, then there's a technique called kick test, which actually is not not a technique all it does is it looks at all the other techniques which insert in the spreadsheet yeah and they'll pick the best one right question here is the way we are discussing ensemble methods this is like a classification and it basically makes a prediction of which class it falls into then we are saying the ensemble method picks the maximum when we are saying the ensemble method picks the maximum likelihood, right? Or whatever is the maximum predicted. But the PICTEST algorithm worked on a measure. The best. Yeah, it basically took the forecasting technique, which produced the least name on whatever is the error measure. Yeah. There are two different things. That is right. What are your comments on that? Yeah, it's a very good question, actually. So I'll repeat the question for? Yeah. There are two different things. That is right. What are your comments on that? Yeah, it's a very good question, actually. So I'll repeat the question for those of you who are remote. Premjit says that in a prior company, let's not name it, there was a technique to do demand forecasting, sales product demand forecasting. And the way it was done is you would tabulate all the prediction models and then search for the model that is making the best prediction and keep that, use the best. It's a way to keep note of all the models that have been built. See, given the fact that all models are learning from the same data and are using equally powerful methods or different approaches, you can mathematically prove that you should not pick the best model because the best model has still seen a partial reality and you're judging it by whatever partial reality you evaluated the model on. That reality is a sub-sample of the underlying reality, right? And your best bet, just as in this picture here, That reality is a sub-sample of the underlying reality. And your best bet, just as in this picture here, your best bet is to take the ensemble of them. You can weed out the worst if you want, but the robust methods that you have come out with, and generally diversion methods are better. You pick those forecasting models that you trust, all of them, not the best only, because that best is only best for that little reality that you trust all of them not the best only because that best is only best for that little reality that you're seeing you take the ensemble and ensemble beats best hands down always so then the way you're describing ensemble in this particular time series forecasting would be take an average for each time bucket average is one way that i for the sake of getting you started, I use the simplest measure, average, but then we'll get it more sophisticated as we go along in the afternoon. We can do better, right? Any other questions, guys? Okay, so I want somebody here, Sachin, would you please volunteer to take everybody's guess? Oh, okay. Right, and the guesses that are there on the... so i want somebody here sachin would you please volunteer to take everybody's guess right and the guesses that are there on the chat i think i didn't show the picture clearly i mean the jar the because of the zoom and the small laptops i will do one thing we will double the numbers that people have sent, because I think Zoom somehow shrunk the size of the jar to half, right? So whatever is on Zoom, let's take the double of it. And, oh, thank you. And so, Sachin, if you can take everybody's answer, and then we'll break for lunch. And when we come back after lunch, I will tell you the average of all of them and the number of stones. All right, guys, let's break for lunch. So guys, I want to keep the lunch relatively brief. Would it be okay if we limit the lunch to only one hour today or it is too little time? One hour, let's keep it to one hour i today i have to break early because i have some personal thing also so we'll do one hour lunch so guys it's 1 30 give or take a minute we'll meet at 2 30.