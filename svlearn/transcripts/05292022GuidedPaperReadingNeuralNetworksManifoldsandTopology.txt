 So guys, I think I'm getting echoes. All right. So today we are going to look at how the neural networks work and look at how the neural networks work and what are the details of training a neural network. So let me give you a basic sense of a neural network. Remember, we are going to create the standard dense feedforward network. What are dense feedforward networks? There are many layers stacked, What are dense feed forward networks? There are many layers stacked, many layers of nodes stacked next to each other. The node in one layer does not connect to any other node in the same layer. Instead, it connects to all the nodes in the previous layer and all the nodes in the subsequent layer. So when we use the word previous and subsequent, it is conventional to lay out the neural networks in such a way that the layer that gets the input data is kept on the left. And we imagine the progression of the signal of the computations to be from left to right, the way we would write English sentences. And on the rightmost end is the output. Are we together? That's how we think of a neural network. Now, we will start with very simple, what I call feedforward networks. And we will start with a very basic data set, very much like we did in the course on machine learning. If you remember, we started life with univariate data sets, which means Y is some function of X. It may be a nonlinear function of X, but we kept it to one input dimension and one output dimension the advantage of doing that is we can visualize it on a page because in a page we have two at the x and y axis if x is the input y is the output we can visualize both the data and the predictions so now let us recap usually what are the what are the, so we're going to play this game, build a neural network, make it learn something from the data, learn to make inferences from the data, predict Y given X for the data. So in other words, it'll build a model. And then we'll see how good the model is. So what are the things we do? First, we need the network, the model is. So what are the things we do? First we need the network, the layers of the network. Then at each layer, what are the layers made up of? We have the weights and biases and the signal that propagates through them, and it goes to the activation function. Now activation function is a choice. We may choose to use, if you remember, either ReLU, we can use, you know, many other things. We can use a sigmoid, a tanh, a ReLU, a leaky ReLU, right, a switch function, and so on and so forth. And I hope when you played around with the loss landscape on Monday, on your own, after the class, I hope you saw that different loss function, different activation functions lead to a slightly different sort of a loss surface. Obviously, it will lead to different loss functions because each activation function does a different kind of distortion. loss functions because each activation function does a different kind of distortion. Right, so we will look into all that. Now typically when you encounter Jupyter Notebook, so this is a Jupyter Notebook you all are familiar with. We do data science typically in a Jupyter Notebook. data science typically in a jupiter notebook it is not a good idea it's an anti-pattern to clutter your jupiter notebook with a whole lot of code code should not belong to your jupiter your jupiter notebook should be more like a like the steering wheel and the brakes and the accelerator in your car. You don't put the whole engine in the details, the pistons, the crank, the crankshaft, and all of those things, the gears, in front of the driver, in front of the user. Instead, what you do is there is an engine block and there is the things below in the chassis, which has all of this. And then inside the car, you just have the steering wheel and the brakes and the accelerator. I often give this example, because I would like to compare that to a Jupyter notebook. Keep heavy code properly factored into Python libraries. Don't litter your code, like litter your Jupyter notebook with reams of code. Now, this may come as a surprise because quite often when you surf the internet, you come across all these articles in which most of the code is right there in front of you in Jupyter Notebooks. While it serves a pedagogical purpose, it is simpler for the author to just show the code in the Jupyter Notebook itself. Actually, when you do disciplined programming, it's a terrible idea. I would go so far, and as many people have pointed out, thatyter notebooks have literally created a culture of bad coding practices. I mean obviously nothing against Jupyter notebook is the most marvelous thing that has in many way happened to the data science communities but with great ease has come somewhat indisciplined. Coding as a discipline requires people to write proper libraries packages modules and so on and so forth instead when i hire people when i hire data scientists for example in my team on a regular basis i have seen time and time again, you have to break the habit of writing reams of code in the Jupyter Notebook. You need to have them refactor it out into proper Python libraries and just have the Jupyter Notebook invoke those libraries. It makes the code reusable. It also opens that code for unit testing. When you write your code properly, then you can do test-driven development and many other good things follow from that. So the way that you'll see this Jupyter Notebooks, it may come as a bit of a surprise to you, but we will keep much of the code away from it. When we were doing machine learning ML 100 or ML 200, the code was not too much. And to illustrate that, I had just put the code along with other people, just literally in the Jupyter notebook. But now it's getting more complicated. We have a lot more code. So we are going to create proper libraries or proper assets, proper packages and modules. So you'll see that. And so that is why when you look at your project, you'll see that there are two directories. One is called the SV Learn, which is our main library. And then you have the notebooks. Notebooks contain the Jupyter notebooks. So this is a as if this notebook is not uh available on the course portal or this this version where we have a linear regression really okay so uh do you have access to it i didn't you mean on github I didn't you mean on GitHub? Yeah, or in the local thing. If you do, please post it to the course page. Okay. Post it. Everybody should have access to it. So guys, at this moment, follow along and then we will do, we will make sure that you do have access to it and you can run it. So what we do is for the time being, because there's a little bit of a mechanics of making a library into a wheel file and then then doing sort of a pip install of that library. I avoided that bit of mechanics by simply adding the library to the path. Just say, this is the search path in the system in Python where you should look for the libraries. So that is that, kept it a little simpler. But later on, as we make progress, one of the exercises we'll do is we'll learn to make proper libraries, well-tested libraries into real files that become portable, that you can just give to somebody and they can just do pip install, right? So that will be a second stage. So now let's move forward. You notice that there is a library svlearn, approximator, regression network. We have a few simple things whose name hopefully is descriptive of what they are. A simple feed forward network means we'll just put a few layers, maybe 128 nodes in the first layer. I mean, it's sort of a conical structure, very high number of nodes in the first layer, lesser number of nodes in the second layer, lesser number of nodes in the third layer. And finally one node in the last layer. Why? Because we are predicting a number. If y is a function layer why because we are predicting a number if y is a function of x we are predicting a real number right so we will do that now now one of the basic things is if you remember we we are used to creating data as just numpy most of us for ml 100 200 so i created a simple class what it does is if you just give it numpy data it will internally do the tensor part of it the tensor part and the and conforming to the data set api because data set remember last time we thought gives you when you enumerate over a data set it will give you many batches isn't it so there's a little bit of mechanics and today we'll very carefully walk through that code i'll walk you through the mechanics but first let's go through the overall flow and see how it works so let's say that there is a network there is a data set from which you'll take many batches and feed into the network and see what prediction comes out the predictions as they are wrong, you will get what? A loss function, isn't it? Because your predictions wouldn't be accurate, you'll get a loss. Now the question is what kind of a loss? Loss has to have a formula. Now day before yesterday, we implicitly or rather all the time using the loss function y hat minus y square. That is the sum square loss. If you average it over the number of data points, it becomes the mean squared loss, right? If you divide it by n points are there and 1 over n, you'll get a mean squared loss. But it is very common in the neural net community to by default use mean squared loss for regression, right? You don't have to. There are some other loss functions that can be used. But for regression, the default is mean squared loss, MAC loss, which explains this function. Now, we are, of course, importing numpy and the torch library. Tensors are, of course, there. Now, we also notice about adam and sgd adam and stochastic gradient gradient descent what was stochastic gradient descent do we remember that it is the gradient descent that you do in which you learn from one instance at a time or whatever instance you're given one at a time. Adam is one of those momentum-based methods that we talk about, very successful. And there are some newer optimizers that have come up. What do they do? They represent the optimization step. For example, W is equal to the previous value of W minus alpha times the gradient of the loss. You remember? By now, it should be sort of engraved in your mind that the optimization step or the learning step is W is equal to the previous value of W minus alpha, alpha being the learning rate, times the gradient of the loss. So then that was the simplest form of it. But when you bring in momentum and you bring in extra things, it gets more interesting because optimizers have a whole session in this series, we'll deal with them carefully at some point. Now we need a data loader. So here is what it is. session in this series, we'll deal with them carefully at some point. Now we need a data loader. So here is what it is. We have a data set. Data loader is the data. What happens is that the way TensorFlow thinks there's a little bit of mechanics here. There is the data set. But who loads the data set and gives you many batches? Right. Then you bring in the data load load so we'll see all of that code matplotlib of course you are familiar with so let's let's create the data let's look at this code we go and create regression data create regression data and we'll see how it does. But let's see through it. As the name suggests, it will create an X and Y, one dimensional essentially data. Even though it's a tensor, it's a tensor in which for all real purposes, there's one dimension, even though there are multiple dimensions attached to it. So we will then create a simple feed forward network. Just assume that we have stacked a few dense layers together. Right, linear layers together. SoTorch uses the word linear. They're synonymous. It's just that two different library creators use two different words. There isn't anything necessarily new about it, or sort of different about it. This is my allergy to heat. So when you learn, what is the optimizer going to optimize on? What is it going to improve or do the learning step on? Surely it is going to do that on the network's parameters, parameters being the weights and biases, isn't it? As we did in the theory session two days ago on Monday, we need to learn better and better values of weight and biases, weights and biases. Those are called the parameters of the model. Then we also remember that when you say W is equal to previous W minus alpha times the gradient of the loss, a gradient of the loss. What is alpha? It's the learning rate. So we need to start with the value of the learning rate. Remember I said that I typically tend to take 10 to the minus five, right? Because in highly complicated loss landscapes, small is good, otherwise it bounces around. We saw that, we saw that effect. But because the problem here is small and I want this session to move faster forward this lab to move forward faster. Raja Ayyanar? i've taken a slightly aggressive learning rate which is 10 to the minus two 0.01 later one person sort of learning rate now. Raja Ayyanar? let's come to the main loop. What do we do? Well, I've created a list in which I'll keep track of losses at each step. At each step, what's the loss? Let us run through it. Now, the first example that we do, notice that I mentioned that there are two inner loops. You go for every epoch, you decide how many epochs you want to go. Here we have taken 2001 epochs, which means, why? Because the Python's thing, if you do range epochs, it will exclude the last value, right? It will go from zero to 2000. So okay, it doesn't terribly matter, but you can write it as 2000. Then dropout is a concept. It's a regularization thing. I'll give you a very brief understanding of it. What happens is neural networks are complicated beasts. They have a lot of parameters. When you make a very complicated model, if you remember your bias variance trade-off, what happens? Overtly complicated models tend to suffer from overfitting. They overfit the data. They learn from the noise also, not just the signal, which is terrible news. So there are many techniques to regularize neural networks. And some of these are the usual ones applicable to all machine learning, like L1, L2 regularization and so forth. But there are certain techniques which are very specific to neural networks. One of them is dropout. By far, the most popular is dropout. What you do is at each stage of learning, you randomly go and switch in each layer some of the neurons. some of the neurons so at each time you cycle through the data what each step that you take every mini batch of data effectively sees a different neural architecture it is slightly perturbed it's not exactly the same as what the previous batch learned you know was given here some different nodes are turned off. That is called dropout. And it turns out that it helps you prevent overfitting. Now, if you remember, we saw the visualization, what does dropout do in the lost landscape? You saw those spikes, right? It makes it look like a, what was it? Like the surface of a jackfruit. This bumpy spike show up by doing dropout. I wouldn't talk more about dropout because we have, again, regularization is an entire session. We'll leave it as that. Now notice that I told you that there are two loops and inside is the learning for every epoch run run through n epochs and each epoch or take a mini batch and then take a step with the mini batch but when you see this loop do you notice that the mini batch loop is missing do you see that missing here deliberately I left empty space There's a ghost of a space here. And what does that imply? It implies that we are not using mini batch. We are using the entire dataset. Isn't it? We are using the full dataset to make a step. When you use the full dataset to make one step, what form of gradient descent it is? The batch. It's a batch gradient descent. That's what it is. So here, now this is a little bit of a mechanics of it. When you use an optimizer, let's say, Adam or whatever, you have to, for each cycle, you want to reset the gradients you don't want it to remember the gradients that were learned from the previous one just just a bad so uh it is necessary to reset it it's just specific to pytorch another library maker may have done something simplicity now look at this to the network i'm giving the input and a certain dropout rate. Dropout means go turn off this percentage of your neurons. That is okay. But to get the prediction, what do I really need to give to the network? The input? If I give it input, it will produce to me the results. But remember, input is not just one dimensional. But remember, input is not just one dimensional. Suppose the data set is 1,000 points. It's basically the whole array of 1,000 points. And it has to do results, the y. So 1,000 x's go in, and let's say 1,000 y's come out, results come out, y hats come out. So I'm using the word results. You'll often see me in code use the word results or use the word y hat. Right? use the word results or use the word y hat right in the beginning stages i don't use a lot of uh you know hats over the y because which is customary in this field to show predictions but as you become more familiar with the conventions of this field you will start seeing that i use special special symbols in the code for example you may have noticed yesterday that I was using Greek letters quite generously in two days ago when we were doing gradient descent by hand for the Geyser data, old faithful Geyser data. But here, because it's a first lab, I've sort of eschewed that. So we take a result. Think of it as your y hat. Once you know y hat, what can you do? You compute the y hat, you compare the y hat to y to know the reality, the actual labels, to know what the loss function is. So let's say that the entrepreneur build a model and the model says that the entrepreneur needs at a given temperature, it needs to will be able to sell about 20 buckets of ice cream. But what actually sold was 18 buckets of ice cream. Data is it. So now we have a gap between the prediction and the reality. And out of that gap, you will create the loss here, mean squared loss. In other words, 18 minus 20 squared. Right. And then, of course, normalize it, average it down to the number of data points. So this is the forward step, isn't it, guys? You're giving the network the input and it's producing a result. This is your forward step. What happens at each layer of the forward step? Data hits each of the layers. Z gets produced. You know, the W dot is the metric. You have a tensor multiplication. In simpler terms, think matrix multiplication. Your input vector gets multiplied by the W weight matrix to produce the Z, right? The linear, it's a linear transformation, right? So far, and then you add the bias. So far, it's still fine. But the next thing that the neurons do is apply what? Apply an activation to the Z. Each of the neuron, whatever it produces, it then applies a nonlinear distortion to that, the activation to that. And then it produces the output of the first layer, which again goes and hits the second layer, where there is again a weight matrix. Right. So the output of the first layer gets hit with the weights of the second layer and biased term and added to the biased term. So that is again a linear transform in the second layer, followed by a distortion, an activation that distorts the result from the second layer. And so it propagates forward, right? Except with one little addition in each, like what happens is as every time you're doing this batch going through, you just go and physically switch off some of the neurons. It's like go turn off some of the bulbs. You don't let it learn. When you don't let it learn, what it means is that it retains the learning from the previous cycle. So you do that. It will produce at the end of it, you'll get a result. You'll get a Y hat. From the Y hat, you now take the difference and you create the loss this is the loss computation now from the loss what do you compute you compute the gradient of the loss because you need the gradient of the loss and that is where back propagation comes in. And this line needs to be unpacked. How does the gradient get propagated? It turns out that where PyTorch differs or TensorFlow differs from, let's say, NumPy, is in a very, very interesting and profound way. in a very very interesting and profound way in numpy when you create a variable let's say you create an array of numbers you get what you see you get that area of numbers that's all there is to it but in their frameworks that know that ultimately that input will eventually go into some function which will where whose gradient would be computed are we together so what happens is that whenever if you so much as touch it or feed it somehow into a function or a operation where you need to take the gradient you need to be careful. You just set it something called auto grad is equal to true. When you set the auto grad variable is true, these frameworks like PyToys, they say, aha, we need to compute the gradients of this function. And it will allocate separate memory, not to just have the values of the values of that very of that variable right but also its derivative so you essentially have so you think you have created an array but in a simplified way think that there is a hidden array also that gets created which is going to store the gradient of that of that but those gradients will be computed when you call the backward function right the backward function will cause the gradient to be computed and populated into your array but the interesting thing with gradient is to compute the gradient, everything that went, every other input variable that went into the function, they also get the gradient. So something else is there, something else is there. You can see the gradients all over the place taking place. So effectively, even if you have just numbers it will have this value auto grad is true and sometimes auto grad in true doesn't mean much because you know there's a raw input vector so it's its gradient is essentially not of much relevance it's just once but that is it that part the fact that it can do automatic differentiation is one of the big, big things with the new computational architectures. Go ahead, David. So where in the code have you specified that it requires gradient? Very, very good. See, what happens is that you didn't but because you used a function msc this internally has said gradient is true internally right so what it means is that the moment you go here now it comes with dot backwards built in and everything that gets into mse what goes into mse y and y how look at this to the loss function what are the things you have you're giving it this and so it will go about computing the gradient but it will wait for you to do this this will cause gradients to be computed and also back propagated if you you had a single layer, of course, it would be gradient. And let's say that you had just one neuron, you would have just a gradient of that neuron there, loss function of the gradient at that. And there wouldn't be any real back propagation, but you generalize the word back propagation to apply to that also. You think of it as a forward pass, loss computation and a backward pass are we together so that is the backward so then the gradients got computed but learning has not taken place for learning to take place a step of learning to take place what you need to do is on the optimizer because optimizer knows the real way to take the step forward the simplest way is w is weight the value of weight is now a change to the current value of weight minus alpha times the gradient with respect to that weight right we saw that in in the theory part but that is for a simple as like a gradient descent the way we learned but actually adam is a little bit more sophisticated than that and the formulas are different because the formulas are different therefore you ask the optimizers to you ask the optimizer and say, whatever your internal way of learning is, go take one step of learning because now you have all that you need to do the learning. You have the gradients and you have the current value of the parameters. You have the current value of the weights and biases. And so go update them. Are we together? And updating them is just very simple arithmetic at that particular moment. The hardest part was the gradient computation where the back propagation takes place. Otherwise it is just subtracting alpha times the gradient. Right? That is it so now once you do that the question is how much of the loss took place right so loss is a function this loss function because it was differentiable you used it to do the back prop of the gradients compute the gradients and back prop you even did a step of learning but one still one step still remains. Let us save that. Let us figure out how much was the loss value, this loss value. I just happened to store it somewhere for display. Not necessary to the learning, this part. This is just for us to keep track and put out a table later on of what was the loss at each stage of learning right and we are saying that if epoch so we run through a lot of epoch 2000 epochs so i'll give a take one if you uh for every 100 epochs print out what the current loss is current what the loss at this moment is right not for every one of them otherwise you'll end up with a long table with 2000 rows right you probably don't want that aggressive level or that so you guys can play with it you can change it to 50 you can change it to 20 to see more fine-grained learning happening so now let's look at this code first we did we print the network do you see that in the beginning we printed the network. What does this network look like? Here is the network. So guys, I'll invite you, give you a homework. I printed out the network in a textual form, right? But there is a Python library that will visualize a PyTorch network. There is a Python library that will visualize a PyTorch network. Are we together? There is a visualization library that will visualize a PyTorch network. Your homework is to discover the library. I deliberately didn't put it here because that's your homework. Your homework is to discover that library, use it, and augment this notebook with a proper visualization of the network. Right, this feed forward network, visualize it. But at this moment from the textual description, we'll say the first layer, this is FC0. Right. I give, why is it FC0? These are the names we gave and you'll see where. It is a linear layer, input is one and output is 128 why is the input features one why is the input feature saying it is the first activation cell no because the data is one dimensional isn't it i'm saying y is a simple function of x x is one dimensional data so input features refers to the dimensionality of the input vector. What is the dimensionality of the input vector? One, right? So it is that. And then what you're doing is, this you're feeding to the first real layer. How many nodes are there? How many neurons are there in the first layer according to the sentence? 128. 128. And you are saying do that and of course also have the bias term. I think even if you don't say bias is equal to true, default is probably true. So then from 128, the next layer narrows down to how many layers how many nodes in the second layer 128 64 second layer has 164 sorry just 64 look at this right input feature 128 output is just so the output is 64 uh out out features yeah so it will produce 64 outputs okay those 64 outputs which have been activated you know they feed into the next layer which does what takes those 64 outputs and then further you feeds it into a layer with how many nodes layer with how many nodes 16 nodes so how many outputs will i get from this layer 16 16. you'll get 16 outputs so those 16 energies or 16 uh sort of light bulb brightnesses you feed it finally into the last layer all of them then converge into just one node. What is that node doing? It's producing an output, a single output. Why am I producing a single output? Because my output is also one-dimensional. I'm just trying to write a function, a simple function, the way you learn in basic algebra. Y is some function of X, one-dimensional. So we are taking the simplest possible example. And so you see this as a table. Do you see the first layer? Input is one, output is 128. So how many weights will there be? In this layer, how many weights will there be across that? 128 weights, one weight attached to each of the neuron, isn't it? Then how many biases there'll be because there are 128 neurons. Now here's a simple thing, just count the number of biases and you'll always know how many nodes are there in that layer, right? Now, how many parameters are there? Well, weights and biases put together, they add up to 256. Now, look at the second layer. Second layer is getting the output of the first layer, 128 features or 128 activations. They feed into this. And the second layer contains how many elements how many nodes 64 and what is 128 times 64. yeah why because it's a Cartesian from every node in the previous layer there is a connection to every node in the next layer so lots and lots of weight lots and lots of edges and each of the edges have a weight so there are lots of weights and this comes as a little bit of a surprise the first time you encounter it you say oh my goodness so many weights so many parameters 64 and this is the total number of parameters in the second layer wow then you go to the third layer and so forth and you notice that this is how it is so when you look at this very simple neural network that is why the word dense people use the dense neural network you see how dense it is in terms of edges and therefore weights isn't it even though this is actually a pretty baby neural net right it's a neural network just three layers with 128 64 i mean one three layers 128 64 16 these are the hidden layers this is the input layer in the output layer right three hidden layers and yet it has close to 10,000 parameters. So what is the problem here? When you have a model that is so complex, that has so many parameters, what can go wrong? It can have a lot of overfitting to the data. Right? So it can have a lot of overfitting. So you need to watch out for those overfitting to the data. So it can have a lot of overfitting. So you need to watch out for those overfitting to the data. And let's see if there is a sign of that as we make progress. So as we run this code, do you notice that we do a print? At every 100 epochs, we print what the current loss is. So that shows up here in this table so what can you tell about the laws do you notice that that loss in the first hundred epochs it crashes down from 151 to 16. isn't it and then it keeps crashing down but after a little while you notice something funny what do you notice in the losses here after the first thousand cycles the learning is slow actually and it sort of bounces back up and down up and down right because now it is trying to fit to the noise your data obviously has noise it's trying to fit to the noise and so let's take this uh this thing and let's see now once you're done with the training what you should do is you say now i'm going to use the network for inference you want to freeze the weights and biases isn't it next time you give it the data you don't want the network to learn accidentally right so one safe thing you do is that you put it in the eval mode. The moment you put it in the eval mode, now the gradients are not going to change. All of your gradients are not going to kick in and whatever is there is there. But those weights, those parameters have frozen at that particular moment. And so when you take the output, when you want to make the prediction on the entire data you can make your final predictions on the entire data one last time let us go plot it now these data that you have you have to do the word detach what is detach and attach attach and detach are a little bit complicated. See what happens is your code could be running not in and this is a technicality. It could be running in the CPU memory or it could be sitting in the GPU memory. Right. So you may have to detach it from that. Imagine like plucking a fruit off a tree. You might have to detach it from the chip. You bring it back home, right? And then do whatever it is that you want to do. So unless you do a detach on the tensor, you can't convert it to, for example, numpy and so forth. So here's the thing. We are creating a plot. Do you see how in the beginning, the loss function quickly crashes? But after a little while, what does it do? It keeps on. It very slowly improves. The loss with respect to the iterations or the epochs, do you see how it goes? Rapidly decreases, and then it sort of stabilizes after a little while isn't it so looking at this you could say that you know we could have stopped learning at a thousand epochs we're not learning something terribly much looking at the figure now is that true well sort of maybe we could have not between 2.2 loss and 1.7 loss there is not much of a gap right but you also see overfitting do you see that it jumps down to 1.5 you see some indications of overfitting and then it is coming back up the losses are coming back up here now you can see more overfitting by comparing the mean squared loss on the training data versus on the evaluation of the test data, which we haven't done, but we have kept the problem very simple at this moment. We haven't done this bifurcation into a training test, etc. Let's see. Now look at this. I have plotted here x, y, etc, etc. Let's see. Now look at this. I have plotted here x, y and y hat. x, y are the initial data. Those little circles, do you see those? Scatterplot. That is your initial data. What is the prediction? This is your prediction prediction curve now if you look at it we started out with the sine curve you remember that actually we haven't showed you i'll show you but take it as first that Okay, so hopeless. So it was a sine curves are smooth curves. What you notice is that you notice that does this look like a smooth curve? It doesn't. so it was a very simple network it tries its best to fit to the data now i invite you to do this to do this make this network more complicated add more layers to it right play around with it change the activation function so there are many knobs to turn you can change the architecture of the network you know add more layers make the size of each layer bigger play with that play with dropouts play with the activation function change that this is your homework guys do that and then see how the prediction the shape of the prediction how does it look do you see evidence of overfitting here guys look at this curve it should have been a nice smooth curve but do you see for example this region what do you see here it seems to have overfit a little bit isn't it so there's some slight indications of overfitting now this one we did using the whole batch gradient descent now let's do mini batches not much changes you just choose a mini batch size now here by the way this was the function that we used right function so that the dad used 7x now let's do that so do you see the do you see the two for loops that i talked about the rest of the code inside is exactly the same or almost exactly the same there's nothing new except that some little steps things have taken care what we up we reset the optimizer at each step we compute the this is the forward pass computing the loss a back propagation to get the gradients then doing the optimization step do you see that this is exactly the same and we happen to just save the losses at each stage for our thing network is exactly the same, but notice something. When I do mini batches, I run it through actually a less number of batches here, only a thousand epochs. And the loss, mean squared loss seems to have crashed pretty drastically to this. Now, let's plot this function using mini-batches. What happens when you plot it through mini-batches? Does it look a little bit smoother? But you also notice that there is some evidence of overfitting still. Interestingly, look at this loss function. What do you think happened in view of the visualizations that we saw last function. What do you think happened in view of the visualizations that we saw last time. What do you think happened here. Got stuck in a local minimum. Very good. It got stuck in a local minimum you know there's some pothole there, and this whole thing was wobbling there and bouncing around a little bit till it bounced off it, and again started the gradient descent after that so you see this happen quite a bit in neural networks right and this should be like you know this is how you see keep that picture the the visualizations you saw last time in your mind so that was that now let's do Stokoe and do you notice that there is still when you do a batch gradient descent there is a little bit of oscillation here it does better it does worse and so forth you can see it once you get down to one it sometimes goes up to 1.3 then gets back to 1 1.2 1 1.19 so forth so you So you see that it never quite hits the minima. What will it do? It's sort of beating about the bush, isn't it? Sort of beating around what would have been the optimal minima in our imagination. Now let's do stochastic gradient descent. In stochastic gradient descent, what is our batch size? do stochastic gradient descent in stochastic gradient descent what is our batch size one it is still the for loop to of this what do we not do now we learn from each instance of data at a time when we do that so here's the batch the same thing, we set the batch size to one. What happens to this, the same network, you realize that learning is pretty rapid because by the time you go from one to 100 epochs, 100,000 learning steps have taken place. And so you notice that drastically the loss has gone from 185 already down to 0.1. Right. Compare this to the previous case where the decrease in loss was more gradual. So here it is pretty sharply gone down. And let us see how it looks. Do you see how catastrophically I mean, how rapidly that it bounces close to the close to the optima except that it just keeps bouncing around the optima like a drunken man it just keeps bouncing around it's like you know it never knocks on the door it keeps on knocking on all the neighbors doors sort of so and look at this curve that you get from uh stochastic gradient descent you see a lot of wiggles are there and obviously there's some evidence clearly there is evidence of overfitting and so forth so this is it guys this is your basic loop of learning from this. But now, let's peel the onion. Now that we have understood the overall flow. And guys, this is it. You have to know, always this will be the inner loop of learning. These one, two. So this is just an initialization of the parameters. I'll leave it. This is is these four you can say it captures the essence of machine learning isn't it forward pass compute the loss compute the gradients but take a gradient descent step those four things are literally written in four lines and that's also the power of a framework like python which makes it so simple that if you know the theory the code is practically obvious that you can't think of an easier or simpler code more intuitive code then are we together guys now what we will do is we are going to step and look behind the curtain to step and look behind the curtain and see what was the network and how did we build the network right so for that let me go to where let's go and look at regression network i will look at this code from the beginning and let's see if we can make head and tail out of it this time now that we know what it does let's start from the bottom well bottom is just a for loop whatever we did and this is what i usually do before i put things into the jupyter notebook quite often i will test it out make sure it all works and then copy over now you notice that this is what i had copied over to the jupyter notebook but this is the main those of you who have been used to c c++ java or python and know know that you can have a main function i'll leave that aside can you guess what this create plot function does lots function does in the ui in the jupiter it's the loss yeah plot and yes this plot these two so there are two plots here so in the language of matplotlib you will say that there are two axes right two subplots subplots exactly you go and that's why you use the word axis one axis two the plot is divided into two subplots and their names are axis one axis two so what you do is you you start out by creating a grid with two one row and two columns for subplots that makes sense guys isn't it this is the figure size what is it 20 by 10 it's the proportion let's see if the proportion looks like that and this is a bit of matplotlib but for the i will mention it only for the first time if you look at the total plot is it twice as wide as it is high it is right because each of the subplots is a square if you put two side squares side by side you will get twice the width as compared to the height. So that is what is reflected in this. Now we plot what? For all the epochs, we plot the losses for each of the epochs. and we happen to choose the color blue and align with two line width is how these are just aesthetic elements if you don't do it you'll be blessed with black color a black plot which isn't nice then you set set the X label, Y label then. That is, you finish with the first part. Then you do the second plot. Very similar. Now in the second plot, it gets more interesting. First is just plotting the loss. Second one, you notice that you plot the prediction. Now in Matplotlib, when you just call plot by definition, it will make a line plot. And then the scatter plot of the original data remember y hat is our predictions and y are the actual values okay so for every x you have y and y hat so you can plot both of those and we and this is in red color let's say right transparent red And this, why white hat is? We'll see what color I got by default. I believe maroon or blue. Okay, blue. So you see this, right? This is a semi-translucent, sort of a translucent red. And then you have the blue color. So this function is easy to understand. No brainer, right? This is just matplotlib stuff. color code so this function is easy to understand no brainer right this is just matplotlib stuff let's go and try and see if we can understand this other function oh by the way do you notice that i i give type hinting i do i could have just said x y y hat epoch so forth. But a best practice says you always give the type of the data so that it is easy for people to read this code and figure out what it is. Otherwise, you have no idea what x is. Is x a matrix tensor? Is x a 10-dimensional thing? Is it an array? Is it just a number? You wouldn't know. But because Python is a scripted language the downside is it's rather hard to read somebody else's code right you have to but when you give type hinting it makes reading somebody's code easy i hope you would agree that this makes the code reading much easier it's called type hinting now the same thing i do create regression data so let's create a regression data in which i'll produce two tensors of input in the label so how do i do that i first create a standard numpy array of some sample size so in your mind imagine so by default the sample size is 300 right so so you can give it thousand ten thousand motivators i am creating those number of x values between zero and one but then i'm doing x numpy array i'm converting it to float 32. this is sort of a technicality what happens is that numpy floor 32. This is sort of a technicality. What happens is that numpy decimals are 64-bit decimals, high-precision decimals. Whereas when you deal with GPUs, et cetera, 32 is already going quite far, right? So you want to build your tensors out of 32 bit numbers, not 64 bit numbers, just more efficient. So this is a bit of a technicality. And so what I do, I then create a tensor. I say Torch from NumPy will produce a tensor. By the way, instead of doing this, I could have also used the tensor constructor. So in other words, let me say that I could have done tensor x. That also would have worked. But I thought from numpy would be more intuitive because it declares the meaning of it. It says that from this numpy array, create a tensor. Once we created a tensor and you do y is equal to some function of x right what happens this and then you again do the same thing float 32 and then what do i do i add some normal noise to it some random noise to. Y plus equal to means to whatever value of Y is there. Just add some noise. What does the noise do? It gives you this jitteriness. You notice that the data points, they are spread out a little bit. They are not perfect. You deliberately inject noise. Otherwise, it won't look realistic. So once you do that, the rest of it is easy so this function would you all agree folks that this is straightforward this function is easy to understand now let's look at the data set this is a little tricky guys one of the and now of course there's a library called scotch which does some of the things that I'm doing. Somebody has open sourced a library. But basically, it does the same thing. It takes NumPy arrays and Pandas and so forth, data frames, and converts them into tensors. But here, I do it, the whole code by hand. So you see me do that, a NumPy array. So you're saying data is that. So when you have a data set for prediction, the data set contains both X and Y. Remember, X train, Y train, basically. So this is your definition. Nothing unusual. I just do a sanity check to make sure that length of X is the same as the length of Y. If they are not not it's meaningless you cannot have input array and output array of different sizes after that this by now must be looking to you very obvious what i'm doing with that creating it into a proper data frame now this data set a simple numpy data set inherits from the data set class of pytorch dataset pipe contains these methods get item and get length when you say get item you have to decide give it an item at a time it helps you iterate over the items and length it tells you how long it is now. And notice that underscore, underscore. Whenever you see methods like that with underscore, underscore, what it means is that you don't expect people to call the method. You expect the underlying framework to call those methods. The PyTorch framework alone to invoke those methods. You shouldn't be invoking those methods directly, right? Like- Those are constructor section. This one is the constructor. This is a constructor. But this is not. This is the underlying methods, hidden methods. So think of them as what in Java C++ you would call private methods. Sort of like that. this you would call private methods. Sort of like that. Now, but here also, so now let's look at another function called define a pretty table str. What was that pretty table? Well, pretty is an exaggeration, but pretty enough. This thing. As you can imagine, printing this takes a little bit of careful fudging around with blank spaces and so forth, white spaces and so forth. So this is not PyTorch. This is just me producing things in a way that makes it easy for the user to see the structure of a network. So that is what it is a pretty table right now this requires you to understand what this does this thing make sense guys colon hat 16 hat 4 what do these mean these are formatting arguments. Say, put it in the center here, right? Or put it here, et cetera, et cetera, of different precisions. So that is all there is. You have to know a little bit of Python string formatting to understand what is it that I did, right? And so how many are these little braces are there one two three four five six and so that's what it is you have at the first line is you take the template and you feed in this string six strings one two three four five six so that So that produces for you the header here. Let's verify. Is it six here? One, two, three, four, five, six. Yes, it agrees. So this is a pretty printing of it. Well, all of these are auxiliary things. Now let's come to the real matter. How did we create the network? So obviously, this is the constructor in which i am taking the dimensionality input dimension one output dimension one i assume now by the the simple network by the way i designed in such a way that you could actually give it two three four or whatever dimensional input you want and have as many dimension output you want typically for regression you commonly go with one but anyway you can change it by the way this is way of python to give default values this is just some sanity check now look here what am i doing i'm putting together the layers. Do you see? So how many hidden layers are there? Three hidden layers are there. Hidden layer 0, hidden layer 1, hidden layer 2. Where have I defined the size of those hidden layers? Out here. Size of the hidden layer is defined out here. then the rest of it is easy but now comes the forward pass when i when i do the forward pass you know when i say network and here's the input give me the y hat how do i do that let's see how we do that what i do is you given the input x first thing you do is you you apply the the in the first hidden layer acts on the input isn't it would you agree the first hidden layer takes the input multiplies by the weights then activates it and produces the activation you have to do it manually so here's the thing you apply to the first layer so this produces what z remember in our language of last two days, Monday, it was Z. When the node Z is bias plus weight times input, that Z gets activated. You need to apply the activation function to get the output from the first layer. Now, once you have the output from the first layer, one of the things you do is you may throw in some dropouts. You can. How do you drop out? You just reject some of the inputs. You say, forget it. Right. Then what do you do? You set those to zero. Then what do you do? you go to the next layer you repeat that process the input output of the first layer goes and becomes the input to the second layer producing its output again its drop out again its output and finally you produce the output from the third layer now what do i do with the output from the third layer what do i expect if my third layer is just one node, one neuron, its output is one. But one of the things you have to be careful with neurons is, with tensors is, one may be a number. It may be an array of size one, vector of size one. It may be a two-dimensional matrix of size one. It may be a three-dimensional matrix of size one it may be a three-dimensional matrix of size one right you don't know it is a tensor of size one right inside so what you need to do is you want to convert it back into a number right into a single vector, one dimension. So this one says, don't care how many rows are there, but one column. And of course, we know that unless you send a mini batch of data, the output column is just one, right? So this keeps possibility open that you may be sending not just one data point, but a batch of the data. And so remember that the first dimension, the rows, belongs to the size of the mini batch, right? So suppose you send a number 5, 7, 3 together, they will go as a column vector. So how many rows are there in that data? Three rows are there, right? So that is why you see that for a tensor, the first dimension, which is the row is always the size of the mini batch right it contains different records there so one analogy that i often use is see see if you think of all the data points imagine that this data whatever dimension in this particular is two-dimensional data but imagine that's an n-dimensional data point n-dimensional data vector data but consider each data as a page so what is your mini batch mini batch is these pages stacked together right so these are your rows right so one data two data three data four data five data six data so your mini batch size here is six isn't it so that is where the first dimension specifies the data itself. It's the mini batch size. And if your mini batch size is one, then of course you just get one row of data. That is what is meant by that. So this is lovely. So we give the forward pass. Now you say forward is fine, but where is the backward? Where is that whole hard part of? This was very simple, just multiplications and activations. What about the backward where is that whole hard part of this was very simple just multiplications and activations what about the backward part because that's where we had to compute the gradient do you remember that on monday when we used numpy and scikit-learn we did the entire mathematics by hand we computed the gradient right the for the backward backward part before we took the step. But what about this? Where is the backward? Who would like to answer that? Why is there no backward? PyTorch takes care of it. Exactly, because PyTorch does auto differentiation, auto grads, and the backward step was just computing the gradients. So you don't need to do it, it does it. So that is the heavy lifting actually. After a little while, once you become familiar with this, you'll realize that this is peanuts, right? This part of code is just declaring what the structure of it is and the forward pass is still peanuts nothing special right you you do weight multiplication z compute z activate it well drop out if you drop drop out a few of the uh results some of those notes you values you just zero it out then feed it to the next layer, again, Z, followed by activation and so forth. This is the forward pass. The harder part is you don't have to worry about the function and its gradient or anything. You don't have to do calculus. Python does the calculus for you. And that is the main, not Python, sorry. PyTorch does it and TensorFlow does it, these are. frameworks, so people often say that the reason you use by torture they using you use a TensorFlow is because they run on the gpu. They look at the hardware consideration, but actually that is not the only reason you need an auto differentiation, need an autograd framework automatic gradient framework otherwise you're screwed you have to do everything by hand as we did two days ago for the case of the old faithful geyser we did the forward and the backward both by hand right that is that is a crucial element now you, well, why is it true only for neural networks? Can I not create auto differentiating computing libraries outside without worrying about GPU and so forth? And I invite you to find such libraries. There's some really good efforts and libraries that have come up that gives you, that only focuses on the automatic, autograd part, automatic differentiation part. So the homework is to find such libraries and post it to Slack. Are we together guys? That's that. And so now does this code look self- self evident? There is nothing else to it. Let us recap this code and then we'll take a break. We are creating a simple feedforward network in which we this is the declaration of the architecture, the layers, isn't it? You're declaring this is the architecture, then you're using the architecture to do the forward passes, forward passes at each moment. the input to each layer is multiplied by the weights and and biases are added to it to create the z then the z is activated isn't it you apply the activation of the z do you guys remember guys or should i go back and review the theory with you let let me bring back the theory just for the fun of it so we remember it. Ah, look at this. It's all there in front of us. Let's see what we learned in theory. Does it make sense now? I talked about activation function, right? Z is W dot X plus B, right? So first you take the input of each layer at each neuron, multiplied by the weights to get Z, and you add a bias to get Z. And then what do you do? You activate the Z, apply activation or nonlinear distortion on the Z, right? Common distortion there, we talked about the sigmoid and we talked of ReLU and so on and so forth. And once you have done that, then compute the gradients happens automatically. And then this is your learning step, right? Which in the case of neural network is a bit more complicated. It is the learning step. Somehow, if you can magically compute this gradients and the system does it through back propagation, you're done. Is this all I taught last time? I think this is what I said. So do you see all of these things come alive now? In code, this is all it is. This is all it is. So now comes, this is it, this is what you see. And the end result, literally you see this inner loop, this inner loop. Result is the forward pass, compute the loss, compute the gradients, take a step and you're done force four lines of code does the inner loop of machine learning okay so all you guys any questions before we take a break and then when you're when you're creating the architecture exactly when you're creating the architecture. How does that exactly work? All it does is that it just says, I'm creating a layer with these many neurons. That's all. Nothing special. And it connects the... Yeah, it connects it. That is it. See that connection you're doing here, when you're wiring the forward pass, you're creating each of the layer. But the wiring is what you do in the forward pass do you notice that you are the one doing the wiring to each layer you feed the to get the z activated and you take the result what happens look at 59 the output of the first and just ignore the dropout lines because they are noisy at this moment you can ignore it so the 59 becomes the input to 61 because we this is a convention people keep calling it x but you're taking the output of the first layer fc0 fully connected layer 0 and feeding it to the fully corrected layer 1. right so you are doing it this forward is where you wire this those layers together. And here you just create those layers. This is like literally just instantiating those layers. Yeah, you just tag them together. But there's nothing connecting them, the connecting part happens in your forward, right? You're taking the output of one and feeding it to this. That is it, guys, you see how simple the whole idea is? But you have to break it down, like you have to unpack it and see it step by step. So what is that? It will be, Kyle, have you posted it to the course page? The files were posted to the course page. Yes. Yeah, okay. Just go to the course page. It is there. And I apologize for some reason I seem to be having different versions of this project on different machines. I don't usually work on Windows. This is a Windows machine. And it's a little bit of a mess. I will clean up the mess and clean the project out so that you guys have access to all the files. clean up the mess and clean the project out so that you guys have access to all the files so during the break um we'll help you um download the necessary files for this yes for this lab yeah reach out to Kyle she can help you thank you Kyle for that yep so let's take a little bit of a uh it's 8 22 we'll round it off to 8 25. let's take a 15 minute break would 8 40 be reasonable 18 minutes or make it 20 well all right 840. let's regroup at 8 40. because then we'll do the universal approximator we can pause the recording. All right. One of the things we covered is the universal approximation theorem, which says that you can approximate any relationship with a neural network. Remember, the purpose in machine learning in predictive models is not to know the true underlying function, the generative function that produce the data, because that is unknown. If that were known, there would be no need to do inference model building. Now, with that being absent, what is the best that we can do? We can build models that approximate that underlying reality to the best of our knowledge. So given an F, which we don't know, we try to build a G that, at least from the evidence of the data, we can say very closely mimics F. So that is that. That is called model build. Remember the famous statement of Box, which says that all models are wrong, but some are useful. Namely, you'll never know whether your G was the F. But if it is producing equivalent result, it is good, it is useful. Now, again, as a recap, we said that if you take a reasonable activation function and a reasonable network topology, network architecture, then it will approximate whatever function that it is that you are trying to approximate. It will mimic it quite well. It will do a pretty good job of it. Let us see if that is true. So what we will do is take some crazy functions and see. We will go from some easy to hard ones and see what happens. Asif, can you share your screen? Oh, indeed. I'm nice. Okay. Yeah, I shared my screen and during the break. So all right. Is that better? Yes, we can see your slack. Oh goodness, that is not better. Well, this one, let's try a look. Attempt two. What about now? Perfect. Yeah, we can see a Jupiter. So there is a directory where you call a universal approximator. There's a notebook. We will use a neural architecture not very different from what we built, almost identical to what we built. We are going to use that same neural architecture, simple neural net, and see whether we can approximate a bunch of functions. So let's take this as an example. So I've created a class called the universal approximator. We'll see it. It just uses internally, it's just a wrapper around the neural net that we create, simple neural net. But what we will do is we'll create some data let's go create some data sigmoid like so what let's create one data set that looks like this you see that this is a highly non-linear data set for example a linear regression method wouldn't do it a polynomial also wouldn't do a good job polynomial regression it may be a reasonable approximation why would a small degree polynomial let's say twice second degree or third degree point i will not do a good job polynomial regression it may be a reasonable approximation why would a small degree polynomial let's say second degree or third degree polynomial not do a good job can somebody answer that oh it will overfit right no because it's a bit of mathematics see transcendental function why it is a transcendental function by its very definition a transcendental function, sigmoid is a transcendental function. By its very definition, a transcendental cannot be represented by a polynomial of finite degree. Or if you try to do it in terms of polynomials, you'll end up with a polynomial with infinitely many terms. That's a very definition of a transcendental function. So sine, cosine, sigmoid, tan, all of these are transcendental functions. So I deliberately took a hard function that linear polynomial regression methods would fail at or not do as good at. We take this and I generate some data. So here it is, this data. You give it this function and what this universal approximator does is it first generates the data set and then says to the neural network okay go learn from it go learn from this data set and see if you can and can learn this data so we do that and this code here is very simple approximator you and we are training it for only one epoch and we are seeing how good it does so when you do that the number of steps are huge, we create lots of data points, you see that it starts with a certain loss and the loss keeps decreasing. The correlation between Y and Y hat, between the ground truth and prediction is, oh goodness, this is five digits of nine, very high degree of approximation so we took this function and we asked the neural network to learn it obviously i did not put noise into it because if you want to see that networks can approximate functions let's try out with clean data i did that and it seems to be you can see that this is not a perfect can you see the subtle differences between the two the neural approximation and the actual function? If you look carefully, there are little imperfections to this, and this is still going up, whereas this one, the actual function is more or less saturating. It is reaching its asymptote, whereas the function on the right is still rising up. Whereas the function on the right is still rising up. The approximation is still rising up. Well, you can say that was too easy. Let's try something hard. Here is a function. I deliberately cooked up a function that is a polynomial and a sign. So now it's a mix of polynomial and transcendental. What about this weird function? How quickly can it learn? If you look at the loss, it learns it pretty, pretty quickly. Right? So let's see what it is. This is the actual function. And even with this very simple neural net that we built, three-layered, almost nothing in it, what do you think of this approximation, guys? For prediction purposes, for practical purposes, would you consider it a useful model pretty similar right it gets the job done especially when you put a throw noise into the mix it would do just fine because real life data comes with noise you say well you know this is still too simple let's go harder so we will make this function it's called this it's the famous sync function or a version of the sync function sync function those of you who how many of you are from a digital signal processing background a communication theory background or are used to for syncs i know what it is from signals and systems yes syncs there quite often so this is a sync function and this is an approximation to a sync function it has imperfections look at the tip of that on the extreme left it doesn't seem to get it right the shape is sort of approximate but reasonably good it gets it right so your homework guys is to complicate it build a more robust neural network see if you can approximate it more closely right you can say well that is still too easy what about this weird function now how many of you would say you can even think in your mind what this function looks like sine of of sign of sign of sign, right? With some constants thrown in between, multiplying factors thrown in between. This looks complicated, isn't it? Would you agree? So what does this function look like? Ah, it looks like this, right? And when you try to approximate this with the neural architecture, this is how far you get in how many epochs you get there in one epoch. So guess guys, guess what will happen if you run it for five, six epochs. Cycle through the data more. I leave that as an exercise for you. And here is the exercise, guys. Make the approximation much, much better than what I did with one epoch. How will you do it? Run it for more epochs and take the neural architecture and add more to it. Add more layers. Add more nodes. add more nodes do whatever it takes to make this neural approximation look much closer to the actual function this is your homework guys and i've written it here try out different activation functions different learning rates play with the structure of the neural network itself and of course play with the different number of epochs i didn't mention it here uh one of you can put it as a slack node. Do that, guys, and do that. Now, I'll show you the code behind it. It's not complicated at all. Universal approximator. By now, you should be finding it very easy. X, Y, Y hat. Okay. You can forget about the slots and so forth. This is the prediction. So this is just a high-performance way. Okay, you can forget about the slots and so forth. This is the prediction. So this is just a high performance way. Those of you who are Pythonic, Python junkies would realize that this creates a more efficient way of storing data. So universal approximator. Once again, I've given all the type hinting and some comments, so you know what it is. What do I need in the universal approximator? I need a function. Remember, to it, if you go back and look at it, I need a generating function from which I would generate the data, right? For example, this function. And you take the function as an argument. This is one of the lovely things you can do in Python in a very natural way that makes you love Python from a mathematical perspective. You notice that, sorry, not here, universal approximator. I give it a function, literally a function, to the approximator as a constructor argument. And you can see that I'm giving it as a function. You see a function as a collable. Input is a float, output is a float. So one-dimensional at this moment. The range of the data. So when you use this as a generative function to generate data, what are the boundaries of the input? The rest of it is straightforward if you know your NumPy. In this raw data space, I generate 100,000 data points. It's hard work, you can play around with it. Then I can find the min max and I scale it by the min max. Why? Because the person may have specified a stop. This is worth mentioning, by the way. Neural networks, they work well with data that has been normalized. You can't give unnormalized data to neural nets they don't do well with it because activations will lead to saturation a very high input value will produce a big value of z a big value of z for a for a for example a sigmoid function will do what it will throw it into the asymptote the saturation regions because it throws it into the saturation reasons, it is useless. So you should always scale the data. Scaling the data or normalizing the data, standardizing the data is a key thing, a key step you shouldn't miss. And you see me doing it here. After that, it's just a normal NumPy mechanics and creating the test and train data, splitting the data into test and train. Remember to shuffle? Yeah, i shuffled it also doing that and then creating two data loaders first two data sets one for training one for test do you see two data sets for training and test and then two data loaders one for training data loader one for test data loader training data loaders is what we use to train now comes the network do you notice that i've created exactly the same network actually i've added yeah 128 64 64 16 1 right so i invite you to make this network into a more complicated network but observe something else i have used a different syntax for creating this network in the last one do you notice that look at the constructor of this network I just declared the layers like this do you see this guys I declared the layers like this and then I needed a forward step to stitch them together do you see me stitching them together signal of one feeding into the other and so so on and so forth, but there is an alternative syntax I suppose borrowed from the kira style. R. Vijay Mohanaraman, Ph.D.: The researchers like this direct because why you can put a break point in this, you can see the intermediate steps stages, but a less. R. Vijay Mohanaraman, Ph.D.: of transparent a little more opaque but a easier way of creating the network is like this in one sentence you can create the network and there is no forward you don't have to do the forward step at all it is implicit right the sequential class will do that forward step based on the way by just looking at the structure of this. Now here, I am being particular. I've given a name to each layer, but people sometimes most often don't even do that. They don't write it so carefully. If you see examples of sequential on the internet and the tutorials, they don't give it a name, but it is good practice to give it a name because when you're debugging or when you're evaluating and stopping the training process and looking at intermediate states it helps to have human understandable names to the layers rather than just you know a very cryptic programmatic names now you notice that there is no when you write it like this you don't need to write a forward function in one sentence you're literally constructing the just like just this constructor is enough in one line you created a feed forward network so this syntax is fairly common when you know you don't you're not going to look into the intermediate you're not a researcher you're going to do some work now the training part is again a no-brainer so there are there is no drop drop off drop drop out you can add that also i didn't i was just being lazy you can do that yeah so why not do that play around with it right so take that as a homework after that the by now the two loops must be After that, by now, the two loops must be no-brainers to you, right? The first outer loop goes over the epochs. The inner loop goes over the mini-batches of the data set, isn't it? Of the training data set, right? So this is the mini-batches, the X and the Y in the mini-batch. And I is basically the index of the mini patch which item it is so by now these four lines are famous four lines are still exactly the same guys this is the initialization zero grad is okay but our main four lines of programming are still the same learning are still still the same, right? Nothing changed. I just wrapped everything inside a model. And then I've created an evaluate function that compares and tells you, gives you all the predictions, evaluate model. It will give you a list of predictions, just some niceties to make it look nice, pandas, etc. Now, it is worth knowing in a complex model model what is the correlation between prediction and reality this is the correlation it computes the pearson correlation when you do the np numpy dot correlation coefficient statistically is the pearson correlation plotting by now is easy for you you're quite familiar with how to do the plots and this is some code that is written right here yeah the pearson correlation of the that is it if you're used to the neural net there is absolutely nothing new by now we are repeating itself the only new information is that here is a simpler syntax to create neural nets and even simpler would be that i didn't even name the layers. And you find those examples quite a bit on the internet. It's quick, it's dirty. In my view, it's dirty and sloppy. Even if I do this, I always tend to name the layers. So that is what was happening. And the only interesting thing here is that this universal predict approximator takes a function. So what you should do, guys, is try to fool this thing. See if this universal approximation theorem is really true. Think of some crazy functions. I should have given that also as a homework. Cook up your own crazy functions. See if the, do do side by side comparison right imagine your own functions and plug it in and see what happens are we together guys right so that is your homework for today from the lab now typically what happens is that we are making progress in the lab section if you were here the last hour from the lab. Now, typically what happens is that we are making progress in the lab section. If you were here the last hour of the lab, you would be actually doing it right here. This is your classwork, right? But since you guys are all at home, we'll call it a homework. But you guys are all busy people. I invite you to do it right now. I will be here. Do it. Play around with it, run this code, Kate is here, Kyle is here, Dennis is here, three TAs are here, teaching assistants are here. We are all here to support you, but do some things right now in the next one hour, right? But we are done with the with the lab part of it. Right. So what did we learn today? We learned to create basic neural networks. We learned to do regression. We learned to do classic. I mean, I didn't do a classific application example. There is an example with CIFAR. Actually, let me do it because you have a quiz with CIFARs, let me teach that also to you. Data sets. This is an example of classification, we'll come to it. So what is the CIFAR data set? Remember, we went to the website, we saw that if you have 10 classes and 60,000 data points, all those classes are some 10 different things. I believe they're just 10 animals right researchers use this c4 10 c400 a lot to see the goodness of their bottle so i've created a c4 net simple c4 net i'll walk you guys through it what is it you won't understand it now actually i won't walk over it because it contains something called convolutional layers i haven't taught you convolutional layers but just think a different neural architecture which isn't just densely connected nodes it uses it is inspired by studying a cat's brain this convolution but the rest of the theory if you just ignore that it's a different architecture it's the same and you can see how well it predicts and mistakes it makes out of 16 it made two mistakes it has an accuracy of 87.5 now the beautiful thing is that on that data set we created a class if you go and look at the class once again you'll see no magic in that class class if you go and look at the class once again you'll see no magic in that class it is right here in data sets okay let's uh so guys i i wrote it the way that you could inspect things that are happening by now the init stacking up the layers i hope it looks pretty obvious even though you don't understand pooling and convolution at least the linear layer makes sense isn't it and just think of these as some slightly weird kind of layers we haven't learned about and the forward is exactly the same you take the output of one and feed it as the input of the second layer. Get the output here, feed it to the third, this to the third, and so forth. So this is an example of that. You could do different architectures. I mean, you can change the values and so on and so forth. Doesn't matter. And then the classifier part, because we are talking of image data there's some image transformations that become relevant so it turns out that there is a python library called torch vision which makes these data sets built into the library itself when you run it it gets downloaded to your machines and trans create transforms or what when you an image, you want to make sure that all the images are the same size, because machine learning, when you give it training data, all the training data must be vectors of the same length or the tensors of the same shape, right? It's important to do that. That is what it does. Just in case those images are not okay, it will do it. The other thing it does is it normalizes the data. It makes sure that the image mean and mean, et cetera. These are like making sure that all the bright areas or the colors, et cetera, you have standardized all of them. When we do convolution, when we do computer vision and convolutional neural nets, this will become far more. I'll go over this very, very slowly and carefully. neural nets this will become far more i'll be i'll go over this very very slowly and carefully but at this moment you can sort of ignore that just remember that we have created a classifier for images now in a in a classifier though there's only one thing worth noting what should be when the output of the last layer comes in a classifier does what does it produce a number or does it produce a probability probability probability exactly and so when you run it you have to in the main loop somewhere Raja Ayyanar?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam?nilam and what you have to do is put a soft max end to it it predicts which of the class probabilities it has and we'll come to that more carefully i have not done i'm just rushing through this because i'm going to do the classifiers much more carefully in due course of time right in the subsequent lectures so now this homework you can do with the cifar lectures. So now this homework you can do with the CIFAR without knowing the underlying structure of a convolutional neural net. I've created a homework in such a way. You're playing with the epochs. What happens if you increase the number of epochs? What happens if you do minor tweaks to the neural network? You know, I've taken layers you can you can play around with those layers so you can discuss with that now obviously here the nature of learning is a cyclic unfortunately the lab is moving ahead of the theory when it comes to classific image classification we will get to image neural networks after quite some time, but you can still do the homework by ignoring the complexities there. So this is the CIFAR dataset. So remember, dataset comes from standard. CIFAR-S10 is a standard dataset. TorchVision gives it to you, and it gives you a way to do the transformations, and it gives you some utilities. But the neural architecture is what you create. You can play around with it. So that is it, guys. I want you to do this, see if I lost, but play around with the universal approximator, the linear regression and so forth. Feed the universal approximator your very own strange function. See what happens. All right, guys, so let's stop the recording.