 All right guys, we have gathered today for our second session on classification. So it is in the top of the screen says classification. The last time we did classification and we and I mentioned that classification is a process it's think of it as a black box right or a match not a black box with a magic box you give it some features and out comes a prediction which is to identify a type for example if you give the height of an animal the weight of an animal the color and some other features about an animal and you ask the height of an animal, the weight of an animal, the color, and some other features about an animal, and you ask the magic box what animal is it? And it might say cow, duck, horse, and so forth. So that is classification. More realistically, you may classification, examples of classification is you get a credit card transaction. Is that transaction fraudulent? You need to decide as a credit card company, you need to decide quickly because the merchant and the customer both are waiting, you know, the payment and transaction is in progress. You need to quickly determine that. you know the payment and transaction is in progress you need to quickly determine that so that you use models to do the prediction so that is an example of using a classifier here you're trying to identify valid transaction or potentially fraudulent transaction isn't it another would be like you are looking at the biomedical markers, some blood test results and so forth, some biomedical markers. You're trying to determine whether the person that these markers belong to, these lab results belong to, does he, does she or does she not have breast cancer? This is a lab example, by the way. We will do that example in this workshop. Hopefully the week after Diwali, that is the example I'll use to explain classifiers. And it's very instructive that machine learning can do that. The question is a binary question. You know, it's still a classification problem. Identify, does this when you when you look at this picture of the tissue or the x-ray does this person have breast cancer or not um does this person have heart disease like suppose you look at the the mri, does this person have clogging in the arteries? Does the person have heart disease or not? And today, the state of the art in machine learning, in AI, has reached a level, surprisingly, and this has just happened in the last two years, that we are doing in many ways better than any experienced physician will do. So what happens is in some of these tests, a classification algorithm outperforms the average physician, the average doctor, and it matches the top-notch doctors in its performance, which is a very remarkable thing. We used to think that medical diagnosis, the ability to tell whether somebody has a disease or not, it is the domain that purely belongs to human beings and not just human beings, to a very elite group of highly trained individuals, medically trained, who have gone through 10-15 years of medical training, who can tell correctly, whether a person has something or not. And we are realizing that machines can beat us at that. So one recent breakthrough that was there in this space was that in, I don't know if it is done in India yet or not, but here you look at a map of the eye, you know, when you go for an eye checkup in the US, you go for the annual eye checkup. So then your ophthalmologist, the eye doctor, he will take a picture of your eye, the corona. It's called the opto, I think it's called the optodome, that's the word. So it's a nice big round circle, some of you may have seen that picture of yours. It was only to decide if they have eye disease. It has been done for enough number of years in the US that there is massive amounts of data across large number of patients. So one person who got an interesting idea, he said what else is there in this picture that we don't know, that we weren't looking for? And to everybody's great surprise, it turns out that if you have diabetes and how strong your diabetes is written in your optoderm, how whether or not you have diabetes and how strong your diabetes is is written in your optoderm how whether or not you have heart disease is very accurately written in your optoderm and human beings can't see it where it is written but an ai can read it somehow and tell that this person has heart disease or this person has a diabetes and and a a whole host of other diseases, I believe something to do with kidney and so forth. So in our eyes are written the signatures of all that is happening in our body. It's a very recent breakthrough as in the last couple of years it has happened. And it has everybody's surprise. It is a classification algorithm. That's the power of it. So when I'm explaining it to you, I'm explaining it with cats and dogs and horses and cows, but I just thought I'll bring in the reality that the reality is that what the algorithm is saying the same, same process, same theory, same everything that I'm teaching. You just applied it to a different problem. This is also true for lung x-rays. It turns out that lung x-rays are another big map to our body in our lungs. A lot of things are written in the x-rays of that. All sorts of respiratory illness can be seen there. And it is beginning to see things that very few people are able to see, actually, when they look at a lung X-ray or lung, not X-ray, MRI data of the lungs and so forth. So that is the new frontier for classification. Now, the question that arises and that we asked last time is, how good is this algorithm? How do you know? You make a magic box, a classification, a classifier box. How do you know that this is a good classifier box? So the way you do that is you look at something called the confusion matrix. The confusion matrix tells you that after curves, let's say if you look at this yellow thing here, let me highlight it again. You look at this, oh, let me make it fatter. You look at this big circle that I made. This is the confusion matrix. And the truth or the performance of every metric of performance about a classifier is derived from this. So for example, here is a cow. How many cows did you get right? 40 of them. You cut the cows as cows, but then you thought 10 of the cows are 10 of the cows you marked it as ducks. So obviously, you can imagine that you would never do that. But one easy way to think of artificial intelligence, and I always give people this intuition, think of artificial intelligence as a two year old child. And I have found it useful. I don't know whether the intelligence maps to that. I don't think so. But I found it easy to reason about artificial intelligence and machine learning or data science by always thinking that these magic boxes, that they are somewhat like a two-year-old child. And you're training them, you're teaching them, and then they're still making mistakes. So you can imagine that a two-year-old child can confuse a cow for a duck and a duck for a cow and so you look at the accuracy measure how many you got right. So this is it, accuracy is how many you got right versus how many you did not get right. Now I said that accuracy, while it is a rough measure, it shouldn't be the only measure. If the data is highly skewed, accuracy is actually meaningless. What you really care for, for a rare disease, let's say that you're looking at cancer. If you are looking at, let's say that you want to do early detection of breast cancer, which is important in cancer, even if you have the slightest hint that things are wrong, you should be sent for further testing. You want to catch it as early as possible because a cancer caught early is just like any other disease. It is curable, completely curable. A cancer caught late kills people. So as the cancer progresses, your chances of survival keep going down so it is important to catch it early in the annual checkups which is one reason of course we do annual checkups we want to make sure that nothing is just growing for years you catch it as early as possible so suppose cancer incidence is one in thousand you realize that giving an accuracy of 99% in an algorithm is meaningless. The most important metric is whether you caught the guy who has cancer, right? Now it's hard to pinpoint the guy because it's a needle in a haystack. To pinpoint the person who has that, this instrument can be a little bit hypersensitive. So even if a person is healthy but something looks odd in the let's say the x-ray or something you want that in the early screening it should just mark you as positive it should err on the side of caution right and so the you are willing to tolerate a lot of false positives, but not false negative. If you miss, sorry, yeah, false negative. False negative means the person had cancer and you missed it. You said he's okay. Because that can be catastrophic, isn't it? The person will now go home happily, one year later will come back, by the time the cancer would have spread. On the other hand, what is the worst that will happen in an early screening? If you're a totally healthy person, you give a false positive reading and say you have cancer, well the worst that will happen is that person will become terribly sad, go home, terribly sad, go home, write his well, right? And there'll be a lot of crying and sadness and all of that. And then the doctor will, maybe two weeks later, do more tests and the new tests will come back and say, well, actually, you don't have cancer. Right? So you may just have two weeks of high drama in the house, but it is a far better, it's a far safer thing that the worst thing that happened is drama in the house rather than missed cancer. So that is the value of early screening tests. They should err on the side of not missing anything. So the word that you use is you need high recall. And I'll explain that concept to you guys in a little bit. Then on the other hand, the final test. So you mark somebody as potentially having cancer. Now, let's say that nine out of 10 people that you marked as potentially having cancer, they don't have cancer. That's all right. You just need a second test whose purpose is not to avoid missing anybody, but its goal is entirely different. It is to not have false positives. You can have false negative for the final test because you know that a previous test has already been careful about that. You now want to make sure that if you declare somebody to have cancer, that person better really have cancer. Otherwise, you shouldn't declare the person to have cancer because after that comes rather a regiment of rather unpleasant therapies, you know, chemotherapy and radiation and so forth, and that are fairly invasive on the human body. So only cancerous patients should go there. So that is it, you know, you have to balance what are you aiming for low false negatives or low false positives, right? You have to set your goal first and then pursue your goal accordingly. So that is the thing that we were talking about last time. I talked a little bit about the receiver operator characteristic curve, ROC curve. And the basic idea was that you want to, you have a sliding scale, how sensitive you want to make your equipment if you make your equipment too sensitive you'll start having a lot of false positive you want your equipment to be at a situation where most of the cases are true positive you catch the true your true positive rate is very high and your false positive rate is low. Isn't it? Ideally you want such an instrument. It catches, if we declare somebody to have cancer that person probably has cancer, right? You don't have false positives. And the converse is also true. You don't want false negatives. So that is your receiver operator characteristic curve. Now, most people don't remember it by its full name, they just call it the ROC curve. Have you together? And then what you look at is the area under the ROC curve, which is that how much space you have under the green line. The more the area, the better. And the maximum value that you can have, so the AURSA curve takes values between 0 and 1. So the closer it is to 1, the better is your algorithm. So these are the ways that you understand a classifier. Now you say, well, a classifier is a very interesting magic box. How do people build it? What approaches have people taken to build that magic box? So it turns out that the literature, the field of machine learning is rich. They're literally, I mean, it is hard to count how many algorithms there are. Very rich literature. And I personally, after being in this for years, decades, I still don't know or encounter very often some new classifier that has existed for 10, 15 years, maybe 20 years. I was just not aware of it. So it's a vast world out here that you do. But what we will do today is we will deal with something like linear regression, very commonly used. It's called logistic regression. Logistic regression is not a regression algorithm despite its name. It's a classifier. It's a classification algorithm. So, we will understand that in depth. After that, there are many algorithms. They all behave the same way. You can think of them as a magic box. I'll just give logistic regression as an example of the beauty and the power of how these magic boxes work. And to understand that should hopefully be enough to give you a sense that other magic boxes also use very clever tricks, very clever ideas on how to catch or how to distinguish the cow from the duck and so forth. So remember that the logistic regression is just one of the classifiers. It's a rich literature. So when we do the lab, we'll do a lot of other classifiers. You won't understand. I mean, you don't need to know the theory of it in the beginning, but you just need to know that they behave and work in the same way. They just have different performances. For example, for many situations, a random forest may do much better. For some situations, support vector machines may do much better and so forth. So that is it. But which algorithm will work best? You never can tell. These days, neural networks are very much in vogue. A lot of people swear by deep neural networks so deep learning is the marketing uh buzzword is a more appropriate word actually should be perhaps representation learning uh there's a class of algorithms that deal with that and quite often used these days and quite often used these days and obviously it just so happens that I teach that two days a week Monday Wednesday so that class is going on you'll see some videos Thank you.