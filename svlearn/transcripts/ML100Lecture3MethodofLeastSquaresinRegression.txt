 All right guys, welcome to the class. I will be giving you today. We'll make progress on the theory part and we'll make progress on the. Lab part and both of these things will happen today. All right. part and both of these things will happen today all right first I'll start by mentioning the collaterals of the class that you should have received one is oh no I should go with a pen one is class material are you guys able to see and read what i'm writing yes also one is lecture two lecture two on youtube now this lecture three will also get posted onto youtube right after this class. The second is Slack. slack so i have not been posting any messages on slack please do accept it what it means is that if you get stuck you can take help from each other and i'll be monitoring the slack and stepping in to answer questions so it is of value to you as you do your lab you can post screenshots you can post files you can post tips you can you can say i'm stuck here. This is what my error message looks like and so forth. It is worth using it. Then there is a Google mailing list. Google group. List. received an invite and I should know this is for announcement purposes I would be using it for much interactivity between us but this is where I inform if anything about the class or post material you know send out material links and so forth so these are our main things at the same time I sent a PDF. PDF of was given last lecture was given. Last. Lecture and today. Updated today. If I remember right, see if you have received a PDF or you do have access to a PDF, which is approximately 25 pages long. If you don't have it, then let me know. In any case, I've updated it and now it's approximately it is actually 50 pages long updated today. And I will post it to you guys right after this class. Yeah, I don't have it. OK, so all of you who don't have it in an email, let me know what things you don't have it. Okay. So all of you who don't have it in an email, let me know what things you don't have. So this is the class material. Today, what are we going to do? Today, we are going to cover the topic of regression. Regression. In particular, we will do linear regression. This will be on the theory side of it. We will learn about, second thing we'll learn about is bias variance trade-off, a topic called bias variance. And it's very important when we select a model. By its way in straight off. We will do this the. Time permitting we will. Also do a model diagnostics. diagnostics. These will be the main topics on the theory side. On the lab side, let me use a different color for the lab. I'll walk you through the solution. Where am I? I'll be walking through the solution. Where am I? I'll be walking you through solutions. Or rather, let me not write solutions. Um, walk through. 2 data analysis exercises so there will be you folks have already done the galton in my notes i left an influence nightingale was simple uh john did any one of you manage to visualize John Snow's data? I don't remember if you want, if you did or not, but I'll be releasing the solutions. But today I'm going to do the weather data. I will talk about the concept of tidy data. When you actually practice data science, one of the most important concept is that of tidy data. Data comes quite noisy. It comes in all sorts of forms and it comes from heterogeneous sources. It can come from a file. It can come from, in file it may come as a CSV. It may come as a tab separated file, XML, JSON, you name it. It can come from a database. The database can be a relational database that you can access through SQL queries. It may be a non-relational database such as Mongo, a document-oriented database, a graph database, and all sorts of NoSQL databases. It could come from a remote location. Forl databases it could come from a remote location for example it can come from a url so when you get data from different sources and when you have to manipulate the data to put it in a form that you want it's a process it's a journey and form that you want. It's a process. It's a journey and. In that journey, one of the important concepts is that of tidy data. Tidy data says that ultimately your data should look up certain way and if it does look a certain way, exploratory analysis and subsequently machine learning on that data becomes much more straightforward. So we learn about the concept of tidy data so we'll learn about the concept of tidy data we will learn about the concept of grammar grammar now grammar if you remember what is grammar grammar tells us whether a sentence is right or wrong it has a structure for example a noun a verb you know subject object predicates and all sorts of verbs and adjectives and adverbs those are the things and how do you weave those pieces together is the grammar for the english language once you have clear with the grammar you can create all sorts of sentences in the same way process, this data manipulation and data wrangling, you can consider it to have a specific grammar. Grammar of data, data manipulation, And grammar of graphics. The concept is very powerful. People used to make graphs in all sorts of ways. It used to be pretty, everybody's API looked completely different. You had to remember a lot of things. It was a nuisance to learn yet another data graph, starting API and so forth. So one day, there was a lot of thinking about it, and people came up with the concept of the grammar of graphics, a very influential work. It's actually a book, very influential book. But based on the grammar of graphics, a few libraries came into existence. One of the libraries, or two of the libraries are very popular. One of them is called D3, D3JS. In the JavaScript world, it's extremely popular. And the other is in the world of R and Python, it is called ggplot, grammar of graphics plotting. Today, we are going to learn a little bit about that, but much more we are going to learn a little bit about that but much more we are going to learn about a grammar to just manipulate data. What is it that we need? A systematic vocabulary of verbs that will help us do any data manipulation in an elegant and clean manner and it is worth learning that. So that is the scope of today's lecture. So far so good, guys. So with that, I will start now with today. Our topic today will be, let's start with something called linear regression linear regression before i start i'll just remind you that we learned last time the concept of correlation covariance regression towards the mean do we remember those concepts guys does anybody feel that we should review all of that? Or can we move past that now? I think I'll move past that. So linear regression. Linear regression is, so what is regression? Linear regression is, so what is regression? First look at the word regression. Regression is oddly named for historic reasons that we talked about. In regression, we think of it as a box, a sort of a box. Inside the box here, some features go in from our data, x1, x2, xn. And out comes a prediction. And this is a model or a box of some sort. What it means, this is the vocabulary that people use. Think of it as a black box of kind. And it need not be black. Sometimes it's very easy to understand, but for the time being, consider it a box. The input to that can be the features. And it can be more than one features. Let's take the example of sale of ice cream on the beach that we use as a reference example. X1 can be temperature, X2 can be day of the week, X3 can be a wind, how windy it is. And so likewise, different features can go in. These are called the explanatory variables and many words are used by people. Then why is the output or the response or the prediction so people use all sorts of vocabulary coming from different disciplines but i'll just use the vocabulary a simplified look vocabulary i'll call it input features and this i'll call the response. Are we clear, guys? So x, you can write it as a vector for those of you who are well versed with vectors. And y is just a number. Y hat is essentially a real number so remember that this blackboard r stands for real number right an example of a real number is for example pi or three or one or two all of these are real numbers positive or negative negative, fractional or whole or irrational. They all together form the set of real numbers or the world field of real numbers. Now, inputs can be either real numbers or they can be categorical. So let's talk about the two kinds of input at this particular moment to kinds of variables one of them is real real valued what does it stand for real valued example Real valued. Example. Let's say you sold 320 buckets of ice cream. Well, that's a lot. 320 instances of ice cream got sold. So 320 is an example. 4.5 is some example. Temperature of 72 and 3 degrees is an example, and so on and so forth. These are all real numbers. Pi is an example, if you want, an irrational number. Then the other type of data or variable that we talk about are called the categorical. I'll use the word categorical. C for that. This is a symbol for this. Categ categorical. C for that, this is a symbol for this, categorical. So these are things that are not numbers at all. They are cats and dogs, for example, or a day of the week is Monday, Tuesday, Wednesday. You realize that there is no point in assigning a number to it because the moment you call Monday equal to two and Wednesday equal to, I don't know, four, it immediately implies that somehow Wednesday is more than Monday. But then right after Wednesday will eventually come a Monday and so forth. So in other words, it does not make sense to assign a number to categorical because numbers have an ordinality, implied ordinality to them. So these are categoricals. have an ordinality, implied ordinality to them. So these are categoricals. For the time being, there are more to it. There's, for example, date and other things which need to be converted to real values and things. But for the purposes of our learning, we will limit ourselves to only these two data types. So far, so good, guys. So can somebody give me another example of a categorical? One of of you if you can unmute yourself and give me some example. True or false very good. Day of the week, in fact, boolean male female. Yeah, male female so a booleans to false uh gender yeah male female yeah male female yes male female is another great example boolean boolean it's categorical too we'll just treat it as categorical not and if it has categorical to is zip code categorical yes because there is a finite set of zip code so the criteria for categorical is that it must be categorical must be a finite set let me highlight this must be finite set so this is a very important requirement i'll just highlight this if it is not finite then it is not categorical one example is the sentences in the English language how many sentences can there be in the English language it can be infinite or in any language it's a infinite set people can create all sorts of sentences or the paragraphs and so forth because it's an infinite set you can create all sorts of sentences or the paragraphs and so forth because it's an infinite set you wouldn't call sentences a categorical variable together so you must know that it is a finite set then only it qualifies as a categorical variable a boolean is of course the simplest example. It is true or false. So it does qualify. Gender qualifies because you can have male, female, and a couple of other genders, but it's a pretty small set. So, and so forth. So this is the definition of the two kinds of inputs and outputs that we will deal with. Next comes the question, what is regression? Regression is a box that takes in, think of it as an imaginary box, and you feed it input features, a data point which is represented as input data. So think of it as regression is represented as input data. X2, Xp. So as an example could be temperature, temperature, pressure, wind, rain, amount of rain. So what will that be? If on any given day you can tell these four things, let us say, and you can build a model or a prediction system, some sort of a relationship or a concept between input and output a hypothesis relationship then this is your x vector are we together guys in simple terms it's a tuple you can think of it as simply a list or a tuple of values of variable values so x goes in and so more formally you can just write it in this notation x vector goes in and y hat comes out now y hat is not a vector by the way why am i putting a hat just to recapitulate this hat signifies hat signifies This hat signifies. Hat signifies. What does it signify? A prediction. Thank you. Prediction and why the actual data would be why remember we use. Why for data, why had four for predictions so a prediction comes out this is a model now what is in here how is it that a box can take an input and produce an output we will now learn ways to build this box. So far so good, guys. Can I scroll up a little bit? Yes, sir. Okay. So let's take this and ask what we can do. So one thing we can do is let's say we look at the data. We looked at this data. And let's say that your data is like this. Let me take a color of data. The simplest example that we took. The simplest example that we took. And we said that this is your y and this is your x. In this direction, it is your x and y. Just looking at this data, one comes up, sort of it gives us an idea that perhaps there is a linear relationship between x and y, isn't it? So one may hypothesize, just looking at this data, that the relationship could be something like, let me take this, this could be a relationship, let's say, approximately. approximately. So when we hypothesize that this is a relationship, this is our hypothesis or model. This hypothesis, we can write, in the case of mathematically, we can write it as beta naught plus beta 1x. So this is to recapitulate what we did. Now, the Greek letter stands for the pieces of our hypothesis, of our model, of our abstract notation. The x and y stand for data. The Roman letters, they stand for the actual data itself. So we can hypothesize a relationship. People often write it like this. But actually, to be much more precise, what you say is that it's beta naught plus beta one plus an error term, a term which represents these errors. You know, there'll always be errors at any given time. And these errors are the residuals you can see that they are residuals or so more appropriately this particular part of the term is your y hat this is what your box predicts are we together so this makes for a model that we can find the model that makes the best prediction so how do we find that we know that we are in search of a line. We just need to find the line, that line which gives us the least total error. So first, and this is a recapitulation of what we did, we have to do two things. There's an old statement, actually, I keep quoting by Kevin, one of the great physicists of thermodynamics, who said that for you to improve on anything, you must first quantify it. You must measure in order to improve. Roughly speaking, Kevin, or is it Kelvin? Kelvin, the physicist. Actually, let me write it in a better way. Some of you may know about Lord Kelvin, if you have done physics, he was very influential in thermodynamics. He says, to improve first you must measure, to improve first you must be able to measure. He didn't say it in quite those words, but we'll say it like this. His actual languages are quite beautiful. If anybody is interested, I invite you to look it up in the way he said it. So in our case, what is it that we are trying to measure we realize that we need to quantify the error the total error actually let me use the e term the error the error first we need to write this error and we realize that we could write it in this way we take the prediction and we look at the actual value and the prediction. So these are the gaps. These are the mistakes for the ith point xi. This part is yi hat and this part is the actual yi. So far so good guys? You realize that, realize that isn't it yes this part and therefore this is the residual r i is y i minus y i hat right so this is the error of this particular prediction and when we take the error of all the predictions so this is our residues so you to compute the error we have r i is equal to this now we know that somehow we need to collect all these residues and because the residues can be positive or they could be negative like for example this is a negative residue we need some way to just look at the magnitude of the residues so let us say that we have a qu and so this is much more interesting y i minus y i hat the the size of the residue so one of the ways we can do it is we can create the total residue by summing over it is we can create the total residue by summing over just the absolute values or you could do so there are many many ways that you can formulate the error term right and people call it the loss the so on and so forth so you can write it literally as summed over so the sigma stands for sum summing over all the residues aggregating or collecting all the residues so you can do this and that is okay but not common not common not common the more common term is e is equal to ri squared so one way to get positive quantity is just a square this time. If I square, you realize that whether the residue is positive or negative, it will become positive when we are together. And so this particular way of writing it, which is the, uh, some square sum of squares. Of the residuals, actually I keep using the word residue, but the term is residuals. Square of residuals. So this is the term it turns out that is most commonly used. Not because it is the only correct way of doing it, but it certainly is the most common. And now the question is, why is it most common? So that has to do with a theorem that was created by Gauss and Markov. There is a Gauss-Markov theorem, and behind that theorem is an assumption. It says that if you build a model, the Gauss-Markov assumptions. The Gauss-Markov assumption, what does it say? I'll give you the intuition for it. And you can I won't give you all the terms it is often called the line assumption line assumption and i'll invite you to go look up what the line assumption uh what are the what the word l i and e mean it's an acronym so you can do that but I'll give you the intuition here see first of all the for if you make a linear model your data it better be linear because if the data is nonlinear then it doesn't make sense to make a linear model so for example if your data is like this and nonlinear data if your data is like this, a nonlinear data, if your data is like this, would you call this a linear model? Would you call that it meets a linearity assumption of the data. So this would not be a linear, a not linear data, nonlinear data. So it wouldn't do. The other assumption is that you must have the data lot more small errors rather than big errors. In other words, the epsilons, the error terms, the error terms. So number one, one. The second thing that you want, and again, let me scroll down a little bit. And guys, I'll send you guys this notebook, sir, as a PDF. The second assumption is that the error terms, you know, all these residuals, epsilon I or R I, these are the terms we use. It must if you look at all of these values, they must be close, more close to zero than. Away from it, in other words, they must form a bell curve. If you if you plot all the error terms. Whether you call it or let me just call it here. In your model at the end of the day, your. your this is zero. So people use an interesting notation. They use a very scripted n for error for the residue. Let me just call it error whose center is zero and whose spread is, well, it is some standard deviation. It is spread around the zero value, which makes sense. Most of the data should be close to the line. If they are not close to the line, the line probably doesn't reflect the data. Do you see how intuitive this is? If you look at this thing, the whole point of the line is it's as close to the data as possible. So therefore, it is representative of the relationship embedded in the data, which means that the departures from the line of the data points, those residues, most of them should be small and very only a few should be large. And so the error terms, they should have a Gaussian distribution or a normal distribution. There's an interesting historic aside to it. The concept of a normal distribution came about actually by studying the errors. People were trying to come up with the proper representation for error terms. We realized that in most situations, errors are small and large errors are fewer. So if you take it and you say, I'm going to look at errors so that they are symmetric, they're equally symmetric, they're positive errors versus negative errors are equally likely in any given situation, and that errors have a smooth distribution and, you know, the continuous smooth distributions, etc. Under certain conditions, you'll realize that the function that satisfies that is the normal distribution. And that is how the normal distribution or the Gaussian distribution was created or discovered. It has a sort of a complicated structure. I'll just mention it. It is a function of n given mu sigma square. And it is equal to 1 over 2 pi sigma exponential of e to the minus x minus mu over sigma square a half. Now this is a pretty looks like a fairly. A fairly esoteric expression, I'll just write it as the definition of the normal function, and it is worth knowing it because it's one of those things that looks scary, but actually isn't. It's mathematical form looks scary, but the geometric interpretation is very, very easy. And soon you guys will become very familiar with this. It's not at all hard to remember after some time. Why is it important to know this particular distribution or this particular function? It turns out that these normal distributions or these Gaussian functions, they are ubiquitous in machine learning. A lot of machine learning, one way or the other, uses or refers to the normal distribution. So we are encountering it for the very first time. And I'm putting the expression there. And then gradually you'll become familiar with this. Now, I'll unpack it a little bit for you. Now, what is this? This is the mean or center of the bell curve. So this is the bell curve, right? Bell curve. The normal distribution, its popular name is a bell curve. It's a bell curve of sorts right so mean or center of the curve bell curve what is sigma sigma square is the variance this is the distribution this is the sigma squared measure it it measures the distribution or a fatness of the bell curve is it very uh for example peaked or is it very broad and so forth right is it a smooth hill so for example if i have a distribution like this this is much more smooth so it has a bigger sigma square for this sigma square of blue is greater than sigma square of black one and which itself is greater than let's say the sigma square of let's take another color green i'll stick do you see that the green is very peaked it's very narrow most of the mass is close to the center this is it so this is it if i have a sigma square for the green and this relationship will follow in this picture is the intuition clear guys so sigma square is called the the variance and it is a measure of the how gathered the bell curve is or how spread out it is so we'll encounter that as we go ahead. And now this term should look pretty familiar to you. What is this term, guys? Do you remember? X minus mu over sigma was what? It is the scaled or standardized value of X. Scaled or remember we did this last time. Standardized value of X. You remember often represented as Z. Scaled or standard. Let me write it popularly, it's written as z. And if you remember, the expression for this was z is by definition x minus mu over sigma. When we were doing the relationship of correlation and covariance, you remember we came to this, that z of x, correlation and covariance, you remember we came to this, that z of x or the standardized representation of x is from the x, you subtract mu. Why? Because you go to the center of gravity of the x data and x minus mu will take you there. And then you bring it to a normal scale divided by sigma so that it begins to look more, the spread is sort of standardized. to look more the spread is sort of standardized so this is it and so if you write it in this expression this entire thing can be written as this thing actually is a very simple thing if you write it in x minus mu term you will realize that it basically says that x given mu sigma square is equal to 1 over 2 pi sigma square root of 2 pi e to the e to the minus z square over 2, right? And that is also equal to the normal distribution of z with respect to 0, sigma squared. Right? And so this notation at this moment may be a little bit unfamiliar. I'll leave it as such. And you don't have to. See a lot of this notation, they look very strange when you come into this field of machine learning, but actually they are not hard. And so experiences as students go through this workshop over time, this all becomes very natural and they start using this notation, but it doesn't come immediately. It takes a little while for us to develop intuition or familiarity with this notation. So I'll leave it as that. And I basically, I will put it at the point at which we say that so long as we are, our line is truly close to this, to the data, we are observing the Gauss-Markov assumption. So now comes an interesting result. The initial problem that we posed is why not this? Why not, for example, why not? Can I ask a question? One second. Let me finish this thought. I'll ask this question. So, for example, why not R to the power of 4 or sigma I Ri cube? So it is a worthwhile question. Why is it that we don't capture error as. Any 1 of these terms you realize that each of these would in some way measure the error and so forth. Why is it that we don't use that? It is something for you to think about. Let me take Albert your question. Go ahead. So there is an X there, right? In that N of X. So shouldn't that be E or why are you using X instead of E? I'm just curious. You mean X is here. You mean this expression? Yes. So, yeah, no, I'm just defining the normal. And in our particular case, of course, in our case, X is actually epsilon. Okay. It is just the error term. Okay. I'm just giving a general mathematical expression. It's a bit unfortunate because here we used X for data, but mathematicians often use the word X when they are just dealing with a single variable. So do not. Yes, you're right. Do not mix this X with the X of the data itself. Here our X is epsilon. So, what we are saying is that the residuals or the epsilon, they have a normal distribution. If you look at all the epsilon values, they have a normal distribution. So that is essentially the Gauss-Markov assumption. So under these assumptions, there is actually a theorem which we'll come to, and there's always... So theorems are like milestones. When you're thinking about some topic and you come up with some interesting result that is not so obvious people capture it in a theorem. So the theorem is in particular. Let me just write the theorem down. Gosh, Mark of theorem. Also called the gospeluss-Markov theorem says that the E is equal to Ri square is equal to sum over and that is equal to Yii minus yi hat squared. If you use this and minimize this, you are much more likely to have a good model so long as the Gauss-Markov assumptions are there. So you see that this quadratic terms is the best linear unbiased estimator, which is called blue. And so you would say, okay, so what is the big deal about it? It's actually fundamental. A lot of example, econometric theory wouldn't be valid unless this theorem were true, which is why most of the people who do econometrist in their syllabus, in their textbook, very quickly they're introduced to Gauss-Markov theorem and the concept of the blue, the best linear unbiased estimator. So from here onwards i would consider the situation result now we won't go into proving this theorem it's a little bit more intricate but uh but we'll just develop some intuition about it why what does this say what does this particular estimation of error so e is is what is an error and this expression is some estimator of the error. The word people use is the estimator. Think of it as some way to quantify the error. big error terms are severely penalized what the quadratic term will do so big i'll just write it down big error terms are severely penalized analyzed compared to small error terms compared to Small error terms compared to. Because of the quadratic. You can imagine that if I take a number one to ten, one square is one, two square is four, but ten square is a hundred. So big numbers, they blow up when you square them they begin to blow up doesn't it they have a distribution let's say x and x square if you well let me not use x because x is used for something let me use t and t square if you look at it the curve will go like this so what happens for big values of t the t square is huge isn't it it begins to blow up quadrant that's what the quadratic term does and that is good it helps you create like by it gives you an estimation of the error such that what do you do? You minimize the next part of it is we minimize the. The error. The error. So whenever we talk of the error, this error, we also call it the loss function. So people often use many things. I use error. The last function. Etc people use all sorts of word utility function, and they're actually subtle nuances between them and but for linear regression, they amount to essentially the same thing but we'll come to that but this term this error term the sum squared error is what you minimize now how do you minimize it if you remember this error term and this is a recap so today will be a little bit of a theoretical recap guys so and we'll we'll use this recap and gradually move into new territory this is when you feed it into the model y i minus beta naught minus beta 1 x square now where did this come from well it turns out that this guy is this term is this term is the definition this is your model. Right so when you expand it out this term, it becomes, uh, is equal to. Since data is fixed. He is a quadratic function. Beta 1. We see this, guys, that it will be a quadratic function. We can expand it out. It will be beta naught squared and beta 1 x1 squared and so on and so forth. square and beta 1 x1 square and so on and so forth. So because it is of that shape, you know that what it will look like is a surface. Now let's look at this. Then this is your beta naught, beta 1, and this is your error, Beta naught, beta 1. Now by error, we always mean the sum squared error. Sum squared error. So this is the word people often use is sum. Let me just write it here. Sum. Squared. squared error, right, is the thing. Now, we minimize this. We have to minimize this. Now, how does this error surface look like? If you remember, I mentioned that this error surface looks like this. It's a quadratic surface, a quadratic surface that is like a bowl. And this achieves a minima if I come down. It achieves a minima somewhere here in the ground. So there is some preferred place place beta naught, beta 1, the solution. This is the best location in the hypothesis space or the parameter space, hypothesis space or the parameter space hypothesis space or parameter space where the error surface where the well i went up too much where they where they achieves its minimum so this will map to some value, E minimum. Minimum, isn't it? This particular value of this. This is the minimum value that it will achieve. Now, the whole question is, how do we reach that? How do we discover that? Now, the way the intuition for that is, suppose we have the data, let's project the data back here. We have the data and let's bring in data again. I won't put too many points here, but something like this. And so we can draw arbitrary many lines, right? We can draw a line that goes like this. We can draw another line that goes like this, right? And then we can draw a third line, let us say the red line, which is, that goes through, like, sorry, maybe the best line, right? Let me make it the best line by adding a few more points here and there. Okay, so suppose this is your best line right let me make it the best line by adding a few more points here and there okay so suppose this is your best line how do you go how do you find this the question is how do you find this um that's the crux of the problem, isn't it? It is not enough to be able to pick a hypothesis, pick a line, which is a hypothesis of a relationship between X and Y, but you have to find the best line and how do we do that each line which we assume is a relationship between input and output is a hypothesis and each line corresponds to a real point actually this point let me just mark it as the real the points here points and let us say that this green point corresponds to this this line the green line corresponds to this point and let us say that the blue line corresponds to some other point here uh let me just take it as, let me just take this as a blue is, yeah, let's see. Blue point in the hypothesis space. So in the hypothesis plane, these are three different points and in data space, they are lines. The question is, we can arbitrarily pick a point, but we need a way to get to the real answer. In other words, it's okay to make a mistake, to pick a wrong line, a wrong hypothesis. We just need a way to find the right one. And the example that I gave is we need to do so-called gradient descent. We need to somehow tumble down from here to here to here. Are we together? So we talked about, and this is where we ended the last Descent. Gradient descent to the best point. So far guys, I hope it is obvious that if we gradient descent from any arbitrary hypothesis, it will take us to the best hypothesis right and when you do that you achieve the two goals or the two legs on which machine learning works you first quantify the error and then you minimize that you improve upon it until you can't improve upon it anymore and you are left with the irreducible error that's about it right so what is gradient descent i will illustrate the concept of gradient descent using a very simple function. So let's take a function, fx. And this is a function, fx. y is some function of x and i've just made a curve here for illustration to illustrate the point so let's take two points i will take a point and take a green point let us say is here so suppose you take a point here look Look, observe. Let me just call this point A and its value here, A prime, right on the curve as A prime. Now, I will take another point, let us say B. B along the x-axis, right? And by the way, I use x, but actually it's because people are used to using x in mathematics. But let's stay with the notation. Now, I will bring about a very simple concept. At this point, what is the slope? What is the tangent? Is the slope positive or negative? So let us define slope. Slope is defined as increase per unit increase. Of X, actually, this is a bit sloppy because a unit may be a huge. So just assume that your unit is very, very small. It's a millimeter or something like that. But how much do you rise invite as increase. Defined as increase per unit actually increase of what increase of effects. Per unit increase effects and the underlying assumption is in calculus. You make the assumption that you hopefully your unit is infinitely small. Fully. Hopefully your unit is infinitesimally small. Hopefully your unit is very small. Why is that? Because the value changes. You notice that the slope changes at different places on this curve. So if you take a very small unit and then ask how much did fx change that is the slope so look here if you move in the positive x direction let me say positive x direction let's say delta x did fx increase or decrease would anyone like to tell me? This value, which is fx, it is greater than fx, isn't it? This relationship is true. So you say that the slope is positive. In other words, slope at b is positive. Now, what about slurp at x? At this one point, the tangent to this line is like this. So what happens is when I go make a unit increase, by the way, this is unit increase delta x. When I make a unit increase, when I go in up to delta x, what does it mean here? This is fx plus delta x, isn't it? So is fx here, is it more and this is fx? Is fx plus delta x more or less than effects? Yes, so would it be fair therefore to say, I'll write it down. Is less than effects so therefore we can say slope. At a is. Negative. So therefore, we can say slope at A is negative. Would you agree with this so far? Now, what do we want to do? We are looking for the best spot. We need to go here. This is our best answer right answer let me just call this uh c we our goal is one way or another from every point goal from every point from any and therefore From every point. Any. And therefore. Every. Point. Point. And. Point of the curve. Point. We need. A way. To reach. C. Quickly. This is our goal, right? Because why C? Why are we in pursuit of C? Because at C. The function achieves a minima and we are searching for a minima of the function. So suppose this is your goal and you are at A. Let's look at A. You make a change delta X. Which direction do you want to go into? You will say that the next, should you go in the positive direction or should you go in the negative direction? From a, if I want to minimize, let's look at the picture again. Sorry this is if I'm staying at a, should I move in the positive direction to decrease the function or should I move in the negative direction? Negative. No, no. I want to decrease the function. Positive. You realize that if I move this, this function, from here it comes down to fx plus delta x. And then fx plus delta x is smaller. Right? So, for example, this is fx plus delta x isn't it it's smaller than fx so i will write the rule down as this at a move in the positive direction move a bit in the positive direction. So we can say that the delta x, the step that we take, should be... Now, you realize that this... Suppose I write it like this. It is some small step in the positive direction. But how do we know which is the positive direction given X at that particular point? So suppose we do this. I will use the word DFDX. It is the derivative, but it is actually the slope. Let me geometrically, this is the slope at delta x at a. Let me just put it this way, fx d fx dx at a, right? This is the slope at a, right? So, suppose I take this step such that x, the next step of x, let me call it x tilde, is the previous value of x. And now you notice that this is negative, right? At a, this quantity is negative. The slope is negative. Let's say that alpha is a small step. Let's say alpha is equal to 0.01. A small step. And then this quantity is negative. So how do I move in the forward direction? Would you agree that this quantity, if I make it a negative thing here, then this criteria will be fulfilled. I would have delta x would be in the positive direction. Does this make sense guys? Because my derivative at a is negative, slope is negative, I multiply it by a negative number and it becomes positive. So therefore I can say that my next position of at x, next position at a is the previous position at A minus alpha dF dx. At this point, guys, if you don't quite understand, it's okay, but we will write it as a fact. Are you guys getting the intuition? You need to go against the slope, the value of the slope. If you go against the value of the slope, because the slope is negative, you'll end up moving in the positive direction. Are we together guys any questions anybody who did not understand that. Now, at C, at this point, a B. We a similar consideration applies. So the same thing applies. Now look at B. You want to take a step in which direction? Backwards direction, isn't it? You reach C from B. Which way do you want to move? Forward or backward? It is clear that we need to move backwards, right? Because we are trying to get to C. So here we can say that delta x at B should be, actually this is too far, delta at x, B should be equal to, well, the slope is positive. So alpha, small step, and if I multiply it by the slope at B, this is positive, this is positive. Well, that would be bad because it would take us in the forward direction away from C. Once again, I need to put a negative quantity there. Do we see that, guys? That in both the cases, if I want to go towards the center, I need to go against the slope. As simple as that. And therefore it doesn't matter whether I'm on this side or this side. You have the more universal formula, which is the famous formula of gradient descent. It is this gradient descent formula. It gradient descent therefore answer result gradient descent is this formula delta x is always minus alpha df dx right or put another way x tilde is equal to the previous value this is the future value the next value of x x of x sorry this doesn't look nice Next value of x is the previous value minus alpha df dx. Now, why this derivative? This derivative is actually, it is sort of a throttle. Think about this way. What happens when we come very close to this what is the slope here close to zero isn't it and this is zero you see that when we achieve the minima what is the slope at the minima there is no slope it's flat do you see that guys that, that at C, the slope is, sorry, where is my color thing gone? Draw this. The slope is flat. So, df dx will be 0 at this point. df c dx is equal to 0. Well, this is rather scriblish. Let me be better here. At this point, df dx is equal to 0 at a. So far, so good, guys. And so this is a way for us to throttle down and not keep moving forward. So one of the questions you could ask is that I could have just taken the sign of the derivative, ask is that i could have just taken the sign of the derivative positive or negative why do i keep the quantity itself the reason you keep the quantities if you don't keep the quantity you'll never be able to stop you'll forever keep making a progress you'll overshoot and so forth so by putting the derivative there you know when to stop you stop when the derivative it vanishes you know when to stop. You stop when the derivative vanishes. In more practical terms, what you do is the derivative will never quite absolutely go to zero because there'll be noise or something in the data. But in a more general sense, for linear regression, it does go to zero very easily. But in more complicated algorithms, you just, in practical terms, come close to zero and you say we are done. We are very close to the real thing. So this is how you find the minima of a function. Now let's take that knowledge and apply it to the same thing in our, where is the mouse going? Give me guys for 1 minute. I seem to have. 1, 2nd. One second. It's down. Yeah. So, no, I don't want to go down too much. All right. I'll just write here and I need to charge my mouse. It's a good point for us to take a segue, a little break so um um where were we so this is gradient descent using gradient descent we can come to the minimum so guys if the calculus is not very obvious um it's all right these things come and become very uh easy to understand after you have listened to it and thought over it many, many times. So in our case, you know, our hypothesis space is this, beta naught, beta 1, and this is the error function in terms of beta naught, beta 1. So how do we bring in this whole concept of gradient descent out here? So the way we do that is hang on. Hang on. All right. The way we do that is this thing just gets modified. We are walking in the hypothesis space. So it is very much like walking in our simple function space. We say beta naught, the next value is equal to the previous value of beta naught minus alpha and partial derivative of e with respect to beta naught so in other words when you do multiple variables you want the slope right slopes are partial derivatives with respect to a single variable you look at a cross section of the surface there's a good geometric interpretation to it. And the same thing we can do for this, beta 1. So this is the rule. This is the gradient descent rule. Find the solution. It can also be written in a much more formal vector notation. You can say that beta's next value of beta is, if you look at it, beta next, I'll just put it, is beta, the initial value of the plant that we need to. Squared error. Works very well. When the line assumptions are met. Line conditions of it. Or the Gauss Markov assumption summit, line condition summit, or the Gauss-Marco assumption summit. Simple terms. Number two, gradient descent is an efficient means to find the path to the best hypothesis Are we together guys? So this is essentially, if you understand these two concepts, you have understood not just linear regression, but actually a whole class of machine learning predictive models. This is what it all is based on. And so at this particular moment, before I move forward, I would like to take questions. Are there any questions guys? Ask if can you go back to the screen where I. You did those epsilon and stuff like that and. I was just why I kind of power hang on so i'm trying to find uh where you're talking about uh epsilon yes then and yes yeah this is it oops are you able to see my screen yes my screen yes okay here we go so ask you what is this giving you in terms of this is this is the error distribution correct yeah basic idea is it's an assumption if your residual terms are not normally distributed, right, around zero, then you cannot use linear, you cannot use your sum squared error the way you have written for your model, it won't work, right. So in a way, I gave you an introduction to the bell curve. Bell curve is something you may or may not have encountered in your engineering or your undergraduate studies. At some point you probably have encountered, but you probably didn't realize how central it is to machine learning. So early on in this workshop series I thought today I would introduce you to the bell curve and we had to encounter it anyway. Today is a good day to encounter it. So basically, so basically for nonlinear data, this is the way to do it. And for everything else, you can use the sum square. I mean, the least square or the gradient. No, no, no, no. The way to nonlinear come in. No, this is the linear assumption. The Gauss-Markov assumption says that if your data is like this, then the blue line can be a good hypothesis. Now, if you look at this, what are the things about the blue line you can tell? By looking at the orange dots, you can tell that the data looks linear, isn't it? It truly is linear. The second thing you can tell is that the residues are rather small, and most big residues are uncommon. Small residues are common. So these residuals, sorry, not residues, I keep saying residues, residuals, but the residuals or the error terms, they will actually form a bell curve distribution. If you plot them as a histogram, you will notice as a frequency chart, you'll notice that they have a bell curve distribution. Okay. So we are still within the world of the linear. Okay. Are we together? But if you have nonlinear data, then you cannot use a linear model. Obviously. So, for example, look at this case. And not use linear model. It breaks the goshmark of assumption for you clearly here. I did itself is nonlinear. So, here the error, we said that it's a sum of a residue. Sum of square of residues, sum squared residues. Yeah, but why did we make it a square? I understand that it is easy for us to make it, but will the error be not of a different quantity than just the sum of errors? Yeah, so the idea is that, see, you can do the sum of errors. You can't take the the sum of errors yeah so the idea is that see you can do the sum of errors you can't take the raw sum of errors because that would be a negative i mean positive and negative so cancel each other out so you have to take the size of the error now you can just take the size of the error like here like this particular thing it is just not very common for a reason that I explained. So you can take this, you can take this, you can take the fourth power, third power, you can do anything. So long as you're adding up the residuals, you can take any power of the size of residuals. So the question that comes is, which is the best one to take? And so that's where an important theorem comes in, discovered by Gauss. It's called the cost Mark of it says under a sensible assumptions. Those sensible assumptions being gosh, Mark of assumptions means your data actually line actually seems to go through the data and the data is linear. Then it is best to take the error term to be the sum of square of residuals. It's a mathematical result. It's a theorem. Okay. And just one general question. In the first one, when we draw the black box to represent the hypothesis, we said the input is an x like. See what happens is mathematicians always look at a tuple, you know, a collection of X1, X2, X3. It follows the natural notion of a vector. In other words, it follows the properties of a vector space. What it means is, and it's a bit of a geometric intuition, you say that regression models, they map to each point, each vector x, a value y. So they are basically, a y hat is basically some function of x vector. That is the mathematically concise way of saying it. So the vector usage is deliberate. In practical terms, if you don't think in terms of vectors, it doesn't hurt you. Like most computer scientists, what do they think of it? As a list of features, you know, temperature, you know, this or that, temperature, humidity, day of the week, and so on and so forth. So if you just think of it as a pressure, wind, rain so if you just think of it as a pressure wind rain if you just think of it as a list of values so long as you know that in data the first one is the temperature the second is pressure wind etc etc and programming you'll make it an array typically of size here for or a list or something like that it's perfectly fine right but more formally it's a vector okay thank you guys uh any questions but otherwise we'll take a very small break and i will then introduce the concept of like so this is sort of the background i'll use this background to go and explain uh concepts of how do you at the end of it know that you have a good model? What are your model diagnostics? What is bias-reinstated or what are regressions? I have a quick question, if you don't mind. Okay. Is there something I can help you with? No, sorry. Go ahead. Yeah. So the question is, can you explain again? Why we use partial derivatives instead of normal derivatives and while. Doing this and because in multi, multi, your error surface is made up of beta out in beta 1. right? and beta one right so think of it so you don't have a concept when you have a multivariate function you don't have a concept of a um of a derivative derivative concept is only for single variable okay so the concept generalized to multiple variables is partial derivative so i'll give you the intuition of it so suppose you are in a hill and you ask yourself if i go north how much altitude i'll gain or lose so for you to measure you don't want to also change go east west at the same time you want to only go north south a little bit north and see did you gain altitude or lose altitude isn't it so there will be a slope along the north south direction and then another slope on an east west direction. And the only way you can find that is when you're going not, you'll keep your position along the east west access the same. You'll hold the other access fixed value along the other access fix and just make a change along the north south axis. axis fixed and just make a change along the north south axis this is what you would do when you're hiking and that is exactly the concept that partial derivative says keeping other variables the same if i make a unit step in this direction how much will their value change okay got it thanks so guys i'll uh we have been talking now for about an hour or so today is going to be a little longer session because I also want to do some coverage of the labs and I have a new set of notes to release to you. To release, but any more questions each of them partially. Yes. Yes. They're independently descending. So, the minimum achieved through that descending through beta 1 and the beta 0. Yeah, can you say both of the mini muscle coincide to be the same? I'm just a little... Yes, of course. So let me tell you. See, what happens is... Let me make the intuition clear with a picture. This deserves a picture here. This is beta naught. Let's make it really big. This is the error. Beta naught, beta 1, right? We have the error surface. Beta naught, beta one, right? We have the error surface. And these lines are there. These are contour lines, right? These are contour lines. Let's do one thing. Let's project it down. Sorry, not these. What are contour lines? Lines which are at the same height. You know, in geology, you use the term contour height. So, for example, all the points along this curve, they are at the same height, isn't it? This is a contour on the hill. So, now, let us look at this. What happens is that if you look at this, actually, I can color it differently. Let me use different colors to illustrate this point. Let me use a blue for this. Let me use green for. Sorry, this one. And let me use something else, red for this. And I don't know. I may soon run out of colors. This. This. And let me go get another one. What color can we pick that we didn't pick? Let's pick more colors. Let's pick some, this color. So suppose this color. Okay, black is good enough. if you see these things are projected onto the beta naught beta one you know you think of beta naught beta one is the floor you know the surface at the bottom so what will they look like they will look like this the red line will project down to this the shadow of the of the red contour will be here The shadow of the red contour will be here. The shadow of the blue contour will be another line if you look at it here. And the shadow of the green line would be here. And the shadow of the orange line would be. Yeah, isn't it and something very interesting in geometric is there. I didn't sort of bring that to you guys attention here. So suppose you take an arbitrary point in the hypothesis space. Suppose you start here. arbitrary point in the hypothesis space. Suppose you start here. Right now associated and maybe even worse than that. Let's take, okay, let me bring that line again back. And there was a black one also there. Now I need a color to show my journey. What color can I pick? Let me use a violet color. I've not used violet so far. Okay. So suppose I start here. Initially, my hypothesis, I just pick a random hypothesis, a random line. What do you want? You want to go straight in, right right so you want to go this direction yeah that's right and this journey is the direction of gradient descent it's literally the if you look at this do you realize that this is the journey because you're going from here to here to here to here to here the best point literally that you can see it you see that and this journey is the journey of literally the gradient descent from the top to the bottom is a journey on the hypothesis plane it is the shortest route back home yeah and that is the intuition of gradient descent so you do the beta beta one parallelly like yes you do it both together so what you do is one step little yeah very good question one step one step so when you write a code imagine that you have a code right your your code will literally run like that for uh for and i is if you're writing something like c or c plus plus right i'm just going to give you the syntax i less than let's say that you are willing to make I'll take an example a thousand house of nitrations right I plus plus what will you do you will just say beta the new value of beta naught is equal to so initially you'll start with some arbitrary values initialize with initialize with with beta naught beta 1 and then all you do is you will literally write code that says take the take this minus alpha de de beta naught or beta 1 and in the same step you update both of them together beta 1 is minus d e d beta 1. it's good that you ask this question because this makes this makes for uh actually yeah hang on let me start with a different color one step exactly and thanks for asking this question actually i should say this is one step uh where should i put it this is actually one step right you see that in the for loop and the four for thousand steps so people use the word iterations or steps or things like that and you will be smarter than that, because what will happen is, how do you know that 1000 steps are enough? Right and or it is too much. So, at some point, what will happen is once you notice that your your change is not too much neither or beta 1 seems to be changing too much. You'll just break out of the loop. Right you say i'm done i found the minima so you do some smartness but roughly speaking this is the code for you are we together guys so far any other questions if there are no other questions we'll take a 10 15 minute break yeah so guys we have a somewhat longish theory session. Are you all game for it today? I'd like to finish linear regression and bias variance . Yes. Yes, sir. So I'm going to pause the recording. And let's go and take a it's being recorded again. So, see, data can present to you in many forms. Suppose the data is like this. can present to you in many forms suppose the data is like this this is clearly what we will call linear data isn't it the moment you see this your basic intuition says i need to just draw a line like this so case one uh case a what if you get data let us say case b suppose you get data that looks like actually i used another form for data so suppose data looks like this The data that we talked about is this linear data can be modeled with the line. We cannot model it with the line, right? So the question is linear regression when we think of a model which is like this, a linear regression model, we wrote it as y hat is equal to beta naught plus beta 1 x. This wouldn't capture this situation. So what can we do to capture this situation? This curve is very obviously it's a quadratic curve. Isn't it? And so we can easily say that suppose we were to add a term beta to x squared. Now you realize that this has become a quadratic equation. Now let me remind you of something interesting about curves and polynomials. A straight line has zero bend. It is, what is the highest power of x? Polynomial of x. It is the first degree polynomial of x, isn't it? Do you see that, guys? The x in terms of x is a linear polynomial. What about this? You write this as a quadratic expression, isn't it? Y is proportional to x squared. The highest polynomial term would be quadratic. Isn't it? So the polynomial term would be 2. The highest polynomial term would be 2. You would write it as y is beta naught plus beta 1 x plus beta 2 x squared. And we can generalize from that. We can say, suppose you have. Free bands something like this. So each band requires an extra done. So, how many degrees do we need here? So, Benens is 3, bens 1, but aligned by definition bens are 0, right? So, this would need y is equal to beta naught plus beta 1 x plus beta 2 x squared plus beta 3x cubed. It would need an equation of the third degree because we have two bends. The number of bends is two actually. This is three. Do you see this connection guys? So suppose I make a curve with three bends can you tell me what degree of polynomial i would need anyone can guess that can you extrapolate from this four right so if benz is equal to three poly degree will be four right and so you see the relationship so one of the thoughts that people had is suppose you are given data you're given a data like this literally like this then just by visualizing the data especially if it is a one-dimensional data, you could essentially infer what degree of polynomial would be good. Isn't it? And so, you can, in general, write it, let's say that this one is y is equal to beta naught plus beta 1x plus beta 2x squared plus beta 3x cubed. Something like that. And you can look at the data and get some sense what equation you would write. These are called polynomial. People often use the word polynomial regression. It sort of generalizes in a single dimension, the straight line to admit for the fact that your thing may be, your model may be like this. This is your model and this is your model. So we talk about polynomial regression. Now given data, how would you know what degree of polynomial to take? Polynomials are good. You can say y is equal to beta naught plus beta 1x plus beta 2x squared plus beta 3x cubed. And you can keep going on to the nth degree polynomial, xn. So it raises two questions. Two questions. So it raises two questions, two questions. And we'll limit ourselves to one dimension now, because from one dimension, it generalizes to higher dimension. Data be represented. As a polynomial relationship. Yeah. That is question number 1 question number 2 two is which degree of polynomial to pick? Now, I'd like to say something about, before we answer these two questions, I'd like to say a word about polynomial regression. This may seem paradoxical to you now, but mathematically, polynomial regression is also linear regression. It is just linear in a sort of more terms, polynomial terms, or people would say in a polynomial vector space, the equation is still a linear equation. Now, why is it linear? Because it is additive. And I won't go more into it. It's a mathematical aside. Let me just put it in the page as a mysterious statement that gradually, as we develop more mathematical sophistication we will understand what it means polynomial regression is also a form of form of despite what people say it is also a form of linear regression mathematical sense as we will see later. So it is just an aside. How is it linear? It doesn't look linear. A quadratic equation and a linear equation are entirely different according to the common language. But we'll get into it when we understand the concept of vector spaces and that won't be for another until you get to the second workshop the more intermediate workshop where we'll do actually not even then if you take the math behind data science i cover it there but for now i'll leave that statement there and now we will come back to two questions this This question and this question, can every data be represented as a polynomial relationship? And the answer to that is quite interesting. When people came up with linear regression, and we are talking of 1805 Legendre's paper on least square and Goss's paper in 1793 on the very elliptically referred to it. Then people started doing linear regression. It's a very powerful tool. And then they encountered curves. They found data. Not all data is actually straight. But the question, therefore, arose, can we model it? And people said, yeah, why not? Let's count the number of bands. I mean, there is a polynomial, and we can model it with a polynomial. There still remains a question, which degree of polynomial to pick? Where should you stop? Should you stop at the second degree, the third degree, the fourth degree, the fifth degree? Where exactly should you stop? And that question will come to later. But let's ask a more fundamental question. Can every function, because the relationship in the data between target and input is a function, some hypothesis function, can every data be represented as a polynomial relationship? So I want people who are new, of course, to answer this people who have been in my math class obviously shouldn't. Answer this on my prior class, I would like to get some guesses. Does this seem logical that, you know, you just count the number of Benz in a line and you'll get. And you can basically write a polynomial that can fit to that curve in the data. What would you say guys? Any thoughts, any ideas? Initial guess is yes, but it depends on how we define a bank. Right how we define the band. That is one answer. OK, anybody else would like to take a shot at it i don't by the way the full nuance will escape you at this moment it's all right you're getting back to the mathematical space a little bit so it may not come to you anybody else would I don't think so. All the data can be fitted into polynomials. If it's distributed as clusters. No, let's think in just two dimensions, x and y. I think as long as it is continuous, I think we can express in a polynomial. Assume continuity. Assume that you have continuous distribution. Then I think yes. Yeah, that's a good thought. Does it have to be a function, sir? What if it's like circular? A circle is not a function in the traditional sense. I mean, it is a quadratic function. We can write it differently, z. But it is not really a function. It's a constraint. x squared plus y squared is equal to 1. You realize that it admits. So let's take the question of a circle as an aside. Circle is more what you would call a constraint because you write it as x square plus y square let us say equal to one which means that y is equal to plus minus one minus x square right so the plus minus makes it a dual value for a given value of x there are two values of y right whereas we want one value of y not two so imagine that it is there are no tricks to it two values so i'll leave that aside The question is very interesting, actually. People initially got very optimistic way back, and they thought, yes, let us try to model a lot of data with it. But then it turned out that there is a class of functions. Their name is quite literally transcendental functions. is quite literally transcendental functions let me write it with a big new color because it merits a different merit something oh I've raised the maximum of this okay this is good transcendental function transcendental function. It turns out that you guys are familiar with this, with the transcendental. Some of the early transcendentals or simpler transcendentals you have encountered in your studies in high school. So what are transcendentals? These are things, these are functions which cannot be represented as a polynomial of finite degree. So if you try to represent it as a polynomial expansion, there will be infinitely many terms. Example, sine x, cosine x etc so for example if you remember do you guys remember the trigonometric relationship sine x cosine x right we'll do right right? Stereometric relationships. Okay. Just happened. Give me a moment. The screen is one step closer, I think. So when you try to expand a sine x sine x for example anybody remembers a taylor expansion of this is x minus x cube over 3 factorial plus x 5 over 5 factorial minus x 7 over 7 factorial plus x9 over 9 factorial. And it goes on till infinity. Infinite many terms. It never stops. And if you think about why it doesn't stop, because a sine wave is like this. So how many bends does a sine wave have? Well, it literally has infinitely many bends, isn't it? Yes. So infinitely many bends. And so it's an example of something that cannot be represented as a polynomial of a finite degree. So you can't write a regression equation because you can't do regression in a model that has infinitely many terms in programming. You can't deal with it. So cosine X is also like that. And then this bell curve. Another example, the bell curve that you encountered. The bell curve that you encountered, the bell curve given sigma, sigma squared mu. Remember the bell curve expression. It is an exponential equation. And when you expand it out, any e to the power x also expands to infinitely many terms. So this is a realization that you cannot model a transcendental function with a finite degree polynomial and if you do that you will encounter something that we'll see in our next lab called the range phenomenon when we and i'll write this warning down. When you try to model a transcendental function related data, in other words, a data whose underlying mechanism is a transcendental function, it's a data with a polynomial. And if this thing looks mysterious, it will all become very obvious when we do the lab. Polynomial function of finite degree. We get a wrench phenomenon in the data. What is the wrench phenomenon? What happens is, it is something I'll leave as a mystery till we encounter it. I also call it the wagging tails. And this is It is something I'll leave as a mystery till we encounter it. I also call it the wagging tails. And this is my word. It's not sort of something you find in books, but more intuitively, your model develops a wagging tail. We'll see what it means. But so that answers the first question, I hope, right? The second question that remains is, which degree of polynomial to pick right we will now answer that question because therein i would like to introduce use that to introduce the the so-called bias variance trade-off so i'll write the question down again once again which degree of polynomial which degree of polynomial to pick. So you realize that the more call, more generally, the higher the degree of the polynomial the more the bends the higher model or hypothesis. More bends, isn't it? So the question is, how do you do that? One easy answer one can give is just go visualize the data and try to infer how many bends are there. Now, two things may happen. Either the data is being produced by a ground truth which is represented by a transcendental function so in that case you're lost but on the other hand if it is not if it can be approximated with a degree polynomial and even transcendental functions can sometimes be approximated with a finite degree polynomial within a certain interval. So then the question remains, how many degrees do we take? So what happens is the more complex model you take, the more easily it will adapt to the data. A straight line has no bends. So if your data is quadratic, you will be lost. Let me explain this with this idea. Suppose you have data like this let's go back and take this this data the other data I'll take is this and the third data I'll take is like this. Let me take this data set like this. Now, suppose you make a hypothesis because in one dimension you can still see the data, but assume in higher dimensions you won't be able to see the data. So you wouldn't be able to very easily get a sense of how many bends are there and so forth. Imagine that you're flying blind and you can't see the shape of the curves or the surfaces, the relationships. Suppose you insist that a linear model is what you will take. You realize that from this, there is no good linear model you can draw. model you can draw. This is linear and here sorry if you try to do the best linear model you'll probably get is something like this. The best. Degree one. Degree one polynomial is line. Modeler. Degree one polynomial is line. The best fit line that you can get. Best fit line. Best fit line. You can clearly see that in case A, it works. Sorry, it doesn't work. It doesn't work at all. In case B, it works in sorry it doesn't work it doesn't work at all in case b it works perfectly case c also it doesn't work very well isn't it guys so on the other hand suppose you take a green model which is always a three degree polynomial third degree polynomial now how would you fit two bends in this data you realize that something like this one two three the green line so what can you tell about the green line versus the purple line. The purple line is simpler. The green line is more complex, right? Here also. Suppose you do this. But here, two degrees. Actually, I should have made two degrees. So so let me mark it like this something like this so is this better or if we take a second degree model let me take a model that is like this, which always is parabolic. One, here it would be parabolic, and here it would be like this. So between this model, the green model and the purple model you realize where is the red model the best it is best for best for a and the green model is best for? C. C. For C. And the purple model is best for? B, right? So you can make different hypotheses, polynomials of different degrees. And you ultimately don't know, flying blind, when you encounter data, which model is best. So let us try to understand the difference between the models is the see the purple is the simplest model this is the simplest right Simplest is purple. Purple. Then next is green. Green is parabolic. And the purple is the complex. The complex. So, as you increase the degree of. I'm sorry what just happened parabolic and the. Green is complex. Yes. Hang on guys. Something strange happened. The red is oh, I apologize. Red was parabolic. And the green was third degree. I missed that one. Let me interchange these two. Red is, should be red. And green. Thanks for correcting me. This would have been a disaster. Otherwise, here we go. Something like this. So what happens is, if you look at the degree of the polynomial, n is equal to 1, n is equal to 2, n is equal to 3, right? For any given situation, a model can be just right. Let's look at B. A model can be just right. Let's say the straight line is just right. Simplest model just works. But if you look at A and C, you realize that the simplest model, the popular model doesn't work, isn't it? It is too simple. It doesn't capture the complexity of the data. Would you agree with that it has no flexibility are we together guys yes so then we use certain words we say that simpler model like for a when simpler model like for A when a model is simpler than the ground truth you will have a you will have it is like they see these errors are the errors of huge amount of errors right huge amount of errors these are all errors then this this this these errors have errors in purple these errors are called called bias errors are we together? complex than the ground truth, you will have errors errors most of your errors will be bias errors if you're if you have a model that is simpler than reality and if you have a model more complex than reality you'll have high high variance. So let me show that. For a straight line, look at the green one. The green completely misses the boat, isn't it? It is filled with... Do you see how widely the green gets wrong for the case of B? Isn't it? Green does perfectly well for C. Should I repeat this concept? Are we getting it? That given the underlying truth, whenever you make a model or a polynomial, it can be just about right, or it could be simpler than reality, or it could be more complex. So, for example, in situation A, which is the best model is A. For A is the red model. For B, it is the purple model, which is really the simplest model. And for C, it is the more complex model, the green one, that is perfect. Right? So for C, if you take a straight line, what sort of errors do you get? Bias errors, right? Here also, you get high bias errors. These are high bias errors. Lot, you can literally see how many bias errors. That you're getting these terms will they actually add up to a whole bio service. So then. Things like that, so it brings up this question that how do you determine which is the best model to which is the best hypothesis to take. And that is a bit of a challenge. There is no out-of-the-box mathematical way that will help you into it that this is the right polynomial, if a polynomial fits the data at all. And so there is an expression actually. You see that the error that you get, the total error that you get from a hypothesis is the total error is made up of the bias error term. Actually bias is a mathematical expression so I'll just square it. A bias error term plus a variance error, variance, right? And plus there is some irreducible error, which I will leave irreducible. We talked about irreducible before. So bias plus variance, total error that you have in a model is bias plus variance. Even when you have learned done gradient descent, have the best fit, still based on your hypothesis, it will have a bias. So when your reality is simpler than your model, you'll end up with high variance errors. When the reality is more complex than your model, you will have a bias error. So this is called the bias variance trade-off. Usually what happens is, as you dial up the complexity, suppose, let's look at this reality, the quadratic reality. So you go from linear, linear is bad, you have high bias error. What about variance errors? You won't have much variance errors. But as you dial it up to the second degree, you're quadratic, you're perfect. But beyond quadratic, when you go, you start having not bias, but variance errors. So if you look at the error term, there is a bias variance trade-off. there is a bias variance trade-off. Right. And the way to find this or to discover this bias variance trade-off and pick a model of the right size is quite an art. There is a process to it and we'll learn the process. See, what you do is you take a polynomial. Let's say you take a polynomial of degree 3. You try to fit it to the data. It may fit the data very well. But when you try it out on test data, new data, it will give you ridiculous results. Like, for example, this green line for the green line for the straight B in this situation, the green line is absurd. Yet, when you train a polynomial model, a third degree model or a fourth or fifth degree model to the data, it sort of adapts to the data. so we i'll write it down model may complex model let me write that statement down it's a warning complex models tend to overfit the data the data. I'll illustrate it with an example. It's very easy actually to see it. Suppose I give you three points. Or maybe four points. What is a model? You could just say maybe a straight line, something like this. Isn't it? This looks reasonable. But if you take a quadratic model, you can actually try to fit it better. You can do something like, I don't know, something like this. You notice that here the error terms are much less because it has sort of adapted to this data. You can take a third degree term and it would be even more interesting. A third degree term can be like this. You notice that by the time you go to a third degree term, you pretty much have a perfect match. In fact, you will if you have four data points. You do equation in four degree, it will get to a perfect match. This complex model has just adapted to the data. So when you look at the error term, it will actually be 0. Error of the third degree will be 0. It is flexible enough to go through all the points. A straight line wouldn't be able to go through all the points because the points are not whole linear. Quadratic will have a bit of a difficulty. You can see that there is no quadratic thing that will go through all of them. But a third degree term will nicely go through of a difficulty. You can see that there is no quadratic thing that will go through all of them. But a third degree term will nicely go through all the points. The question is, is that a good model? Something tells you that that's not a good model. The straight line is too simple, perhaps, or maybe it is okay. You don't know. So how do we build good models? Because ultimately a model should be able to make good predictions on new data. So to do that, the trick we use is quite interesting. You take the data, split the data. You take the data. To train and test. So what you do is you take the data typically you'll do it as a 70 30 split or something like that. Example, you take the data, suppose it has a thousand rows. You will keep 700 rows aside as training data and 300 rows as test data something like that or you can take some ratio you take now what you do is you hide the test data under the pillow you train you build a model on only the training data right so the steps are steps number one split the data into train and test. Hide the test data under the pillow, sort of under the pillow sort of under the pillow so your training model your algorithm does not see it while learning does not see it while learning, when it is doing graduate learning fitting. It sees only the training data, only the training data that is a very important realization you need to hide half the data a little bit uh one portion of the data not exactly hide but some portion non-zero portion of the data you must go and hide now why will we hide what happens is that number three go build models build models of different complexity to fit the data affect the training data so you may build a line model a a quadratic model, a cubic model, a quintic model and so on and so forth. And now what will you do? Now comes the crucial step. Let me put it in a different color. Now comes the crucial step. Look for the error in the test data. In other words, which model is able to predict test data best. So what happens is you took some data away, and now you feed your model that has been built, you give it a test data, test, and you look at y hat test and compare it to y hat, the y test, because, you know, you have kept this data under the pillow you look for that and you pick the model which has the lowest test error right because test is the real proof how well is it able to predict on data the model has not seen because that's the closest you can come to simulate in future data data that will come here after you hide it from the model and you say that. So this is a crucial step guys. Are we understanding this journey? any feedback is this simple you take the data you split it into parts and oh goodness my mouse is again misbehaving give me a second i need to fix this what is happening here guys what are you seeing on my screen? Nothing, just blank. Nothing. I will just share the screen and share it back again. Something that is just going on okay please give me a moment let me see if I can get another mouse one moment you you Thank you. Gracias. Thank you. All right, guys, i'm back and i'm hoping now it is not the mouse it has something to do with one note Wow, so there's something to do with OneNote. Let me see. Can you save the document and reopen again? Yes, actually, I seem to have gotten back the... Yeah, I can save it, yes, and do it. But okay, let me finish this thought. It's important I finish this thought. And let me go to something else and then come back. I finished this thought and let me go to something else and then come back okay all right at this moment I'm having a bit of technical difficulties so what let me just speak it verbally so there is something called a bias main straight off that we are seeing what it means so there is something called a bias variance trade-off that we are seeing what it means says there's a ground truth you never know what is the real complexity of the ground truth before you have experimented with the data so you will make models of different levels of complexity and what will happen is there will be one model whose complexity will match the underlying truth the ground truth it would be the best model models that are simpler than that will have high bias errors they're too biased or simpler and models that are much more complex in the ground truth they will overfit the data on test data, when you try it out with the test data, the data that you had under the pillow, it will end up showing high variance errors, overfitting errors. So this is a trade off. As you decrease the bias errors, the variance errors begin to go up. What happens is as you dial up the complexity, the bias errors will continuously decrease. So ask if you are sharing your screen, like I'm not, it's blank. Yes, indeed it is blank, unfortunately. This, I'm having some technical difficulty at this moment. Something to do with, anyway, I will save all of this, these notes and send it to you and we'll I'll find what is the reason WebEx and OneNote of Microsoft don't seem to be going too well together we should solve it maybe next time I'll use another thing so we'll go to meeting or something like that. Sir, I have a question. Sir, can we use polynomial regression to explain step functions or should it be continuous values? See, the moment you talk about non-smooth functions, it gets complicated. Non-smooth function, right, is not differentiable. Non smooth function right is not differentiable. So polynomials won't represent it ever. These are discontinuous functions. Okay. reason otherwise we are looking for continuous smooth functions in one dimension we are looking for continuous smooth curves in higher dimensions we are looking for continuous smooth surfaces so that is so sorry if we're building a model based on like let's say house price and then the increasing number of bedrooms, we have to assume it's a polynomial function. Instead of a step. That is right. Yes. You cannot assume a step function. A step function would be a really bad, a bad assumption. Okay, but generally in machine learning, you don't tend to do that. together okay but generally in machine learning you don't tend to do that so i'm trying to open one note again but for some reason it doesn't seem to like it uh let me see if i can reopen it otherwise i'll go into the lab part of it anyway we are in the last 20 minutes of it so yeah, yeah. Okay. My mouth seems to have come back. Go ahead. So, how how do we differentiate between the curve and the linear. Uh, graph do we graph and visually see it or how do we yeah actually the answer is pretty unfortunate in one dimension we can just visualize the data your next lab will be that you visualize the data and you see and you get an intuition on which model to pick right but in higher dimensions, human beings, you know, evolutionarily, we have no eyes that don't help us visualize higher dimensional data. The kind of data that we encounter these days are extremely high. You know, the hypothesis these days, like even the data spaces are very high dimension. High is not just five or ten dimensions it's very common to encounter data which is like three hundred thousand dimensions or hundred thousand dimension data so for us to visualize data in such very high dimensional spaces we lose intuition uh all our eyes nose, we give up on that. We can't directly see it, get an intuition into it. So what you have to do is at that moment, you're flying blind. You're working with mathematical tools. So what you have to do is you start with simple models and you gradually dial up the complexity. And what will happen is the bias variance tradeoff leads you to a situation where at some point, you know, the bias errors will keep falling down, the variance errors will keep going up. But there will be a point at which the total error, which is the sum of bias and variance errors, it will achieve a minima. And that minima is the point we are looking for. Let me actually try another one. Give me one second. I want to use another tool, Sketchbook. Maybe Sketchbook doesn't have this problem with WebEx. doesn't have this problem with WebEx. At this moment, I think seems to be... So I had another quick question. Go ahead. So when you say that you have a test data and you present some test data and you hide the other which means uh you feed only part of the data small part of the data and not give it everything that you have that is right you hide the test data under the pillow yeah so you don't feed that into that black box that we are talking about yeah when you are building the black box see there are two phases first you build the black box your model your algorithm train your algorithm the learning process takes place don't give it the whole data because if you give the whole data it will go and overfit and you would not know that you have high variant centers you can only find that that that your model has overfit if you hide some data under the pillow and try your model against the data the model did not see during the training process so it couldn't have a fit to the data that's hiding under your pillow and that data will help you discover if your model has overfit if your model has overfit. That is it, guys. That's what you do. So in the same line, I had another question. So you said 30-70 about the quantitative split of the test and the train. Is there something to the quality of the test? Is there a way that you could sample the test in such a way that it will not present the train to something we should know about? Yes, exactly. That is a very, very good question. See what happens guys is when you split the data, you must make every effort to ensure that test data is representative of reality and both training data and test data are representative of reality but if you don't watch out for that bias if you have training data which has a hidden bias then it will perform badly on the test data and it will perform badly on the reality so since i can't write more guys at this moment and stop we'll do it next time I'll just tell you a story about biases in the data testing the test and train biases. The story I don't know how true it is but it is often given in that commune in the machine learning data science communities. Once the US Army was in a, Army came to a startup and said, all this AI and machine learning, can you look at a picture of a vehicle and tell whether it's a civilian vehicle or a military vehicle? The obvious reason that if you're targeting a vehicle, you want to target only enemy military vehicles. You don't want to hit civilians. So can there be an AI algorithm that can do that? And I said, well, of course we can do that. We can. That's what machine learning is for. So just give us a lot of pictures. So the army went back and told its soldiers, take a lot of pictures of civilian vehicles and then take a lot of pictures so the army went back and told its soldiers take a lot of pictures of civilian vehicles and then take a lot of pictures of military vehicles and send it to the start the startup got boxes and boxes huge quantities well digital a huge number of pictures now it went through this photos those picture files and it trained actually happened that it trained a neural network on it in the lab they did they even did the test and training split they randomly shuffled the data hit some test data under the pillow on the training data they tried out and what would happen is their results would be perfect in the lab, very high good results. Then the military came, the army came and says, is it working? And they said, yes, absolutely, it's working. Let's try it out. So they went and got more data of their own that the algorithm had not seen. So they asked the soldiers, give us more pictures of military and civilian vehicles. And the soldiers said, yes said yes sir and got more pictures and even those pictures passed in the lab very very accurate distinction between military and civilian vehicles there's an interesting catch to the story though when that algorithm was deployed in production the entire thing failed miserably and everybody was confused. Why is it that the same algorithm works just fine in the lab, even on new data, but doesn't work on new data in a theater of war, in the field? They were really scratching their head till somebody noticed something Something a very interesting bias inherent bias in the data. The data had 1, all the pictures of military. So when do say, so just take pictures of the military. Well, either early in the morning when they are going about to go out on their duties. During the, you know, 2 duties or going out into the city they would just take military vehicle pictures and how would you do that they would just take pictures of each other's vehicles lots of military vehicles in the morning and late in the evening when they would come back again there would be lots of military vehicles parked in the campus and they would take lots and lots of pictures. When would they see the civilian vehicles? It would be apparently in the daytime. When in broad daylight they would be touring the cities and so forth and take lots of pictures of civilians. Now very interesting thing even though you followed all the process correctly, the test and train data had no bias the overall data set itself has a inherent bias the the the bias was that all the military vehicles their pictures were taken during very low light conditions you know early morning or late evening so the ambient light was low whereas all the civilian vehicle pictures were taken in broad daylight. So the ambient light was high. So what the algorithm picked up on very quickly is just look at the ambient light. Now well that algorithm is far more complex than our linear and polynomial models. Those are deep neural networks, convolutional networks and so forth. But one way or the other, it picked up on the ambient light as the factor. And because neural networks are a black box, you can't see exactly how it is thinking. It's a little hard to do that. You couldn't see why it was making the mistake. It took a long time to realize that. So that is what bias in the data does. So, the data inherently can be. And come to you as bias like that, or even if the data is proper. You have to make sure that the. The sample, whatever data you were given is a sample of reality. It doesn't have bias, which is the first situation. Second situation is given the data, when you split it into test and train, once again, you have to make sure that neither the test nor the train data has developed any specific bias. For example, if you're looking at the height of children based on age, you should not do such a thing that all the training data are male and all the test data are female. You know, boys and girls, boys of different age and height and girls of different age and height because the regression curve the function curve that predicts the boy's height with respect to an age would be different from the the curve which would be for girls the line that would be for girls isn't it and so you have to watch out for the bias in the data. It's very, very important to do that. So that is it. Any other questions guys? The bias and the variance are both kind of errors. How do we know we are measuring the bias versus the variance on real data sets? Yes. So that is the trade-off. What you do is you don't know. What you have to do is build a lot of models of different complexity and see which gives you the lowest total error. At some point, you know, bias errors will keep going down for more and more complex models and variance errors will keep on increasing. But there will be a sweet spot at which the bias errors have come down, but the variance errors have not become too much. but the variance errors have not become too much. And that point where these two things cross over is the point that you're looking for. Are we together? So the understanding is when we start with the simple models, we assume that we have bias, and then we tune the models into more complex if predominantly the error becomes variance. Is that understanding? I'm sorry, please say that again. When we start with a small simple model, what we see is an error might be biased, but as and when we apply more complex models, the error tends to be of the variant side. That is true is true that is true and that is it so i would encourage you to go and read chapter at this moment in the textbook uh let me give you the chapters to read this topic is actually a crucial topic and it is the section 2.2 and 2.3 sorry 2.2 actually much of 2.2 is devoted to this so and 2.2 all the way up to 2 yeah 2.2 so guys read chapter 2.2 it's unfortunate that something fishy is happening with the wix and this uh thing i'll try to have it fixed by next time so we have a better experience now what what i would like to do is uh show you the labs and i'll send you guys the notes for the labs all right so um All right. So are you guys game for it? If my machine cooperates here. As if one question, if the data itself has bias, do you actually identify that? Yeah, that is a problem. In fact, this is a classic case, right? You can't. You can make your best effort not to make that mistake, but you can. It's very hard not to. And a bias seeps in in very subtle ways. Today, we live in a world in which people have extraordinary faith in AI, extraordinary faith in these models that we build, with sometimes pretty disastrous consequences. For example, one company released a facial recognition system and facial recognition systems are particularly problematic these days. So one they exposed, it's a pretty large company, they created a service that you can give it any face online and it will recognize and tell you who it is right it's see obviously the company believed that it was fairly accurate which is why they were selling it and it's one of the biggest companies without naming it so then somebody did a simple experiment which is quite remarkable somebody just took the U.S government from the U.S government from the Congress they took the black caucus the the set of all congressmen or senators who are uh Afro-Americans or Blacks and they fed they they showed each of those pictures their pictures to the algorithm and asked who is it and guess what the algorithm said for each of them or at least for most of them if i if i'm right i don't remember the exact details but it identified almost all the senators are to be various kinds of rapists and cl killers and murderers and thugs which is not at all, obviously, pleasant. So what went wrong? This became actually quite an issue. I believe it was last year, it became quite an issue. Obviously, the Black Caucus was not amused by this, and they were very concerned that this sort of bias is there. Today, a lot of these facial recognition systems, we know for a fact that they do very very poorly on uh minorities they do very poorly with women sometimes right they do much better with the Caucasian crowd and so you ask yourself where did the bias come in well it turns out that when you work in these companies most of the data that you have access to is of the mainstream data you may not realize it but the mainstream data that you have collected if you have just been gathering data by taking pictures of each other taking pictures of people in the street and so forth, it will dominantly be of the Caucasian people. And so the algorithm will work quite well with them. But there wasn't enough training data for ethnic minorities and racial minorities and women. And so for whatever reason, because the training wasn wasn't enough it actually does very poorly with them and it is quite a concern you never can know whether you have subtle hidden bias in the data and when it blows up in your face it's a huge problem it is one reason there is a strong movement these days for something called explainable AI or explainable machine learning. In other words, a model, see the kind of models we are learning today. These are linear and polynomial models. These are very explainable. You can see the values beta naught, beta one, beta two. So it can tell you why it believes it made the prediction. Why it made the prediction. It can show you the coefficients. And you can see that this factor matters more. This factor matters less. And so forth. But with our modern generation. Some of the algorithms. They are literally black boxes. You don't know what they are doing. A deep neural network for example. Is doing a gradient descent. In a. Can you guess how many dimension space the parameter space or the hypothesis space how many dimensions does it have would anybody like to hazard a guess yes today if we are looking at a word in which we do this gradient descent and this whole learning in the parameter spaces are like 500 million dimensions. Imagine how complex it is. It's bizarrely complex. We use massive hardware that runs for a very, very long time and then produces a model. After many days, produces a model. And that model has 500 million parameters. How in the world can you understand what exactly it is doing? It's beyond comprehension. So if it goes wrong, you don't know. See, it may go wrong for specific areas, like, for example, the facial recognition system. It worked for the majority, but that's not good enough. It didn't work for the minorities of all sorts of all kinds, right? So you wouldn't know. So a new area, which is very hot these days, is to say, well, even this black box, how do we derive interpretability out of them and see if there is bias? You can never shoot a model, right? So ultimately, so your model is not completely accurate at any given time. I apologize for this. Your model is? Not completely accurate at some point, right? Yes, you never know. See, here's the thing. When in the next lab, you'll see a famous quote by Box, a great data scientist, what you would call a statistician of a previous generation, he said that all models are wrong. I heard that. Inherently, all models are wrong. But some are useful. We will never know if you took the right. Yes. In science, there are no useful things. Yes. Some are useful, right? Yes. What is around some are useful? Some are useful, exactly. So the idea is that all of science is not the pursuit of what is right, but what is effective, what is useful. For example, is the theory of... For example, Newton said that gravity is given by, you know, m1, m2 over r squared up to a proportionality constant. Newton's law of gravity. Then for many years, it worked just fine. Einstein came and then he put another theory. Now, that theory agrees with Newton for small distances and not large masses. I mean, for most situations, it agrees. But there are situations in which we know that the Newtonian gravity is wrong. And it's the Einsteinian gravity that gives you a better answers to more accurate answers. So you may say, therefore that Einstein was right. But that is not the way you look at in science in science. You say Einstein's theory is a better theory it's a more effective theory data agrees more with einstein observations i agree with him but is it right in fact we happen to know that it cannot be right at this moment relativity does not agree with quantum mechanics quantum field theory and these two fundamental and brilliant theories that underlie physical nature, both of them disagree with each other. So there is some deeper underlying theory that may someday unite these two. So these are effective models at best. And so it goes on and bringing it back home. In machine learning, all the models you build, you'll never know. You write a function that approximates the data. But is it the correct answer? You wouldn't know because you're not being told the underlying function that produced it. If you knew that function, there was no point in doing data science. You already know the answer. But you'll never know the answer. All you can do is come closer and closer to it yeah got it the learning yeah thank you guys it's 10 o'clock I would have liked to do the lab but this webex is behaving quite cheerly in this particular case. My desktop seems to have at this particular moment frozen. So what I will do is the lab part, I will send you the PDF to all of you. But let me give you an explanation of what or sort of a preview of what is there in the pdf it is the same pdf i gave you the last time and the last time you remember that i talked about the galton data set we talked about nightingale and the snow the nightingale data the Crimean War of 1853 to 1856. She, it's a well-known story of course, she went there to nurse and take care of the wounded soldiers. She was taking care of the wounded soldiers of three armies, the Russian, the Brit, and the French. She had no partiality. But when she was doing it, and so obviously she was a person of great compassion and commitment. When she was doing it, she observed that most of the mortality in that war was not from bullets, not from actual wounds, battle wounds. They were actually from malnutrition and poor hygiene and unsanitary conditions in the hospitals. And she presented that data that you saw in the notes as the so-called two roses. I'm mentioning this for those of you who are new, that visualization. And that visualization was profoundly influential in helping her change the medical field itself. In fact, he convinced the powers that be and established the modern practice of nursing as a profession, not as something done by non-professionals but as a profession in its own right, different from the doctor's profession. And it is heavily based on keeping the hospitals very sanitary and so forth. And the effect has been profound. If you go to modern hospitals, you see they are kept very clean and so forth. So that data is of high value. Let us walk in the footsteps of the giants and start with that. The second data set was John Snow's data dataset, the cholera dataset, which pinpointed that probably the cause of cholera is germs in the water that get – when people drink the water, they get it. So he was more leaning towards the germ theory rather than the previous asthma theory, which believed that diseases are spread by bad air. The third dataset, which was in the homework in the lab, was the GALTENS dataset, which was about regression towards the mean. The Florence Nightingale dataset, I asked you guys to just do exploratory analysis, not visualize it. Visualization is a bit harder than the visualization that she did. It's a little bit more advanced. When we go into visualization in depth, you will learn how to make this beautiful visualizations. It's a bit early for that at this moment. The second one is obviously snow. I left it as exercise. It was a Galton, Snow, I left it as an exercise. It was a simple one. I hope you have done it. The third one is Galton, and I essentially gave the solution to the Galton one. If I remember right, I gave the solution in Python. Now to the nodes, I have added a few more things. One of them is the concept of a formal grammar for data manipulation. It is called the grammar of data. You do different manipulations of data. Think of SQL. You take some rows. You filter out some columns with a where clause. You put some order, some group by, and so forth. It is a set of operations on the data. So if you think of it as a set of operations, you can actually construct a very complex data manipulation pipeline using simple primitive, simple verbs or things like that. So it talks about that. And it talks about that and it talks about something called the tidy data. When data is in one particular form called the tidy data, then it is more intuitive and dealing with it for both exploratory analysis and machine learning becomes far easier. So that is that. And to illustrate that, I have taken a weather data set. For a few years, the weather in some about 36 odd cities, what was the weather like? What was the temperature like on different days or different days or months? And what was the pressure like? What was the humidity like? What was the so on and so forth? Wind speed? Things like that. So there is an analysis of that. That analysis I have done because this whole data wrangling and grammar of data and tidy data, they form core concepts. So I have given the solution in both r and in python they are very close to each other and are they use the dplyr library in python the pandas comes built in with it next time when meet, we will go over those solutions, but I highly encourage you to try it on your own. Next dataset is the IRIS dataset, which is a very, very simple dataset. It is sort of a rite of passage. Every person or every student, almost every, who has gone through or every student, almost every, who has gone through and done machine learning, data science, etc., has in the early stage done an analysis on the iris dataset. It is a dataset that was gathered by a botanist who went out to a field and observe 3 species of. Iris flower, and he measured. The length of the battles, the flower part of it. And the separate, you know, the green part that's under the flower. It holds the flower together the length and width of the battles and samples. So there are only 4 attributes and use that. And then there is the species. So while at this moment we are just exploring the data, later on we'll build machine learning models, in particular regression models to predict all sorts of things. So we'll see how much can you predict petal length from the, let's say, sepal length, and so on and so forth. We'll do those exercises in the future. In any case, I'll send these notes over to all of you who are in the mailing list. Those of you who just joined today. Please drop me an email again. Those of you who did not receive some of the. Material example are not a part of slack mailing list because you didn't receive an invite let me know i'll invite you if you have received an invite please do join i remember i sent i have received only half the acceptance compared to the invites i said slack is important we are going to engage using slack also the google mailing list i'll add all of you to the google mailing list right and finally those of you who haven't paid yet i believe there are a few of you new students who have not paid please reach out to Prachi and she will help you with the process. So, do we use a general channel for communication or? No, no, no. Once I see all of you, I'll add you to a special channel, which is a closed channel only for participants of this workshop. And I'll bring you and those of you who are new and have joined us today, welcome to the workshop. I hope you enjoyed it. I wish we didn't have technical difficulties. It is actually the very first virtual classroom that I have ever held. I suppose with the coronavirus, we are doing a lot of things for the first time in our life. Any feedback, guys? So we'll follow this sort of a format, but next time we'll be more lab heavy. We'll walk through code, a lot of code walkthroughs. But any feedback, guys? Anything? Yeah, I felt I didn't have an issue with the meeting and I felt it was very well communicated. So that's the feedback from me. I think I didn't really miss not being in the class. It was, except for the issues at the end, I think it's a good medium from my end. Not sure about others. not sure about others. Thank you. So what I'll do is I'll certainly go and share this recording with all of you in YouTube. I'll put it as a private video. In other words, only people who are in the classroom can see this video. And I will send you the PDF of the handwritten notes. And so with that, I'd like to end this meeting guys, you guys can stay and ask questions if you want. Otherwise, let's conclude today's meeting. Thank you. Thank you sir. Thank you sir. Thank you. Thank you. Hello. Good evening. Thank you. Thank you. Welcome. Thank you. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Hello. Thank you.