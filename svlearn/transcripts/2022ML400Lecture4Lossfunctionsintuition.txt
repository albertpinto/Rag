 All right folks, yesterday evening, for those of you who attended the extra session, we talked about, we just reviewed the loss functions in machine learning. What it means, why it is relevant, and this is fundamentals. It is something that we are supposed to know, but occasionally a review always helps. So as I was doing this loss function stuff, I realized something. We did the, oh, hang on, let me find my writing pen, yeah. So we did the loss function for regression, which was straightforward, mean absolute error and mean squared error again i mentioned that the gauss-markov theorem the blue theorem says that the best linear unbiased estimator is the squared which is why it is much more common we talked about the trade-offs between the MAE and MSE, which is that MAE handles mean absolute error, handles outliers better, but it's sort of unstable because it only looks at the signature. It's the sign of the gradient, not the actual value of the gradient. So irrespective of whether the gradient is big or small, the size of the gradient descent step remains the same, which leads to instability because you keep hopping around the minima. MSE is better because it also looks at the size of the gradient, right? So, or the error. And so if the errors are small, then you take smaller steps. Then we talk about the Hubble laws, amongst other things, which is taking the best of both the worlds, saying that, you know, if the errors are small, look at the mean squared error. If the error is big, if you're looking at outliers, then revert to mean absolute error for those terms and then take them together. So Hubble loss is pretty common. Then there are other loss functions, Hinge and this and that, we won't go into. Now, then I talked about regularization. Once again, a review of things we did in ML100, the first course, and most of you coming to deep learning should have done that in some machine learning course if you haven't taken ML100. Namely, you have L1 regularization, L2 regularization, Lasso, Ridge, and then combination of the two, which is elastic net. So that's that. And that regularization is true whether it's classification or regression. So that's a very short intro to regularization. Today permitting we will do more on regularization now then we went to classification and there we talked about the the this we went a little bit theoretical or probability theory we talked about what is likelihood likelihood is a short form of likelihood that the evidence likelihood of a hypothesis producing the evidence but that's the full form of it so likelihood is not probability likelihood is the probability that a given hypothesis, if true, will produce the evidence or the data that you see. So what is the likelihood of the data given a specific hypothesis? And you pick that hypothesis which gives you the greatest likelihood of the present evidence. So for example, to trivialize it, let us say that you land in the middle of the night, you and your friend land in a city and you don't know which city it is. And let's say that you are quarantined because of COVID in a box and you have a little window you can look out for a few days. So both of you argue one says it must be it must be a desert, we must have landed in Phoenix. Another says no, no, no, we it must be Seattle, right or any place. Now, which of these two things is true. The next few days, you notice that it rains first day, second day, third day, not the fourth day fifth sixth seventh day not again so it rains let's say seven days out of ten right or eight days out of ten now which of the two hypothesis looks more likely are you in a desert or are you in a um are you in uh in seattle or are you in a rainy place? Now you can say either is possible, it is true. In desert also it rains, but so eight days of rain is possible in a desert too. The probability is much lower. So you can say in common sense language, it is far less likely that you are in Phoenix, the hypothesis that you are in Phoenix than the hypothesis that you are in Seattle if than the hypothesis that you are in Seattle, if you observe eight days of rain out of 10. Does that make sense guys, the intuition? And that is the intuition of a likelihood function. Likelihood is the likelihood of a hypothesis producing the evidence that you actually see. Evidence being eight days out of 10 it rained. So you would say, oh man, quite likely we are in Seattle. But it is still possible, you might be in Phoenix, but maximum likelihood is that you are in Seattle, right? So that is what maximum likelihood means. Now, there's a little bit of a maximum, the probability stuff that these are joint probabilities. Now from the joint probabilities, we are joint probabilities. Now from the joint probabilities, we are seeing that hypothesis, which is likely to produce, most likely to produce this data is the correct hypothesis in terms of a probability distribution. Now that tends to get a little bit technical into probability theory. So, and from there, I mentioned the fact that when you take the product of these probabilities, computationally, it becomes a bit intractable. Why? Because all these probabilities are fractional. You multiply a hundred data sets, hundred points in the data set, and you multiply the joint. So you're multiplying a hundred numbers, each of them's between zero and one, and then you get a number that is so vanishingly small, your computer will have a hard time dealing with it numerically. So what you do is, fortunately, you notice that you can take the log of it. Log will make it into an additive problem for multiplication. Why is log still safe to take? The technical reason is log functions are monotonically, monotonic functions, increasing functions of x, right? And therefore, it's legitimate to use log. So if you're saying I'm going to maximize the likelihood, it is as good as saying I can maximize the log likelihood. Because log likelihood, the computer can handle much better with this numerical libraries. But then you realize that in our machine learning world, most of the code is designed to minimize a function, not maximize it. So how do we convert a max likelihood to a minimization problem? You can say, well, if I'm, instead of maximizing a log likelihood, I can minimize the negative log likelihood. And therefore, the famous term negative log likelihood is there. And that is a derivation of the... And basically, out of that comes the log functions for binary classifier and multiclass classifier with minor variations. I also talked about the fact that as we go in, and just giving you a little bit of a preview into the future that from example next week we'll encounter many more loss functions for example autoencoders they use a measure called KL divergence right how much one distribution your probability reality differs from your guesses measured by KL divergence between the property between the reality distribution and the guess distribution. We'll talk more about it. But yesterday, and throughout this thing, I had this uncomfortable feeling when I went back home, and I was having dinner, and I felt that maybe this was all way too abstract. The regression problem is straightforward. We all understand the absolute error or error squared being added up. But for the classifier, all of this business of likelihood functions and negative log likelihood is getting a little bit, or perhaps a bit too abstract to reason through. So I thought about it and I asked, can I explain it in a simpler way? And so today, if you will permit, I'll take the first few minutes to explaining the loss function for deep neural networks and for all classifiers in a simpler way, in a more intuitive way. I'll just look at the results and try to give you an intuition about it. Would that help? Yes. Okay. It's a fun idea. Okay. So what I'll do is I'll create a, this is the thing we have. See, I will create, so let me put the words on the table. I'll say, what is probability? What is surprise, what relative entropy. That is scale, divergence, etc. These are the terms. So it turns out that this is actually a beautiful intellectual journey. Let's go through it. So how should we do it? Let us say that you live in a place you live in a place which has no rainfall at all ever. Like you live in some Sahara desert. Well, please, anyone of you geographically enlightened, is it true that some parts of Sahara never gets rain? Maybe it gets, I don't know. But given my ignorance, I assume that it doesn't get rain. So let us say that you're in such a part of the desert. So what is the probability of rain out there? Probability of rain is zero, isn't it? And so probability of not not raining. Under one. Equal to one. So now what does probability really mean? So there are two definitions of probability actually. It turns out that this word probability that we all use so commonly, when you try to be precise, then you realize that in the people who think about probability day and night, there are two schools of thought. One school of thought says probability is the frequency for long running trials, means just keep on every single day, peep out of the window, is it raining or not? Keep a track of it. Then take sufficiently sufficiently long runs let's say a thousand days or whatever sufficiently large number of days and then look at the proportion of times it did rain and whatever that was that is the probability of rain right so the law of large number kicks in so for example or another way to put it is if you toss a coin it may be heads it may be tails you may even get a sequence of heads but in a long running trial with hundreds of uh coin tosses on average how many heads would you see with a fair coin about half of them right roughly maybe give or take a little bit of plus minus but the more trials you do let's say you do a million trials you'll start seeing that approximately half a million trials you'll start seeing that approximately half a million will be heads half a million will be tails so that is a frequentialist probability definition there is which is pretty good there is a problem with this definition. Suppose I were to ask you, what is the probability that the earth will get destroyed if we continue to do the human activities that we are doing, you know, have long factories burning coal and having driving gas guzzling cars and factories and so on and so forth. So how likely is it that it's going to destroy the earth? When you say you're asking still about probability, want to estimate so for example if the probability that all of our mischief is not going to make much of a difference to the earth it will it has a huge resilience and the probability is one in 10 billion or something like that right one in one in one trillion and then you would say no you know we need to have these factories to keep people well fed we need to put use these fertilizers the human population is huge so we need, we need to have these factories to keep people well fed. We need to use these fertilizers. The human population is huge. So we need to do all of these things that we are doing. And it is fairly justified. On the other, the probability that our human activity is imminently going to destroy the Earth, let's say that it is something like 90% probability. That should stop us dead in our tracks and say, good grief, we need to do something about it. Otherwise we will lose the only home we have. Do you see that? So the probability has very, the value of the probability has very real consequences, especially about policymaking at a large scale level what should we do as a humanity or where should we focus our interests between keeping between easily feeding people and transporting people over long distances and you know entertaining them with lots of toys on the one hand, as opposed to stopping dead in our tracks, taking some drastic measures and even austerity measures to fix the situation before it's too late. These are huge policy decisions. And one has to choose one versus the other based on what the probability value is. Except that one can argue if you were a frequentialist you would say now wait a minute where is the evidence that the probability that will destroy the earth is very very high right because in their thing if you look at the frequentialist perspective one could argue that the only evidence that you can have is have a sort of a world, hypothetical world, in which you start, you make, let's say, a million copies of the same Earth. And people continue to do exactly what they're doing. And see out of the million copies, then how many copies of the Earth's evolution over time did the Earth destroy itself? I mean, did we destroy the Earth or make it absolutely toxic for our habitation given the human activity? And suppose that number turns out to be out of the million Earth's copies of the Earth, let's say two or three times we destroy the Earth, we'll say, well, there's a risk. Maybe we need to do some mild action to prevent it. On the other hand, if it turns out that most of the time the earth gets destroyed in those simulations, in those realities, then you say, well, we need to take drastic action because that is the frequentious definition of probability, the proportion of the time that the earth got into trouble. Are you so far with me, guys? By this definition of probability, one would have to do something like that. Speak up, guys. I can't see you. So please speak up. Does this look reasonable? Simulations. Yeah. The trouble is, is simulations of course you can argue that's not data that is pretending based on some hypothesis so you need to make a million copies of the earth and actually see time evolution of it then only you can do it but but there's a problem with it the problem is we don't have a million copies of the earth, right? And there's no photocopier for earth with all its humanity and all its life forms in existence at this moment, right? So we can't do the frequency as probability. And yet it is of paramount importance. It is relevant to speak of given human activity, what is the probability that we'll be in trouble? Isn't it? So we need an alternate definition of probability. The alternate definition of probability is the probability definition that comes from another form of thinking called the Bayesian probability. probability. And it comes from an interesting reasoning. People said that suppose we want to quantify the degree of uncertainty, right? How much we know and how much we don't know. Then our degree of belief, you can say the opposite of that will be the degree of belief in something so how strongly should i believe purely from rational data that the earth will destroy itself if we do what we do we are not looking at a frequentialist perspective because we don't get unfortunately the choice of doing a of doing a 1 million time evolutions of the earth. Right? We have one earth and one arrow of time. And so there'll be one destiny that we'll all get to. And we need to have a certain degree of belief that it is either being harmless, whatever we are doing, or it is going to destroy the earth, one of these two, isn't it? So what is your degree of belief that we are heading into trouble? When you look at the degree of belief and you churn out the mathematics, and that mathematics, of course, as you know, we cover in this, that's at the heart of machine learning, actually, a bias shins. We haven't done the bias perspective, but increasingly we know that the bias is the right perspective. Machine learning is all bias in thinking in many ways. But even though I've not reformulated much of what we have been talking about, I've been trying to talk in simpler terms, but if you really think about it, you never know when you say that a picture is a cow or a duck. It's a belief. The model believes to a certain degree that it's a cow and to a certain other degree that it's a duck. You're dealing with beliefs. Those beliefs, they follow the same laws of probability. And as people notice, as mathematicians notice, that they follow the same rules of probability, which the frequentialists use. And so it comes up with that. If you really think about it, what your machine does, it sees one example of a cow, a picture of a cow, which is very different from all other pictures of a cow. Nonetheless, it predicts a probability. It couldn't have predicted the probability in a frequentialist sense because it's not getting gazillions of such experiments. It doesn't even make sense. But it comes out with a certain belief that it's a cow or a certain belief that it's a duck. So that is Bayesian probability. So keep that thing in mind. So that is Bayesian probability. So keep that thing in mind. Now, given that fact, we will talk of a new concept now, given the fact that we could talk about probability without necessarily doing long experiments, but this is an aside, by the way, I wanted to tell you that there are two different definitions of probability. But now I'll talk about something called surprise. So let us say that the probability of something happening is 100%, right? For example, what is guaranteed to happen? I think there's a quote in US that death and taxes are the only inevitabilities. Isn't it? So, okay, let's say that sun rises from the east. Every single day sun rises from the east. So what is your measure of probability? If the probability is one, P of the sun from east is equal to one, then tomorrow you see the sun rise from the east. How surprised are you? Not at all. Not at all. Surprise is zero. Not at all. Not at all. Surprise is zero. On the other hand, suppose all of a sudden, so suppose the probability of sun. So imagine a contrafactual world, sun from the east was 90 percent 90 percent then every morning when you wake up and you see the sun either in the east or the west you will be a little bit surprised isn't it if you see it in the east you would be less surprised if you see it in the west you would be a little bit more surprised is that correct yes 10 10 right so sun comes out in the east you say oh yeah it tends to come out of the east sun today comes out in the west you get more surprised or and it's related to history west you get more surprised or and it's related to history most of the time the sun is bright and shining and then you're not surprised but one fine day you wake up and you see that the sun is all red right because it's a solar eclipse let's say or something like that right what does it do to you? We are hugely surprised unless you have been listening to the news, or unless you are familiar with astronomy, but you can imagine a couple of hundred years ago, a few hundred years ago, when most people didn't have access to that knowledge, and much of this knowledge was not disseminated. Suddenly to find that the Sun is not what it's supposed to be, is an element of huge surprise, isn't it? And you know what it did? It caused most people to immediately start praying or sacrificing animals. If that didn't suffice, then taking a few of their fellow mates and sacrificing them and all sorts of things used to happen. Those are all expressions of surprise and fear. So when a rare event happens, you have far greater surprise. So you see that the higher the probability of something happening, the smaller the surprise, isn't it? And the rarer an event is likely to happen, when it happens happens you have a far higher degree of surprise so far so good guys right yeah so you could say to the first approach let's try to quantify surprise you could say hey you know what surprise seems to be inversely proportional to the probability of something happening. Does this make sense? Probability of an event. Right? Let's see if this works. When the probability is high, let's say the probability is 1. Let's say for p is equal to one or maybe 0.99. Nine, nine, nine, nine, nine. What will be the surprise if you use this equation? It will be forgettable. Let me just make it an equality here. It is equal to one over practically one, one, right? So your surprise is one, but actually you were not surprised at all, were you? You would somehow want it to be zero, but okay, zero would be better, better. We want an expression that makes it zero. On the other hand, if the surprise is very small, if on the other hand if the surprise is very small if for sorry if the event is very rare now what is the surprise surprise is equal to one over zero point zero zero zero zero zero zero i don't know how many zeros I put one. It is basically it tends to infinity, isn't it? You're infinitely surprised. All of a sudden, in the medieval ages, the sun doesn't look like the sun. It has sort of vanished and gone dark. Right? Are we together guys? Yes. Right. And we are enormously surprised. Well, there is a problem. This all looks nice. But wouldn't it be nice if this expression did not evaluate to one but zero? So how do you take an interval which goes from one to infinity and actually somehow transform it to zero to infinity. What could we do? Activation. No, no. All you have to do is take the log. Log of this, yeah. If you take the log of this interval, it will go for... What is the log of one? Zero. Log of infinity is infinity, right? So this is good. So we now learn that, okay, what we should do is, this is a good starting place to define surprise but it would be better if we define surprise as equal to log of one over p let me let me put it x x being whatever event that you're measuring, head, tails, whatever, sun, not sun, sun from east, sun from west, log. What do you say? This is lovely, isn't it? And you can use whatever base of log you take. This is a measure of surprise. Now, in different scientific communities, it is a tradition to take this log with different bases. Our physicists, they take the natural log which is log to the base e right computer scientists and information theorists. And this is just a convention. It doesn't matter which log you take. Theorists take log log to the base 2. Why? Because it's very computer friendly. For no other reason. Simply because doing logs with base 2 is computationally far cheaper. Are we together? Right, that is it. But remember that at the end of it, doesn't matter which base you take the log in, we come to an element of surprise, right? And now I'm going to use this surprise to explain to you the cross entropy term. Let us say that something there were Y1. Why there were data, there are ten pieces of five pieces of data, three, why four? These are cows. And we are looking at probability of a cow, right? They are genuinely cows. First, third, and fourth instance of the data are cows. And Y2, Y5 are ducks, right? So their values are actually zero. So far, so good, guys. And we will take cow as the positive case so let us say that for the first positive case you realize that the data said y1 hat is 0.95 y3 hat is 0.1 and y4 hat is 0. what should we say zero zero one right let me make it zero zero zero one practically zero y hat right now let's just look at the cows you know that y1 was a cow so when you evaluate the result how surprised are you if the machine makes a prediction it says my belief is this is a cow, 95% probability that it's a cow. Are you tremendously surprised? No. So this looks right. You look at this and you say, huh, isn't it? This doesn't look right. So you are surprised. And what about this? That's when you get get shocked you say my model is probably wrong does the intuition make sense to you guys sorry as if i lost you a little bit here so y1 the one on the left hand side the y1 y2 y3 y4 so those are like the uh these are actual data you get five pieces of data you get cow you get duck you get cow cow duck right and we are looking at the probability of a cow right the machine is predicting that something is a cow. The convert that it's a duck. So just look at the cows. Suppose you were looking at how wrong you are or how's, see surprise is often is, if you think about it, a measure of how wrong your machine is. If your machine is fine, you already know it's a cow. And if the machine says cow, you'll say, that's fine. But if it says it's a duck, you'll say, that's fine. But if it says it's a duck, you say, wait, something is not okay, isn't it? It says it's more likely to be a duck, you'd be surprised. So look at this. So suppose I look at this log of, now let's look at this log of, would you say that if I were to add all the surprises, add cow surprises, it would be log 1 over y1 hat plus log 1 over y2 hat plus log 1 over y3 hat. Would you agree? No, no, no. Y three, y four. Sorry. Y three, y four. These four data points. This is how, this is your total surprise at seeing the predictions. Only with respect to cows. Does it make sense, guys? Yes. Now we'll come to ducks also right and now let's look at ducks. The ducks are zero so now let's look at ducks. I'm sorry what is y1 hat mean? A prediction that it's a cow for the first data point. This is so this is y12, this is the reality. Y5 is the reality. And y hat is what? Y hats are the predictions, right? Y hat is a 0.95 prediction, 0. No, actually I didn't mention it here. 0.1. Oh, that's what the machine tell us uh the change i've seen that the y y three is ahead that is okay hearts are always predictions in our world in machine learning world whenever you see a variable wearing a hat it is saying i am the prediction of a model i see okay thanks that's a basic convention we follow now let's say ducks so anybody would like to suggest a number y2 of a duck let's say that your machine says remember that we are talking about the probability of a cow right so suppose y2 is equal to um take a number 0.25 right so it is saying that for the second data point which is a duck the probability that it's a cow is 25 so what is the probability that it's a duck y hat 2 this is the probability that it's a duck right 0.75 1 minus Raja Ayyanar?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro?nilro What is the probability that it's a duck? 1 minus 0.25. 0.75. And so how surprised are you that the machine says it's a duck when it is a duck? Right? So once again, the surprise for the second data point is 1 over log of 1 over what? Probability of a duck. Right? 1 over log of 1 over what? Probability of a duck, right? Probability of a duck is y2 hat, right? And so it will be log 1 over 0.75. So in other words, 1 minus y2. Likewise, the surprise for the fifth element, so now let me put it 0.25, which means probability of a duck is one minus 0.75. One minus y hat two. Surprise that it's a fifth one is also a duck because that in reality was a duck. Let's say that, give me a number guys. What's the probability that it's a cow? Throw a number. 0.3. 0.3 0.3 so now surprise once again y 5 is 0.3 that is probability that it's a cow so what is the probability that it's a duck is it's a duck is 0.7 right so what is the surprise here log of 0.7 right so if you look at all the surprises like how surprised you were to see that it's a cow or a duck you would you would add up all the surprises isn't it surprise surprise over all the i-th elements zero to five would you agree this is a total surprise that you get machine is making some predictions if it made perfect prediction every cow it said is a cow. Sure. Every duck it said probability of a cow is zero. But there would be no surprise. Would you agree with that? Right? Yes. In other words, probability of a duck is also one. Priority of cow is one when it's a cow. Probability of duck is one when it's a duck. There is no surprise. Your machine is working perfectly. But the surprise is the element to which the machine is imperfect. Your model is imperfect. Would you agree? And that is why this is your loss function. This is literally the loss function for a classifier is equal to this. Now, let me make it in a more precise way. So this was, if you remember, what were we doing? Let us put it in this form. We break it up into two positive cases, i belonging to i is equal to 1. How many cows were there? 1. Which were the cows? 1, 3, 4. which were the cows? 1, 3, 4. For 1, 3, 4, what did we do? We did log 1 over y hat i. Because these were cows. And we took the cow as 1, like basically 1. It was a cow. This was the surprise, guys. Do you remember? Here, just a moment ago we did. This is the surprise guys do you remember here just a moment ago we did this is the surprise this is equal to summation over i is equal to one three four log one over y i do you see i'm just writing this thing in a more succinct notation, it is this and what is the surprise that you get when you say it is equal to a duck what would the ducks J is equal to two and five isn't it. R. Vijay Mohanaraman, Ph.D.: But when it was a duck the probability of a duck is one minus y hat, so it was log of. R. Vijay Mohanaraman, Ph.D.: One minus white to write and one minus So it was log of 1 minus y2, right? And 1 minus y5 log yj, y hat j prediction, right? And this is it. Now, one of the interesting things is how do you make it one? Probability, the label is zero. Label for this yj is zero because it's a duck, right? We said that one is cow, is duck the reality so how do you make you don't want to multiply it by zero you want to multiply it by one minus zero right so this is your cow and by the way this is just putting it all in the same notation don't worry about it if you work out this equation log of this and log of this this becomes this is just your y i and this is 1 minus y j in other words 1 my this is your this is your duck sorry 0 is the this is the probability or the duck the reality of the duck and so this equation becomes summation y i like when it is a cow y i is one of course so this is by the way forget the y it is just a fact right one over y i hat plus i is equal to cow cows belongs to cows and j belongs to ducks whatever data points are ducks 1 minus y j times log 1 j hat yes would you agree so far guys are you following the chain of reasoning why did we multiply y i with log one over y i because that is the surprise this is the surprise we are adding the surprises this is the actual surprise and why did i manage y i because y i is equal to one it is just a mathematical convention to do that right ignore this this is all one uh i'll tell you why it's a little bit but okay so here's the thing i'll remove this now you agree that i'm just adding up the surprises right and i think the one log of one over one minus yj, right? One minus yj. Excellent. Thank you for pointing that out. One minus yj. So would you agree the total surprise or how wrong our model is, which is the loss function, would be this equation right this is for cows this is for ducks right how much surprise you get from cows and how much of cow predictions and how much surprise you get from duck predictions now log is so you know that log of 1 over x is equal to minus log x. You know this convention, right? Because logs are additive. Right. Let me break it up into smaller parts, just in case you have forgotten our log. No, this is good. Log of 1 minus log of x. This is 0. So it is log x. So now let's put that there total surprise which is a loss function summation over minus log y i for cows i are cows right all the cows and cow data points and minus and again minus summation here of j is equal to ducks for ducks and that would be log 1 minus y hat j now does this look lovely to you easy right this is the loss function yeah this is the intuition this is the one intuition you can carry that your loss function is actually a measure of if you knew the reality because because you do know the reality, you have the labels. So how surprised are you that the model or unpleasantly surprised are you that the model is making the predictions that it is making? Right? So we want to minimize our surprise. You want to minimize your unpleasant surprise. Are there any pleasant surprises? The negative of this is the pleasant surprise, I guess. You want to maximize that if you want. I see. How come in the last equation you remove the 1 over y hat? Yeah, because this is it. Let's work out the details. Let's make a box. you remove the one over y hat. Yeah, because this is it. Let's work out the details. Let's make a box. Log one minus y hat is equal to- You move the, okay, okay, got it now. So that's the one there, okay. Yeah, this is it. But guys carry this intuition because some of this is not there in books right at least you don't easily find this sort of intuitive explanation and books is there in the mathematical community it's sort of it is there in the air people talk about it like this but not so often uh in the in the books and it's a good way of looking at it. So remember that, so I didn't get to entropy, which we will get to a little bit later. But think of entropy as the average degree of surprise at seeing all the pieces of evidence. But we will leave that aside for today. Now, if you understand this, it is just a mathematical convenience for reasons that we will get into when we talk about entropy later on. Mathematical convenience, which makes no difference to this equation. If I multiply it by the labels. So, you know, when it is actually y i so let's look at that total surprise loss function for classifier and in this case binary classifier loss function for a binary classifier is equal to minus i is equal to curves belongs to curves and see look at this term y i hat you know what is the y value here label if we give label one to curves zero to duck right what is the label here suppose i it by y i does it make any difference because y i here is one guys true right it's such a silly silly thing i'm saying i'm multiplying it by one because i know y i one y j is equal to 0 because all the j's deal with ducks are we together the first what is it the first the how many of them are cows um let's go back the first the third4 are all 1, and y2, y5 are 0, right? The labels are 0. So I can put a 1 here, and in the same way, I can just multiply j is equal to dux. And if I do 1 minus yj, which is the real, what does this become? We know that yj is zero this also becomes one this is also one and this is log one minus yj hat right so when i write it like this you it becomes the more conventional form that you find in books and you always worry that what is this whole mysterious equation like so i'll write it like this last function the way you see it in books is minus i belonging to case one let's say cows y i log y i hat right minus summation j is equal to that's they won't talk of cows and ducks i'm sure they talk of more formal language but cows and ducks are more fun to talk about one minus y j log one minus y hat j so when you see this equation in your mind here here is how I would do it. I would think about it. I would say, oh goodness, this is too complicated for me to understand. So I would, in my mind, translate it and say, hey, wait a minute. First thing I notice, this is one for cows and this is one for ducks, isn't it? So I would just go and erase those equations. And then in my mind, I would say, okay, knowing that this part is only about cows and this part is only about ducks, it is minus, it is basically log y i hat minus over cows and j is equal to ducks log 1 minus y j hat. I would write it like this. And the moment I write it like this, the next step I would do is I would say this is, well, you know what, this is summation over log 1 minus yi hat plus i is equal to curves, i is equal to ducks, log one minus yj hat. I would realize that this is the same thing. And then I would say that, aha, this is nothing but total surprises about cow predictions. Predictions are models beliefs, models beliefs models beliefs hence plus surprises about ducks duck predictions Doug's predictions models, again, models Doug beliefs. Would you agree? And so it is just total surprise. This is the way in your mind, if you notice that when I summarize it, let me decrease the, I tend to write in big forms, but in one page, I hope you can see it. So the formal log function, this log equation that you see in books, and you always wonder where did it come from? Yesterday I went through a formal derivation of it, but of course it was our optional session today i thought i'll explain in a way we'll use it because classification is the most common thing you do in deep learning right so i hope that i have interpreted this equation to nothing but a set of total surprises the loss function is just a measure of total surprise is it making sense guys yes right so that is the intuition that is the real intuition that you should carry in your mind any questions before we uh pause here is it clear guys i don't know uh it's it's i was just trying to make something that was opaque a little bit more uh intuitive pay a little bit more intuitive is this clear this was very good this is really good yeah this is the loss yeah it's simple because both are negative you can just in your mind multiply it both sides by negative one and it's the same yes all right guys so this i i had a key question All right guys, so this I had a key question. Go ahead. Why J hat is the machine's prediction about a dot or about the output is a dot or the output is a count. Why J hat? What is the? So that okay, so let me frame the problem. Here is the data. Here is data, x i goes in, the data, whatever input vector goes out, the machine will come out with y i hat, right? This is by definition, this was something I said, probability that X refers to Xi refers to a cow. Right? We also happen to know the reality, which could be like, the model doesn't know. But we know whether it's a cow or a duck. Because we have the answer. Isn't it? And so suppose it was a cow and the machine comes and tells you, absolutely sure probability 0.99999. But it's a cow, would you be surprised? You would say your machine is doing well isn't it your model is doing well but if your model comes out and says you know that it was a cow but it says that the probability that it's a cow is 0.01 now you would say now wait a minute that's not right you're surprised isn't it means you need to further train the model yeah i, I want to know why j hat is the probability of a star or the probability of a cow. Why j hat? What that means? Oh, why j hat is also the probability of a cow, but where you happen to know that the object is actually a dog. Oh, okay. I got it. Just two different indexes to distinguish yeah it's still probability of a cow when xi xj refers to to a duck in other words yj is equal to zero okay okay thank you that's what we are saying. So is the intuition clear, guys? This is our intuition. So carry this, this is very important. The intuition for regression is clear, you know, you take the error terms, you take his absolute value, or you square it and you add it up, all the error terms either. Classifier is a little bit harder to get because it gets into a more theoretical argument, maximum likelihood estimation, the log of it, negative log. If you're trained in it, after a little while it begins to look easy, but in the beginning it doesn't. But I thought I'll start with the answer itself and put some intuition behind it. So this is the intuition, just a measure of surprise. All right, guys. So now we will take, what time is it? 8.18. We have been talking for an hour. Let's take a very...