 doing live. All right, good morning folks. This is Saturday, the 21st. Another beautiful sunny morning in California, as always, and it is awesome to see that you folks are here present for this bootcamp. It means we might have something useful here to take you away from a beautiful Saturday, California Saturday, sunny, perfect weather. It really is perfect weather today, isn't it? All right. So today's topic is very interesting, and it was one of the sort of milestones in large language models and generative AI. It got people's imaginations like nothing before it. And it put the art world into quite a frenzy. This is the world of diffusion models and generative art. Did we have generative art before that? We did have. For example, you could do neural style transfer. If you remember, we did in a previous workshop, we learned about generative adversarial networks, how you could use generative adversarial networks to do a neural style transfer. What you could do, if you recall, we could take a loss function, which was partly on the content and partly on the style of another artist, and then by hybridizing the actual content, let's say a photograph with a style of, let's say, Van Gogh, you could create, you could render your photograph in the painting style of Van Gogh. I hope you recall that we did that we have done this in the past. Those of you who attended the generated the free generator AI class that I gave was a few days ago on Thursday, would also recall that we covered this territory. So generative art from AI has been from neural neural architectures has been there for a few years now. It has been from neural neural architectures has been there for a few years now. It has been doing very well. If I may, I would recommend a book. Someone asked me, what is a good book for generative AI? And I would say that one very good book is this particular book. It is called Generative Deep Learning. This particular book, it is called Generative Deep Learning. Generative Deep Learning, second edition. Get it. It has, and the updated edition is in color, like all the new books these days are in color. The color makes a vast difference in understanding the text. Those of you who have O'Reilly subscriptions, of course, can just go and visit the O'Reilly publishers website. Those of you who don't and are very interested in generative learning can attend this. Now I would like to also announce that there is a generative AI specific boot camp or workshop actually that's coming it's a seven week but it's in the style of a workshop uh two evenings a week that will start imminently the word imminently i'm deliberately keeping cryptic i'm trying to work out my schedule it is a price, a very reasonable, it's a usual workshop price. It's $1,000. It used to be $1,500, we have made it $1,000. If anybody is interested, we can go register for it. It goes very much into generative part in particular, like generative music, generative art, generative poetry, and so on and so forth, things like that. It does quite a bit of that. Now you can say that a large, I mean, a transformer inherently is generative, but we do more than the transformer. We do GANs, generative adversarial networks. We do various autoencoders, generative autoencoders, like variational autoencoder, Wasserstein autoencoder, and so on and so forth, and whatnot. We do a lot of that. We do energy-based models. We do normalized flow models. We do diffusion models. And of course we do the, I mean, as we do the diffusion models, of course, do the I mean as we do the diffusion rivals of course the large language models Etc LLMs the transformers they all make their way in right but that is dedicated only to generative AI so if you are interested the course is already available the workshop is already open for registration on the course portal supportvectors.com please feel free to register it will be very hands-on now unlike the boot camp in which i give you guidance and you have to go do it on your own as a team this will be in the same style you'll work in small teams but you will get you'll get a lot more hand-holding more like a workshop You'll get Jupyter notebooks in which there will be a solved example and then there would be some extension problems that you have to try and solve on your own. And in the style of the workshops, every session will be followed with a quiz on the concepts because we cover a vast area of concepts, all dedicated to generative. we cover a vast area of concepts all dedicated to generative and there will be quizzes there will be uh lecture sessions there would be labs guided labs and there would be then projects to do projects of the boot camp style right so the boot camp style is the new thing that i will inject into the workshop so uh please feel free to go register for that if that interests you but in this particular bootcamp because it's so compacted and you have to cover so many things now we are going to enter today this workshop itself we are going to do this bootcamp itself we are going to do generated but today is the only time that i may sort of deviate outside the LLM because the name of the boot camp was LLM boot camp we will stick to only LLMs only transformers for the entire duration of the boot camp but today would be a small digression into territories outside just transformers but we won't go into GANs and things like that in this particular case. We will. This week we'll do art, next week we'll do music, and the last four weeks we will do everything we did but not using pre-trained models but fine-tuning your own model. In other words, get ready to use the big server. words, get ready to use the big server. I did something and the table came down. Give me a second. Maybe this is good. I can see you better. Isn't it? I'll raise it just a little bit. So that's that. So the scope for today, today it's all about diffusion models. Now, this thing I keep telling you guys that we are the shapers on your journey. Take our help. Now, I do apologize. The last two days I was very busy. A good friend and teaching, part of the teaching faculty, sorry, Chander, was having his last two days in the US, and I was helping him do the shopping and so on and so forth. As of this moment, he has, he must be somewhere over the North Pole or Russia or Kazakhstan or somewhere, way on his way to Bangalore. So, well, that was that, but we we are here and i apologize that the last couple of yesterday we didn't open support vectors at all but i'll be more regular here now and we'll do this what do we do support vectors remember that we not only teach we also give you yeah go ahead oh generative deep learning i'll put it on slack also generated deep learning uh might as well do it right now um oh such an already posted it okay excellent so then i won't post then uh just as a reminder and please forgive me for this little bit of a sales pitch, we not only do training, we also provide consulting. Like if you are a company that is launching on a new AI project or want some guidance or have an AI project in progress, you want us to look over it, make sure that your architecture is right, then we can provide you invaluable or what I would consider very valuable advice for a fairly low price. So this is a consulting part. We have decades of experience and a track record of success. As you know, anytime you get consultants, it's a throw up the dice. They market themselves very well but quite often they are not as good as you hope they were. Now here it is it's an open book you all know who we are and whether we can be of help so if you ever feel we are of help please do feel free to come by. Now this entire boot camp just to recapitulate its core goal was to bridge the gap between Keri and an enterprise-scale, robust and high-performance architecture. I hope the lesson that you have been learning in the first half of the bootcamp is that it's really hard. Doesn't it? People tell you, and I've had many, many people come. They say, hey, I got deep learning. It's so easy. It's just Python code. And most of the codes are 10, 15 lines of code, a Jupyter Notebook. I hope if I've done anything, it is to convince you that you're just peeling the onion, the outer layers of the onion. It's a pretty, pretty, pretty multi-layered deep onion. Every time you peel a layer, you find another layer, isn't it? For example, even when you do rag, how many of you have done rag? Succeeded in rag? Okay, so that seems good. Praveen succeeded. Satyam, almost there. Not yet. Okay so uh then you realize that what looks easy in theory it's not complicated it's a little bit of a hero's journey in the beginning it looks easy you embark on the mission then the going gets tough right you're in the belly of the beast and after a little while there is a light at the end of the tunnel and you come out of it and the whole thing looks easy again right but uh i won't since all of you haven't finished your ad i wouldn't share the lessons learned in drag yet i'll hold off on it but suffice is to say that it's not hard and it is hard right if you haven't thought about it, it's hard. But when you do it, it will just be a few lines of code. Not pages and pages of code, just a few lines of code. Well done code. And you have to learn basic techniques of giving instructions to LLMs and you'll learn that. ARAG is another kettle of fish. instructions to LLMs and you'll learn that. ARAC is another kettle of fish. One of the questions that many of you have asked and come to me and asked is this paradoxical situation. You take a LLM from the open source and the thing seems to be producing only the next token, whereas for ARAC to work you need what else? The probabilities, right? The probability or the confidence in that token. So how do you get there? And for that, and the reason I brought ARAC is, I wanted it to be a first foray in reading the source code of those models, seeing how they have been implemented. In particular, looking at what is a headless model versus a full model and how you can take a model headless and therefore use it for the purpose you wanted. That is sufficient hint. I should say no more because that's practically giving you the solution. But are you guys having fun with these projects i hope there is a lot of learning in this project uh so far and those of you some teams which are a little bit behind us started a bit late and now i will start sitting with you and helping you catch it i'll come with you uh if you need if you allow me to i'll help you just catch it right i don't want you to fall too far behind. Once again, the AI centric enterprise, I keep repeating this and I'll keep repeating it every single session, my next three slides, is that AI is more than just models. An AI system is the data infrastructure. It is models and algorithms show. is the data infrastructure it is models and algorithms show right that's one of the drills of this ai system but you need a platform you need operations you need security and compliance you need analytics and interpretability and ethics did you check for bias did you protect against adversarial attacks did you do all of that? And the people. Are the people really capable? Today, see, if you go to a, if you get a cardiologist, for example, and the cardiologist says, hey, I do heart surgeries, right, a cardiac surgeon. Assuming that the credentials are true, right, and the residency and all of that is there you assume competence in the cardiac surgeon a typical interview process for a surgeon for for that reason is very brief it's typically 10 15 minutes and you pick a person over a handshake you hire a surgeon in software have you noticed that the interview processes are getting longer and longer and longer? It used to be that there would be two rounds of interviews. And nowadays, five rounds, six rounds have become the norm spanning over months. And if you really think about it, is it really helping out? No, it was my, in a past life, it was my job to study quite literally the most effective ways to hire people. We were in a startup evolve and in fact the head of Google's HR, Google People Division, was on our board of directors observing what we were finding. And amongst the things we found is that interview processes are notoriously biased and great. You can only do so much. And still, even today, and as even Google, Facebook, all these big guys admit, their interview process may be slightly better than others, but by and large is relatively ineffective. Half the people they end up hiring are not worth it. Right? More than half. Right. So we only hope you have is pick up some gems along the way. So. So anyway, the interview processes in this field are very long because people make tall claims and it's very hard to verify. If you give them a test, they'll practice to the test, websites will spring up, need code and whatnot, that will help you practice to that. And they all bring some value, they'll practice to the test. Websites will spring up, need code and whatnot. That will help you practice to that. And they all bring some value. They at least teach you basic algorithmics. Like, but it's hard. AI is particularly pernicious because knowing who's good at AI is extremely hard. I have been at the receiving end or the acquisition end of many startups which came to be leading Edge in AI and when I would when we would acquire my company would acquire everything would be present but genuine AI talent would be conspicuous by its absence it would be nowhere to be seen it would be like unicorns and yet the marketing literature would be full of the great AI they have done. I remember one in particular, I won't name it not to embarrass that, which sprinkled the word neural networks in every single paragraph they could. And it led to a very successful sale for 500 million. Only after that we realized that the neural network was nowhere to be seen. realize that the neural network was nowhere to be seen. So that's the reality with AI. And in that world, I hope that as graduates of support vectors, as alumni of support vectors, you would come across as the few really well-trained, really legitimate people. And it was really a pleasure today to hear Subrata's feedback. Thank you for that. That what he has been learning here is helping his team do quite powerful strategic and leadership stuff in his big company. So which was the hook, which is the whole point of this. So do that. Remember, AI is a complicated journey. It is many tribal cultures all working together iteratively. The data scientists are continually iterating over the model. The data engineers are continually iterating over the data and the data pipelines and data transformations and computations. The AI ops people, the ML ops people are continually trying to get the infrastructure ready and make sure that the model that you deploy is better than the previous model, that the model is not stale, that it is not open to adversarial attack, that it doesn't have bias, it doesn't have security holds, and so on and so forth. It's compliant with all the regulatory requirements, the right to be forgotten, and so on and so forth. So it's a very complicated world that we saw in this big diagram from the AI Alliance, Infrastructure Alliance. Yes, please go ahead. So one of the things, I think it came up last week as well, we need some sort of an overarching chief architect or a person responsible for the entire stack or oversight over the entire stack. The challenges I've seen is between the teams of AIOps, data science and data engineering, there is a lot of friction and the roles and responsibilities sometimes are not super clear. So I've seen a lot of friction and the roles and responsibilities sometimes are not super clear. So I've seen a lot of process issues related to that. Absolutely, absolutely. I'm seeing it everywhere. It's my job, as you know, in support. We go and advise a lot of startups and give them guidance. I'm seeing it everywhere. Nine cases out of 10, I see this dysfunction. Reminds me of Tolstoy saying that I keep repeating, all happy families are like each happy, unhappy family is unhappy in its own unique way. And software engineering has 99% unhappy families. It's just a question of which dysfunction you have. And at the risk of sounding like an advertisement for ourselves, for support like this, I would just suggest that wherever you go and lead projects or you do your own startup remember support vectors can be the bridge the the leading architect to put whole things together for you our services are there yes yeah my point was is this part of the growing pain or is this something which will eventually get resolved as people find more maturity with these things? That's the part I'm not sure about as yet. It doesn't get resolved, it just becomes an uncomfortable compromise. It becomes like a lot of royal marriages where two kingdoms make a strategic alliance and a boy and a girl, a prince and a princess are married and they sort of have to live together in uncomfortable, I wouldn't exactly call it harmony, but that's how it is. So in most organizations, actually what happens is different groups, all if you look at this, you'll realize that all these groups ultimately, they are not going to change the opinion about the other tribe. The data scientists will think that the data engineers are bozos, data engineers will think all the data scientists can do is work in Jupyter Notebooks and so on and so forth. It will continue. However, there will be a need, a growing need, for lead chief architects. If you think about Oracle, can you imagine Oracle database kernel without a chief architect, without those leading lights sitting on top of it, making sure that the storage layer and the query processing layer, the upper and the lower layer, are genuinely well harmonized, it would be chaos, isn't it? And yet, I mean, in the AI world, we haven't reached that level of maturity. So maturity is yet to come. Will it come in every company? I don't think so. But certainly the successful companies will figure a way to solve it i think uh would you mind if i add a little bit of tidbit to what you are saying sure yeah um nicely put there uh you're absolutely correct so my experience has been as you know i'm part vector. So, you know, I hope this doesn't come in as a sales pitch. our attention is that the gap, the skill gap between where they wanted to land, where this whole technology is taking the world by surprise to how they wanted to approach is vast. What does that mean, right? So most of the companies, they want to retain their existing employees, which is the right thing to do. And many, I would say 99% of them do not understand this yet. And this is a huge opportunity, especially for folks going through this boot camp and learning this. And you are ahead of the curve at this point, as far as I can tell. And the opportunities are really tremendous as I see us moving into 2024, because from the economy perspective, from all these macroeconomics are going to be playing a major role in terms of really reshaping how the technology will be looked at as we move into 2024. So you are ahead and we are seeing those trends and we're seeing those massive articles coming in, people all talking about this technology at a 30,000, 40,000, 50,000 feet level. But when it comes to a thousand feet level, you are ahead. but when it comes to a thousand feet level you are ahead and when it comes to a single feet level you are way ahead so that is where the the you know the change is going to be as we progress it's my two cents awesome thank you thank you for saying that and this is always true see when companies don't have the right resources or they hire people who claim to know things, the biggest problem is the opportunity cost. You lose time. In the time that you could have been building something worthwhile and leading, you instead build things that don't work, that are not built to last, and then you redo it. So thanks for saying that. All right, guys. So what's the lesson plan for today? This is deep sea. Today we are really talking about some of the core algorithms that are being very dominant in this space. So this is the plan for today. We are a little bit behind, but now we'll work up. Welcome back is done. Administrative notes, once again, there's's food and i hope more of you show up oh i have to open this room sorry um food by the way if i do if i forget to open the rooms please take the keys and do unlock your rooms and administrative wise the same old request guys it's a mom and pop shop please help keep it clean before you leave in the evening. A couple of basic things. Turn off your TV. Turn off the big monitors in your room. Take all the dishes back to the break room. Rinse it. Put it in the bus tray. And if you can help with a little bit of just keeping your own team's room clean. Try to clean it up before you leave. I really appreciate that. And but in general, most of your teams have been doing a very good job of it. I only have to pick up one or two dishes from the rooms every time. Not much. So thanks for that. And I noticed that with all these admonitions, now I don't find a lot of Biryani lying all over the floor. Those incidences are decreasing. So thank you for that again. What are the lessons we have learned? I hope the one lesson we have learned is doing anything as a proof of concept is very easy. Doing it right is hard. But we have learned many, many things along the way, lots of technologies. At this moment, we are into the seventh week. We have learned hopefully six core things. And we'll review that in a particular in a moment. But today, we are going to go completely into two different areas. One is diffusion models. But I noticed that none of you have really taken pains to pick good data sets so now i'm letting you know those data sets for text i want all of you to pick wikipedia download the wikipedia data set make it the base so that we can do now what in the second phase i would like to have an open competition between the teams phase I would like to have an open competition between the teams. The final day will literally be a show and tell and ratings review of the overall projects from each of the teams. For that we need to all standardize on the same data set. I was hoping that you guys would all bring unique data sets but it's hard because we are moving very fast and all of you look rather tired and sleepless nature of a boot camp if you didn't look sleepless i wasn't doing my job so so uh standardize on wikipedia for images standardize on leon dataset it's an image dataset it's one of the largest image data set. It has many, many data sets. Don't take something too big. Stay in hundreds of millions, not billions of images. Try to take aesthetically pleasing or meaningful images. There is actually a subset of the data set whose aesthetic rating is greater than four, eight, which means that those are the pretty pictures. There is also a data set which is of high resolution images. Take those. You will need those. Pick a couple of those. Now, for example, for RAG, taking a good image of a Blip2, taking a good image and then having a narrative come from that is far more useful. By the way, they themselves have used Blip to generate captions and narratives from the data. Use Unsplash. Unsplash gives you 25K images, but I believe Praveen, you managed to get a bigger data set from them, right? They just used the data set, not the images. Just the 25K data set, the one that I gave. 25k data set the one that i gave yeah that i can download it from bug 35 but actual unsplash on hugging face and all they just give you the data set on that oh they give you the urls and you have to go scraping it but that wasn't wouldn't unsplash me quite angry that you're scraping okay so anyway is 25k is good, treat it as your baby data set. And the lay on is obviously a pretty impressive 400 million and so forth. They are in hundreds of millions. And even the beautiful images, they are said to be pleasing images are 7 million or something like that. And high resolutions are also in millions. So I'd like to download some of the bulk, particularly images that we can download. It's a 2020 image, actually. But the bulk productivity images that have you can download it's a 2020 images actually but the latest whatever they have on the dataset okay all right let's use the lion because it has yeah as if can you repeat what pravin said we couldn't hear everything yeah what pravin said is that getting the unsplash full data set is hard because what they give you is a csv with the file name and that and it is uncaptioned so use the leon data set see 25k images that i have that that we had as part of the llm book the llm uh with trans i mean sorry uh the llp with transformers workshop that of course you have the jupiter notebook it is there in your sample solutions and everything just use that for now but go to lay on and get the bigger data set those data sets just for your information have already been properly tagged. Some are tagged with clips, some are tagged with blips, right? So they're cleaned out nice data set. It's really a very clean data set for research. Has anyone tried to? Oh yeah. That is the one they use in all stable diffusion. Everywhere. yeah that is the one they use in stable diffusion everywhere yeah and of course wikipedia wikipedia you can get from the wikipedia dump itself every night they publish a dump or you can just go to kegel and get a relatively not so old dump and they even have oh yes yes if you go to wikipedia you'll get the fries and getting everything don't use that right otherwise you know i mean don't let people spoon feed you because you'll never learn it and these days wikipedia is available in parquet format this format that formats and all sorts of things do that now when you that, I will ask you to do one thing. One of the racks, I'm giving you a specific rack. When you search on a topic, ask it to use the full Wikipedia, not the simplified Wikipedia. Then ask it to take the search results and create an essay that an eighth grader can understand, a pre-high school child can understand. Synthesize using RAD the results of the search into an essay of about, let's say, a thousand words, a thousand tokens, in a language that an eighth grader can understand. Are we together? Second part, which I'm adding for today, based on the content generate an image to be the banner image to your essay at the top of your essay render all of it as a dynamically generated page we had a plan to do the text and the image and the like all the Wikipedia right exactly the nlp yeah nlp transformers. So now what you did with the NLP with transformers, now do it at a more serious level using the full power. You must have a banner image that must be relevant. We will all vote for how relevant it is. The text must be understandable by an eighth grader, but you cannot use the simplified Wikipedia use the full Wikipedia. Are we together. But I didn't understand generating image that you used if stable diffusion and just generated like what. That is a today's learning lesson is stable diffusion so you don't use the stable diffusion of the diffusers. So yeah, one basic thing is that try not to use like somebody's API. Try to load a model and do things on your own. It is not that hard. See guys, by now you realize that every week's project is not hard. It is just adding a little bit to your existing project. So yes, you will be using diffuser models okay but generate a very try your best to generate a very relevant image so what it means for you i wish it is see when you get search results you get a lot of text you have to do two-stage operation from that first generate a good prompt to feed into the diffuser models. You realize that? You can't feed all that text into a diffuser model. You'd be totally confused. So your first stage of RAG is to generate a good prompt. And the second stage of RAG is to, from the prompt, generate a good image. You see the subtlety there isn't it because if you try to feed your whole essay into an image generator it wouldn't do a good job no generate image basically summarize the content that is generated and then when you're headed the easy win is you generate a banner image in your essay what you do is at the bottom of the essay or have a separate tab of relevant videos audios and images which you can get from your index search index are we taking that so there is there is both a retrieval task and but not text remember text went into the rug so you can use for images i get it for video also like you could do that like small models of their right video you could do video generation let's keep it for next time but yes we can right now yes if i'm not 100 clear on the last uh one minute of your explanation yeah see what happens is imagine look at your retrieval task you search for something you will get some text search results some image results search results some video search results some audio search results so keep your audio video and images show them as search results as retrieval tasks but take the text and from the text and from the text use RAD to generate a thousand token essay that an 8th grader can understand. In other words, you can't use complicated language. So this is the lesson to learn here is How do you speak to an audience using an LLM to a specific audience? Are you clear? So, I understand the first step is to just do the same and display the text, images, audio... Not the text, not the text. Don't show the text. Only show the related images, related videos, related audios. But use the text to feed it into the rag to produce an essay that an eighth grader can understand. Just to summarize that, so it's not a chatbot? It's not a chatbot. We're not chatting with it. Chatbot is another project we'll do, but it's not a chatbot. So here you just take the text input and summarize that? That is it. Or elaborate that, not summarize that not summarize elaborate that into something in eighth grade i can understand along with that generate the images and generate one binary no no not audio just generate a banner image that should be relevant using stable diffusion or using diffusion models are we together so that is the project for this week guys now believe it or not you have done most pieces of it have we done image search yes right have we done audio search yes where do i get audio files wikimedia you can go to wikimedia and some right? Where do I get videos from? Well, i'll give you some liberties with it. You can get whatever videos i'm giving you a specific usage of RAC instead of doing RAC for whatever you want. I'm saying use a R model to generate a banner image. So, points go for aesthetics, relevancy, and speed. And my request is, you should be able to do, you should be able to process every single query in this, except for image generation. You should be able to do this in under one second per query. 1000 milliseconds. And the image generation should happen asynchronously and it should not take more than a minute. And it should be able to take concurrent requests on your server. Your architecture shouldn't collapse just because two different queries came by. So that is the engineering part of it that you have to think through. How would you do that? I'm going to write up these things and post it to the course web pages. And you'll have the details of what I'm asking for. I'm sure you can do some diagram. Oh, no, no, no. That I leave to your creative liberties. I mean creative inspiration. Any page that fulfills all these requirements is fine, from simple to complicated. Some of you are great artists. For example, Hamad here makes beautiful web pages. Some of you are totally backend people. Right, so a very simple streamlit version may be bare minimum, but I'll take it. React is better. Are we together guys? So what's the topic we learned today? We learned about latent diffusion model, unit and glide. Unit and glide are the foundations on which the diffusion models are built. So we'll read these three papers silently and we'll do the paper reading at two. By the way, are these paper readings helping you guys? I mean, if you feel they're useful. So we'll do that guys. That's the core of it. See, it isn't enough to blindly use things. It is important to know why they work, how they work and so forth. So we are going to do that. We'll have one, at least one, team presentations are optional attendance but I'm hoping there are some, which team would like to present today? Satyam, I thought last week you promised something. You're not there yet. Okay, any other team that is in a mood to how about you, Sanjay? Not yet. Okay, so we'll let it slide this week. But guys, Cambrian Explosion. Some facts, some new things to share going to bring something but who else? Guys, all it takes is reading the latest AI news for half an hour and finding something that you liked and remain. Do that please do that. Let this Cambrian Explosion event not be a bust i want it to be a weekly tradition even beyond the boot camp we'll all benefit as a community if we all share our findings so that is that guys i'll let you it's a it's time now to let you all go so uh what's our journey so far we have we learned about text extraction and semantic chunking, as you realize that itself can keep you entertained for the better part of two weeks. We learned about vector databases, sentence encoders and ANN indexes. We learned about hybrid AI search right which takes the best of keyword in AI search why would you in the world of AI search just a retro question why would you use keyword search go ahead Go ahead, Abhay. It could be relevant, right? You also said. Come again? It could be relevant. Like it could find something which LLM can, you know, it's really short. Very, very. Can do that. Sorry. Yeah. One second. Amrit? Yes. There's a similar answer. Sanjay? Tabular data, perhaps. But yeah, let's see sometimes AI needs semantics. Semantic search implies that the sentence you wrote had semantics. People have gotten into the habit of just entering a keyword. For example, bank. Is it a river bank? Is it an aeroplane banking before landing? Or banking in flight? Or is it a river bank? A financial bank, river bank, bank. These are homonyms. Which one would you want to just go for? Sometimes keyword search is useful because it just looks at statistically which is more likely to be true for your document set. And it gets you the result and it tends to sometimes perform better in these situations. But when you explain what you're looking for more generally semantic search beats it. We learned about multimodal search, clip, blip, lib2, video llama, etc. We did all of that. We did retrieval augmented generation, RAG, and then we did active RAG. And today, we also did memory efficient fine tuning, LoRa quantizations, QLoRa. Do you remember that, guys? Did anyone get a chance to review those papers? Did anyone get a chance to review those papers? And finally, today we are going to do diffusion models and image generation. Very, very exciting topic. Guys, when this thing first came out, when DAL-E came out, it took the world by storm. You could literally say, I want a chair designed, a chair designed that looks like an avocado, right? Or I want a radish taking a dog for a walk a turnip or something like that and it was amazing it is just mind-boggling that a computer which is supposed to be dumb it's actually think about it what is a computer it's just a bunch of electrical circuitry isn't it with its high and low voltages and band gap semiconductors right with its band gap with electrons going under certain activation flipping across the band gap to the next energy state right it's a transport of electrons and holes that i've mediated with some voltages, the transistor base voltage and so forth. With that, what a long intellectual journey it is from there to be able to do Boolean arithmetic, Boolean logic, and from there to do programming languages and from there to hybridize it with calculus and mathematics to create AI models and from there a long journey to deep neural networks and then finally you end up you find yourself doing a thing like image generation if you just think about it and you try to just imagine in your mind that you're trying to show this to your grandpa you would agree that it would look like miracle there's a state there's a saying I think this person who wrote 2001 Odyssey uh what's his name Clark who said that a sufficiently advanced technology is indistinguishable from magic. To a person who hasn't seen all of this, the first encounter with technologies like this appears like magic. And so you're touching something that is literally like magic. And like with all magic things, you can, there is a causation, there's a reason, there's a physical reason why it works. And we are going to learn about that. And that is what it is all about today. So these are the three papers you will would say this could easily be, this is very realistic, it's a child having fun with paint. And yet, it is a prompt going in and a picture coming out. Isn't that magical? So we are entering the trade. What is it? We are entering Hogwarts. And you guys will soon be the Harry Potters. So these are the three papers we are going to study today. And please do study them. By the way, study them, please. I should have changed the order steady unit first glide second and latent diffusion model which builds upon both of these last the diffusion model is the crown jewel that builds upon these foundations right not only the quality book the picture yeah you can turn the really expensive lens. Yes, yes, it looks if you were doing it with a real camera. Like today, like I have, I'm into photography. And it's one of the things you know, being into photography, I learned the zone system, Ansel Adams. And then people started, came up with Photoshop and they could fix these pictures. And I was like, then I could do things with filters. I have a whole collection of filters. Right? I have gradient filters. I have the, yeah, that is right. And all of those filters, physical filters, nobody even knows what physical filters are. Polarizers, etc. Because I don't know, can Adobe also do polarization? Maybe polarization is the only filter it can't do. It can. And if you see the last thing there is the AI filter. Oh, that's right. OK okay so by now I'm wondering am I a dinosaur to still love photography? Anyway so this is it we are entering this beautiful beautiful world guys. Please do as a background material you will see that we are entering into territories we did auto encoders in great detail in the neural architectures course you remember guys we did we did auto encoders in great detail in the neural architectures course you remember guys we did lots of auto encoders from the basic auto encoder to the dc gan sorry deconvolution auto encoder from there to variational auto encoder to many many other things right to many many other things right Wasserstein autoencoders and so forth and for each of them there's a corresponding GAN also generated by the sale network which which used to generate things there is a VG GAN there is a read this that and so on and so forth vector quantize quantize, VQGAN, and many, many things we did. And we did conditional GANs, whatnot. So go back and review your autoencoders. But just in case you didn't take that course, here is a little link to the review paper that you can quickly serve, a survey paper that you can quickly read in Hapena. Not for today, read it in the evening. If you have time, read it in the evening, if you have time read it today, I should have put one link for the gallons also so they all this wonderful website they're literally called awesome. auto encoders and awesome guns and so forth that I curated list of the wonderful things you can do with these things. check them out. The users of transformer this paper was written last year, I think it is still very relevant it's sort of a companion of all the different users transformers have been put to. I may want to do some background reading and that's it guys, and so I will let you guys go lunch should be here shortly and. We will we will continue at two o'clock. The time is two o'clock when we'll start the paper reviews. Make sense guys? And I'll come to your rooms and I'll come and start helping you with your projects also. And as I said yesterday, I wasn't here in the day before or so. I wasn't as regular, but now i'll be here much more often so you guys can keep coming and working here and i noticed that new computers keep mushrooming albert is the proud owner of a new machine a really powerful machine so is there any team that hasn't built a machine of their own every every team has a machine if If you don't, by now you must have realized that to make good progress in this workshop, it is okay to use support vectors machine, but it's even better if you have your own machine under the desk.