 Last time we started the topic of regularization. What is the core theme about regularization. When you take data, you can have one of two situations. Either you have lots of data, you don't have enough data. Quite often, data is expensive, you don't have enough. So when you try to fit models, the more complex you make your model, the more flexible you make your model, the more risk that you have is that your model is not fitting to the data per se in itself the signal in the data it is fitting more to the noise in the data also now that is something you don't want first of all you can't remove noise from the data data inherently has the noise right so the whole thing is what's that? . And that is what we are going to. Regularization is essentially that what happens is that when you get data like this, and your basic hypothesis should be that the simpler the model that can fit and still give good results and the gap between the training variance the training error and the testing error the the model that minimizes that gap is likely to be the correct model you just go with the hypothesis see in this field you can never prove that you are right all you can prove is that you are right. All you can prove is you're wrong, right? So all you can see is that this is likely to be the effective model. And we define the effective model as that model in which the gap between the training errors and the test errors is very small, right? If the gap is too large, it means that you have overfitting errors. So that's the way you do it in this field, right? So, all right so we will so anyway just to recap when you have data there's always a risk of overfitting listening to the noise rather than the signal in the data so when you do that of course it's not good because then the model doesn't work in practice. In training, it does very well, but in actual practice, it begins to do very, very poorly. So the remediation is a set of techniques that are in machine learning called regularization. These techniques are also called in the statistical community for example the book it calls it shrinkage or shrinkage methods right regularization is shrinkage what do we mean by shrinkage you you realize that when you when you when you have overfitting you have wild oscillations now those oscillations manifest themselves as very interesting. If you look at the coefficients, the size of the coefficients, for example, if you're looking at polynomial regression, when you look at the size of the coefficients, you will see that the sizes are huge, right? Each coefficient is saying that its feature is very important, right? So one sort of a rough metaphor that I use is, see, when you have a room in which there are 10 people sitting and each person has its own reason why something happens, and each person is very, very loud and absolutely insistent that that feature is really very important. What do you have in the room? In the discussion, you have nothing productive. You have a cacophony, right? And a more reasonable discussion says, all of these features contribute to different degrees, relatively different degrees, but none of them is so way outsized unless it truly is outsized. So that is the process of shrinking the value of the coefficient in regression. So we will talk about that a lot today. Now one easy way, and so we will see even the regularization is applicable to the broad class of all machine learning algorithms, all supervised learning algorithms or models that we build. It is, we are taking polynomial regression as sort of an exemplar, right? It's sort of the, it's a good exemplar to start with and work with, because if you start and work with this exemplar, here, the hyperparameter of the model, how do you dial in and dial out the complexity of the model quite easily you dial in and dial out the complexity of the model by simply increasing or decreasing the value of n are we together yeah so excuse me actually I realize I'm not able to see you very clearly because of all the lighting and so forth. So would you mind a little bit? So I want to make sure I have eye contact with you too. Yeah, maybe a little bit to this. Yeah, this light is coming in my way. So thank you. So, or you could just go to the back seat or whatever it is, but all right, thank you. Now this is whatever makes you comfortable. All right, So with that, more data regularized the solution. We saw that. You will see that in an animation in the lab today also. Very clearly, it leads to the suppression of oscillations. Today we'll see in a very direct way, or rather I'll explain it to you in a very direct way what it does to the coefficient that's what it does it suppresses the value that's why the term shrinkage now we will look at another technique what if you can't go and get more data which is often true sometimes you have data is data right and then you ask people to go out and gather leaves and then they don't do that, right? So you have to work with what you have. Then what techniques can, it turns out that all is not lost and there are some very good, powerful mathematical techniques that you can use to still regularize. Two of them that we'll talk about, which are the great classics in this field and very, very powerful. They have various names. They are called ridge regression. They are called L2 norms. Then the other one is lasso regression or the L1 norm. And then there are all sorts of hybridizations of these, elastic nets and so forth. And then of course you can go to other norms. So you often find this very mathematical word or jargon being used, norms, right? If you read machine learning literature or you read the scikit-learn literature, you often find the word L1, L2 norms, and et cetera. Whenever we talk about regularization or optimization, those of you who have done deep learning should also know that every time you use an optimizer, one of the big questions is, does it or does it not regularize? So what are these that we are trying to do with this? We will learn about that. So we stopped here. Let me go to the end. Question I said. Yes. This technique of regularization shrinkage and stuff like that, that's what you talked about. Are these concepts borrowed from other applications in physics and things like that or are these things kind of where machine learning itself basically started this uh way of optimizing equations yeah it's a there is an objective answer factual answer historic answer and there is also an answer that gets sort of subjective and politicized. What is machine learning per se? If you ask a statistician, he'll tell you, in fact, the authors of your book, they'll tell you that machine learning is nothing but statistics wearing a marketing hat. If you ask a computer science person, they will tell you that machine learning started with the invention like 1950s. If you ask a theoretical physicist, he will assure you that all of these concepts were done way, way before. It was done by mathematical physicists, like Gauss, Legendre, and all of the legendary people. And so a lot of the key ideas were there. This field has gone through, like it depends upon which lens you look at it from and you'll get different answers. I happen to be in an unusual situation. As you know, I'm a computer engineer, computer scientist. At the same time, I have doctoral work in theoretical physics, right, mathematical physics. So when I look at it as a lens, I feel that all knowledge is a collaborative tradition. Different traditions contribute. They all move the needle forward. I would argue that this field started with theoretical physicists like the Gauss and all these great mathematical physicists who made rapid progress. So regularization was already well known at the time. Then came, then for a while, if you look at the history of theoretical physics, they got very fascinated with relativity and quantum field theories and quantum mechanics. And they sort of, in a way, they ignored the whole, the data analysis aspect of it. They had enough to deal with it. So this field was more or less moving forward fairly well in the hands of statisticians who made quite a bit of contributions. And then came the machine learning, then came the computer scientists to whom they were not interested in statistics or anything. They were just interested in creating learning machines. And it took them a while to realize that they were saying things which was already known, right, in the scientific, in the statistical, in the theoretical, mathematical, you know, sciences. So it's a convergence of many things. But regularization certainly is not a term of recent coinage. In one form or the other, it has existed for quite some time so most of the key ideas that go see one thing with knowledge for any deep breakthrough if you look deeply at its roots the core ideas you will find that those core ideas go back often centuries or decades and they remained either they were unappreciated or they were applied to other areas. And in this breakthrough, their relevance was realized. So most of the breakthroughs are not about completely giving birth to a whole set of new ideas in a vacuum. But it is bringing together a lot of things that are there and then generating one new idea. So as a digression and as a physicist, the one example that comes to my mind over and over again is that of Einstein and his theory of relativity. People often think, and for example, in your school books, it's always told that the Michelson-Morley experiment they were trying to find what is the speed of the earth through this supposed ether, which was supposed to be the imaginary ocean or that static field through which earth and all the planets were moving. So there was a stationary something and everything was in motion in that stationary something. And so Michelson-Morley, that ether and Michelson-Morley did all sorts of experiments to find what is the speed, and to their, they were completely confounded, because no matter what they did, they couldn't establish the speed of the earth through the ether, right? So it was terribly confusing, and supposedly that helped Einstein get an idea. But actually, while that makes for a very good story that's not how it happened in Einstein's words Einstein didn't actually know much about the Michael Morley experiment he was asking a very simple question why is it that Maxwell's equations for electrodynamics are complete in complete contradiction with Newtonian physics right the Galilean translation and. And so the idea in those days was that Maxwell was wrong. Maxwellian equations are wrong because Newtonian physics was very well established. Mechanics was very well established. And everybody looked at the strange differential equations, you know, all of those div of E and all of that and the four Maxwell's equations equations and they were they looked as concerted and thought there must be something wrong with it because it doesn't agree with newtonian mechanic but the insight and there was a guy named lawrence who found a hack a mathematical hack to make the maxwell's equations work with uh newtonian physics but in that hack somehow the Newtonian physics. But in that hack, somehow the time had to be adjusted. It seemed to dilate, and then there was a length contraction and so forth, but it was all considered a hack. The main insight that Einstein brought, all of these ideas were sitting there. The main insight that Einstein brought is he did one simple thought experiment in his mind, that Einstein brought is he did one simple thought experiment in his mind and he made that hack into a reality. He said, it's not a hack. And this is the interpretation of this Lawrence equations, right, of time dilation and length contraction and so forth. He given explanation for it. And therefore he merged space and time into a combination. And consequence of that is a profound statement. It says that the same thing that to you looks as electric field, to you may look like a magnetic field. An example is that suppose there is a charge sitting there. If it is sitting stationary with respect to you, you see it as an electric charge. You feel a sense of attraction or repulsion based on what you hold in your hand, what charge you hold in your hand. On the other hand, if you're passing in a train, now the charge is moving. A moving charge is current. A current generates magnetic field around it. And so the person going in a train does not just see electric field. He sees an electric and a magnetic field. Now, these are very real things. And with a simple thought experiment, he realized that therefore, these are just relative perspectives of the same thing, isn't it? And from there, he continued and he's realized the same thing about he began to look at space time in a critical way. So his great breakthrough was one tremendous idea resting upon other great discoveries that had been made, already been made. So that is much of machine learning if you look at it, most of the great discoveries here, they are in the same flavor. One great person comes, puts many ideas together and after a little bit puts one crucial piece it's like missing piece of the puzzle puts it there and learn behold you have a breakthrough so science always is a collaborative growth process right it's an accurate process so i will stop with that and leave leave it leave it like that with that so all right coming today we will do we will do non-linear oh sorry regularization yes let me do that i actually have Is that better? Right. Okay. So regularization is what? It is suppression of the overfitting. Suppression. Suppression of overfitting in some sense. So we will look at polynomial regression. And I will mention something, which in the lab, when you look at the values, it becomes clear. So there's an interesting phenomenon. The polynomial coefficients when overfitting happens. When overfitting happens. What is this phenomenon that people observed what they observed is suppose you have data limited data and you try to fit a polynomial equation you will get those oscillations but those when you that is visually what it also will do is suppose you have written your equation like this y hat is equal to beta naught plus beta 1x plus beta 2x squared. And I'm just taking univariate, but it generalizes to higher dimension, to higher, to multivariate results also. Beta 10 x 10. Let's say we take a 10 degree polynomial. When you try to fit the data and there is overfitting, what you will notice is that the size of the coefficient, size of the beta i become is large, is large. is large, is large. This is an observation. So typically you want to make a model. Let's say that a good model would be something like two plus three, let's say X, right? These are reasonably small numbers. But on the other hand, so let's say a meaningful, but suppose you get a model that is like a minus 1, 3, 5, 7, 9, 8, plus 2, 4, 3, 2, x, minus, let's say, again, some vastly big number, 4, 4, 3, 3, 443 321 i'm just cooking up numbers and they have no meaning so take it don't take it too literally like this, plus and So what do you notice this coefficients what can you tell about the coefficients in case a. Raja Ayyanar? versus case be. coefficients in case A versus case B. The coefficients are large. Do you see that? Isn't it? Yes, go ahead. I'm assuming when we get to this discussion, we're also making an implicit assumption that all the variables have already been normalized yes you can normalize the variables and nonetheless you will see that in spite of that in spite of the standardization that is a good point in spite of that you see so now you can see why there are vast oscillations yes for instance the power of x right these are the powers of x, so it doesn't really matter. Yes, it won't, but let's always assume the data is normalized. Right. One dimension that you're looking at. That is right. The square and that part of it, what I think you're looking at. See, two aspects to it. See, what Premji's point is, if it is not normalized, then the x value itself being large or small can have effect. But because it's one dimensional, you can sort of standardize it. It won't make a difference. Yeah. That's what I'm talking about, right? That is true. Yeah. And it's analyzing multiple variables. Yeah. So now, yeah, for multiple variables, it would be best to normalize. And for reasons that we'll see, for multiple variables, linear regression happens to be one method that is somewhat safe from non-standardization of data. That still functions. But what it does is your gradient descent gets corrupted. It gets weak, right? So it does get affected, but not thoroughly destroyed. Many other algorithms will just simply fail without standardization of data. So all right. So what do you notice when you look at these coefficients? What can you conclude from this? They are rather big. It doesn't make sense. You know, they are each speaking very loudly. Each coefficient is saying, hey, my feature is more important effectively, right? And you can imagine that this leads to wild oscillations. So now look at it. And now I want you to pay attention to what I'm going to say. So now look at it, and now I want you to pay attention to what I'm going to say. Look at it from a geometric perspective. What does it mean? Let's go back to our features, to our errors in the hypothesis or the parameter space. Let us go. This was your error. This was your beta naught, beta one. I'm just making it there, but imagine that this is actually a hyperplane of, what is it, 10 dimensions, let's say, because we are looking at this particular equation of 10 dimension or n dimension. The n parameters are actually, yeah, 10 plus 1, parameters actually 11. no you can't skip it intercept intercept cannot be skipped right n plus one dimension but we won't get into such finities but remember just to recapitulate this is our this plane is our R. Vijay Mohanaraman, Ph.D.: This is our this plane is our. R. Vijay Mohanaraman, Ph.D.: The hypothesis plane hypothesis space every point in this plane represents a value of the beat us isn't it another way to say is to say that every point here. R. Vijay Mohanaraman, Ph.D.: Is a beta vector. R. Vijay Mohanaraman, Ph.D.: Right, it has components and beta vector. Right? It has components, beta 1, and it has a component here, beta 0. Let me just call this point A. This vector has two components. Now, this is just a review of what we have done so far. Now, let me ask you this question and pay attention to it. When I'm saying that the betas, the parameters explode, they become big. What does it mean geometrically? The hypothesis space is big. Imagine that hypothesis space is becoming huge exactly so what it means is that when when you do gradient descent see at this moment the gradient descent made the best point to come to this this is your beta is where your best you know gradient descent takes you to the optimal point beta a but if the cof what it learns the coefficient is large what it means is your optimal point actually let me use a more conventional terminology that people use in this let me call it beta star because that's what people often use, beta star. Beta star for our optimal value, right? The beta star 1, beta star. So your optimal value from gradient descent, right, will become very far from the origin, isn't it? When the components are large, it means the value is far from the origin somewhere in this plane it's not close to the origin and therefore you get your first geometric insight aha this is it has run away the more you add terms the more higher degree of polynomial you do the more you see that your bowl of the error surface bowl it begins to run away from the origin, isn't it? The parameter space begins to get bigger, but it also runs away from the origin, right? So that is a crucial problem. That's a crucial insight. So what can we do? The solution to that is you say, hey, you know what? And we won't run away. We know that the moment it runs away from the origin, it's a disaster. The solutions we get are not. But is the converse true? Suppose we do. We put a constraint. We say you cannot go more than some distance let's call that distance d from the origin so you make a circle around or a sphere around the origin it's a circle in two dimensions but it's a hyper circular sphere in n dimensions in the parameter space you can't go more than that away from the origin right so let me draw this a little bit you say that so this same figure if you look at it i'll just render it without the error function rising about it let's say this is beta naught beta one and obviously when i say beta naught beta one in two dimensions it looks like that but it is actually a 10 dimensional surface or 10 dimensional plane or 11 dimensional plane or whatever it is that you think about it you say you cannot go more than a certain distance d from the origin so that makes a circle you are limited to a circle around the origin and you basically saying, what is the best values of the parameter betas that I can find within this space? Are we two? Now, at each point, you know that there is an error value. There's a net error of the hypothesis. So this thing we ask this is we call this a constraint in the language that people use this is constraint it's a constraint that you put now what's the equation of the circle right let me write this constraint as constraint g beta vector is equal to well beta is not square plus beta 1 square equal to d square yeah is equal to d square right so d is constant right now the same thing and i'll develop this terminology make it more familiar, would you say that this is basically a beta vector dot beta vector right is equal to some constant. d squared is given some constant, so the moment you write your, this is a constraint equation. equation. So you say, so what? Now, how does this relate? You are saying that for each point in here, there is a certain value of the error. Now, let's look at the contours of that figure above, this figure. Let us draw the contours. If you draw the contour surfaces, remember that I draw this contour surface. So this surface will come and fall here. Do you see? The next one comes and meets. I'm just looking at the projection of this equi-error surfaces, you know. On this parabola, would you agree that these lines that I have, these curves that I have, they all represent, because they are the same height from the same height, therefore they represent all points with the same error, all hypotheses which have exactly the same error that curve so when we project it down in this plane these are called the contour surfaces and we are reviewing what we talked about before contour surfaces or contour lines are contour lines. Contour lines. Isn't it? These are contour lines, or contour curves, so call you whatever it is. But visually it is this. Now what we are saying is that, so you see that every line, the more you go out from the optimal center, the more the error, isn't it? Now the statement being made is, what if we say we don't want the global best? What we want is that we are going to limit ourselves to a circle. Let's say a circle. Well, my circle doesn't quite look that much it's a circle and you're saying find me a solution within the circle now let's look at this projected down what it means when I project it to the two dimensional plane so I suppose that circle let me draw it with red line because I drew it with that line there. Let me go here. Oh, sorry. Is that circular enough? Well, this is the quality of my art. We can't help it. killer enough well this is the quality of my art we can't help it right so now look at this thing we have uh well since i used up this space i'll pretend it's on this side if you don't mind i'll just pretend that these yellow curves are this this was your optimal beta it is here it looks it's to be here but actually i could make it here still one second to to be consistent i will move this text somewhere else so let's move this here yes so this is the same as g beta is equal to beta dot beta constant. So now let's look at the yellow lines. They were like, this is the point. These are the contour surfaces, the contour lines, isn't it? These are the contour surfaces, the contour lines, isn't it? And let me make it even bigger. Now, you realize that these contour curves on this plane, this is only in the beta, beta, not beta, one plane hypothesis plane. Now, there's something. There is something very interesting that's happening here. Observe. Let me give this name to the plane. This is the beta star, but let's give a name here. This is that point. This is called A, B, C, D, E, F. Well, let me not use g because that h j so would you agree that the error of a of beta star is less than error on the a curve any point on the a curve error on the A curve, any point on the A curve is less than the error of any point on the B curve, and so forth, is less than any point on the J curve. Would you agree? Because why is this true? This is a very crucial observation, folks. So this is it. If you get this, you will look at this because above each of them is an error surface. Where is the minimum of the ball of the parabola? Parabola here. But as you go to outer and outer, this contour rings, what happens? They represent higher and higher equi error curves in the E-axis. When you look at this higher dimensional space, this plot, right? So that is the realization. So this statement we agree with. And once you reach this point, we have reached a milestone in our journey towards a foundational idea. So would you, and now let me also make one curve touching, which I should have been careful to make. Let me call this curve the P curve, the P contour, right? Now you realize that if you're told that you must find, you're not allowed to go outside the red circle, so then what can you do? You cannot leave this region. This is your region. So it reminds me of a story in the from the Indian Mahabharata, not Mahabharata, Ramayana then there's Lakshman and Sita. And for a whole variety of complex reasons, they're exiled and they live in the forest. They're exiled from their kingdom and they live in the forest. While they're living in the forest, obviously forest has ferocious animals and all sorts of bad characters potentially so when Ram and Lakshman go out I suppose hunting for food or looking for food in the daytime the Sita who stays in the hut in a little hut that they built she needs protection so Lakshman uses his magic because after all he's one of the godly people so he makes a circle around the cottage it is literally called lakshman reka reka means a curve at the line lakshman reka makes that circle and says you are com inside it is enchanted land you're completely safe nothing can come and harm you so he tells sita that you better stay inside the circle inside the lakshman reka you better stay inside the circle, inside the Lakshman Rekha. Sort of, yeah, like an iron dome. And then obviously the whole story of Ramayan gets complicated because then comes the evil Ravan and tempts her to step beyond the Lakshman Rekha and abducts her and war ensues and so many terrible things happen and there's the festival of Dasara coming up in a few days. So this one easy way that I would suggest of you to think of this circle of constraint is just think of it as that story of Lakshman Rekha. It's the safe zone. If you go outside it, your model will start overfitting right you'll start seeing not a good model all the good models are within your constraint region within the lexman ray curve so as if i get it can you just explain the g of beta equal to beta times beta equal to constant that part i didn't somehow lost but that is a very trivial thing see if you have a vector beta so let me go back to the white color suppose you have a vector beta is equal to beta naught or beta naught and so let's look in high school notation you would say a beta 1 j this is your beta vector right remember this is the way you write away right so what is beta dot beta the dot product it is equal to a beta naught square plus a beta 1 square okay and so this is nothing but the thing that you're saying. So you're saying that G of beta is equal to, we realized that it was this, which is nothing but beta dot beta dot product of beta with itself. It's just a vector notation of writing. Right. Okay. That's all it is. And go ahead. So as if you scroll up and in that. Yeah, so these lines here, not the control lines but the lines on the, on the ball. If you go from bottom up, right, the, the errors are increasing there, isn't it? Errors are increasing, yes. Then what you're saying, though, in your equation down there, error for A is less than error for B. Yes, yes. That's the absolute error. The absolute error is less. The sum squared error or the residual error a is less than b is less than c and so forth but we are also saying that while that is true while the residual errors are true we are not allowed to leave the leave your safety region you know the constraint region the circle so what is the best you can do? So you can look- My problem is the statement that you wrote there, error of A is less than B less than C, right? But then if you go up, your minima is at, sort of if you go up there, isn't the minima at A, is thea at a so are you going a b c d upward from in the on that curve let me just write it once again bring the a this is your a b c so forth right so you agree that the error is least right the the error is least, the height of these points is much less than in the parabola, all of these things. You literally see these bands, right? So this could be, let's say, this could be A, this is B, this is C, D, rather error of D, error of C, error of B, error of error of a isn't it you see the relationship now right tanji is that clear yeah yeah that is all we are saying right and i had a quick question yes um so going back to the the diagram at the bottom um when are we looking for the curve that just touches the circle or if that goes like like is there like an optimal curve inside the circle that we have to find yes that is the question so think about it this way if if you pick this curve if you are here look look at where my mouse, are you able to see where my mouse is? Yeah, yeah. If you're here, you are touching the curve J. You know that the error is high. So what are you tempted to do? You'll go to this curve, this location perhaps, right? Here, the error is less. This is H. H contour surface. It's less. So you'll be tempted to go here right which is even less error here is even less and finally you will go to this point this point on the very very periphery of that constrained surface constraint region because you know that the closer you go that is as far as you can go in the direction of beta star do you see that guys that that is the that is the best you can do any other point so at this point if i magnify this point magnify this point here it is like this. And you have constraint surfaces going up, sorry, constraint surfaces, the contour surfaces rather going like this. So this is the constraint surface, you have the contour lines going like this. I'm sorry, the last one was poorly drawn, but okay. Right, so you realize that as you go, the best you can do is this point, right? Let me bring the blue dot. This is the best you can do, because every other point will have more, inside your red region, every other point will have more errors. Does that look obvious now? Isn't it? In other words, here, observe something. What is happening is that, well, I don't have a good circle with me, so forgive me for using a soda can. Right. If these two things were there, they're just touching each other, isn't it? The contour line, the contour surface and the constraint surface, they're round. Well, this is not round, but okay. I wish I had a ball here, but okay. This is a ball. And this is your circle. At these two, they're just touching each other does that make sense guys tangentially touching each other well that is our insight now what happens is the statement is here the beaters are not too big you're within what you're saying is you don't want the absolute best beta beta which would be the beta star far away. Because experience has taught you that during the training process, if you stop, rather than go all the way to absolute beta, stop, stay within a concerned region. The model that you get, right? The parameter models that you get will actually not have overfitting. In other words, the error of the training and the error of the test, the gap will not be so much. You would have regularized, you would have a regularized model. By just geometric obviousness, I think you can see that your coefficients, your parameters have shrunk. They are not blown up. You have deliberately forced them to be small. Isn't it? And here comes a very beautiful bit of mathematics. So we are saying that these two surfaces just touch. Now I will take a small mathematical detour guys it's not very hard. Yes. Yes. Oh, then, of course, there is no problem. There's no problem, but at that point, it's not the tangent, right? At that point, it's a different. That is right. That is right. So see, this is one of the interesting things about regularization. If your budget is quite large and your optimal solution is inside the region, then you don't look at the, then effectively you're not looking for regularization at all. Correct. Right? you're not looking for regularization at all. Come again? I was about to ask the other question, which is the way we have visually represented the problem. Yeah. Beta star is not very far away from what we put as a constraint zone. Right. What if in reality, beta star was quite far away? In reality, it is quite far. So imagine that I have made it look near, but actually it's miles apart. Point of view. Then what we would also end up with, by the choice of how we constrain regularization, we could end up with a solution that is not optimal. That is the idea, yes. For training data, it turns out that choosing is one of the interesting things, even though it looks suboptimal on the training data, but actually when you cross validate or when you run it on the test data, it will turn out to be much better solution. The reason is that BetaStar is listening and optimizing too much on the noise and when you when you stop short see the way the learning happens is first of all the model picks up on the big signal and then smaller smaller and then it starts listening to noise what you're basically saying is i'll stop short so that i'm listening mostly to the signal and not much to the noise like a politician not listening to special interest rules but taking a pulse of the entire country sort of yes just just people yes yes