 I'm about to start recording and all right guys welcome to this workshop introduction to machine learning or introduction to artificial intelligence All right, guys, welcome to this workshop, Introduction to Machine Learning or Introduction to Artificial Intelligence. Now, before I get into the main topic today, I'd like to take about 15 minutes to introduce the basic format of this workshop. So we will meet every, well, your Sunday. And for Californians, some of you i noticed have joined from california for you of course it is saturday late night so we'll meet once a week at about this time we will hold uh up somewhere between six to eight sessions quite likely each session will run anywhere from one and a half hours to on some rare occasions, a little bit longer, we will alternate between theory sessions in which we learn about concepts and code, we will learn to analyze data and see some interesting, make some interesting predictions, do some pattern recognition and so forth. These are the things that you do in machine learning. So while we do this, there are a few ways or a few things to keep, to be aware of. First is all our sessions are recorded. They will be available in the Support Vectors channel of YouTube. I'll invite you to go subscribe to that channel and to watch the video whenever you feel like reviewing it or if you miss something, you can go watch it. Or if you join late, you can again go and start it there each of the sessions will be live broadcast on youtube as this session is being besides that we'll have a weekly quiz that you can take just to check how how well you have understood the material we are covering. At the same time, we'll have a lab. Now, and I will give some examples. Every alternate week, I'll walk you through the code and so forth. And then I'll leave you with a few data sets, a few homework things. It is purely up to you whether you do them or not. What I would suggest is quite upfront you decide on your goals. There are multiple goals that people can have. For example, if you come from the humanities background, arts and humanities and social sciences background, in that case it might be a little bit of a stretch to be able to do all of the programming assignments. So then your goal should be that you understand the theory sessions, you understand the main concepts and you focus on making sure you understand those. And later on, you can cycle back back come back and learn about the labs the programming a little bit later so in other words you can take longer time to get to it or maybe you don't need to get to it you need it because you are in some either management role or you are in marketing or in business and what is more important for you is to understand the broad field of artificial intelligence, not so much to program it. So for that is one goal. The other goal that you can have is to say, no, I want to be able to get started with data science. I should be able to go find a job in data science. Now, surprisingly actually, in the past, I have taken a lot of people through this workshop that you're going through, and they have gone ahead and found jobs in data science field quite successfully, even with the amount of knowledge they picked up here. But these were people who did all the assignments. They did all the labs. The field of data science, or machine learning and AI, as they are variously called, it's a very rich field. And it's, at this moment, an exploding field, which means that from a very practical perspective, it's a new creative field. A lot of companies are looking for people who can do data science, who can do artificial intelligence and so forth. And it is hard to find people. We ourselves have difficulty firing and hiring people into this field. We can find engineers easily, but it is very hard to find data scientists. So a lot of the people who are in my team, they have actually learned pretty much like you would be learning through these workshops. So I hope that gives you some indication of the potential that it has. Now, Kunal will send you an invite to the Slack discussion group. Slack is an engagement or a chat kind of a system that helps you. That's very popular in professional environments. It's not very different from WhatsApp, but it has the concept of channels and different channels under which you can keep different bits of information. You can upload files and when you share code or examples, it gets syntax highlighted and so forth. So it's much more geared for professional work and it is very popular within the technical communities. So we will be using Slack. It's completely free. You do not have to pay. You can install it on your desktop. You can install it on your cell phones and your Tablets. It's quite convenient. Once you join Slack. There is a channel that will have there is a channel that we'll have dedicated only to this workshop. People will be monitoring the channel, so if you have questions, we'll be answering that. At the same time, you folks should try to answer each other's questions too. So that is one aspect. There is also a learning portal to which is at supportvictors.io we'll send you a link to that you can register into that portal once you register into the portal at kunal and there is a page there will be a page for this particular workshop so all of the things the source code the solutions the data sets So all of the things, the source code, the solutions, the data sets, and also links to these video lectures will all be there in one place. So if you miss something, you can go there and get it. So that is how we will proceed. All the announcements we'll make on the Slack channel. So that is about the administrative aspect. Before I get into the actual technical or the topic at hand, would anybody want to ask any questions or any doubts? Anyone here? All right, so if there isn't, I will stop this particular recording and now we'll start with the main thing. So this recording you'll find on YouTube later called administrative stuff on session one. So, this is our first session for the data science workshop. And in particular, this workshop will focus on machine learning or artificial intelligence as it is variously called. Now what is the distinction between these words data science, machine learning, and artificial intelligence? People often use them interchangeably. And if you ask the experts, different experts will give you different answers. It's quite amorphous at this moment, what we mean by data science. But more and more people are gravitating to the belief that data science is using, is the study of data in some sense. Analysis of data, for example, simple analysis like the SQL queries is also data science. Data visualizations, making plots and graphs is data science, as well as machine learning, the topic that we will focus on, is a core part of data science. There is also the term artificial intelligence and one often has this question, what is the relationship with machine learning and artificial intelligence? So I'll start with that first. Artificial intelligence is the broad topic which has within it the theoretical aspects, the core of it, which is machine learning. Then it has robotics, for example, self-driven cars and so forth, the drones and so forth these are robotics your vacuum cleaner if you're using a robotic vacuum cleaner and all those things that's robotics and there were other areas like aspect system aspect export systems and so forth which are there but we will focus primarily on machine learning now while that is a theoretical or academic way of looking at this, quite often people use the word machine learning and AI interchangeably, and that is considered all right. In recent usage, you might also see people sort of abuse the notation in a colloquial way and say that artificial intelligence is one specific area of machine learning that deals with neural networks, deep neural networks. Actually, that is not the way academics would like to hear it. Because academics and generally broadly, we consider artificial intelligence to be the big subject of which machine learning is a part. So today, I'll start with this question. These words that are there, we talk about artificial intelligence, we talk about machine learning. Artificial is a word that we understand, you know, what artificial means, something man-made. Artificial means artifact, the creation of mankind. Then when we come to machine learning, the machine part we understand. We all know what machines are. Machines are usually, for example, things that do repetitive tasks. Machines are again artifacts, they're creations. We create machines. But then there are two words that we should understand. What is intelligence and what is learning? When we speak of artificial intelligence and today people have all these movies and books that came that machines will become artificially intelligent. They will achieve human intelligence or surpass human intelligence. Some people even believe that they have surpassed human intelligence. So what do they mean by that? What is intelligence? And then people say that machines can learn far better than us. So what is learning? And let's spend a couple of minutes trying to understand intelligence, excuse me, and learning. So if I were to ask you guys, just as an open forum question, what is intelligence? Could somebody give me a definition of intelligence? Is for example, a stone on the road intelligent? As for me, intelligence is the ability to understand things and analyze things. How do you know that that stone on the road is not understanding and analyzing quietly? The stone on the road has... It is... Yeah, it is like we have to understand because it has no life, it has no brain. So it cannot analyze that a car is coming on me or somebody will step on me. But we can look at it and we can understand and analyze that whether i will step on it or not that's what i believe that is a good answer would somebody else like to give a different answer apply knowledge and skills apply knowledge and skills see a program that you write when it runs it takes your knowledge you know it is applying your knowledge that you have encoded into it and doing pretty smart things it can tell you what the product of two large numbers is. A calculator can do that. So would you call a calculator intelligent? Or would you call Wikipedia intelligent? Wikipedia is perhaps the largest repository of human knowledge. No, it is a source of information or like yeah it is not intelligence intelligence is with all my sources all my source all my informations I use my information at the right time at the right place yes you get into that so people have in philosophy and in science have asked, what is intelligence? And it starts with common sense often. You know, in school we compare children, which is a terrible thing to do. We should never compare children. But you often say that this child is intelligent and that child is dull. When we say that, what is it that we mean by that? Think in the context of school. When do you call a child not intelligent? Any guesses? Sir, when a child's performance is not up to the mark of the school, then we often refer the child as a dull person and compare it with other children. So the way you do it is you teach the child some things, then you try to see whether the child has learned it or not, and if the child has learned it poorly, you say that the child is dull. early, you say that the child is done. There is something to be careful of. Suppose a child memorizes everything that you have taught and is able to reproduce it. Is that intelligence? No, sir. It is just a mugging, I believe. No, sir. It is memorization, isn't it? So. So, Wikipedia, for example, has a repository of knowledge. Today, we have created systems that have read just about every book mankind ever produced. So, when you ask it a question, it's able to retrieve, dip into that, and produce something that looks like the answer to your question. But you don't call that intelligence. So I would say it this way. Intelligence and people have asked this question for a long time. What is intelligence? Intelligence seems to be first of all, people in the Western world at least thought that intelligence is unique to human beings that animals are not intelligent but it was even more extreme actually people in the western world believed that all all things except for human beings are machines the the animals the cows etc they just respond to instinct and mechanical behavior, programmed behavior. And only human beings are in a true sense living things. They appear to be living, but they are not living. But human beings are living. Fortunately in the East we never had such beliefs. We pretty much grew up with the common sense understanding that all things around us, all creatures, all living organisms are truly living. Then the question comes, are they intelligent? Now, those of you who have ever owned pets know that animals also exhibit a very high degree of intelligence. They have emotions, they have intelligence and so forth. Then you ask this question, so then how do you quantify intelligence? Science studies things by first quantifying it, making some things measurable. Unless you can measure something, it is not yet science. So when people in engineering try to create artificial intelligence, the very first question that comes is, we should be able to quantify intelligence, we should be able to quantify learning. People initially believed that intelligence is the ability to think, that intelligence is the ability to think, to reason. The trouble is nobody knows what thinking truly is. If you just pause for a moment and ask, what is thinking? What is a thought in your mind? Can you quantify it? Can you touch it? Can you measure it? You'll realize that actually we don't have a clue how thoughts arise in our mind. In fact, the entire pursuit of Indian philosophy has been to look at the roots of human thinking and its causations and so forth. But certainly it's not a measurable quantity with instruments. So thinking wouldn't do. The old notions of artificial intelligence was let's create thinking machines. Here in Silicon Valley, there was actually a very famous company that tried to create thinking machines. It was founded by some of you were born, many Nobel laureates came and worked there. And there was a high hope that they would create thinking machines. But those efforts all failed. And then people began to doubt that we can create thinking machines ever. So then they took to a less ambitious approach. They said, all right, can we create machines that can learn? And that brought up the question, what is learning? So I would like to illustrate that with an example. Suppose you take some children that you have in your neighborhood, in your family, you take them to the countryside or a meadow or someplace. Let us say that in that countryside, in that area, in the meadow, there are only two kinds of animals, cows and ducks. So you point to a child and to a cow and you say, well you know my child, that is a cow. Do you see the horns on the head? Do you see how big it is? And do you see the horns on the head do you see how big it is and do you see the swishy tail and four legs and so forth so it's a cow then you go after a little while you encounter another cow and now you tell to that child that this too is a cow because it has horns and it has a because it has horns and it has a certain shape, a certain size and legs and tail. And then you encounter a duck. It has feathers and beak and webbed feet and so forth. And you explain that to a child that these are ducks. After a little while, suppose you ask that child, how would you know, like how would you test the child whether the child has learned the concept of a cow or a duck? Can it recognize a cow or a duck? So you can do one thing, you can go back to the cows you showed and ask again, is that a cow or a duck? And the child may be able to identify. Let's say that you showed the child three cows and four ducks. And you go back and ask the child, look at this. What is this? Is it a cow or a duck? One of two things can happen. Either the child can make mistakes in giving you the answer or the child may correctly identify the cow or the duck now suppose the child correctly identified would it make you feel that the child has learned what a cow is and what a duck is you know the essence of the the if i may use the word, the concept of a cow or the cowness of a cow, if you grasp, then you can recognize cows anywhere, likewise for ducks. So if your child is making mistakes, not able to correctly identify the cow and the duck, you can be pretty sure the child hasn't learned yet. Isn't it it on the other hand if your child does answer those questions what can you conclude now do you conclude that your child now has learned about cows or ducks would you like to make a guess? Anyone? Yes, at least my child can recognize by seeing that this is cow and this is duck. Yes, you would think so. There's a flaw in that reasoning, one subtle flaw. If you go back to the same cows and ducks that you showed the child and you say, what is it? Some children have photographic memories and they can just do a recall. They have a perfect recall. They will just recall that cow or that duck, they'll recognize it. And they will remember that you told them that it is a cow recognize it and they will remember that you told them that it is a cow or it's a duck. So they may give you the perfect answers without actually understanding what a cow or a duck is. They're just recalling it from memory. Do you see that? So how would you truly test whether a child has learnt about cows and ducks. Show them more cows and ducks, like cows will have different colour right? That's right. You show it instances of cows and ducks that the child has not seen. Now each cow is slightly different from other cows. So when the child is able to recognize cows that she has never seen correctly, now you say that the child has grasped the concept of a cow. And so the crucial word that you use is the child is able to generalize from the examples is able to generalize from the examples that you showed to other instances that the child has not seen. The ability to generalize comes when you can get a sense or a concept of the thing, the cow, the duck, isn't it? Because if you don't get get that you won't be able to generalize from that do you see the relationship between generalization and learning yes yeah so learning is the able ability to generalize from instances and not learning is not generalizing from instances and if you go back into your own life you know when you went through schools and colleges you all must have gone through some subjects that you didn't like what did you do when you didn't want to learn about a subject you would pick up in India if I remember right there used to be a tradition of getting the so-called question bank or important questions instead of studying the book you would just memorize the answers to important questions because professors and the teachers they tend to repeat the same question year after year And so you go to the exam and you successfully pass because at least some of the questions in the exam were the ones that are from what you memorized. And so you pass that subject and you forget all about it. That is a classic example of not learning because you went there of course not to learn but to beat the system you didn't want to learn that subject and you move past it i hope you all can identify with an experience like that at some place so that is the distinction memorization is not learning learning is the ability to generalize to form concepts in your mind. So that raises a question that is all right. But how do you quantify learning? And if you go back to the example of a child to whom we are showing cows and ducks, what happens is in the beginning, as you show new instances of cows and ducks, let us say that the child has not understood anything. You show it a cow or a duck, the child will, she will just guess what it is. Now guesses could be, they have a certain error rate, isn't it? You show it an animal and it could get it wrong. It will get it, let's say half the time, it will get the cows, she will confuse a cow to be a duck. And you know, by looking at the number of mistakes the child is making as a parent, as a teacher, you would know that the child hasn't learned. But progressively, as you keep explaining to the child about cows and ducks, gradually that recognition forms, that concept of a cow and duck forms, and the child now is able to, or begins to generalize from the instances to new instances. So then what will you observe? When the child begins to understand what a cow is or what a duck is, you show the child an instance of a new cow. It is likely that the child will make less mistakes. Isn't it? The child may not be perfect yet. She may still make some mistakes. Maybe if you show a cow at a great distance, it will look very small. And the child will say, well, you know, it's small, so it's a duck. There may still be mistakes. But if the number of mistakes the child is making significantly drops, it would be evidence of learning, isn't it? In a very quantitative, in a very measurable way, you would say that the child has learned something. Would you agree? Yes, sir. That is it. And that is the technical definition of learning. Learning is reducing the errors that you make at a given task. For the child, the task was recognizing cows and ducks. In the beginning, the child had a certain error rate. Child was just guessing and getting a lot of mistakes in there. But at the same task, after some time, as the child learns, the error rate goes down. And therefore, you can turn the argument around and say, wherever you see a reduction in error, a gradual decrease of error, you are seeing evidence of learning. That brings us an interesting question. Can machines learn? We spoke about a child, it's a living organism. You ascribe intelligence to human children. But what about machines? Do machines learn? Do animals learn? Those of you who have pets know that animals learn. You teach a dog to fetch the ball for you to do things. People have taught the dogs to do incredible things these days. Their dogs, their cats, their horses and so on and so forth. Now, what about machines? Can machines learn? If you stick to the definition that learning is reduction in error at a given task, it turns out that machines can learn. does the subject of machine learning. It is when you don't program the machine, don't write code and you say, do this, do that, because that is not learning, that is machine following your imperative commands, your commands, your instructions. But on the other hand, when you don't tell the machine, do this, do that, but you give it a framework to learn from data, and it learns in a specific way. You see a reduction in errors at a given task. Then you say that the machine is learning or the machine has learned, and therefore the field of machine learning. Now we associate intelligence today in a very practical term as learning. Machines artificial intelligence is exhibited when machines learn, they improve at a task on their own gradually. As you give it more experience, more data, it improves upon the task. And today, these machines have learned incredible amounts of things. They beat us at chess, they beat us at just about every game. us at just about every game. Long, long ago, they started beating us at calculation. But calculation, you don't need learning. You don't need intelligence. It's a mechanical process. But cognition, our ability to reason, to think, these machines are doing with incredible ability. Today, they can recognize handwriting far better than human beings can. They can recognize voice. they can recognize songs. You just play a little bit of the song and it will immediately recognize which song it is, what the lyrics are and so forth. It is able to translate from one language to many languages in practically real time. So as I am speaking to you at this moment, I could train As I am speaking to you at this moment, I could train a machine and your network to immediately be giving live broadcast of this speech in Hindi, in Tamil, in Kannada, and so forth. This is not a pipe dream. This is actually happening today. Unfortunately, it's not very practical yet to do it in real time. The amount of computing resources you need are far more than what you find on your cell phones, on your smartphones. But the day is near when the smartphones will become powerful enough computationally that you can run those algorithms on these little devices also. But they can certainly be run on big machines with great success. Today, we use machines to do things that human beings can't. They help find terrorists. They find signals that are really deep hidden and we can't, human beings have a great difficulty finding it. Today, for example, we can look at an image of the human eye, the octodon. of your eyes. I don't know if in India they do that or not, but in the US they tend to take these circular pictures, the octodons, and it turns out that for the longest time people just looked into it and they thought this is just telling us whether a person has eye problems or not. Is there any damage to the little parts in the eye, for example, the circulatory blood vessels and so forth, the retina and so forth. Is there any damage to it? And that's what they were being used for. Recently, not so far long ago, people asked the neural network, what can you find in these optodomes? To their great surprise, to everybody's great surprise, actually, the artificial intelligence was able to detect diabetes, heart disease, and a whole variety of disease that people may have just by looking at the optodome. Now, it is not something anybody programmed into the machine to learn. It just came about, came out and found it. That is learning. That is the power of artificial intelligence today. And you see that everywhere. They seem to be able to drive cars almost. It turns out that driving is one of the most complicated activities human beings do. And it's a grand challenge to make the cars be self-driven, especially in the chaotic streets that human beings have. They seem to be driving fairly well, 99 plus percent of the time, when you are on the highway. And in US, as many of you know, on YouTube you'll find videos of people here driving on the highway and they are sleeping in the happens that the driver is completely asleep. They have caught that on tape or they caught that on the cameras and they have posted it on YouTube. It's still a dangerous thing because the machine is not perfect. And when it makes on the rare occasions where it makes mistakes, it is a fairly catastrophic mistake. People die. So it's not a perfect technology. It shouldn't be done. But still, it is quite impressive that the machines have come this close to it. So we are going to learn about this subject of machine learning. This was an introduction. This broad field of machine learning has three areas that we talk about. One is predictive modeling. The word people traditionally used is supervised learning. In supervised learning, you give it a few examples and you say learn from it. For example, this cows and ducks problem, when a machine learns to recognize cows and ducks, then when you give it an instance, in the jargon of machine learning, you say that the machine is predicting whether this animal is a cow or duck in a more practical sense. It's trying to recognize whether it's a cow or duck in a more practical sense it's trying to recognize whether it's a cow or duck that is an example of supervised learning because that could be possible only because you gave it instances of data instances which were labeled where you told that this thing that you're looking at is a cow. This thing that you're looking at is a duck. And so having looked at enough number of examples, it continuously learns and then it learns to recognize. So that is called predictive modeling or supervised learning. Now, another example of supervised learning would be, let us say that you are an entrepreneur and you want to open an ice cream shop. When you try to open an ice cream shop, let's say that you do it next to the beach or next to a river, whatever you want to think someplace where children come and play now you want to determine how much ice cream will sell in a given day because ice creams are perishable goods you can't hold on to ice cream for too long ideally you would want to go to the wholesaler and buy just enough ice cream in bulk quantity as you can sell in a given day on the in your shop on the beach let us say because now the thing is if you buy too much ice cream it will go to waste if you buy too little ice cream you may lose business because you know children will come ask you for ice cream, and you won't have it with you because you are out of it. So you want to predict or guess or estimate the amount of ice cream you'll sell on a given day fairly accurately. But the amount of ice cream that you sell on a given day, depends on multiple factors. It may depend on the temperature. If it is too hot or too cold, children won't come to play. Parents won't bring them there. If it is a working day, less children come to play because parents are busy working. If it is a weekend or holiday, more children come and play. So there are multiple factors that determines how much ice cream you will be able to sell on a given day. It depends on whether your competitor is also there selling ice creams or not, right? And things like that. So there are many, many factors that are involved. But at the end of it, what you're predicting is how much, a quantity, an amount. When you're trying to predict an amount based on certain factors, let's say the temperature, the day of the week, and so forth, this process too is predictive modeling, is supervised learning. The only way you can do that is if you give the machine enough examples that on this day the temperature was this much, it was a Tuesday, and we sold this much ice cream. Somebody has to give a lot of examples to the machine. And then the machine internally finds some pattern in the data, some way, some function, if you imagine a multivariate function such that if you give it the inputs, it will produce an output, which is a pretty good estimate of the amount of ice cream. It says that estimate doesn't have to be perfect. It just has to be a good estimate of the amount of ice cream and that would be solved, right? So it is therefore supervised learning. Now, this kind of supervised learning is for a whole set of historic reasons called regression. The word regression is actually unfortunate. Regress is the opposite of progress. So the word has negative connotation. In software engineering, when people see regression happening in their software, it usually means that the word has negative connotation. In software engineering, when people see regression happening in their software, it usually means that the software has gone from a good state to a much worse state, right? More bugs have been introduced and so forth. But in machine learning for historic reasons, actually predictive modeling, when you're predicting a number it is regression when you're predicting a type it's a cow or duck it is classification the words are classification so i'll write it down in a little bit on the blackboard and it will become then you can remember it these are simple terms and sometimes you don't want to do any of these. What you want to do for example is notice clusters. So what would be an example of clustering? Suppose let me think of example of clustering. See if you go over a balloon for example of clustering. See if you go over a balloon, I don't know if you have or maybe just over through an airplane, if you fly over a city, have you noticed that you see an interesting pattern? Most of the big malls and shopping areas they are in the commercial district. And most of the residential areas they're far out, they form their own clusters, right, they're grouped together. So when machine recognizes such clusters, it notices that in the data, it is not just random, but there is a pattern to it. Certain things go together. That too is learning because it is quite useful. Finding patterns in data is a form of learning. And that form of learning is unsupervised. Usually you don't have to say this is a house, this is a shopping mall or things like that. You just let the, you leave the data there and you ask the computer, do you see any pattern in this data? So that's unsupervised learning. It is also called pattern recognition. You recognize patterns in the data. So that's another form of machine learning. There is a third form of machine learning called reinforcement learning. Reinforcement learning is through carrot and stick. So what you do is you don't tell the machine anything. You ask it to solve a problem, do a task. For example, you ask the machine to play let's say, checkers or chess with you. Every time the machine loses, you penalize the machine. There is a penalty. So it's a carrot and stick sort of appraise. There's a penalty associated with losing and there is a reward associated with winning. And that's all it is. And the machine gradually figures out what moves or what steps cause it to lose and what steps cause it to Win. And it becomes extraordinarily smart about it. So to give you a sense of what machine learning can do when it comes to reinforcement, I would like to give you an example. I'll show you a little video. It's a three, four minute video I want you guys to watch. The reason I mentioned this reinforcement learning video is because in this particular workshop, we won't get time for reinforcement learning. It's a very compacted timeframe. If we are going to do about eight sessions, we won't be able to reach reinforcement learning. Yet it is fascinating enough that I thought I'll give you guys a taste in the first lecture and leave it at that. fascinating enough that I thought I'll give you guys a taste in the first lecture and leave it at that. So, wait a minute for me to pull up that video and show it to you. This video is part of actually a curriculum. It's not a video that I created. It's created by some people who were some researchers and the English is not an Indian English. It's not even American English. It's by a researcher who is not a native speaker of English, just as we are not native speakers of English, a two-minute paper. Let me just find this. And for that, I'm going to share my screen for a moment. So, and let me see if I have shared the sound. Okay, I've shared the sound. So, this is a six minute paper, we need not watch all of it, but watch a part of it. ...see some interesting emergent behaviors. This is Two Minute Papers with Károly Zsolnai-Fehér. Are you guys able to hear the sound? Yes. Yes. Yes. Yes. Yes. A very recent paper. This is Two Minute Papers with Károly Zsolnai-Fehér. In this project, OpenAI built a hide-and-seek game for their AI agents to play. While we look at the exact rules here, I will note that the goal of the project was to pit two AI teams against each other, and hopefully see some interesting emergent behaviors. And boy, did they do some crazy stuff. The coolest part is that the two teams compete against each other, and whenever one team discovers a new strategy, the other one has to adapt. Kind of like an arms race situation, and it also resembles generative adversarial networks a little. And the results are magnificent, amusing, weird. You'll see in a moment. These agents learn from previous experiences, and to the surprise of no one, for the first few million rounds, we start out with pandemonium. Everyone just running around aimlessly. Without proper strategy and semi-random movements, the seekers are favored and hence, win the majority of the games. Nothing to see here. Then, over time, the hiders learned to lock out the seekers by blocking the doors off with these boxes, and started winning consistently. I think the coolest part about this is that the map was deliberately designed by the OpenAI scientists in a way that the hiders can only succeed through collaboration. They cannot win alone, and hence, they are forced to learn to work together. Which they did quite well. But then, something happened. Did you notice this pointy, doorstop-shaped object? Are you thinking what I'm thinking? Well, probably, and not only that, but about 10 million rounds later, the AI also discovered that it can be pushed near a wall and be used as a ramp, and, ta-da! Got em. The seeker started winning more again. So, the ball is now back on the court of the hiders. Can you defend this? If so, how? Well, these resourceful little critters learned that since there is a little time at the start of the game when the seekers are frozen, apparently, during this time, they cannot see them, so why not just sneak out, steal the ramp, and lock it away from them? Absolutely incredible. Look at those happy eyes as they are carrying that ramp. And you think it all ends here? No, no, no. Not even close. It gets weirder. Much weirder. When playing a different map, a seeker has noticed that it can use a ramp to climb on the top of a box, and this happens. Do you think couchsurfing is cool? Give me a break. This is boxsurfing. And the scientists were quite surprised by this move, as this was one of the first cases where the seeker AI seems to have broken the game. What happens here is that the physics system is coded in a way that they are able to move around by exerting force on themselves, but there is no additional check whether they are on the floor or not, because who in their right mind would think about that? As a result, something that shouldn't ever happen, does happen here. And we are still not done yet, this paper just keeps on giving. A few hundred million rounds later, the hiders learned to separate all the ramps from the boxes. Dear Fellow Scholars, this is proper box surfing defense. Then lock down the remaining tools, and build a shelter. Note how well rehearsed and executed this strategy is. There is not a second of time left until the seekers take off. I also love this cheeky move where they set up the shelter right next to the seekers, and I almost feel like they are saying, yeah, see this here? There is not a single thing you can do about it. In a few isolated cases, other interesting behaviors also emerged, for instance, the hiders learned to exploit the physics system and just chucked the ramp away. After that, the seekers go, what? What just happened? But don't despair, and at this point, I would also recommend that you hold on to your papers, because there was also a crazy case where a seeker also learned to abuse a similar physics issue and launch itself exactly onto the top of the hiders. Man, what a paper. This system can be extended and modded for many other tasks too, so expect to see more of these fun experiments in the future. We get to do this for a living, and we are even being paid for this. I can't believe it. In this series, my mission is to Alright guys, I hope you had fun watching that, and that should give you some sense of what artificial intelligence today can do. It is exceeding everyone's expectation. No one expected that artificial intelligence would be so successful to such an extent. Today people are saying that we are going through perhaps the biggest revolution in our lifetime. Most of you are old enough to have seen the internet come about. That was about 25 years ago when it began to get mainstream around the world and websites began to emerge. the world. And websites began to emerge. And we felt that it would change the world. Much of the world came online gradually, there were social discussions, a lot of data was generated, then we went through the world of big data. Because there was so much of data being produced by all these systems. And the big data movement was fairly transformative for example google can search vast quantities of data right there all of these things we can do we were finding cures for diseases by navigating through massive amounts of data that we couldn't think possible and then along the way came artificial intelligence artificial intelligence is actually an older subject machine learning is old if you go back and look at the mythologies in every culture at some point or the other you will find that people you will find that people, man has tried to become God. We notice that people assume that we are the creations of God, and there is a bit of a God complex or God envy that is there in all humanity. So we want to create beings of our own and imbue it with intelligence. The Greek mythologies, you find reference to that. For example, the Hebrew mythology of the Jews, for example, had a concept of golem. You could make a doll and a human figure and you could blow life into it and it would do your bidding. If you think of the story of Aladdin and his magic lamp, and a jinn comes out and does whatever you want, that magic lamp or the creation of something like that is reminiscent of that. It's human desire to create, to build powerful entities that exhibit intelligence. So in every culture you see this desire to create intelligence. Though arguably the first machine ever created or dreamt about, but not successfully implemented, was a person named Charles Babbage. Charles Babbage tried to create a machine in the world where before there were semiconductors or vacuum tubes. So he was thinking in terms of gears of all things. He managed to create a machine but his dream was not to make a computer, his dream was to build artificial intelligence. And the first programming was actually done by a lady, a child of Lord Byron the poet, the British poet, A child of Lord Byron the poet, the British poet, Lovelace, Ada Lovelace, arguably the first programmer in the world, or certainly the first lady programmer in the worldations in the process of breaking the Enigma code. Some of you may have seen this movie, The Imitation Games, and the whole history of the World War Two and how this encryption machines are broken. Alan Turing's main dream was to create artificial intelligence. But for the longest time, artificial intelligence had a checkered history. It was coming and going. People thought there would be great progress, and there would come a winter in which people would give up and lose hope in artificial intelligence or machine learning. And then a few years later, another breakthrough would come, and the subject would move forward. And again, it would get stuck but people always thought that it has very limited use cases it's a very academic field that it will never become practical and then suddenly in the 21st century almost like magic all the pieces came together it turns out that artificial intelligence was waiting for two things to happen. First is the computers were not strong enough, were not powerful enough. And it is only in the 21st century that we have the kind of computing resources needed to have deep machine learning algorithms succeed, complicated machine learning algorithms succeed. The other thing is this complicated, this very powerful machine learning algorithms need a tremendous amount of data and there simply wasn't enough data. If you go back and look at your old statistics books, the kinds of data you encounter, 100 lines of data, 100 rows of data, 1,000 rows of data, and so forth. And people were trying to do something out of it. Today, we live in a world in which if you ask for a billion rows of data, you absolutely don't even think about it. It is there in many situations. So you can make these machines learn from vast quantities of data. And if you guys want a reference, this could be a good homework for this time. Read about something called GPT-2. Actually, let me share my screen. Are you guys seeing something on my screen? You are seeing something on my screen, right? So I will start writing down a few things that we are talking as we talk. And we talked about regression. Regression is a box into which you feed in data. So let's say that you feed in some data. It is a way that finds some relationship of this input. You call this the input. Imagine that this is a box or algorithm. Somehow it produces a number, a real number. Real number is like anything from minus infinity to plus infinity. Something like one point three two is a number is a decimal number. Think of it as a decimal number. That is it. Given an input, it ascribes or it finds an output for it which is a number the other thing is classification you give it some input features let's say that you give it x x here could be a size of an animal the the size whether it has a tail or not beak or not right and so forth etc etc this is your x and it is able to tell cow or duck so it is able to identify based on input, what is it that it is seeing? And when you can do that, that also is some sort of a function, but it classifies. Its job is to classify the input as belonging to, say cow or duck. Now, with these two examples, let's make it more practical. In reality, you don't worry too much about cows and ducks, but it is more like, given this data, is this person diabetic or not? Or more specifically, is this person diabetic or not or more specifically is this yes please go ahead go ahead I can't hear you anymore. You said you had doubt. I'm having difficulty hearing. Are you guys able to hear the question? No, sir. No, actually, she is offline. Hello, sir. Can you hear me now? Yes, I can hear you now. Sorry, sir. Sir, actually, my question is, has you told the input can be anything, right? So like, for example, it can be even the tail of an animal or whatever it is. The output will be the only in that case of numbers. No, no, no, no. I did not say that. I said there are two different things. In the case of regression, one form of machine learning is called regression. When it is regression, the output is always a number. When it is classification, then the output is a type, is an identification. You say it's a cow or a duck. So this machine, you give it some information, it will tell, it will answer. It will either say cow or it will say duck. Are we together it is not producing a number it is telling you a type the type of animal that you are looking at is that clear uh yes sir i got it now thank you that is it so classification is entirely different from regression and so let's make this much more real see usually it's cows and ducks is not what you do in practical life quite often the question would be like this given these medical parameters about a person is this person likely to get diabetes in the next five years or not? Or does this person have diabetes or not? Does this person have lung cancer or not based on this x-ray? And the surprising thing is today we are able to discern problems, medical problems, by looking at x-ray much better than the average radiologist. The doctors who study x-rays and images, the artificial intelligence is able to do better than them. For example, when you take an x-ray of the heart, it's very hard to see subtle problems, you know, clogging and so the heart, it's very hard to see subtle problems, you know, clogging and so forth. But it turns out that artificial intelligence can give you an answer, yes, no. Is there clogging? Yes, no. Things like that. Is there a medical problem with this? Is there heart disease? Yes, no. So it distinguishes this patient has heart disease, this patient does not have heart disease. So that is the power of artificial intelligence. The third form that we talked about was clustering. So, for example, if you have data like this and the data is broken up into situations like this. Just say the data in some plane, XY plane, is given to you like this. What a machine will do is immediately look at this data and without being told, it will go and it will say, hey, these are the clusters. And what you just did is clusters, this guy and this guy are two independent clusters. It's pattern recognition. So this clustering is a form of pattern recognition. Now just to summarize what we learned, I said that machine learning is like this. First machine learning, when we talk about, right, and a measure, a measure or human or person has learned, has learned if and only if it does the task P with better performance. task P with better performance, i.e., error decreases. P decreases, isn't it? The total error decreases. So this is a very simple and scientific definition. Anything, anywhere you look, if you notice that at a given task, gradually the errors decrease when it is being done, you see an exhibition of intelligence, right? So a calculator, however clever it is at doing multiplications, never gets smarter. If it makes mistakes in a certain kind of arithmetic because it can't handle such forms of calculations, that will remain a flaw of the calculator, isn't it? But human beings learn and machine learning algorithms learn. So what you do, how does it differ from programming? In programming, so this is a concept that is important, programming versus learning. See, when you write a lot of code, lots of code is needed as instructions for machines to follow. That is programming. And as you know know much of computer science has been about programming these very dumb machines and when you program a tell the machine how to learn from data, but you give it no instruction, no imperative thing, do this, do this, do this. The only thing is a very high level statement, go learn from this data. And this is how you can learn from the data. You show it how to learn from the data then the subject is machine learning. So when you have machine learning as a subject people often ask don't I need a computer science degree or an engineering degree to enter data science or machine learning? The answer surprisingly is you don't. If you do computer science, you learn programming. You'll become very good at programming and you'll learn all about machines. But that, it turns out, is not... It helps you a little bit with machine learning or data science, but it doesn't help you a lot. Machine learning is a new subject. Data science is a completely new subject and traditionally very little of this was taught in the computer science departments. Now the situation is changing at least in the US they're teaching computer science departments are focusing a lot on machine learning but traditionally it wasn't. Computer science department focused on various aspects of computer science and software engineering and programming but machine learning was actually almost a different subject sitting on the side right but today we are doing machine learning now those of you who have computer science background or have a lot of programming background it might be it isn't that it's a completely lost cause and you're starting a new subject there are still advantages because we will do some basic programming in data science you don't need uh the the sort of traditional programming that people do which requires a lot of code. You instead do very simple programming, but you do a lot of thinking with data. The subject is more about reasoning and thinking with data than it is about programming. The programming here is very short, but still your programming background will help you get started. Now, for those of you who don't have background in machine in data science, this is actually good news. So long as you remember your high school stuff. The subject is very easy to learn. And in fact, I'm hoping that as in the next eight weeks, I'm able to teach you enough that you feel confident, and you're able to make progress on it on your own. So the way we'll run this workshop is we will have one week given to understanding concepts, another week to doing labs in it. And those labs are simple labs, but quickly you'll develop competence or ability to do lots of practical problems, right? And it turns out that in the industry, when you go and do a job, that is all you need. If you're going to do research, then you need more knowledge. Like for example, the subject of artificial intelligence is deep and machine learning is deep. It can take you a long time to master it. I have been doing this now for decades. I still feel that I'm just learning. There is so much more to learn and so much top of it. Every day I'm surprised with some student of mine bringing to my attention some very exciting work that has been done, really important work that has gotten done and that I entirely missed or I wasn't aware of. And I get to learn a lot from my students because of that. So it's a very exciting field, it's rapidly growing, you guys are at a very good stage to enter the field because it's a young field at this moment and it is always good to enter a young field and grow with the field as the field increases and takes over the world. How important is this field? People who know this field well agree that this is perhaps the most profound revolution that we are going through. People say the industrial revolution or the various phases of industrial revolution. You know, first we discovered the steam engine, the mechanical engineering revolution, then came electrical engineering, and then came electronics and all of that, computers and so forth. All of these are phases of the industrial revolutions in some sense. But with the coming in of artificial intelligence, it makes all those things look small. It is a transformative change way bigger than anything that you will have encountered in your lifetime. People who study revolutions in human culture deeply, human civilizations, are saying that this is even more profound than the agricultural revolution that led to the formation of civilizations. There are people who say that its importance may be comparable to the discovery of fire or the invention of the wheel in human history. It is that profound. It's going to transform life as we know it completely. Your children will not even be able to imagine what your life is like by the time they come. So this revolution is happening very, very fast and knowledge is expanding very fast. To give you a metric, more breakthroughs are happening in artificial intelligence in the last two years than in the entire history of human knowledge. Just think about it for a moment, that more research in AI has been done in the last two years than ever since people have been dreaming of creating artificial intelligence for thousands of years. continuing every time you think wow this is so fast and so fascinating the next year is even more an even faster pace of development so it is it's very very exciting times to get into now today's session was a very general session in in future we won't have sessions this general or this broad. We will have more specific topics. We will do code. We will talk about it. But I thought I'll leave you today with the understanding that machine learning and AI, at the end of it, it comes down to one simple thing. You need a task to form the context you need some way to measure the error and then you need to teach the machine some way to make make less mistakes and then when it does make less mistakes it builds a model it creates a concept in its mind. And you say that the machine has learned. I will end with one question. How do you know that the machine has learned correctly, that it has found the right model? It's a question that you often ask when you're doing math, for example. You need to have a correct solution. So when a machine makes a prediction about something how do you know that the machine is making good prediction correct predictions would somebody like to take a guess at that when the code is correct trial and error possibly but you know the space of trial is so vast that the universe might die before you exhaust all the cases so when the coding is correct coding no because you don't program the machine at all you just ask the machine to learn from data that's the whole point that this is not programming this is learning this that depends on the results sir it depends on the results yes so what happens is when it makes prediction it will it will never make perfect predictions and the reason it won't make perfect predictions is there there will always be noise in the data it won't make perfect predictions is there there'll always be noise in the data so imagine that you're measuring temperature five different thermometers will measure five close to each other but different values for the same for the temperature on a given day even if you measure it exactly the same place and the same time five instruments will have five different readings measure it exactly the same place and the same time, five instruments will have five different readings. So now if you say that, which one is correct? You don't know, there's no answer to that. You said that there are five versions of the truth, right? So there are errors in all measurement. Not only that, when you build a model based on certain factors, you don't have all information. Machine learning is the ability to build models to conceptualize in the absence of complete information. So for example, if you ask this question that suppose you throw a stone in the air and then where will it fall? Now you need to know the velocity, you need to know the angle at which it was thrown, and so on and so forth. So many things you know, but there are things that you don't know. For example, at that moment, how strong is the breeze? So when the data was gathered, how strong was the breeze? Because the breeze is going to drift the stone a little bit from its trajectory. So it would have fallen at some place without the breeze, and with the breeze it has now shifted its position. And so you don't know that. And because you don't even measure that, all you measured is the angle at which it was thrown and the speed at which it was thrown. And you use only two factors to build your model, it will never make perfect predictions because there are things your model doesn't know, but that affects the results. And that will always be true. So you build the best model that you can. And so in this field, there is a famous statement that goes to a great scientist named Box. His name was quite literally Box. He said, a landmark statement, he said that all models are wrong, but some are useful. What it means is you'll never get a correct model. There is no definition of correct in science. But there is a definition of usefulness in science. And this is broader. It's not just machine learning. See, when you learn science in schools or college, it seems as though we know everything. We are told that Newton's law of gravitation is true, right? And you do little experiments in which you drop stones or you swing a pendulum and things like that. And then they all seem to agree with Newton's laws of gravitation, right? And so on and so forth. And so you take it as the correct law. But actually, as you go and do research you realize that there is no such thing as a correct law newton's law actually happens to be wrong it is superseded by einstein's law of gravitation the general theory of relativity because space-time contractions and space-time deformations affect the attraction that one object has for another, which is gravity. And so now you say, well, okay, now we know that Newton is wrong, but Einstein's equation is the correct equation. That is how most people talk, but actually that's not how a serious scientist would say a serious scientist would say einstein's a theory of relativity gives you much better predictions than newton's theory of gravity gives for a large number of situations in fact it newton ein Einstein's theory of relativity makes predictions that so far have never been contradicted, never been shown to be wrong. But it doesn't mean that it is correct, therefore. It just means that it is a good, effective theory. It works. It is effective. Those of you who are, if there's anybody here who's a physicist, would probably know that, we know for sure actually that the Einstein's theory of relativity cannot be correct. It completely disagrees with quantum physics. And quantum physics itself cannot be correct because it disagrees with Einstein's theory of relativity. We know that both these theories, they're correct in their own way, but both of them cannot be correct. And so quite likely both of them are wrong, but we haven't figured out what the right theory of nature is. So a flavor of that applies to machine learning and things like that. Machine learning, data science is science. It's like any other science. And in science, you don't ask for the correct answer. You ask for effective answers, answers that are effective in making good predictions, theories that make good predictions. So the models are theories. These are models about how things work. And you know that the model is effective by observing that it makes pretty good predictions. And that is something to bear in mind, that there is no end to making better and better models. But the question is, where do you stop? Where you stop making better models depends upon practical realities. You're able to tell that a patient is likely to have a heart disease or not by looking at the optoderm or the image of the eye of a patient. And yes, your error rate is one in a million person. One in a million person you get wrong. one in a million person one in a million person you get wrong would you consider your model wrong it is wrong but is it a useful model it is a tremendously useful model because it far exceeds what human beings could do or it far exceeds what previous models could do. And so it is of great practical use and of efficacy. You can use it for real things. And that is something to bear in mind whenever we do machine learning. We are not in the pursuit of the right answer or the truth. In fact, in science, you don't use the word truth with a capital T because a thing can be disproved but theories can never be proved. It's very interesting. In mathematics a theorem can be proved which is derived from certain axioms. In nature you can build an effective model, a theory. Now one single experiment can disprove a theory, but a million experiments producing results that agrees with the theory does not prove a theory. Nothing is proven ever in science to be correct. Things are only disproved in science And that is an important thing to bear in mind as we keep doing our machine learning and all of these things. In fact, the only place that I hear people talk about truth is when people get and philosophy, they have truth with a capital T. But outside those domains, which are in my view, very non scientific domains, you never speak of correct answers or truth with a capital T, but you ask for what is practical, what is effective, and you know, what moves the needle of knowledge forward. So that's that. So all right guys, today I will stop here. I did not introduce the machinery of machine learning. I wanted to stop right here, but I would like to recommend you a textbook for a moment. This textbook is a little bit academic. It's a little heavy reading. Don't get that textbook. It's freely available. Those of you who like to buy paper books, you can order a paper copy of the book, but it is actually legally and freely available on the internet, which is why I recommend this also. It is an excellent textbook. So I'm going to end today with that textbook today. So are you guys looking at my screen? Yes. Yes. So there is a textbook called ISLR. If you do that, ISLR, you'll see the picture and you will get this page. Let me increase the size so that you can see it. Are you guys able to see this? The cover of this textbook? So this textbook is freely available. It's written by two professors and two graduate students. The professors are Hesti and Tebseerani. Hesti and Tebseerani happened to be in a college, in a university near my house, close by. The university's name is Stanford University. Some of you may know about Stanford. It's a Californian university here in Silicon Valley. It's a pretty good university, one of the best actually. And so these two are very well known professors of this field. It's a very well written book. And these two when this book was written, these two were the graduate students, but they they now, I believe both of them are professors and the independent in their own right, or assistant professors. Daniela Witten, actually, for those of you who are physicists, perhaps, if you're any, Daniela Witten happens to be the field of theoretical physics as the brightest living mind at this moment. So anyway, this book is very good. It's unlike most books, you know, which are written quickly and have a lot of errors. It's not like that. It's a very well written book. You can download the PDF free. And when you get the PDF, you when you start reading it, you will realize that there is a it's very well written, but it's also something that can occasionally feel a little scary. So I would suggest do this. Today, just go and read chapter chapter one and try to just glance through chapter two read chapter two is okay if you don't understand half the things because as we make progress with this workshop these things will become easy to understand i've taken generations of students through this textbook and at the end of it they all find it very easy so you will also find it very easy so please get this book and try to read chapter one and chapter two okay all right guys so with that i will stop the session and I will take questions. Before I take questions, I'll pause the recording or stop the recording. Again, as I said, today was a very high level conversation just to ease you into the subject. But as we go into future sessions it will get a little more technical and we'll start doing things with practical things any questions guys did you find this useful or interesting, any one of you? Yes, sir, it's very useful and interesting. And I understand it in simple things. Good. I don't hear many more questions. So if there are no questions, then I'll close the session. Otherwise, Kunal, are there questions? Actually, I have a question about sir. I'm on the side here. It's a little hard to understand what the... also i'm sorry i can't make out what you're saying maybe you can type it in the chat and Kunal will tell me what you're saying. It's hard to hear what you're saying. And you can- Sir, there is one question from Shrikant KJ. He's asking is the, in the upcoming lab session, are we going to use Python for programming? Yes, we will use Python python and so python is a simple language but even as a language it can be intimidating actually for people who are who don't have programming background the good news is we don't need all of python we just need the very very basic aspects of python so it would really help you if you pick up the basics. Don't go and pick up a big book on Python and start reading it from end to end, but pick up some basic tutorial on Python. Like as in, if you give just three to four hours picking up Python, that is more than enough when it comes to our labs. So do get started picking up Python from that perspective. No programming background may take it longer, give it a day. But in a day you would know more Python than we will need. So I have a question. Yes, go ahead. Sir, can you give us basic information from where we can learn Python easy, easy as well? See, there are two ways of learning that. One, go to Udemy or Coursera. In Coursera, there is a course called Python for Everyone. And then in Udemy also, there are a couple of Python courses. The trouble is they teach you so slowly that it needs something like weeks before you finish a Python class. And in my view, they go too slowly. You waste a lot of time. But on the other hand, if you are scared of programming or you are encountering programming for the very first time then you like that course you like the fact that it goes so slow you may want to get started for this workshop if you do it along with this workshop side it is perfectly okay the faster way is just go and pick up on the internet. There are many basic tutorials on Python. Just pick up the basics. What is a variable? What is a function? Right? And that is it. That's all we need. Learn the if else and for loops. You won't need anything beyond these three, four things, because that's all that we will use. You don't need all beyond these three, four things, because that's all that we will use. You don't need all the esoteric aspects of Python or how to use Python to do web scraping or how to do object oriented Python or any of those things, you won't need that. You would need only the very basics of the language. So those are the two. Also, you can get a textbook of Python. Those of you who are still remember what paper textbooks look like and the younger generation seems to know it less and less or want to read it less and less. But if you are of the type who likes to read books, get yourself a basic Python book. There are many. They're all good. And it's just such a simple language, especially considering that you don't have to learn all the language. Maybe the first two, three chapters and that's it. So you have to just give it one day of your life and you will learn it. But the only tip I'll give you to learning Python is don't just read a book like a novel. For everything you learn, sit on the computer and do it. Install Python. And so I would suggest those of you, actually in the next session, that's what we will do. I will guide you through installing the Python and everything on your laptop. So next time when we meet, do make sure that you through installing the python and everything on your laptop so next time when we meet do make sure that you come with your laptops but go to this website anaconda.org this website hang on let me see if you can see this anaconda.org anaconda and there you'll see a download button here and when you download it it will just say your data science toolkit just download it and when you download it just click on it and it will install a python and everything you need to do data science that's it it's a one-click install think of it as just an application that will bring it up are we together guys yes thank you so much actually actually sir i wanted to know this like from where i should download this morning i was going through as i thought i will just have a basic idea before we started what is it so it was asking us to download from different sources i wanted to know like which is the right source to download so we can download and the book you suggested yeah the book you suggested an intro to uh statistical learning i believe we can read one or two chapters and maybe next time we'll be with more questions just read the first two chapters and there are parts of it which you won't understand. That is all right. Because as we make progress with the course, all of those things will begin to look easy. Okay, thank you. Any other questions guys? So remember whatever we said, one last thing I wanted to show you. If you go now to the Support Vectors YouTube channel, let's go and see whether it is there or not. Do you see live? Remember we said, one last thing I wanted to show you, if you go, you literally see it there, right? This is what we were showing a little while ago. Everything is here. The entire lecture is already there. You can go and review the sessions by going to this. So all our sessions will be there available on the YouTube channel. And everyone please who are attending this, go and subscribe their channel oh yes that would be good so then you you will get notified every time there's a news a new video there that we post anything else guys otherwise I'll close the session also can you show them how to restore on support vectors what are you mr. that is true that is a worthwhile thing so if you go here let me go there because it remembers me I left a boy in an incognito mode if you go toctors.io, you can go here and do you see there's a button here called create new account? Go and create a new account for yourself. And you can either actually, I would suggest that instead of creating an account directly here, you could just do login using Google. And when you log in using Google, what will happen is it will take you through the whole process of creating a new account and so forth. So all of you do go create an account for yourself. You won't, it will say, send you an email for confirmation. You may or may not receive it. Actually, the email system at this moment on the site is a bit broken, but I will see your name waiting for confirmation and I will confirm your membership to this. But once you do that, what it means is, like, for example, it means that I will just log in myself. Once you log in, you will see something like this. At the very top, you'll see your courses that you're registered to. So this is ML100. If you go there, you will see some notes and some things. You'll see some material. This is, right? You'll see some material. This is from the previous time I gave this class. So that material can be useful. But just about everything we do now, it will show up here, right? The videos and everything. And if you want to know what things we are going to cover, all those things, you'll start seeing it here. All right? start seeing it here all right anything else guys all right have a nice day same do so you, sir. Thank you, sir. Thank you. Thank you, sir. Thank you, sir. See you next Sunday. Thank you. Thank you, sir.