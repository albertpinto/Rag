 Good. And I need to go copy the link and share it. Here it is. Those of you who are watching it on YouTube, that is the link. Now I need to... Alright guys, I'm going to start recording now. This is Saturday, December 19th. We have gathered here to cover the quizzes. There are two quizzes, word embeddingding and the other is on anomaly detection. The second thing on the agenda is project review. So our situation currently is that word embedding has a majority of the people who have taken the quiz. So it makes sense to cover that. I am a little hesitant to cover the anomaly detection quiz if by the time we get done with the first part of the quiz, the first quiz review, we reach a majority then we'll cover that also. Otherwise let's wait a little bit and we'll certainly cover the project reviews. That's our plan today today so I'm going to share my screen biology are you here biology can I please use your solutions as the review point for the embedding right embedding yes you know very well what I'm asking you. Yeah, I mean, it's just the embedding quiz, right? This one I just started taking, sorry. Just finish it, then I'll use this of yours too. All right, guys, so this is the word embeddings quiz. This quiz was staggered in such a way to help you decide that are you is do you have clarity in word embeddings? Word embeddings, we think of it as a simple topic, you know, ultimately, what is it find a lower dimensional latent representation and more efficient representation of the words in the corpus so on the face of it it looks very simple but there are subtleties and there are trade-offs between one kind of word embedding versus the other and so forth so in words, it's a subfield in its own right. So given the fact that we all know what word embeddings are, then the only purpose of a quiz is to see whether you have enough clarity on the fundamentals of it. And so I made the quiz in such a way that there was negative marking. The purpose is if you get zero or below, you should then come to the conclusion, not that you don't know word embeddings, but that your understanding is a little bit blurry. The optics is not very sharp at this moment. So what you need to do is go back and review your understanding and make sure that you have got the finer details also. And those finer details sort of matter. So as I work our way through this quiz, do pay attention to the questions and the solutions. But more than that, look at your score. Obviously, you know your own scores and make a judgment call. If you're getting a lower score, it doesn't mean that you don't know word embeddings. It means that you lack clarity at this moment. And clarity is important to this thing. All right, guys. So the first question was, word embeddings create a lower dimensional representation of the words in the vocabulary by studying their co-occurrences and proximities in a corpus of documents. So remember that all of NLP is done with reference to a, with a corpus. The corpus is sort of the universal set of documents that you use to train a neural network on, an NLP model on. And a document is a more abstract thing. It could be a sentence, it could be a paragraph, it could be truly a file, the whole text in a file. So we use the word document in NLP in a more specific sense. And it, it sort of differs from the colloquial use of the word document in popular language. Then we also use the word sentence. Now, once again, when we use sentence in NLP, we don't quite literally mean the English grammatical sentence or grammatically full sentence in other languages. A sentence could be many things in this space. You could, for example, define a paragraph as a sentence. You could define part of a clause, one clause as a sentence and so on and so forth. It is some logical unit of words, combination of words is a sentence and so on and so forth. It is some logical unit of words, combination of words is a sentence. So that is a distinction to bear in mind to distinguish the words that we use in NLP and how they are subtly different from the use of the same words in colloquial usage. So now is this statement true? The word embeddings create a lower dimensional presentation. Yes,, is this statement true? The word embedding create a lower dimensional representation? Yes, it is true. As you remember, we often start with, let's say, one hot encoding. And one hot encoding of words can lead to a vector space that is 300,000 or 100,000. Or you can pick your number, sometimes a million or 3 million, big, you can pick pick how big a purpose and how many unique words you have when hot and cooling create very large vocabulary for you so then you're reducing from this ginormous vector space. Raja Ayyanar? Which doesn't contain any relationship because every word is orthogonal to every other word. any relationship because every word is orthogonal to every other word in that original input vector space. The point is to find another vector space, a latent representation, which is sort of more semantically rich, where the relationships of words are more reasonably well captured as vector arithmetic. To be in other words, two words that are reasonably similar or imply similar things or adjacent things, they should be represented with vectors that are fairly adjacent in the vector space. They shouldn't be orthogonal to each other. So when you consider it like that, and then you go about creating all sorts of algorithms to build the word embeddings. Now in all of these word embeddings, we use specific methods. We'll talk about that in the next questions and so forth. But in general, this statement is true. How do you find the relationship between words? You study the co-occurrences. So you see how often one word occurs closer, close to another, given a certain window, a context window. Let's say you take a context window of 10 words or 11 words or three words, whatever it is, three to the right, three to the left, and so forth. And you see what words sort of tend to be in the neighborhood of a word. The implication being that the meaning of a word can be essentially captured by studying its neighbors, by studying the company that a word keeps in the entire corpus. So from that, this statement is true. I believe most of you got this one right. Second question was, to create lower dimensional word embeddings, GloVe, GloVe words, global vector, uses, this is one of the algorithms of word embedding we covered, uses the global word-word co-occurrence matrix and its factorization to generate lower dimensional approximate representation. Unlike Word2Vec, it does not utilize a local sliding context window around the words. So obviously the way I worded it deceptively, I was sort of tempting you to fall for true and most of you did. Actually that's not true. The GLURV is unique because it forms a bridge between two different kinds of approaches. There are approaches that use the context window, let's say word2vec, and there were approaches that simply used global co-occurrence matrix factorization. In a way, GLOBE bridges the gap, and it says that we will look at co-occurrences within a certain context window. But that co-occurrence, now we will look at sort of a more global structure or you will do something slightly similar to matrix factorization, but not quite that. Remember we worked out the the probability ratios, right? Xij over X sum over Xik over all possible values of k, where xi's are the probabilities of co-occurrences and so forth. So I wouldn't go into the GloVe detail, but it does utilize context window. If you look at the original paper that is there for GloVe, If you look at the original paper that is there for GRUB, in the very first paragraph, it makes the strong point. First few paragraph, it makes this. Actually in the abstract, it makes a point. So moving forward, which of these algorithms uses word pieces instead of words in generating the word embeddings? So this is a matter of knowing. Remember, this is just going back to the lecture notes and seeing what I said. Fast text, the way it differs from a word to work is it's nothing but word to work, except that you don't use word, you use word pieces. That is a distinguishing feature. From a broad essential perspective is a big failure. Next question, did I already cover three? I believe so. Yeah, the fourth question is, which of these can be used to create context sensitive word embeddings? Sesame Street, Word2Vec using Skip Grams, Glove, Elmo, Word2Vec using continuous bag of words. It seems that Sesame Street had no takers. So none of you fell for that. But almost quite a few, almost most of you got this answer right. You got it as Elmo ELMO was the first, the research paper of ELMO specifically says that we can create context aware word embeddings, or contextualized word embeddings. And those contextualized word embeddings are superior. The word apple to the farmer is different from the word apple to computer people. I think Kate used the word stand. So is it to stand somebody, tolerate? Is it to have a music stand? Or is it that you stand up? So words take on meanings contextually and ELMO used, if you remember, bidirectional LSTM to achieve that. We did not go into the details of ELMO used, if you remember, if you remember, bidirectional LSTM to achieve that. We did not go into the details of ELMO. We just left it at saying, we did go a little bit, very little bit, but when we were covering the BERT paper, then we did that. So those of you who attended the Saturday, I mean the Sunday research paper readings, so I took you folks through the whole thing of how a bird relates to ELMO and so forth. So this is it. It is ELMO. And what does ELMO internally comprise of? So this was something that obviously only people who attended the Sunday research paper reading would be able to answer, or if you have read the paper on your own or something. So it was essentially an invitation to go read about ELMO on your own if you haven't. And so ELMO, the important thing is that ELMO does not use attention. It predates attention. The breakthrough and all of that came afterwards. I mean, actually it doesn't predate attention, but it doesn't use attention. Actually, I take it back. It doesn't. Attention was done in 2014, but yes, it wasn't used in this. It uses a bidirectional LSTM followed by feedforward and then all the feedforwards culminate into the softmax and so forth, the usual stuff. So that's what it was. Bidirectionality is important, but remember the context to the right and the left. You have to be aware of both. Next question. Any questions by the way? You guys are all quiet. Is there any confusion so far? Then we'll move forward. So I say what is the single directional mean that option there? A simple LSTM is one directional. So unless you lay two LSTMs together, one reading the sentences, the sequence forward, and one reading the sequence backward, you won't get a bidirectional LSTM. A typical LSTM takes a sequence of something, right? So generally the implication is that if you're feeding it a sentence, you would feed it first word first, then second, the third and fourth fourth and the last word last but when you do a bi-directional lm what you are doing is when you give it it will read the the whole sequence backward and forward it will read it first to last and then from last to first. Okay. That's by direction LSTM. Next question, did I cover this question? Which of these algorithms for generating word embeddings does not employ a classifier in the training? So for this, of course, you had to know a little bit about each of them. Do you remember that in Word2Vec, we have a softmax, right? At the end, you do have a softmax, if you remember. And what do you do? You do a dot product of that softmax and so on and so forth. So you very much have a classifier at the end of it. You don't quite use it like that, but okay, for what it is worth. Glove does not have that. Glove just works off the probabilities, global probabilities. Glove would, and I hope if you go back and see the details of my explaining the glove, it will become clear. Glove, Word2Vec and Fast Text are trained with? Well, this is a question with supervised learning, statistical methods alone, well that's not true, you do use a neural net, with semi-supervised learning, with reinforcement learning, with unsupervised. So the answer is unsupervised. Now, why is it unsupervised? Since there is no training, no label data, and we are simply searching for lower dimensional embedding. This is a classic example of unsupervised learning. So the correct answer is with unsupervised learning. So this brings me to one more point. See, when people talk about this, the whole thing is not watertight. Sometimes you find some other researcher will reinterpret it and say, oh, well, you know, word embeddings are self-supervised learning, right? Or something like that, right? Creating a word embedding, you create a word and then you predict its context and so on and so forth. So you often see that there's a little bit of a fuzziness and sometimes people will with great confidence say it is this and then then somebody else would say, well, no, maybe it's that. But the majority will more or less say it is unsupervised learning. But the point that I made long, long ago that these methods, on the face of it, look very simple. If you have labels, it is supervised learning. If you don't have labels, it's unsupervised learning. Now think about word embeddings. Do we have labels? Well, the context of a word, maybe the label, if you're doing the skip gram, or the context maybe the input in the word itself is the label, if you're doing the continuous bag of words approach. But these are all words within the context window. You have no real honest label data. So it gets a little bit more nuanced, but people generally broadly still call it unsupervised learning go ahead yeah this one is I'm not very crystal clear I mean there's some clarity but it's not very crystal clear at least for me and this is not the only question I made this mistake here I think in the other quiz also where you have similar question I made the same mistake. I noticed I noticed that. And my point here the way I was thinking here is you know I know the output in the learning in a training part right when I'm training the model I know the output and I'm comparing with the output so if it's not still you know technically labeled I'm still knowing the output that I should do. And you hit, you're arguing it correctly, but see, if you really think about it, you are predicting something. For example, in the skip gram, you're taking a word and hoping that all the context words will light up in the softmax. And you know those words, they are in effect the labels for that input right but and this is the the whole part you and you train it as a classifier class i mean when you do that whole thing you you create the data and you use negative sampling and all that you use a classifier classifier is essentially a supervised learning algorithm. But those are the people say, oh, those are the internal details. From a business perspective, you didn't ask me for label data. You just asked me for data. You just asked me for corpus. Therefore it is unsupervised. You internally happen to chop it up into two pieces, a context window and do it. But externally, you didn't ask me for label data. So broadly speaking, people still call it unsupervised learning. But it again, goes to the point of making that sometimes, you know, as the world gets, as we get into more interesting stuff, this whole thing gets a little blurry, which one to take. So generally one thing I would say is take the answer which makes sense from an outside functional perspective, not from the inner detail implementation perspective. Generally people tend to converge around such answers. Even in that case, Asif, in the training part, right, isn't that, you take the data, but essentially don't you label what is the outcome here that you are comparing with? No, you don't label. You don't label. There are no labels there. All you have is a corpus of lots of documents. orpahs of lots of documents. Okay. Thanks for the clarification. That was a good question. In other words, you have a giant collection of... Now, which of these uses a single one direction? Go ahead. Yeah, so can you explain the difference between like self supervised and like supervised learning? In supervised learning, you need a label. Yeah. In self supervised learning, the input is also the label. The ground truth Y is the same as X, the input. As if that's applicable for the autoencoders and so on. That is true, autoenc is that's that does that clarify uh no still yeah i'm not getting that intuition um okay uh let me draw it out also i said if you can just uh when you say um the output is labeled if you can clarify that also let me do that label if you can clarify that also let me do that oh this is our paper from last week let me create anomalies this let's create one more all right so are you guys seeing my writing board yes see what happens is when you get data you may get data as x vector right and xi and now the question is y i right so the distinctions are this unsuper the unsupervised from this perspective, you have just xi, right? Which is equivalent to saying you have xi and you have null. No labels, right? Each of the data items comes with no label whatsoever. Then you have supervised, wise, super, am I writing it right? Supervised, you truly have xi, yi, right? Xi, yi, where explicitly yi, it is not equal to null. Are we together? And very explicitly, this is a must. yi label must exist label must exist and be specified in training data. Right. On this point, then the novelty detection, would you clearly classify that as supervised then? No, no. Hold your thought. We're coming to that. So let me let me itemize that and we'll think through this. All right. Then comes an interesting case. Self-supervised. And so see these two, there is broadly a consensus. Everybody agrees what these two words mean. All right, things get fuzzy in the next two things, self-supervised and semi-supervised. That's where the vocabulary, this dichotomy begins to lose that watertight clarity that one is supposed to have have self-supervised in my view so is it like an entanglement kind of a thing X I and the output is X I this is very peculiar in other words which is the same as saying X I Y I saying xi yi, right, where yi is equal to xi. When the input and the output are exactly the same, the label is the input, then you have self-supervised. So in other words, you're trying to predict yourself, right? But what is non trivial about it, you can just transfer the input to the output. The reason the non triviality comes because you don't give it enough memory. You create a bottleneck and the system is forced to discover latent representation and efficient latent representation right and then obviously we're talking of auto encoders and then you look at the reconstruction loss and then there is semi-supervised in semi-supervised what you do is you have there are multiple meanings that i have seen of semi supervised and by the way this is i'm speaking from experience. If somebody has authoritative definition somewhere, and I have seen like conflicting authoritative definitions, but just in case somebody believes that there is truly one correct way, just let me know. In semi-supervised, many fuzzy meanings. many fuzzy meanings. For example, it may include any one of the following, including A, just the self-supervised itself. Some people don't use the word self-supervised and they will just use the word semi-supervised. A B, only some data is self-supervised and they will just use the word semi-supervised. B, only some data is labeled. You have a situation where you have xi, yi, where yi can belong to, let us say that it can belong to, let us say that it can belong to, maybe, null. You see that some values are labeled and some are not. This is one another way of interpreting it. And the third way that people interpret is the training people interpret is the training uses only one class of the target y category of values. So for example, in the case of anomaly detection, it was very straightforward. What are the two categories? For anomaly Category is normal. And now, so you can say that, or let me write it in a more intuitive manner. Why? Whatever the value of y is, y must belong to this. This is the category or the set, right? This is your, usually you represent it with a G. This is your set of possible values. But what you do is, in here, you only train the novelty detector with normal. The set of such data where this condition is fulfilled. Right? IE, which is equivalent to saying that Xi, Yi, set of all training data where y i is equal to normal it has only specifically this value so are we are we getting a sense guys so now let's review what we are saying um for unsupervised do we have a clarity guys when we, can you include example also of the- Of unsupervised. So for example, okay, hang on. Our clustering, dimensionality reduction. These are, these things, if you remember in ML 100 100 we did, specifically if you did ML 100, this is chapter 10 of your textbook, the ISLR textbook we did, right. Examples of this are clustering, not classification classification actually i'm handled up the spelling completely classification and regression right these are examples of whenever you're doing classification or regression, you are doing supervised learning. Right. What is an example of self-supervised learning? You just encountered that. It is autoencoder, variational autoencoder. Yeah, variational autoencoder is one classic one. And autoencoders in general. then what is semi-supervised learning many examples so for example novelty detector would be like i just took the example novelty detector is that but now there are other meanings also so some authors some writers in they will call self-supervised as semi-supervised and also they'll be fuzzy about this then sometimes if they feed if they have only some label data not all data is labeled and they are training on that they would still call it semi-supervised learning right so there is a little bit of a fluidity on what people mean by semi-supervised learning they can mean any one of these three things uh do we have clarity now guys yeah as if can you go to the bottom uh to the last row can you scroll here? What specifically are you looking for? I was looking at the what's the criteria. So the input is the normal data. Right. So that's that. Should we move forward now guys? Any other questions? Okay, let's move forward. Thanks, sir. See guys, that's the value of quizzes and reviews of the quizzes. And if you do the quizzes and then we review it, your understanding sharpens. Likewise, guys, that's the biggest value from this workshop, maybe at the end, when we review the projects, because you learn a lot in seeing how you did it and how it could have been done, alternate ways that it could have been done. So do the project guys. So we did this. Word2vec utilizes the factorization of the global word-word co-occurrence matrix to create a lower dimensional approximation as word embeddings. It is false. In fact, Word2vec explicitly uses just a local approach. Remember a context window. It does not use any global information at all. So the moment you see the word global, you should have run away from it. Given, and of course there is no matrix factorization happening here, given a context window around any word in the corpus, in skip-gram word-to-word, the input is the word itself and expects the output preferentially point to the other words in the context window. Or more colloquially speaking, when you give it a word, you expect that the softmax lights up the bulbs around or lights up the nodes around all the words that form the context of this word in the context window. All other words in the context window, right? That's how Skipgram works. In which of these algorithms is negative sampling used to train the word embeddings? This is, again, Skipgram word to reckon. Because you have to train a classifier. So you know that the word X existed with word Y, but it did not exist with the word pizza or something like that, right? So you have to create negative sampling that was there in our lectures. Please do review that. Given a context window around any word in the corpus, in CBOR, continuous bag of words, word2vec, the input to the neural network is, here it is the context in other words the context of window all the words in the context window and what is the output of course the word itself given so these words in the input uh additively you want to find the output word the the actual word that they surround so the the way to look at continuous bag of word is that, what do the, which word do these words surround? Okay, that is that. And that is it, a very simple quiz of what is it? 10 questions or 12 questions? 12 questions, yes, and you did very well Balaji. I trust by now you have finished the other one. No, actually, if you can see the timing for the last one I started. It's and I finished on Wednesday, the other session actually, I'm running in a similar timeline because I didn't attend the last Monday lecture. So I'm reviewing the YouTube. You don't have to review. By the way, review from the formal cleaned out lecture. It has already been posted. I'll remove all the live videos now. By the way, guys, if you review a video and you like it, you like the explanation there, do give it a thumbs up. I would like to know how many of the lectures you like. That's one way for me to know. If you like a particular one while reviewing, give it a thumbs up. If you hated it, give it a thumbs up. it a thumbs up if you hated it give it a thumbs up um i see one question not on this but on the anomaly detection um so how can you like under what condition you can create like uh a detector which is both outlier as well as a novelty see the point is, there is no distinction between the two. They are both anomalies. The question is, while you're training, do you choose to include the anomalies and say, figure out what is normal and what is anomalous, which is cheaper or a little bit more expensive route. You say, hey, you know what? I know that at least this part of the data is completely normal. So go realize a representation of normal and anything that doesn't agree with your definition of normal will be an anomaly. So end result is the same, they both detect anomalies. The subtle difference that some people use and many people don't make that bigger distinction, they will often call the novelty-based approach a semi-supervised learning, and they won't use the word novelty detector at all. Actually, these days I don't find that many people use the word novelty detector. Some do. Mostly they just say we trained it using semi-supervised learning. Whereas the former method is completely unsupervised. Outlier detection, giving you the whole data and say, go figure out what is normal and what is not. What the anomalies are, or outliers are. That is unsupervised. Okay, so for outlier detector, you're saying that it includes the normal plus the anomalies. Anomalies. Okay. And so give me a moment guys, I'm going to, I just unshared my screen to protect your privacy. I am going to now see if we have reached majority but if just one more person finishes it we might reach do you guys want to give people time to finish it or should we review it today itself i said we should give time because this is a very good quiz and then i think reviewing it will clear a lot of doubts so i should give time isn't it i believe so okay all right so then we'll do it next week so as if did we do the auto encoders review i I believe we did that, isn't it? Anybody? Anybody remembers if we did the autoencoders review? I do remember doing that. I don't think so. Oh, we didn't review the autoencoders. I don't think we did. Okay. No, then it means that that too has, let me see how many, oh, that has now reached majority by just one person. So I'll be happy to do that if nobody else is going to take it. Let me see, I'll pick the highest score person, 12. So let me pick one high score person. And that would be, Kate. Can I use your Sure. or maybe Okay, I'll just I can see what I got wrong. I don't, it's all right. Okay. Thank you. So let me share that. Before I do that, let me break up the video, stop this recording. That way we'll have two separate reviews, one for Word2Vec and one for AutoEncoder. So I'm going to start the review again. Let's take a five minutes break, guys. And then let's drink some water, etc. Then we'll start the next one. Good idea. so okay okay so so okay so so yes yes so Thank you. Thank you. so Thank you. all right guys i'll be back. Ah, yes. Okay, nice. So I'll start the recording again. This is Saturday noon. We are of December 19th. We are going to review the quiz on autoencoders. And this also seems to have 12 questions. Let's go through those questions. This is of course the famous picture that is used in all image processing. All your textbooks will have it. It's sort of iconic. For some reason, the field decided that this would be the picture to use for seeing the effect of different algorithms and so forth. So it's called the Lena. And I believe it was first taken from Playboy. Consider the original image on the left, the famous and widely used Lenhar image in the world of image processing. As an input to a denoising autoencoder, some noise has been added to the image. Observe the image on the right. Observing the image on the right, we that specifically salted pepper noise was added so how would you know i'll zoom in for you that's why i put a relatively high resolution picture here look here the way to tell is you look at this noise, for example, look at the cheeks here. And you look at the noise on the cheek. Are those noise black and white in color? I had to see more pictures to understand that. I'm sorry, you need to see more. Well, I had to go look at pictures of the type of noise because I didn't Oh, right. understand salt and pepper until a little deeper into the quiz and looking up some images of noise examples. Yes. And so in fact, I don't believe I covered salt and pepper noise. It was something for you to see this question, go read and you did that, which is very nice. So we noticed that the noise is not black and white. It's not that some pictures have been completely turned on and some have been completely turned off. Right. So it is not. The answer simply is. Oh, sorry. Yeah. So it should be false. The correct answer is false. And I think you didn't get many wrong, but this one you got wrong. So training of the autoencoders is an illustration of reinforcement learning, unsupervised learning, learning by memorization, and supervised learning. Now notice that I didn't give you a choice, self-supervised learning. If I had given you the choice, self-supervised learning, then that would have been your best choice. But given the fact that I did not give you the choice, and as I said, some people consider it to be unsupervised learning. So it is unsupervised learning that you could choose. And there was a subtlety here because, as you notice that in the subsequent quiz, I throw in the word self-supervised and it is just to make you familiar with the different words, different sort of a perspective that different people take on this. And, sort of a perspective that different people take on this. And the next one, the loss function of a sparse autoencoder has an additional penalty term. Now what is that sparse autoencoder? Remember it is and it forces many of the notes in the latent representation to be effectively switched off. I spoke about it very briefly in the class. I was hoping that once you see this question, you will go and read up a little bit more. How many of you went and read up a little bit more on sparse autoencoders? Oh, I go look up a lot of stuff during the quizzes. Oh, I go look up a lot of stuff during the quizzes. Nice. So sparse autoencoders are overcomplete encoders. They don't have a bottleneck. They actually have more nodes in the latent layer than in the input layer or the output layer. But the point is, you would say, then what's the whole point? It will just copy the input to the output. You prevent that from happening by forcing many of the nodes in the latent layer to be effectively switched off. That's the point. And it's a form of regularization in some sense. An underlying assumption about training a denoising autoencoder is that, what's an underlying assumption of denoising autoencoder is that, what's an underlying assumption of denoising autoencoder? The correction of the input must be the noise of an isotropic Gaussian distribution. Now, we don't say that. We don't require that. It could be salt and pepper. The correction of the input must be the noise of a uniform distribution. No, it could be a Gaussian or salt and pepper. The latent representation is robust and stable with respect to minor perturbations in the input. And that is the whole point with autoencoders. See autoencoders are great when they work. Training them has always been a bit problematic because they can lead to unstable instability in the in the representation and which is why you need to put in things to make them more sort of a robust so when you train a denoising autoencoder and for example one reason that variational autoencoders were considered a breakthrough is generally a Generally, a Bayesian reasoning is a very strong sort of a built-in regularization in the Bayesian argument itself, in the Bayesian inference itself. And so it prevents that instability overfitting. So when you use a denoising autoencoder, for example, with variational, you get a stability. But no matter which autoencoder you you use the main point is the latent representation must be stable so in other words a picture and its noise should have essentially the same latent representation then only you will be able to produce a cleaned out picture do you see that guys so in the latent space they should map to the same value. Small perturbation shouldn't affect that, or noise shouldn't affect that. Any questions there? In training an autoencoder, one hopes that it will learn an effective latent space representations of the data. Of course, that's the whole point of an autoencoder. Practically, practically its definition. Next question is when we use an under complete autoencoder, so what's an under complete autoencoder? It's an encoder which has a bottleneck, right? Less nodes in the hidden layer, latent, than in the input or output layer. So which of these is true? The latent representation has fewer nodes in the input layer. That's it. The other ones is the same or more is not correct. Overcomplete autoencoders, i.e. autoencoders which have more nodes in the latent representation layer than the input layer are rather useless since the autoencoder will always learn the identity function and transfer the input straight to the output no matter how you train. And so the trick wasn't the last phrase, no matter how you train. The point is over-complete autoencoders are very effective, for example, in generating sparse representations and so forth. So you can use some regularization in training. And that will make it very useful. It will prevent the system from just transferring the input to the output. And therefore, you can use over and you do use over complete autoencoders. You just have to remember to have a very strong regularizing argument somewhere what's the example of application of this as far as representation but paradoxically to create a sparse representation of a sparse representation is what let's say that suppose it's a 10 dimensional representation, a vector. So you can say that only any one of the three dimensions will light up, will have non-zero values, seven dimensions will have zero values. That's a sparse representation of a point. Yeah. What's the application though? Where would we use that? Where would we use a sparse representation? That is a good question. Actually, off the top of my head, I can't immediately think of a place. I used to know a few examples. I don't know. At this moment it's escaping me. Maybe in a few minutes as we make progress the moment i recollect i'll tell you oh you look at this this is now if you look carefully at this what is the nature of those uh noise can you tell it is clearly black and white isn't it definitely salt and pepper Definitely salt and pepper. Definitely salt and pepper. Classic signature of a salt and pepper. And consider the noise that was added to the image while training a denoising autoencoder, and the resulting image that became the input to the autoencoder is shown below. By observing the image, we can conclude that the added noise is salt and pepper. What was the other noise three noises are pretty commonly used one is just uniform noise and if you look at the code sample that i created for denoising autoencoder i think i don't know did i use the uniform or the gaussian one of the two i use the other is is the Gaussian bell curve noise, right? Small, you know, centered around zero. Lots of small noises, very few big noises, you know, big big shifts. And salt and pepper is extreme. There is no small noise. It's all big noise, either black or white, right? So is the opposite of the Gaussian is the salt and pepper. You got that, Sanjay? Yeah. Yeah. So Gaussians will shake it a little bit most of the time and a little more a fewer of the times. Salt and pepper will be just extreme. So, of course, sparse autoencoders use an overcomplete representation. It was a simple straightforward one. Next question. Actually, I think there is a typo here. It's a contractive, not contrastive. A contractive autoencoder aims to learn a latent representation of the input that is robust to slight perturbations of the input. So how is this different, for example, from a denoising autoencoder? Do you guys remember? Anybody remembers? We talked about the contrast, contractive autoencoders and I give you the math of it. If you remember, we use the gradient of the Jacobian, the squared gradient of the Jacobian or the gradient of the Jacobian, a dot product with itself. You add that as a regularization term in the loss function. So something that you probably forgot but that's that if you go back and look at the knowledge you'll see it there next question consider the vanilla version of the auto encoder see often i use the word the vanilla or the direct version what it means is the auto encoders is a whole subfield now. People have created so many variations and subtle changes to the autoencoders that you almost feel compelled to use the word vanilla version when you mean the simple, you know, the way you learn it first before you throw in everybody's own special variation. Consider the vanilla version of the autoencoder which reproduces uh guys please hold on a sec I'm getting a call from my PG&E you All right guys, this was PG&E saying that we may lose power for four hours in this neighborhood so just in case this meeting abruptly finishes we we want consider the vanilla version of the autoencoder which reproduces the input in the output and learns a latent representation of a lower dimension than the input let xi be an input and xi prime be the corresponding autoencoder output then the loss function can be written as well this is just remembering the loss function there's nothing magical here this is reconstruction loss so you compare a thing with its oh there's a type I don't know why I became cap bold but xi minus xi prime squared. What are the other choices I put here? Here the square is missing, here KL divergence has been put, none of the above, and this is cross entropy loss, certainly not that. So obviously, if you know the very basics of autoencoder, this is your last one. Most of you got that right. Then last question, variational autoencoders are generative models. Of course, what do you learn internally? You learn a Gaussian representation, low dimensional Gaussian or latent Gaussian representation of the input. And when you have done that, now you can go on generating as much data as you want by sampling from the Gaussian representation. So that's the beauty of the variational autoencoder. Well, that's the beauty of the variational autoencoder. Well guys, that's that. Any questions on this? Any one of these questions? Otherwise I'll stop the recording. So go ahead, Kate. What kind of winter weather?