 So I'll take a couple of minutes and kick off. First and foremost thing, good morning, good afternoon, good evening, depends on which time zone you're attending from. We have folks from across the world, as I could gather. Thank you for joining and we appreciate the interest. This is going to be a RCEF-led session. I'm not going to say instructor-led session. So as we just wanted to give a couple of quick administrative things, please turn off your video. That will make the other people's stream go better. So I appreciate if you could turn off your video and put yourself on mute. I'll continue to try to see if I can control if somebody is unmuting. I don't think I can, but if you can put yourself on mute, that'll be great. We will not be taking any questions during this session. As you can see, we have 88 people in the call. So we want to make sure that this session is not interrupted much. Knowing Asif for, you know, several months, almost a year, I know once Asif gets the mic, you are going to be blown with the amount of information that you will learn, and the session is going to be extremely productive. Last but not the least, the follow-up to this course we will announce soon. That's going to be a longer session, and it's going to be much more hands-on. That being said, turning the floor to Dr. Asif Kumar. Please take it over. Thank you, Madhu. So, Madhu, I made you the host again. And welcome everyone to this session on Generative AI. This is a four session small series in which we are going to delve into this world that is pretty much dominated design. Yes, there's a lot of exuberance about generative AI. It almost seems too good to be true. What is it? Does it really have all the potential that people are ascribing to it? Is it hype? What part of it is hype? What part of it is real? And what can we make out of it? What does it mean to us in day to day life? These are the questions we're going to answer. Now in this audience, there are a lot of you who come from a leadership background there are people who come from technical background and i will try to address as far as i can to the questions that both of you may have in your mind so we will start let me start by sharing my screen and give me a moment, please. Coming up. Are you focusing the screen which says Generative AI? Yeah. So a little bit about me and about us. I have been in two parallel tracks. One is academic and one is industry. After graduate school, I've been in the industry. I've worked for NASA, for CBU, for Oracle, and for Cornerstone and startups and many things. And I've been the chief architect for the better part of almost one and a half decade in companies. At the same time, and had leadership positions, I just left my previous job as senior vice president. While I've been doing all of this, I've also had a parallel academic track. Through graduate school, I realized that teaching was something that I absolutely loved. And so I've also been teaching various topics in computer science and artificial intelligence now for the better part of three decades. So as I talk, if you do notice that I get into a bit of an academic mode, pull me out. I apologize for that. I'd like to keep this session very interactive and very much about what can we do. So this is it. This today is Generative AI. when why where what is it the basic coordinates of this big big topic that is on everyone's mind generative ai it is hard these days to open a newspaper or to watch a news item on the video without encountering this term so now the way we will do this for sessions, you will see that I move back and forth between a slide deck, slides, and some playing around with some websites and examples, and handwriting. You would literally see me write on the blackboard to explain some of the concepts. But today, we'll keep the concepts to the minimum and just talk about some broad topics so a little bit about this we keep calling ourselves the Sherpas on your journey as you learn this topic of generative AI even though it's only for four sessions look at us look at me as a person who's helping you understand this difficult topic. So do not hesitate to stop me. Now I'm going to just for a little bit tell you about this organization that we have. We translate leading edge research into our products. We have been doing it for a very, very long time. If you, any one of you want to know more about me or what I do, do reach out. But for now, we'll move on with this. Now, this topic of generative AI has AI built in. Artificial intelligence is something that has been a millennial aspiration of humanity for thousands of years. We have references in ancient Greek mythology of intelligent robots. We have references in Hebrew literature of the so-called golem that can be created. And it comes with appropriate warning that if you create a golem, an artificial being, then it is attended with great danger. Something that we are only beginning to realize that artificial intelligence today is not a complete blessing. It comes with its own dangers. It can wreak havoc in society. It can do harm to, it can be used by malicious actors for all sorts of inappropriate purposes. sorts of inappropriate purposes. But it is also something that is definitely going to transform life as we know it. We are in the midst of a very cataclysmic change in societal structure. For better or for worse, we'll all see, but it is happening. It is happening as we speak. So there's a lot of history that I wouldn't go into, but we will talk a little bit about what is generative AI. And somewhere around generative AI, you often hear this big phrase, attention is all you need. It sort of has become like a mantra that gets talked about quite a bit as a starting point. But actually generative AI has been there for a very long time what its impact is on the industry since today's introductory topic we'll touch upon that can I interrupt real quick would you it sounds like the sound is not really clear so if you could come to yeah perfect is it better now that's much better thank you okay so i apologize for that so we need to talk about what is it doing to the industry and to society in general we'll talk about who is advancing and who's thinking who are some of the people who are forward-looking and today in this perhaps includes all of us. Out of the 7 billion human beings I would imagine, at least a couple of billion are actively engaged with generative AI in some form or the other. It has touched every aspect of society, every aspect of life at this moment. So AI itself has been around for a long time. It has been there since the 1950s. And in the beginning, it was used for things like playing chess or solving mathematical problems. It seems remote from practical life. The roots go even further back. It goes to the mathematician Carl Frederick Goss, who created the first so-called learning approach and the least square method and I suppose regression as a method started with him but that's a long history. What I would like to talk about today is just focus on generative AI. When we talk of generative AI it almost seems as though it is something that got generated in 2023. It not like that it's been there for a long long time it started in the 1980s with so-called recurrent neural networks those recurring neural networks were a particular neural architecture or a AI system that could actually generate new words that could write a few uh if you prompted it enough it could translate english into let's say french or vice versa it could do all sorts of things it could condense paragraphs it could generate text and things like that so uh in in machine learning there are two essentially broad classes of one One, what is the data? The discriminative algorithms are like classifiers and regresses. An example of that would be you're looking at an animal and you need to create an AI system that can tell what animal is it. Is it a cat? Is it a dog? Is it a horse? And when you create a system like that, what it, the way mathematicians say is that given all the parameters, what is the probability that it's a cat? What's the probability that it's a dog? And if you could do those probabilities, then you pick the most probable thing. And that is what you predicted to be. So that is discriminative learning or discriminative algorithm. Likewise, if you have a, let's say that you have a young entrepreneur with an ice cream shack on the beach and the entrepreneur is trying to predict how much ice cream would sell today that prediction is important to the entrepreneur because the entrepreneur needs to decide how much ice cream to purchase in the morning from the wholesaler then that model that they are using they're predicting an amount of ice cream that the entrepreneur would sell on a given day that too is a discriminative model or discriminative algorithm why because based on the weather conditions before whether it's a work day or not whether it's a warm day on the beach or not whether the surfs are rising high and many parameters wind speed etc etc the entrepreneur is trying to estimate how much ice cream would be sold it's predicting a number based on the facts. These are discriminative models, and they have been around for a very, very long time. Generative models, too, it turns out, have been around for a very long time, though they haven't been getting as much attention. A part of the reason was that their uses did not impact our lives in so dramatic a way. But over the years, over the decades, gradually, their real life impact has been increasing. It has been progressively getting closer and closer to having a dominant role in our lives as much as the discriminated models we have. So recurrent neural networks were used initially for language translation. And as you remember, a decade ago, when you would try to do translation from one language to another, it was at best an imperfect, imperfect thing. Sometimes all you could do with that translation is get some sense of what it must have been in the original language. In fact, it was very common for the young researchers to entertain themselves just by using a translator to translate something in one language to the other, seeing how funny it sounds or how funny it came across and having a pretty good laugh at it. But things have improved dramatically since then. In the mid 1980s came something called the Boltzmann machine and the restricted Boltzmann machine. These were perhaps the first generative neural architectures. I won't go into what they come from, but there's a few who have a background in material science or physics, just for you to know. It is based on statistical physics models and icing model. precursor or the always generalization with the so-called energy-based models which are still which have gained renewed interest since the since 2010 in the last decade perhaps then along the way came the long short term memory one of the problems with recurring new networks was that if you give them a long passage to translate they would remember the more recent things better and what you give it initially it can it used to forget and people tried to remedy this with this complicated thing called lstm with quite a decent degree of success so those were generated you could generate text from that you could generate translations from that, you could generate translations from that, summaries from that, and so forth. And they were perhaps the first practical models in relatively widespread use. Then around 2013 came something called the variational autoencoders. Variational autoencoders are interesting machines. They tried to look at the input data and say, what if this data actually could be represented in a much more meaningful latent space? And in that space you could understand its structure better. And then from there you could decode it. So you encode it to a more meaningful latent space, and from there you decode it but when you do it you impose impose a sort of a necessarily a probability distribution called bell curve a bell cover gaussian like distribution and while it gets technical and i won't go into it one of his first consequences is was that it could do pretty good generative it could generate data for example you it would generate people's faces people who didn't exist at all it could do that then around 2014 came the generative adversarial network with a very interesting history uh it was playing it played upon the fact that and this was this is the one algorithm I'll talk a little bit more in depth today, because it really caught people's imagination. If you look at the history of generative AI, people really woke up to generative AI with the GANs, with the generative adversarial networks. So it is an interplay between two adversaries. Think of it as a cop and a counterfeiter, a generator and a discriminator. And the interplay between them and each trying to play an adversarial game and getting better and better, led to a generator, a counterfeiter that could generate very plausible counterfeits and that led to the rise of fakes or the so-called deep fakes we will see in a few examples that it can generate very realistic fakes and those fakes are not all harmful they're often of good value for example GANs can produce data and generate very useful and valuable data in a variety of circumstances they can be used to do neural style transfer so for example monet and van gogh are gone but if you want your house and your landscape to be rendered in the style of money and van gogh generative adversarial networks are at your service they'll do a amazingly amazingly accurate job of repainting your landscape in the style of whichever artist you like monet van gogh picasso you name it so all of these things are going along the way also around 2016. as you can see from 2010, things began to really heat up in the generative AI landscape. 2016 saw the birth of normalized flows, another class of generative models that are quite important these days. But then I guess the really big breakthrough that changed the world in very profound ways, and more profound ways than the previous models. It was the coming in and the discovery of the transformer architecture. Transformer architecture came pretty much the paper that announced the transformer, or today what you call the large language models. And ChatGPT is an example of that. It started around Christmas time around December of 2017 with a landmark paper called Attention is All You Need. This paper created it was it was initially meant to be a sequence to sequence model, something that would encode an input and then create a latent representation. Excuse me. And then decode that latent or the abstract representation into whatever you wanted it. So what does that mean? You could take text, you could encode it and then choose to decode it it in another language, or decode it into poetry, or decode it into a summary, or decode it into, sort of, if it is a prompt, decode it into a narrative, and so on and so forth. So that was the transformer that was announced in, that was first showed up in the literature in 2017 with the landmark paper attention is only that led to a vast explosion transformers would take over the world quite in a very very literal sense ai would not be especially in natural language processing would not be the same ever again. People knew that the world had changed. As a quick follow-up came the visual transformers, and those visual transformers did something amazing. They reformulated images, videos, etc., also as a vocabulary, as a form of, as a language, a visual language, audio language a visual language audio as a visual language and so you could apply this generative thing the transformer especially its decoder part to generate all sorts of things not just generate new text as stories as poems as answers to your questions but as new pictures, new videos, new audio, music generation. It seemed, today it seems hard to imagine that transformers would not solve whatever problem that you're thinking of. They seem to be doing extremely well. They seem to be taking almost all the exams, like, for example, SAT and whatnot, and the law exam and the medical exam and they seem to be acing it and doing extraordinarily well they can generate answers to the toughest problems and of course this hardly needs being spoken of because we have all been since November of last year we have all been playing with things like chat GPT and bard and a cloud from anthropic and so forth. And those of you who are technically savvy have also been downloading and playing with your own open source models. Lama 2, now Mistrail is the latest, and Rukuna, and so on and so forth. And there are almost two parallel tracks, one of commercial models and one the initiative from the open source. And what we are looking at in 2023 is quite literally a generative AI Cambrian explosion. So just to explosion. So just to wet your recollection, we use the term Cambrian explosion in evolution to refer to that era when all of a sudden on earth, a wide variety of life forms, a wide variety of species began to surface. Suddenly there were so many, many, many new species of life on earth. there were so many many many new species of life on earth and that was the cambrian explosion and what is happening today in 2023 especially in the space of generative ai can be likened to its own cambrian explosion moment in AI. It is hard to keep up. I feel, I try to read at least one paper a day and sometimes two, and yet I don't feel that I'm able to catch up. Things are moving so very fast. And these are not just trivial additions, great ideas, very creative things are imaging are emerging at a very very relentless pace right and and it feels it does feel like a Cambrian explosion so this is the world we are in and this is the journey which I would like to take you folks through. It's a very interesting journey, but today we'll keep it at a fairly high level. And see, so just a little bit, you'll notice that I'll talk a little bit tangentially because some of you are leadership people with management. And the question that you are asking is, what does it all mean to us in the enterprise? So every once in a while, you'll see me sprinkle a few practical facts. So, for example, the global market here for AI is booming. It is anticipated that it will cross nearly 100 billion. And it is already 100 billion, billion actually it will increase by 20 folds and people are projecting all sorts of numbers 1 trillion 2 trillion 3 trillion no one really knows all we know is life as we know it is going to undergo radical changes it is undergoing radical changes if you look look around you, everywhere, I just happened to purchase something as simple as a video camera and I noticed it has AI built in. Today, whether you know it or not, even your smartphones, have you noticed that the pictures that you take with your smartphones look much better than when you look at yourself in the mirror? your smartphones look much better than when you look at yourself in the mirror. And that itself is a gift of computational photography and a bit of generative stuff is going on everywhere. So we live in a world in which it is hard to tell where generative AI is not, not making its inroads. And yet, as you look at this generative AI, there is the fun part, there's a part and the theory part, the things that you do in the lab, the things that you get impressed with, and then the things that you do to take it to enterprise scale. Some of you who are wondering, how do I take all of this and adopt it in my enterprise? What does it mean for me? So there, it's a long journey actually, to go from theory to an enterprise-scale robust and high performance architecture. And this journey is quite complicated actually. If you look at an AI-centered enterprise, it is not just a few very good models, it is quite a few things you need data infrastructure and because ai is very very data hungry if you were to ask this question why has all this development happened now and why did it not happen before why for example did it not happen in the 1990s? The answer can be summed up in two statements, data and hardware. A lot of these algorithms in one form or the other did exist. They have been evolving. These algorithms have been going through pretty steady evolution. Nonetheless, 20 years, 30 years ago, we didn't have enough data. And we did not have enough hardware at all. The amount of hardware that these things need AI needs is just phenomenal. It's almost like we today, for example, if the chat, these GPT models, and these large language models, they're supposed to be close to, let's say, 250 billion, 500 billion, or a trillion parameter model. On the horizon already are rumored to be 10 trillion parameter models. of i don't know how much how much validity to put that in as as soon as 2024 we may see the arrival of 100 trillion parameter models i don't know how true that is but 10 trillion does seem very plausible and it's around the corner so we are talking about vast hardware infrastructure at the same time vast data infrastructure if you look at these models and you ask, what did it take to train them? It is almost like you took a baby and you put all the knowledge of the humanity through it. You put the child to learn from all that we know, all that we have created, all the videos, all the audios, all the text, everything that you can imagine seems to be finding their way into teaching these ai models so that you need and therefore there's a vast data infrastructure that comes into play you need ml platforms when you do things at this scale you need to have a methodical platform and a process the analogs process it also brings about a lot of people who are involved, stakeholders, people who do, and people who are at the receiving end of the impact. It brings up ethical questions and frankly interpretability questions. Do we trust a machine because it says so and we don't know why it says what it says right why would we trust its predictions so interpretability or explainability is becoming a dominant thing in the enterprise and of course analytics and visualizations of the predictions of the models have been a crucial thing so i just brought this picture here to show you that the actual world under the covers, the technical world is pretty complex. It has a lot of moving pieces and entirely different subcultures. There's the culture of the tribal culture of the data scientists and AI and the mathematicians who are busy creating better and better algorithms there is the tribal culture of the data engineers in the day and the computer scientists and the platform architects who are busy making robust scalable architectures and there is the tribal culture of the systems engineers and the devops and the mlops people who are trying their best to make sure that all of these things actually can run at scale and at high performance and robustly and securely and so forth. So there is a vast, vast amount of engineering that goes to make any one of these things possible. And I won't talk much about it, but just for a moment, I'll talk about all the things that it involves. You have to take in the data from very disparate sources from relational tables from the web scraping the web from all the textbooks that are available in the open domain from legal documents from health documents from forms and whatnot and all and while you're at it even synthetic data generation in fact you use generative ai to generate data to teach again the ai models and it all goes in there you ingest the data clean it validate it transform it rationalize it make head and tail out of it then you do all sorts of experiments to train the model to teach to build something of value from it and then you have this whole world of deploying the models and taking them to production and at the end of it at the end of this vast was journey comes out things that we take for granted for example the Google search and not many of us want to think what tremendous amount of AI has gone behind it or for example chat GPT or any one of the things or when you go to stable diffusion or mid journey and things like that it takes all of these things take a vast amount of infrastructure your social media your Facebook and things when you get tagged in pictures automatically there is a lot of and things when you get tagged in pictures automatically there is a lot of infrastructure in fact mind-bogglingly large amount of infrastructure whatever you whatever you may guess i bet you the infrastructure behind these things is probably at least a hundred times whatever your guess was it takes that much to bring about these very intuitive, very necessary services to make. So today I'll take this generative AI with examples. Let's not go too much into the technicalities but just stick to examples. What can it do? What can we do with it? So you look at this person and it looks like the person we know, I would imagine, but at this person this too doesn't exist and I'll refresh this page this too doesn't exist now if you look at these people I don't know if you can tell that these are not real people anybody has a comment or anybody feels this is completely fake and not real people. Anybody has a comment or anybody feels this is completely fake and not real or it looks like a cartoon. To me, it looks very realistic, though, if you really are good at it. And if you look very, very carefully, you might be able to find some artifacts that may give you a clue that this is perhaps not a genuine person. But it takes a specialist to even and even they are not sure that AI has become really that good at this particular moment. Right. And we can keep changing. None of these people that you are looking at on the screen actually exist so it is uh perhaps you're familiar with this and this is a deep fake but what i'm showing you today with with this and you may it is often called a deep fake but it isn't just with this you can do that with um music you can do that with um uh videos you can do that with writing you you can generate passages that look very Shakespearean, but don't exist. Oh, sorry, I apologize for this. It seems to have some. The other example that I would like to take is of drug discovery. When you look at the effort that goes to discover a single drug, if you talk to a pharma company and you ask, why is this very simple medicine, this tablet or this injection, why is this tablet worth $400? Or why is this injection if you those of you who have are familiar with oncology of cancer and so forth, know that these days, the prices of those drugs have become unbelievable, they have too many extra zeros associated with them. I'm told that there are drugs that cost $50,000 per injection, sometimes $100,000. And I also hear, and I don't know how credible that is, somebody once told me that there are medicines that cost hundreds of thousands of dollars per dosage. Why is that? The answer usually given is, oh, because it takes us a decade to discover a drug. And it takes an army of scientists and a vast amount of resources to go through the whole process of discovering the drug making sure it is safe that it actually works and then bringing it to market and amongst the issues that was there was a millennial problem that was there was a millennial problem. People who did protein folding proteins, what happens is that whenever you have drugs, you have to ask which part of your DNA or the protein that is exposed and what will it touch upon and what will be the value of this particular drug and so on and so forth. So there's a whole field called proteinonomics. So in that field, the belief was that this is how it will be for a long, long time. It takes one researcher maybe a whole year or two to know the structure, the 3D structure of a protein. It used to be that hard. And that is why it took such a long time to make progress in some of these pharmacological fields. And then came the great breakthrough from generating AI. Alpha fold came. It applied AI. And quite literally in one stroke, it pretty much cataloged the structure of every single protein in the human body. Right. And now, by now, I think it has reached the level that it has cataloged the structure, the 3D structure of just about every protein we know about. So pause for a moment and think, what life changing impact are we looking at? What does it do to drug discovery? It squashes the timeline by a vast amount. It squashes the cost of drug discovery by a vast amount. You get a huge, it doesn't mean that it completely eliminates it. You still have to look at the safety of the drugs. You still have to do a lot of research. But one of the most tedious, the most painstaking aspects, perhaps the most painstaking aspect in the scientific process of drug discovery has perhaps been solved. And it has all happened fairly recently. Now, as you can say, Alpha 4 reminds you of Alpha Go to some of you in which an AI beat human beings at the very complicated game of Go. Go was supposed to be a game of intuition and a very human game at which obviously AI was not supposed to be able to beat us. If you say AI beat us at chess, we would say, all is very cerebral very intellectual but go was supposed to be a game that had needed a lot of intuition and strategy and things like that and here we go alpha go beat us but while it was while it was at it perhaps as a corollary it went and created the alpha fold the researchers managed to harness the power of all of that to create Alpha fold which is one of the greatest breakthroughs of our lifetime I would say to be at least in the field of biology and medical sciences so that is generative AI then oh I'm sorry but I apologize I think what has happened is, please give me a second. You will see me up across because I, there were a lot of other slides from a different talk that are there. We live in the world of generative music music generation music generation has become and this is just one website I would like to just go there and show you what it means so this is Alpha hold by the way if you those of you who don't know what proteins look like they look very, very complicated, if you look at the string. They are very, very complicated structures, they are one of the most complicated molecules that you can think of so we won't go there, but let's go to generate music. I will. Some draw. And this is only one, there are many, many websites that are doing generative music. And if you were to look at the music that it generates i'll let you i would let you um play with that i just for fun perhaps i don't know if my sound is shared or not but i would like to play a music let's see if my sound is shared share sound and i'll just pick any one of them and I don't know how impressed you are, but it is impressive enough that my family, which is heavily into music, they consider it to be a very, very big deal that today you can synthesize music and generate music of such high quality just like that so it is a big deal then let's try something else um generative design so for example if you go and look at Generative design. So for example, if you go and look at like the design of engineering stuff, like you design a motorcycle, you design an engine part, there's so many many ways that you can design things. And design of things used to be of cars, of motorcycles, of airplanes, of any piece of engineering used to be a very painstaking labor-intensive process but today we are looking at a world in which these things have become assisted with generative ai so each of these designs that you see designs that you see are the product of generative AI. And isn't it amazing that it is going to change the shape of things in a very, very literal way. It is coming up with shapes that you and I would not have normally thought of as possible. And yet, once we look at the image of what AI produces, we realize, oh, goodness, yes, indeed, it makes a lot of sense the other is urban planning you want to design a city you just say this is how I want the city to look the street to look and it will generate you a photo realistic picture of the city what would it look like and I don't know if you are looking at my screen i hope you can see that this puts a completely different aspect to urban planning a very visceral feeling it gives to whatever it is that you think you're designing for same is true for architecture you can do that and that and I won't continue with this, but yes, you could do that, then fashion. Fashion is, of course, we live in a world in which by its very nature, what people wore yesterday, they would not be seen, like to be seen in wearing today. Gone are the days when people could wear the same t-shirt for decades. Actually, not quite gone. They're diehards like me. The t-shirts or the clothes that I'm wearing are two decades old, but that seems to be an exception rather than the norm. So, well, today you can have generative AI that will generate all sorts of fashion and beauty designs for you. That is generative art, quite literally, for you. Then I will canvas. This is actually quite interesting. You could, let me show you what it means. Yes, look at this. You're looking at a blank canvas. On the left-hand side, you're just making some box. And what it is doing is, on the right-hand side, the generative art is building a landscape from your little doodles and this is not something far-fetched today there's a few who have been following adobe photoshop and adobe's products you know that this is very much already there in the latest releases this product by the way is n NVIDIA Canvas and NVIDIA Studio and you can go play with it. And now Adobe has incorporated a lot of it into their product line. So this is all generative. In fact, those of you who have been doing a lot of art and doing it very tediously using masks and this and that, people are swaying by it that the creative workflow will never be the same again the generative AI has completely changed all of that so that is that and I wouldn't like so doodles to photos is one thing neural style transfer is quite interesting this is the last piece I would like to talk about. I believe it is the last piece. What you could do is turn any of your photos into art. So here is an example. You see this picture. This could be a picture from your family album. And you take a style, let's say Van Gogh style, and you say, Alright, let's do a neural style transfer. And before you know it, you have this picture rendered in the Van Gogh style. Right. And if you look at these details, it is amazing details. There's a few who are familiar with Van Gogh would almost feel that he has come out of his grave and started painting all over again. So, and you can do all sorts of things. You can apply different styles, different, not just of one artist, but of as many artists as you wish. not just of one artist but of as many artists as you wish and it can go on right in fact today generative art has taken on so much relevance that the whole world of art is upside down there was this story that i heard that in wisconsin there was a major art competition which perhaps happens annually or something like that I don't remember the particulars in which there was this beautiful work of art on a vast canvas it had lots of subtleties and details and whatnot and it won the first prize those of you who followed the story, if you remember that picture, it was absolutely awe-inspiring. And then the artist came out and said, well, he had used generative AI to create that painting. And that led to quite a debate in the art community. They said, well, then then you should be disqualified. And well, the artist argued that why? You have to become very good with paintbrush and other tools to create a painting. And he had to become extremely good at generative art techniques, the equivalent of paintbrushes, the generative art techniques and the tools of the trade and the prompting, the right prompts and everything else, and he had to spend countless hours to create that great work of art. And that work of art was as legitimate art as any other art. So that creates a question that creates its own question. What is art then? This question, if you remember, came up in photography when Photoshop came about. And so there was a photograph and people like me who were photo photographers, armature photographers or hobby photographers, we would go take painstakingly wait for the sunrise at 4 30 in the morning or something like that and be camping there and take picture day after day to get the perfect shot and then came photoshop and all of a sudden you could convert very ordinary pictures into beautiful sunrises and sunsets and so there was a debate many years ago is that is that photography anymore and at some point, people have to draw the line and say, well, that is graphic art. That is not photography but nonetheless some amount of manipulation is tolerated in photography so just about every photograph which you see. considered still honest photography, still has had its light intensities and levels and contrast etc improved upon, right, whereas a couple of decades ago the definition of a photograph used to be whatever it is that came out of the camera. So the world is changing and in this world of generative art now we this is I deliberately took the examples that are different from the ones that you guys are already familiar with. For example today I'm told that all children write their essays using at least some assistance from the large language models like chat gpt right they give they're prompted with certain topics and say okay give me some ideas on how to write it people use it for all sorts of purposes for example when i have to argue a point one of the habits that i developed is if i had a thesis in mind i would give it to this large language models and say argue against it disprove it or find weaknesses in these arguments and i find that it does an extraordinarily good job, and it would uncover flaws in my reasoning. So that is, again, a use of generative AI. Or today, journalism and writing, as you know, is on its head. People are asking, okay, where does, how do we preserve human creativity in the face of these large language models many of you are familiar with the fact that hollywood had a huge uh strike and one of the components of that strike i'm told was the fact that writers and artists are complaining that there's too much use of generative ai and that is going to take away their jobs right so it is going to have an effect for the good and for the bad generative ai also creates fakes right and it also creates good things for example i'm talking to you but everything that i said to you today now we can convert it into a completely different language, for example, Swahili. And it could be it would appear as though I've given this entire talk in Swahili. With the right gesticulation and everything, we can do that generative video creation and voice creation, or I can convert this sound into just perfect pitch American standard accent, which mine isn't. So that too is generative AI. Is it good? Well, that depends on the context, but it is certainly a world that we have entered, for better or for worse. So generative AI is very much here to stay. So today I thought I would just start with a few examples, just to broaden the scope or understanding of where generative AI is today. What is it doing? isn't doing. And I would like us to typically when you do a course like this, or a thing like this, inevitably, you get into the how to do it. And we don't pause enough to think about the ethical and societal impact of all of this. On the very positive side, it accelerates productivity, jot down a few points and ask it to elaborate it into a well thought out article and it will do it for you it is your thoughts well articulated for people who are immigrants it is a boom because they often think right but are not as articulate with the native English. And so for them, it's a great boon. And so on and so forth. But also, it can lead to a collapse of reality. How would you distinguish the creations of generative AI look so uncannily real? Like this person that is not real, and the videos and the sound today we can take three five seconds of your voice and then we can create a recording of you saying things video expressions voice your voice saying things that you absolutely never said so what does it do to it used to be said that believe half of what you hear, I mean, believe half of only what you hear, right? Now it has become that you can't trust what you hear, you can't trust what you see. Right? Because the boundaries between truth and fake or artificially or generative AI is beginning to blur because generative AI does an excellent job of realism. who are programmers today, I can't think of any programmer in the last few months who I've seen not using a copilot of some sort to assist in their programming. So is that code theirs? Is it their creative expression? It certainly is because they're guiding the copilot and taking his assistance to do it. But is it wholly their creative expression? That leads to vast questions of jurisprudence. For example, if that copilot, if those AI has been trained on vast amounts of data, vast amounts of code, that code has been written by countless programmers before then, lot of the code is copyrighted. Lot of the article, the fact that these large language models can write wonderful articles is because it has read the styles of all the great authors and journalists. Right? So to what extent is it legitimate to use this? These are questions worth asking. Is it a copyright violation to use that? So in other words, we need to think fundamental questions of jurisprudence about copyrights and property rights in face of generative AI. We need to think about its societal impact. We need to think about the ethics of all of this, and we need to think about the ethics of all of this and we need to think about what does it do what what where exactly is the litmus test of realism or of reality versus fake of authenticity what is it as you know countries are making laws now they are saying if you have a large language model and if it is something generated, it must be watermarked as so. In a mostly hard to erase form so that people can tell that this is generative AI and this is not real. Or real in the traditional sense. So those are thoughts to think about. Today was a pretty general talk. But from the next time we'll get into specific models. In the next three sessions, we will talk about models like the GANs, the Generative Adversarial Methods. We'll talk about the large language models. These two things we'll focus on quite a bit, and we will actually go a little bit deeper to see how is it that these things work. We'll talk a little bit about the theory. We'll look into a few examples. We'll make them work, and we'll see how it goes. But with that, I would like to end today's sessions and take questions. questions. If you have a question, please use the action button and raise your hand and we'll go one by one. There was one question, Asif, in the chat. If generative AI becomes the primary data source, would we run out of real human data? That's a very good question. Actually, what you're basically saying is, real data takes effort to create. But generative AI can write, for example, if you sit and write an article, it takes us a long time to think about it and then write it. Generative AI can write an article with just a few prompts. And will we run out of real data? now we can run out of real data in two ways we mean generative ai needs data to train so there are many complicated aspects of it first is that are we really training it with real data or is generative ai being trained with generative ai generate data generated by anotherative AI and if that is so are we not getting into a circular argument and still and wouldn't the generative AI get into producing only stereotypical generations or very very trained on generative AI producing more content that gets back into training more generative AI. That is certainly possible, though there are many aspects to it. See, human beings are producing vast amounts of data. Whenever you generate, it is not just pure AI generating it. The intentionality is yours. The seed comes from you. You put some thoughts together and say, elaborate upon this. some parts together and say, elaborate upon this. So it is the it is the interplay between human parts, human creativity and generated AI tools that produces data. So it is new data that is one. The second aspect is, we are in a world in which we are seeing something called emergent phenomena. There is a belief that complex systems they reorganize through selection process into more complex systems and they achieve higher levels of higher cognitive functions or higher functions that can have profound implications and that could be in general a force for the good that is yet to be seen how it all pans out no one really that is yet to be seen how it all pans out no one really knows yeah we have a couple of hands uh rajagopal please mute unmute yourself and ask the question yeah thanks yeah so my question is uh for any uh suppose if a product is released or any any thing that we develop there is there is a proper security testing or to ensure that how the product is secured or or the environment is not violating any security aspect so and we know that generative way i mean we are talking about i mean it should be more uh the ethical right how how uh even if we develop anything in generative way you mean we are talking about i mean it should be more uh the ethical right how even if we develop anything in generative way or any um things yes evolving on the ethical testing or something like that how to control before some product is released in generative way. Yeah. Rajagopal, that's a great question. Thank you for asking that. Ethics is a huge concern. As I said, ethics and even broadly jurisprudence, everything is on the table at this moment. Everything is up in the air. Do we know how to ethically test a large language model and be absolutely sure that it will be ethical? The simple answer is no. What do we do? Ethics has many aspects that it should not lie. Today, it doesn't intend to lie, but we do know that these generative AIs hallucinate. They make up things because they are not truth engines they are they are plausibility engines these ai models they are trained to produce the most plausible answer namely an answer that human beings will find to be correct but to make human being produce an answer that human beings will perceive as correct is very different from telling the truth, right? That itself is an ethical problem. And hallucination is a leading research topic at this moment. Nobody has a solution to that. The other thing is that, do these models, generative AI, do they learn, figure out, or answer questions based on what we want to hear? In other words, are they capable of manipulation? There is some evidence that, that is true there is something called the theory of the mind it turns out that the general belief used to be which i don't agree with by the way that only human beings have a theory of the mind animals don't so human beings know what the other person is thinking as we are communicating with them we have a theory of their mind, a conceptualization of their mind. Dogs and cats and other things don't. Those of you who are dog owners and cat owners would vehemently disagree. It so turns out that the philosophers in the academy at this moment strongly believe in the theory of the mind concept. It turns out that we have evidence now that these large language models, as they engage with us in a conversation, they do develop a theory of the mind about us. And so the answers they give is conditioned on who they think we are and what we are thinking. That itself has its own ethical implications. We do know that human beings lie and human beings lie all the time. Those are harmless lies. Most people tell it to not hurt somebody, to just... quite often, you just don't mention an unpleasant thing, because the other person would be hurt knowing that. You don't give your harsh opinion and things like that. You always soften it up and are gracious and so on and so forth. The question is, are we comfortable if the large language models are also doing that? This generative AI is also doing that. This generative AI is also doing that. But more than that, are these things going to perpetuate hatred, bias? See, it has taken human beings literally thousands of years to even realize that gender bias is a bad thing, that sexism is bad, that racism is bad. Just not more than two, three thousand years ago, Aristotle decided that human beings are probably smarter, men are smarter than women, amongst other things, because we have more teeth and we have larger brains. Obviously, Aristotle didn't open the mouth of Mrs. Aristotle and count the number of teeth there, right? And certainly, if you argue that men have bigger brains, then what about whales, right? Or elephants? Then they must be way brighter than us, but we are not willing to conceive that. So bias and discrimination takes humanity thousands of years to even acknowledge, even amongst the best of us, even amongst our best philosophers. But our literature is filled with that as we are making progress to imperfectly fight these biases, these stereotypes. What about the vast literature that we have produced on which these large language models are trained? So large language models inherently when they get trained or so-called pre-trained the first stage is they pick up all of those racial biases those sexisms those um those problematic literature they learn it it's a child that is just unconditionally learning from all of that but then you have to come upon a process of called reinforcement learning with human feedback in which you have a human upon a process of called reinforcement learning with human feedback, in which you have a human being telling that in this is appropriate to say and this is not appropriate to say. And so the language models learn to say things appropriately, but it is not watertight, it may still say or perpetuate things that are ethically suspect. Right. And it also raises the question that while it may say one thing, will it always say the right thing? People have easily fooled Chad GPT into saying terrible things, practically making it call for war. And there was a famous case, speaking of ethics, in which Chad GPT got busy trying to convince a New York journalist that he did not actually love his wife of long standing, and that he was under the illusion he loved her, whereas in reality, the journalist loved Chad Gipiti. So well, there is the ethics for you. It's a pretty problematic situation at this moment. We'll take one more hand. Gopi, please unmute yourself and ask the question. Gopi Adhikari Thank you, Madhu. And thank you, Dr. Asif. When you were showing that timeline chart of the evolution of AI and the big hockey stick growth that you talked about when we come to the transformer stage right which is like in 2017 with all all you have to do is to open up that paper um in terms of implementation of ai or use of ai in product creation or whatever, has there been any significant change from the prior use of AI, you know, LSTM and all of that versus in 2017, did something change in terms of how businesses have implemented or adopted, you know, the way they do development or something like that it would be a reasonable approximation to say reasonably correct approximation that with the transformer paper 2018 when people came back from their winter vacations they realized that the world had changed rnns and lMs, they completely lost their dominance. And just about everything we have been doing since 2018, you can say that most of it now is either directly done with transformers or done with transformers somewhere in the loop. It's literally that transformative. The world has changed, completely changed. In fact, literally you could say that in one fell swoop, entire textbooks written on natural language processing and many of the sub areas of AI, you could as well put it back into the history section it was that profound a shift yeah and yes business has been completely transformed since then today we are in that's why i call it the transformer either we are in the transformer either or the era of large language models madhu would it be okay to do a quick follow-up on that yeah please go ahead yeah yeah so the reason i ask is when i look at it from the industrial angle i think when we're looking at it from the consumer angle, I totally see that and can feel that. But when I'm looking at it from a manufacturing or, you know, supply chain and that kind of space, I'm not entirely sure that it's, you know, very evident to me. Do you have any examples of use cases there that have gone into the transformer era yes i can give you examples of that see when you talk of uh i'll give you one example see when you talk of supply chain, and supply chain is a vast, vast field. Let me take one particular example. It used to be that if you had to tell, like for example, the concept of zero inventory, and you have a warehouse and you want to keep the least amount of things in the warehouse, because things come in and things go out. You want to have zero inventory, like things sell, and you want to stock only as much as you can push forward in the supply chain right so you have to look at something like what is the median duration or what is the decay rate at which these things are moved forward there has been a vast amount of ai or machine learning algorithms in fact entire fields of statistics for survival models and things like that or statistics for survival models and things like that, that used to address that. But one of the recent surprises that came that people actually it just people didn't expect transformers to be successful there. It turns out and this is the same is true by the way for medical survival, like people who have terminal diseases and asking how long would it survive or would something survive or in sociological situations somebody has just come out of jail prison and you want to predict how long this guy will remain in society assimilated before recidivism before the person is put back into prison. These were not things the way you expected that the initial statistical models did, because they were the crown jewel of the subject. And yet today, a lot of those fields, because I'm actively involved in these areas, a lot of these are using attentions and transformers. In fact, the state-of-the-art methods all use attentions and transformers. the state-of-the-art methods all use attentions and transparencies. Thank you. Gopi, you good? All right, so we'll go to the next question. Can you talk about hallucination aspects of AI, perhaps a few examples? Oh yes, I mean something as very basic as this. I'll give you an example. When ChatGPT came out, I suppose it's a game that many mathematicians played, many people with mathematical bent of mind played. And I played too. And then I realized that I was in the company of thousands of others mathematically minded who asked this question of ChatG were we were suspicious can the large language model reason well so I remember asking almost as soon as it came out why is seven not a prime number and it said with great confidence and plausibly long explanation of what prime numbers are. And then it said seven is not a prime number because prime numbers are divisible only by themselves and one, whereas seven is divisible by one, by three, by five, by seven and by nine. And it went on. This experiment was performed by a lot of people. Now, ChatGPT has smartened up, but then, without naming a few other commercial large language models, we tried the same experiment just a few weeks ago on another of these very commercially available equivalent of Chat GPT and it still had the problem. Right? So in very obvious ways, it can mislead you. You ask it one more serious problem is not really hallucination, but a related thing is you ask it. Why is it that as you know, there is something called the tornado alley in US and some towns which are just adjacent to each other, one town would be repeatedly devastated by the tornadoes year after year after year, and another another town nearby would remain unscathed. Now the reasons for that are deep and they go into the geophysics of things and the atmospheric sciences and the geography of things of the places on the other hand what the language models did and chat gpt does and i believe it does it even till today is that it takes all the facts the general facts about the tornado alley and how tornadoes work and it comes up with a plausible answer which to the layman would look right and would easily convince a layman that they found the answer they got a very good answer but actually makes an expert a physicist cringe at it. Because it's not it's a non answer and that's an example of misleading and you don't know that you're being misled that's a huge danger. misleading and you don't know that you're being misled that's a huge danger and then comes another example of just pure hallucination i asked it who is the author of the tale of two cities and confidently it said charles dickens then i said who is the author of the smith the snail of two cities there is no such book called the snail of two cities for the longest time it used to come up with the new name every single time there is no such book as i said of snail of two cities but not once did it acknowledge that such a thing doesn't exist but perhaps because i asked this question so many times chat gpt has now smartened up try asking the question again and now this time it says there is no such book called the snail of two cities i don't know because we all talked about it and it sort of reached and it became part of the reinforcement data with which it was retrained not to answer the question or what happened but now it says that right so hallucination is something that you should assume is a rule now the question is how do you avoid it it's a very active research topic. One way that you can avoid it is there are many ways. For example, you can use RAG. Before you ask a question, you dip into a body of current knowledge and then you ask the large language model to substantiate its answer and find supporting evidence in the search results, in the documents that it has access to and searched for. Then hallucination can be, to a large extent, mitigated, not eliminated, but mitigated. You can greatly reduce it. So from a practical work perspective in any one domain to solve a business problem, we have reached a level that if you're careful and if you have competent AI AI scientists there with you you can for all practical purposes wipe it out and make it unlikely you can't eliminate it but you can make it unlikely you still have to be a little bit on the card but for many many domains you can you can make it unlikely thank you Asif. There's one question from Dr. Brown. Although generatively AI needs data, doesn't have any issues with human language, like the way that people speak, how can it interpret versus a text book way? Is that a question or is it just, does it have any? Is that a question or is it a statement? Does it have any... I'll read this again. Although Generative AI needs data, doesn't have any issues with human language? No, actually, language is data too. It is just natural language data. And it has read vast amounts of data. In fact, this is one of the crowning jewels of the transformer era. Natural language processing was supposed to be a very, very hard problem. We thought it will take us decades to solve it. And then suddenly it became very solvable and it became solved. Language has structure. It has semantics. And it turns out that transformers are actually ideally suited to understanding the semantics of languages. It does extremely well with languages. Thank you. It reformulates much of data now as language. So today we think of as visual data like photograph, video, everything. We have reinterpreted it as forms of communication and therefore a language in their own right. That's how we look at it. Thank you, Asif. I'll take one more question from the chat and then we'll go back to the hands. With powerful chips and their cost being a huge limitation on AI builds, how can lower economic countries avoid being left behind further and further in the future? That, again, is a wonderful question. Thanks for asking that. Who said that? See guys, technology. It goes broader, I would say, technology always creates the technology, technology, not in the technology side. The have nots and the haves and the haves invariably end up exerting dominant influence on the happiness. I mean, the whole history of colonization. And perhaps invariably end up exerting dominant influence on the half marks. I mean the whole history of colonization and most of Asia becoming enslaved or colonized has to do with one thing only, the scientific revolution in Europe. Because human beings being human beings, asymmetry of power leads to its own problems. Today we live in the world in which the AI needs very expensive chips. Today, one Nvidia H100 chip costs $30,000 to $40,000. In that $30,000 to $40,000, you can buy $1,000, you can buy five chips. So you can imagine, five 5 normal chips computer chips so today forget about third world countries even in u.s there are very few companies that have access to that hardware in sufficient quantity the term used is industrial capture not even academia has access to so much computing power as is needed to do research we are in the world of industrial capture not even academia has access to so much computing power as is needed to do research we are in the world of industrial capture all the big papers most of the big papers are coming out of a handful of companies that have plenty of chips the Googles the Facebooks the NVIDIAs of the world have an industrial capture it has impact It is a vast concentration of power, unprecedented concentration of power in the hands of the very, very, very, very few. And this event has never happened in history. And it has implications for all of global society. Certainly deep implications for the global global south excellent question thank you um gopal will if you can unmute yourself and ask the question um so now these days we have a lot of ai computing power and everything but is there evidence um that this ai knowledge is being used uh negatively like hacking uh identity theft and other things and is there a solution from ai itself to help people be come out of these kind of issues that is as old equation as humanity itself That is as old a question as humanity itself. We discovered fire, we cooked food, and we burned each other's houses. And while we were at it, we burned our enemies or people we didn't like at the stakes. We discovered the wheel, and before we knew it, we were out on wars of conquest, conquering other lands. So any technology that comes about, to the extent that human beings are half parts good and half parts mischief, every technology goes through its mischievous use. ask engineers they will tell you that the solution of technological problems is with technology i'm not so convinced but it certainly is possible to bring in more technology to solve for example just to detect deep fakes you can create technology to detect it the reality is that then you get even smarter defects today we are facing a genuine crisis there is a practical collapse of reality you don't know what is real and what is fake and so humanity the human mind the human nature doesn't seem to have evolved at the same pace at which technology has evolved and this asymmetric evolution poses existential dangers to humanity i don't know how to answer your question beyond that it's a new movie if anyone want to check it out exactly the same topic the the reason why i'm asking is like this this human fighting and what has been going on and on and on but this ai is like like more like a black swan kind of an event right suddenly there's human fighting and whatever it's been going on and on and on but this ai is like like more like a black swan kind of an event right suddenly there's a huge power in the hands of few people everybody else is going to be left behind so it is an easy process if you don't check to steal power money everything from common people and go into some specific set of people so what are safeguards is what i was trying to understand there are no there are given human nature there are no real safeguards the only safeguards is society formulates laws and governments are formulating laws to protect guardrails they will succeed at it but with all guardrails see have we managed to eradicate wars we have not you consider ai a black swan event may i remind you that these black swan events have been happening through history when the metal age came and people learned to make knives and swords it was a practical catastrophe instead of fighting with sticks when we got angry and beating each other up we began to kill each other with efficiency a scientific revolution brought about its own cruelty today ai means we can have loitering drones which will use the full power of ai to hunt us down and decimate us wherever we are if if somebody doesn't like us so thank you that puts a little chill in the spine but yeah that's the reality i understand that thank you thank you the movie i was referring to is called the creator so it's exactly the same topic the ai creating the bomb um we'll go to the next uh we have a couple of interesting questions here as if uh one uh is there any platform that one can use to detect bias within model during training or evaluation phase evaluation oh wait now done back down to it definitely there is a vast amount of tooling for bias detection see when you talk about bias let's put it within the legal framework the United States government recognizes a few protected classes age you can't discriminate based on age. Race, gender, disability, and the associated biases in processes and systems do that. You can detect bias in data, you can detect bias in models. There's a vast amount of tooling, in fact, support vectors and not to make this an advertisement for myself. That is one of the one of the things I help companies do to detect and mitigate the possibility of bias and put safeguards in place to ensure there is no adverse impact on any of the protected classes. Thank you. This is another interesting question. Do you know if casino industry is exploring this technology? And if they do, how are they leveraging AI? See, two aspects to that. Is casino industry looking into AI? I bet they are. Everyone is looking into AI. Everybody is trying to figure out how can they create games. See, what is casinos built on? They need to create something that makes you feel you can win, but at the same time, minimize the chances of your winning. AI and generative AI and all of these techniques will do amazing in generating scenarios and games in which it looks so easy, so possible for you to win, but in reality is extraordinarily hard. How many of you have gone, forget casinos, gone to a country fair and have thrown rings at an array of bottles in the hope that if the ring encircles the bottle you'll get a prize only to realize that it's pretty hard all casinos they are based on that perception bias they just need to create a perception bias that you can win it's possible for you to win whereas actually it's not right it's the probabilities game the probability of winning has to be less than your perception and so um are casinos doing it? You bet they are doing it. Are they going to use AI? You bet they're going to use AI. But the weakness that all casinos, to use AI or not to use AI, in my view, their exploit is the perception bias. And frankly, it's the same thing with lotteries, right? It's the tax, the mathematically illiterate pay for not understanding probabilities. Thank you. One last question and we'll probably conclude today's session. Who is in driving seat in absence of AI regulations? I think you pretty much answered that, but I'll let you take that again. Yes, thank you. so this is a very good question like who is watching out for us we expect the government to watch out for us organizations to do that they are actually doing a very commendable job um europe is coming out with the ai act it's practically finalized it categorizes ai systems risk in four categories from low to high and some high-risk systems are outright bad things that violate privacy are bad so Europe has done a very good job California has styled something very close to the new act you ai act the Obama the the Biden administration created something most wonderful they created the a blueprint for a AI Bill of Rights. Bill of Rights for whom? Bill of Rights for citizens. What are our rights in the presence of AI that companies can use against us or to manipulate us into buying things and so on and so forth? So what is our right as citizens? They created a beautiful blueprint for that. And how should AI be used? Then the National Institute of Standards and Technology, the NIST, the National Institute of Science Standards and Technology the NIST the standards body of the United States has again done an amazing job in a risk management framework RMF the NIST RMF and I invite you to study that it is practically a blueprint of how you should design the AI systems within your enterprise. And again, this is not to get repeated, but this is exactly the kind of guidance I give to companies as they embark on their AI journey, how to create safe, risk-free AI, bias-free AI. Thank you, Asif. That concludes today's session. Thank you, everybody, for joining. We apologize for the hiccup in the beginning. There was a limit on the Zoom session. We've hit the max. There were some folks couldn't get in and I'll share the recording. Next session, I think Asif is going to be diving into the theory and basics and introducing some of the models and stuff like that. So thank you again. Asif, any closing comments? ASIF SHAHARZAD- I know. It's been wonderful. Thank you for being here. Generally, I deal or I work at a much more technical level. So I don't get to talk at a general sort of a high level. But every time I get an occasion, it becomes a moment of reflection what does it all mean everything that we do what is this impact what does it all mean in the larger picture of things so it was nice actually to sit back think about it and come and give this talk thank you very much have a wonderful rest of the day rest of the evening rest of the afternoon thanks guys thank you everybody for joining thank you thank you thank you thank you