 books are you seeing my screen yes so let's get started uh first of all welcome back folks today is november the fourth saturday again another beautiful morning in california excellent. And thank you for being here despite the excellent weather outside. We are going to cover a new topic. I'll recap what we did before. But before I recap, just a few reminders for all of you. Folks, all of your lesson plans, all the videos, they are there on the course portal. I don't know if you're keeping track but they are all there and you can refer to them this portal will be accessible to you forever or so long as the server lasts right this is one the other thing to be aware of is uh if you go to the youtube channel in youtube support vectors as a In this channel, there are quite literally hundreds of videos, close to 400 videos that you will find on the channel. upload it and there are videos that are from live sessions these days if you remember we just live uh we just put the live sessions straight onto the portal so for example if you want to see what we did the last few times this is the one that is live if you want you can just watch what's happening now right now now. Last week, we did the morning session on adversariales. Then we did the fast gradient sign method for adversarial attack. And then we did the dimple manifold hypothesis for why adversarial attacks are so easy to do, or they happen with machine learning models. So today, we are going to do or they happen with machine learning models so today we are going to do a completely new topic and that topic is voice clothing oh yes i should excellent point let's see if it comes through. Yes, something should happen. This is today's topic. And today, I'll take a slightly different approach. I'll take the approach that and you'll see what approach I take. But before I go into it, you'll see what approach I take. But before I go into it, the usual things folks, just to remind you, we not only give training, we also provide consultancy and we give corporate training. If any one of you are interested or if your team needs to get something done we do implementations also so we have a lot of experience by now hopefully you're convinced next point to make is the entire boot camp is about this long journey from taking what are POC codes or research papers and bringing them into production making them into Enterprise scale robust high performance architectures, which is not an easy task. And this task often requires that we understand not just how the models work, but we also understand how to formulate everything in such a way that it scales, that it runs in a distributed computer environment, right, and you can do distributed training and distributed computations. So that is the long journey. In that long journey, I must also mention that you, many of you know that you have access to the enterprise or the inference server. I'm getting some very good numbers. Hammad yesterday reported that he was able to index and vectorize, create vector embeddings of the entire Wikipedia. Right? And the whole thing happened in a few minutes. We are talking about 80 million vector embeddings so obviously if you're working on your god forbid macbooks or laptops or whatever it is high time that you started doing these things on the proper ai inference server that you all have access to now many of you have built your own axe your own machines thanks to sukpal and if you have those machines you have a single gpu you may still consider that for do do many of the things on your single gpu machine but when it comes to compute at scale, like doing this AI inferences at scale, use the inference server. But use the inference server only when you need to. Don't use it for non-AI tasks. I will be enforcing the quota system. Each team will get a day of the week. So use your day of the week wisely. The machines are, the inference server is massive. Yesterday, Hammad wrote some code that used the full CPU utilization and GPU utilization. It caused the circuit breaker to trip off. So we have put it on us. Due to Ray. The Ray thing. Ray did a distributed computer. Don't properly optimize that. Even on my Mac, it gets... Completely used up, yes. So as Praveen pointed out, be careful with the configurations on Ray. Otherwise, it will end up hogging all the resources. And well, today today the infant server is in a massive electrical circuit you can't trip it off but you can waste a load of electricity and overload the machine right so be careful and these are normal considerations you'll have in production once again ai enterprise is a sum of many parts. There's data infrastructure, there are people, there are models, there are algorithms, ML platform, ML Ops, visualization, and then the ethics and interpretability will be our last session. We are going to do that. We'll end this boot camp with that. Also, the folks know how to use and monitor all these resources. That is very important. That is true. That is true. So Ray Dashboard has it. And also the NVGISMI. NVGISMI. So yeah, Praveen is pointing out that you guys need to be really skilled at monitoring how your AI jobs are progressing. Please do develop those skills. Look into NVIDIA SMI, look into Ray Dashboard, see what is happening. Don't just blindly fire things and leave it running. So again, this is by now you must have, I'm not going to dwell upon it, but we have a lot that happens in MLOps. By now you should become, you should have become quite familiar with each of the pieces and each of the pieces here. So today's topic is this. We are going to do voice cloning. When you do voice cloning, I'm going to do a slight shift. I noticed that I would come every day with some papers. Go ahead. Oh, TV is not on. Okay, I apologize. I didn't know what happened. And. Better. All right. So usually I would pick the research papers and then ask you guys to do a silent reading. And then I would discuss the paper in the afternoon. Or what would usually happen is nobody, not many people would do a really good silent studying of the paper it would be just glancing at it or the abstract and so forth so today i will expect each team to come forward with one paper on voice claim sit where i'm sitting and present it or present it to the to the team so today I am putting some emphasis on paper reading guys let us see which paper each team picks pick a different paper voice cloning is a very very important topic and voice based AI models voice processing is big. A voice cloning is something I want you to take seriously, but there are alternatives if you can't think of, I mean today let's keep a voice cloning, then there is texture speech and so on and so forth, but let's stick to voice cloning. You'll do that. Now we'll review it in the afternoon. We'll do some team presentations. Which team would like to present their work today? No team. People seem to be petered out. Guys, I know that this is the holiday season starting up. Diwali is around the corner and everybody seems to be in a holiday mood. But we need to make progress with this.mber is going to be a tough month you'll have to multiply within multiple priorities the home celebrations and everything at the same time we need to do this boot camp seriously so now i'm going to announce the project today what What is the project? The project and by the way, what are the things that we have done? These are all the things that we have done today. We are entering voice coding. As you can see, we have done a pretty long journey. I'm going to give you your final project today. Go ahead. I think you're not sharing this. I am not sharing the screen on zoom. Okay. Let's see. Oh screen sharing has stopped because of our external display getting connected. I apologize. All of the presentations are linked. Okay, I'll send it right away. But remember that all the presentations on the course portal but this one hasn't been linked. I'll link it immediately. So guys, this is what we have done so far. Today is voice cloning. And here's the project. This is a big project. I want you guys to do it as your final and big project for the whole month of November. to do it as your final and big project for the whole month of November. What you need to do is you need to go and take all the videos that are here on the support vectors portal and they're about under 400 videos here. I want you guys to go get the transcript of all the videos in each of the teams. You know that you can get the transcript of the videos. When you get the transcript, you'll be a bit disappointed because those transcripts won't have punctuations or anything. It will be just one long running text. Right. text. Now, I want you guys to sieve it through. First of all, repunctuate it as best as you can. Put it through transformer models. Do everything that you did, your chunking, your everything. Generate a summary. For each video, use an LLM to create a good summary of it. Extract the salient points that were talked about. Next, I want you to create a virtual assistant, a virtual teaching assistant that you can ask questions to and finally it should respond in either your voice or my voice right so create a teaching assistant that completely clones you can pick a person you can pick my voice and it responds maybe for uniformity you can take my voice it will speak back the answers in my voice this is a big project i want you guys to give your best to doing this project are we understanding all the parts of the project can you just say that yes or take all the 400 odd videos at SupportVectors' YouTube channel, get their transcripts, clean it out, use large language models to A, create a punctuated version of the text of the transcript, B, have the large language model create really good summaries with important points summarized or itemized for each of the videos. And finally, to create a rag on it, then for any question that is asked, have the answer come out from a virtual teaching assistant who responds in my voice as well as in text. Looks easy, guys? I also can pull up the video. Yes. There'll be multiple. If you synthesize the answer for multiple videos, then as part of the rack also pull out those those different videos as references point to the exact location will be hard I I that will be a bit of a stretch but if you can do that then all power to you I think you can do that you have done it okay so then point to exact locations in the video actually that part I don't know I'll learn from you guys I haven't done that so whisper gives you oh because with whisper you can get that yes thanks with the timeline they have just released last two weeks bad that API whisper has a just two three weeks and so you can give it an audio and it will give you annotated. Yeah, you need to give that a new API. Excellent. So Abhijit just mentioned that Whisper has come up with a new API that given the audio will annotate the text of the video and give you the exact locations. So guys, please take this project seriously, do it. I will release a reference solution, but I won't do it till end of December, which means that, and this final project and your last project and your RAD project, I mean, everything that you have done till now, will give the final day of this boot camp as a team-wide competition. Whichever team does it well gets a special prize. Those of you who did the last competition well are wearing wearing let's just say that they are wearing the special price well if you aspire to win it again you can always wear it on the other hand so that's your project guys that's all i'll say i'll end with that do you guys have any questions all I'll say. I'll end with that. Do you guys have any questions? Yes, we will be. So, in fact, this project will require you to fine-tune. Right. So, it will require you to fine tune to get good answers, fine tune to the machine learning domain. So when you get all of those texts, so by the way, maybe I'll make it a necessary part of the project. See guys, when you extract all of the text, you'll notice that when you ask it questions and it comes back with answers that when it comes back to search results, generic search results are not good. What you want to do is do contrastive learning on the text, which means that you must create at least each team should create at least 2000 triplets. triplets. Create 2000 meaningful triplets from the text of the videos and use that to fine-tune your model. That's the fine-tuning part. Any questions guys? You need to fine-tune the chatbot kind of yes you need to find it you need to find it in the chatbot also so guys there are many opportunities to do it right and the hint is you will have to fine tune you will have to do voice cloning you will have to do rag you'll have to use llms pretty extensively i can't tell you how many let me just say that by the time you're done with this project, you will be using about a dozen transformers. You'll be using different transformers at different places of this project. And you will have a true enterprise class product, which you'll run and raise. Praveen is asking, what is a triplet? See, See for contrastive loss you have to give triplets. One is a reference sentence, one is a similar sentence reworded and one is a completely different sentence. So we can start at home to do the triplets? Yes, you can get started. And remember, guys, each team has access to the inference server. At this moment, I'm not setting up a rotation because most of you have not started using it. But you should start using it. The only thing you should not do is start putting SQL server, MySQL database or Postgres and other things. And you won't be able to because you won't have pseudo privilege but even if you don't have pseudo privilege don't start putting lots of sql server i mean my sql docker and elasticsearch docker and whatnot those things should be on the machines that each team has been given each of you have been given a server, a very powerful server. So now some of you have built your own powerful service with Gpus. Keep the infrastructure there. Use the inference server only for the Ai part for influences only computes. Only computes. Yes, only for computes don't use it for anything yeah for storage you should use another machine and i will also release i'm still in the process of building but with some luck today i will put unraid with the pulse help on uh one of the servers so you will have access to 120 terabytes of disk space as an NFS mount available on the network. Right. Trust me, 120 terabytes is more than enough. Right. A bit of a point for some of you to know, point for some of you to know uh Hamad just ran the uh Wikipedia the the embedding the vector embedding and indexing yesterday on the entire Wikipedia content or with its close to six million articles after chunking it became about 60 to 100 million chunks those 100 million chunks the inference server well if you do 100 million chunks, I don't know how long it will take on your machine. Anybody has an idea? What is the chunk? What is the indexing? I mean, what's the vector embedding rate on your machines? Most of you are getting something like 100 embeddings a minute, 1000 embeddings a minute at most, a few hundred embeddings a minute on the inference server just to give you a measure of how fast and brutal it is. It does 100 million embeddings in the better part of eight minutes. So you're looking at a beast of a machine. And it is proportionately very expensive. So try not to burn it down. Right? It's really a beast of a machine, we have put massive cooling on it, to keep sure make sure that it stays cool, it's heavily faned, and there's a dedicated AC on top of it, use it, use it wisely. And you will get a real sense of how powerful AI servers are in production grade systems. So with that, I will stop. If anybody has questions, please ask. Anybody has questions, guys? Any questions? For the voice cloning uh i assume that also you need some fine tuning based on your voice right well there are voice tuning models that easily learn from your voice but yes the answer is yes let me just say let me just drop some magical works say, let me just drop some magical works. Woof, woof, bark. If that's a hint. Got it. Okay. Models are available. Yeah, and Valley and more models. So this time guys, because I'm expecting you guys to discover a good paper on voice cleaning and present it. I won't give any more hints. But guys, come back, come to the stage in a couple of hours at 2 o'clock and explain those papers. For all of this time now, for many months, for six months, I've been doing the paper reading. But now you should have reached the maturity level at which as a team at least you can dissect a paper and explain it in clear terms. So today you guys will explain the paper and I will be learning. So there we go. Any other questions guys? Shashinda, I hope you pick your paper. You'll be the first one to present. What's the time? Okay. The reason I'm saying this, this is multimedia and this is very close to the work you do, Shashinda. You like it? Okay. Yeah, sure. Nice audit guys. So I'll end the session now and we'll take it from there. We'll meet at two after lunch. You have three hours to read a paper, a long time.