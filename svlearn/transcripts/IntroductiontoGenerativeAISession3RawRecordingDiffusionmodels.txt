 And I'll make you back the host. Okay. Oh, how come I don't see you? Oops, there are two cosines, so are you and Athita. So I don't know who I'm making the host. Oh, here, I'll make it easier. Oh, it doesn't show me. I'm the one who's unmuted you're the one yes so then you are the course you're the host i do see that okay we should be solid all right all right folks so welcome back to uh the third session of the Generative AI course. We had to get some technical aspects right for recording. And the last week's recording is in the process of being uploaded for those of you who are interested in that. Today, I would like to start with a big topic, the transformers. with a big topic, the transformers. Transformers have become such a big topic in recent years that it almost seems there isn't much else left. Everything has now, whether you're talking about feedforward networks or convolutional networks or encoder-decoders or whether you're talking about G forward networks or convolutional networks or encoder decoders or whether you're talking about GANs and UNETs and so on and so forth, we tend to look at almost everything now in conjunction with a transformer. We look at it and ask if we throw a transformer into the mix what what interesting things will come out of this out of this part and it turns out that the creativity is vast actually that people are doing very very creative things every day there are research papers lots of them coming up if are following archive, you will see that on archive every single day there would be about, I would like to say about a dozen papers at least, papers at least, that one way or the other use a transformer. And as they use, they create, I mean, they affect many, many domains. Some of them appear theoretical, they move the foundational knowledge about transformers and AI forward. A lot of them are applied to various specific domains. Some of them have to do with computer vision, some have to do with natural language processing, some have to do with tabular data, and so on and so forth. So there's a vast amount of activity that's happening around transformers. Today, I would like to just start by showing you some of the things that people do. Now, these things, a lot of these things this is dally too you can do it because it's putting many ideas together transformer is one of them when you bring these ideas together into a unified architecture you can achieve a lot for example if i were to say what should i say a golden retriever because i have one smelling a sun flower with some butterflies hovering over the flower eyes hovering over the flower. Let's see. And let's make it make it photorealistic. Photorealistic. Let's see what happens. Now, this is something all of you have played with, so this should come just as a you all know and most of you perhaps can write better prompts than i can so if you look at this picture here which one should i take let's take this one it is a few years ago it would have been just a couple of years ago it would have been hard to believe that this is not a photograph. That it looks quite photorealistic and yet this is DALI 2. Now there is DALI 3. Stable diffusion has gotten better, they have come up with the SDXL model. They have come up with the SDXL model. There is MidJourney that makes a lot of photorealistic images. And so lots and lots of people are trying out a lot of these transformer and diffusion-based models. So I'll keep that as a topic of generated AI today. We'll start with transformers, what they are, and we will from there onwards move quickly to diffusion models. Transformer is the underlying core, and since I've covered it, and many of you have participated in my previous sessions on the transformer, I'll keep it relatively brief. It would be sort of a reminder session and then i'll go into this very interesting topic of diffusion models that makes this kind of photorealistic rendering even possible and the thing that i find quite interesting is, see, things like statistical mechanics, mathematical physics, or mathematical or theoretical computer science generally comes across as pretty dry. and yet it is amazing how much how much those fields are contributing to the foundations of of things that engage people on a day-to-day life in such a such overwhelming ways so if you ask where did some of these ideas come from for the diffusion models the diffusion models original idea came from uh as as the word diffusion is a giveaway it's a term from physics in particular statistical mechanics which looks at the dynamics of atoms buzzing around and as they buzz around with different levels of energy and different different kinetic energy different pressures and so on and so forth they lead to interesting effects that thermodynamic effects so. The diffusion is best explained take a drop of ink or color and just put it in a in water let's say in a beaker of water and you will see the process of diffusion take place. Some of you pour, if you have a glass of coffee and the glass is transparent, you pour. For example, if you go to a Thai restaurant, you would see this. You would get concentrated milk at the top. And if you observe carefully, you will see the diffusion process process how the milk gradually permeates the rest of the coffee and of course you can assist it with a stirrer so that process until it reaches complete or homogeneous distribution in which the milk and coffee are fully mixed or in the case of ink and beaker color and water they are fully mixed when they are fully mixed is the equilibrium state till they get fully mixed that process is non-equilibrium it's a diffusion process taking place so the ideas for this diffusion model actually comes from that the original paper is a bit is a bit should we say mathematical a beautiful idea breakthrough paper that started all of this but most people if they were shown those ideas they would be quite surprised that such fun stuff as generative art actually has as foundations on such breakthroughs at such a deep level so what i'm going to do today is i will take those ideas and i'll try my best to make it accessible to you so you understand how this generative AI thing works. And if you understand how it works, generally, we observe that people who really know how these things work under the covers, they tend to become much smarter at the generative AI part or at prompting and many aspects of this. In other words, if you want to really accelerate generative ai you have to know the foundations in the last session we did a gan as an example so there are many classes of generative ai architectures for example gan is a whole generative adversarial networks that we did last time remember the discriminator and the generator, the counterfeiter and the cop? Using that adversarial game or adversarial learning, they both become very, very good. So that was one architecture. The other is something called variational autoencoders and, well, the different variants of the variation autoencoder, the Wasserstein GAN and so on and so forth, and the Vichu GAN. There are many, many such things in style GAN, and they all create very photorealistic images, amongst other things. They can imitate sound, they can imitate, they can create completely realistic pictures, they can do text, many things come out of that whole world. Then you have, you did neural style transfer, you could have Van Gogh render your photograph into a Van Gogh painting, in a sense, using a neural style transfer. Then so GANs are powerful, autoencoders are powerful. There's also things like flow models, the normalized flow models. Normalized flow models are interesting, and I would like to sort of, because I won't cover them, I'm going to give just a one minute idea just so that this fact stays pinned into your mind that there is such a thing as normalized flow as an approach to generatively and so towards that I'm going to go into the writing mode. I'm going to go into the writing mode. If you try that. What happens is it's somewhat like GAN. You take an input. Let's say that you take an input. And what you do with this input is you sort of pass it through a function let's say that the input is x you create a rendering of this into a latent space and what is a function in the world of neural networks the word function or rather continuous differentiable function. Continuous differentiable, these are words that we can mostly forget. functions. Is roughly the same as a neural network. And this is the, this is the one sort of a core idea that you should have in mind, that in many ways a neural network is a very, very clever way of approximating a function, of creating a function, and that function is a universal approximator. In other words, this neural net as a function, it can approximate just about any function in the world, right, so long as it is well behaved. Generally, well behaved means reasonably smooth and continuous function. So it can do that and that is a very powerful result. It's a mathematical result and perhaps the power of neural networks derives to a large extent from this that it is like a chameleon. It can change shapes continually and it can adapt to any or approximate or mimic any reality that you throw at it. So with that being there, a normalized flow, and we won't talk much about it, what it does is you have a well-defined neural net and then you do some mathematical G. And then you do some mathematical magic using things like the Jacobian. Jacobian is named after the Jacobi brothers. Jacobian function which can do f inverse x without needing a neural network, so you don't have a inverse, I mean you don't have another neural network to undo it, if you had a another neural network to undo it. If you had another neural network to undo it, it would become your encoder-decoder architecture, but normalized flow models are slightly different. Models are slightly different, and then they produce the output y hat, which would be something Something like this. So that's sort of another generative class of models called normalized flow models, but we won't talk about it today. Today we'll talk about, because some of you requested this, we'll talk about in particular the foundations of the most dominant generative AI in visual domain models, these are the diffusion models. So let me write the word down diffusion models. models they borrow ideas from multiple domains so one is obviously the idea of diffusion that comes from non-equilibrium non-equilibrium physics i should say say, or stat, statistics, statistical physics. But I'll just, let me just write down non-equilibrium systems. And B, we'll talk about the transformer today. We'll talk about something called U-Net, a very successful architecture of 2015. We'll talk about something called Glide. And I think by then we may we might run out of time. Today will be a slightly longer session. So, but these are the things, these are our building blocks and with all of these will gradually build a latent diffusion will gradually build a latent diffusion model, right, which is the underpinning behind things like DALI, DALI 2, not DALI, not the original DALI, but DALI 2, and stable diffusion and mid journey and so on and so forth right and so so obviously i assume that all of you have played with it if you haven't please do so today we have diffusion models to produce even videos so you can create it can create pretty realistic short duration videos of a couple of minutes it can produce very photorealistic images or just about anything that you want to such an extent obviously i don't know if you are aware i am told that the art community is quite quite worried about all this there was an event in wisconsin where a great art competition was won by a person who had created a remarkable piece of art, absolutely wonderful piece of art that did deserve to win the prize, but he had created it through generative, generative art, through generative AI, not using a paintbrush and that had the whole, the whole art community up in an uproar. That is that creativity. It is creativity because to write that prompt, you and I, at least I certainly can't write any prompt worth anything actually, when it comes to generating art and terrible. So, but it must have taken a lot of practice and a lot of study to become that absolutely amazing to produce that art and so the question is does he deserve to get the uh prestigious art prize the traditional artist said no this is not fair no paintbrush used and so this is not art and so he shouldn't get the prize on the other hand you can come to argue that the world has changed today in just about everything we do ai is a co-pilot and generative ai is an excellent co-pilot for everything that you are beginning to do today so we will keep that in our mind and let's start from the very, very beginning. Diffusion is something we'll come to in a little in a moment. But we all know what diffusion is. We talked about diffusion. Let's go to the transformer. The transformer thing started actually with this paper. Let me expand this paper. Attention is all you need. Now, the interesting thing about this paper is, and I'll go over this, only the core idea, I wouldn't go over it line by line. Let's go over the core idea. Oh, sorry. This. If you pay attention to this, attention. Attention was a concept that was already invented or discovered in the USA by 2014. And what attention means is literally what you think it means. Let me, when you say I am attending to something, let's say music, what does it mean? You're paying close attention to music and excluding a lot of other things, other noises in the background. For example, the horn of a car the traffic the hum of the air conditioner and so on and so forth you're paying um that another way to say it is when you pay attention to something you're picking that you're giving different weightage to that relative to other things so suppose you have 10 different things one two three four five six seven eight nine ten just say that I'm attending to this means I'm giving far more weightage to this and not looking at other things as much and so now you can generalize from that and say well I could have different levels of attention that I'm paying to different things. Most of you, if you have had experience with little children, you know how it is. You have to pay close attention to them, even while you might be working on a few other things to cope up with your workload. to cope up with your workload. So attention, therefore, is paying differential emphasis to different things, different inputs. That's it. But what decides what you should pay attention to? It is the context. So attention presupposes presupposes, presupposes a context, a context. This is very important. You cannot pay attention, like there's no such thing as I'm paying attention. Or I'll give you an example. I go for a morning hike every morning. When I go for the hike, it's still dark. So most of the time, I generally when I go for the hike, I can see Orion these days up there, more or less above my head. If I really look around by now, perhaps because it's getting cloudy and also winter is coming, it's a little hard to see the Big Dipper. But I would like to, I just look up at the stars because at that moment there is dead quiet. And I walk on the trail, generally I'm looking at the horizon, I'm looking at the, I walk next to a river, a creek actually, so I'm looking at the fog that has settled onto the creek so my attention goes towards absorbing the beauty of nature but suppose right at that moment I were to hear a sound like whoa right the roar of an animal what would happen then what would happen is all of a sudden the stars, the river, the fog on the river, the mist on the river, and the hills, everything would sort of fade out from my immediate attention. I would be looking everywhere to see if, for example, there's a coyote or a mountain lion anywhere in my vicinity. And I'm here in California, in Northern California. So these are the two animals you probably would watch out for if it is late night. Or very, very early morning before it is sunrise. So, and especially if you're walking as I do in the wilderness. So that is attention. When I suddenly, my attention, when I don't hear the roar is on something else. But the moment it, I hear that sound, now my attention, I'm looking visually at the entire landscape completely differently. My mind is looking for the form of a four legged predator. So context, the context has changed. So context tells what we pay attention to. And this thing is much more mathematical. Essentially what it says is that if you have different vectors, let's say that these things can be, in machine learning, in AI, everything is a vector. So let's say that I have internal representations of each of these objects as vectors. Let's just call them H1, H2. In other words, these are some internal states that the neural network has produced, Hk or Hn. Then attention is, roughly speaking, up to their mathematical formalisms, but attention. This tells how much weightage I'll give. I mean, by the way, I am eating up many things. I'm eating up soft nuts, which is a mathematical operation. But let's not pay attention to that. And there is some underlying normalizing constant here at the bottom. Ignore all of that. Let's just pay attention to the fact that. Well, that's interesting. I use the word attention. Well, that's interesting. I use the word attention. Well, let's pay attention to just the yellow thing and say that the amount of attention or the differential attention I pay is to a particular vector is its alignment with the context. The context being this. Let me, I made A the context. A is the context., let me actually not use a let me you see the context. Right how aligned you are and typically alignment in math is. The degree of alignment and higher dimensions is computed as dark products. scalar dot product so that's what it is but we'll just sort of skip that mathematical aspect of it so what it means is suppose i give you a photograph and i ask you what uh who is this person let us say in the picture you see a child child is wearing a standard jacket that you can get at the mall, trousers and shoes and so on and so forth. But, and you want to know whose child is it, you want to identify the child, your attention would immediately go to the face. Right, to the eyes, to the face and so forth, because the face would help you identify to a large degree who the child is quite often. So in a photograph, you have paid overwhelming importance to the face, but not so much to the rest of the body. Let's say this is the child. So your attention has gone basically here, and that is essentially all that attention is. So this attention, its mathematical formulation as a vector's alignment with the context, was already there in place in 2014. So now comes the rest of the passage, attention is all you need. What does that mean? What happened is that they used to be the so-called sequence to sequence models. Those were recurring neural networks, LSTMs and so on and so forth, RNN, LSTM, GRU, etc. These are all, they used to be very dominant. And what they could do is you could send a sequence of words, tokens, T1 to TK, into it. And, well, actually you send it in the oppositor, T1 first. And then TK would go into it. and this used to be called an encoder it would create a hidden representation abstract representation it is the way the machine understood it and then you could decode this decode this using a decoder Decode this using a decoder to whatever you want. Let's say that this is your Y output. Now, your output could be one of many things. For example, if I sent input, let me just call this input. was a French sentence and the output was English, then this encoder-decoder or this set-to-set is called sequence-to-sequence model or encoder-decoder model. What would you call that? It would be a translator. So this is translation. For example, right, if you, on the other hand, send an input, a long text, input is a long text, and you wanted a summary, and you wanted a summary then all of those are being produced from the hidden state and there is an auto-regressive mechanism which you won't i mean i'll talk a little bit about it what you do is the decoder just produces the first token the first word and then uses the hidden state and the first word that it produced to produce the second word right so it's like this the first word in all of these things is word one output you don't use the word word because you use the word token because karma is also karma punctuations can also be there numbers can also be there so the generalization of word is a token so you produce the first token t1 which is completely dependent on depends on just the hidden state the hidden understanding that the encoder that this machine understood from the input. What did it make out of that sentence? But then T2 depends on both the hidden state and the word that it just produced, t2. And by now, you probably have understood the generalization. The nth token depends upon the hidden state t1, t2, all the way to t n minus 1, the last token. And at some point, the machine will end up producing a special token, end token. And when it produces the end token, the machine will just stop and not produce anymore. And you're supposed to have the output. So this architecture, this encoder decoder architecture has survived just the internal implementations have changed the old record in neural networks the way they used to do it and we won't go into that it turns out that even though they were the workforce the workhorse of the industry for decades today after the transformers came about in way, transformers have taken over a lot of functionality from the RNNs, LSTMs, etc. Those RNNs, LSTMs have not faded away. Sometimes people use it in conjunction with attention and transformers. Sometimes there are situations where they do better. But by and large, the revolution of AI that you're seeing is in particular, generative AI, is often the conjunction of a transformer with other things. Like for example, with a unit or with glide or with this or with that. So we will talk about this. So now I just mentioned that the output, do you notice that T1 depends on just the hidden state, T2 depends on hidden state and the word that you have just produced. So there is an inherent dependency or autoregressive nature. You can't produce T2 till you have produced T1. So in other words, the decoder cannot produce all the words at one go. So in other words, the decoder cannot produce all the words at one go. Isn't it? And so this brings about today also one to the extent that the transformers and these large language models that you're seeing are transformers. They just large transformers in many ways. With additional things, but transformers, which we're going to talk about today. So they still have this big limitation that when you give it a question, a prompt, your input, which nowadays we call a prompt, and the output in the world of generative AI, we call it a continuation. So there's this terminology that is often used. Prompt input is the same as prompt output. People, if you see continuation, the capital capital of california is and you just give this as an input and so the output would be sacramento would be sacramental. So this is how it goes. That happens to be the capital of California state. So from that the word has stuck. People still often in formal literature call the output a continuation. If it is coming from a decoder, the autoregressive part of it so now that brings us to a problem what it means is these uh transformers this decoder I mean this whole architecture is just a next word prediction machine it will produce the next token and the next token and the next token. And you hope that by the time it is done creating the tokens, that this together, all these tokens put together makes sense. It is some text that actually makes sense. And we know today that actually it does surprisingly make sense for something that is just a next-world prediction machine. The fact that we get coherent answers at all from this, and all of you have played with ChatGPT, with BART, with Cloud, and with LAMA, open source models and so forth it is quite remarkable how much sense it makes it's almost as though the machine can think internally and it has premeditated what tokens it will produce one by one but to the best of our knowledge mathematically it is still a next token producing machine so that's the nature of the sequence to sequence models. Now that is where this paper comes in. If you notice that I talked about the encoder and the decoder and encoder producing the hidden state that goes into the decoder. So this is it. This is your and without going into too much detail. This is your decoder. And do you notice that, let me color it big and happy, this. Do you notice this output of the encoder, which is this, which you can think of as the hidden state, going into the decoder, making its way into the decoder. And obviously you have, so this is, this particular thing is your classic sequence to sequence model. Now, why is this paper so remarkable? This paper is remarkable and the giveaway is in the title itself. It says that you can implement encoder-decoder architecture, or a sequence-to-sequence model, entirely using the attention mechanics. You don't need to use RNNs, etc. So what came before? What came before is, first there were people using RNNs, LSTMs, etc. Then when the concept of attention was discovered in 2014, there was a gradual realization that if you add attention to the RNNs then or LSTMs, etc., somehow you hybridize the two, then you get better results. That was beginning to dawn on people. And so the groundwork was there. These people noticed that actually you can do away with RNNs altogether and only deal with attention. So remember, this is 2017 December. And so this work was being done in 2017. At that moment, the big problems that people were facing is that the RNNs, you could give it token-only sequential. And so it was a very slow process. The hardware had moved forward. The computer vision people were using the graphic cards, which had a lot of compute power. The AMDs and the NVGAs were producing these powerful graphic cards. compute power, the AMDs and the NVGAs were producing these powerful graphic cards. And those of you who have worked in creative art, like Adobe Photoshop, Adobe Premiere, etc, know that having a good graphic card accelerates your workflow. So even for the convolutional neural networks and other things, they were doing a pretty good job. They were happy and making a lot of progress. Whereas the natural language processing community, the text community, mining community, they were rather stuck with a sequential machine. One token at a time goes in, one token at a time comes out. And so that's what those RNNs and LSTMs were. That's what those RNNs and LSTMs were. So when this attention is all you need came out, it created an architecture purely for attention from something called attention, which had two remarkable properties. First of all, people had not fully realized how utterly foundational the concept of attention itself is. One could argue that even when this paper was written by the authors, the realization was still dawning on the research community, how vitally central the concept of attention will become to the whole field of AI, to become one of the foundational concepts. In fact, I would say attention, if there is one concept that is at the whole core of generative AI today, it is that of attention. The second thing people realize is that, see, with attention, you can send in the entire input at a time. And I'll explain what attention is in a moment. You could send all the inputs at one go. And so it would become the hidden state literally in parallel. In fact, there is no choice. You have to send in all the tokens the whole text at one go right so that opened up the the floodgates to parallel processing and the rest is of course history because when you do that too good a good thing comes out and a little bit of angst also is there. The good thing is that now you can process a lot of text at very high speed. You can build a model, train a model with massive amounts of data and you can then start decoding if you want to do it. If you don't want to decode, you just want to use only the encoder part, you can train it, pretty large models with this. And thus came models like BERT, distilled BERT, and so on and so forth. And then there were models which were, so there were models that we just mentioned this as part of history, there were models that were only encoder based, oops sorry, encoder based, let me use this one. Yeah. encoder based model. Yeah. Encoder based models, they are very good at retrieval and classification and such tasks. But the whole BERT family, BERT, Distil, BERT, Roberta and all of that, Distil, BERT, etc, etc. Right? And then they are decoder only models like GPT, the whole GPT series, and so forth. Right. GPT 1, 2, 3, 4. Right. And then these are very good at generative tasks. Very good at generative tasks. And these are very good at retrieval and discriminative tasks. So and then there are models that use the whole transformer, whole transformer. And there were things like Bart and so on and so forth, many, many models that use the entire architecture, great benefit. And so I believe, all of these, so there's a whole long list we won't go into it today it's a zoo is a very table zoo of large language models or transformer models out there. So we won't go into that, except for the one fact, the fact that I mentioned that there is such a thing and remember I mentioned that. It is just the heart of a transformer or the concept of attention is this dot product, the dot product of a query vector with the context in this particular case, I mean so with a given key how much attention you pay to any given thing. You bring it and. query is your context in some sense and the key like every every vector so given a token token ti you burst it out into three things a query a key and a value vector. And so what happens is suppose you have let's take five tokens but the one to do. Let's take five tokens, T1, T2, T3, T4. Let's say arbitrary many tokens, Tn. And let's write a sentence to make it all real. The cow jumped over the full name. So each of these are tokens. jumped over the full moon. So each of these are tokens. Question is, each of these therefore can be thought of as its own query vector. Q1, Q2, Q3, all the way to Q4, Q5, Q6, Q7. You would agree that the cow should be very much paying attention to the moon and full is all about the moon. Right? These should be big attentions. Right? And the word jumped, jumped, who jumped? And where did it jump? Here. So this is the way you would like to make meaning of the sentence. These different tokens should pay attention, differentiate. So the way to think about this is this query is sort of the probe or context. Then with which you probe. So suppose you want to find how much does the word cow need to pay attention to different words. You take the query of cow. This is your and for every word. Let's say that every word has a location to see how aligned that particular token is to the context, right? So K1, K2, all the way to Km. So you would do the dot product of this with K, Ki, and so up to some scaling factor and softmax, we'll just ignore it. Let's deliberately be sloppy and focus on the key concept and based on what this number comes out you multiply it with the value. So that particular value, which is the value of the actual vector. Sorry, this is pretty fast. Let's take a little bit more moderate. Let's take a little bit more moderate value, v1, v2, vi. So in other words, you would imagine that if this all works out, then what you should see is a q-cow with cow jumped. Let's say that the word jumped, k jumped. jumped let's say that the word jumped k jumped this should produce a pretty good value a reasonably high value because jumped who jumped cow jumped accounted what jumped high value one would imagine so this would come out and therefore whatever jumped is you you would pay more attention to its value to the token jumped right the cow would pay quite a bit of attention to jumped right that is attention that is the self-attention or this topic here is sort of self-attention because the tokens are paying attention amongst themselves to other tokens. And so this is, I mean, just to be mathematically precise, for technical reasons, what you do is you scale it to prevent it from blowing up, scale it by the dimensionality of the vector, and there is a mathematical trick to sort of normalize or just make it into probabilities right and it has other good properties which you won't go into you soft max it before you multiply it by the value and that is the big equation and this is the i suppose at this moment one of the most celebrated equations in all of ai as these days so that is this paper attention is all Need. Now, what you do is once you realize that attention helps you get a lot out of it, then you say if one is good, more may be better, the more the merrier. And so in this transformer, they went bonkers, quite literally. They just went, they just said that we see no reason to have only one. Let's have lots. So how can you have lots? What you do is, suppose you have these tokens, T1, T2, Tn going in. You can do, first of all, you can put these attention heads. These are called attention heads. I'll just call it attention head. Then you take the you feed it in here. There's more to it, something called position encoding, etc. But let's let's ignore that for the moment. Output of that you put it to another a one a two another attention head. A three you would daisy chain, so you would create a daisy chain of these of these, feeding from one or sequential chain, and then output would come. And then what you did is you said, well, that is sequentially doing it. Why not create another chain while we are at it? Just create another chain. And so you could have, I will just colloquially call it a chain or a tower. These words are not used in the paper, but I tend to use it. Think of these as one tower or one chain. Think of this as another chain, through which the input goes. And what people learned is actually this works out. This paper, for example, later on mentions that they observed that observe that one of the interesting effects that comes out is that each of these towers or chains, they begin to learn different aspects of the sentence or the text. Some will pay, I mean if I were to make it too colloquial, if something is paying more importance to the grammatical structure, something else will pay more importance to the semantic structure. So another table will do that and so forth. So that is it. And when they did that, I think the original paper had six such tables. And each table was 12 such tables. I think they made two models. I forget the exact number of the original ones. OK, I wouldn't go into that. I'll randomly say 12 towers and each tower six deep. But I may be off. It's been a long, long time since I read this paper. So we'll move past it. But the important thing to notice is, with this, in one shot, if you look at the results it completely it completely goes and blows away everything so just let's pay attention only to. Things. That I hear so do you notice that at that moment, the state of the art models, this is what existed before, right? And even these existed, these were beginning to use attention, right? All of them, they had results like this. And this blue is an important benchmark. Right off the bat, it made a vast improvement in just about every category like this one for example is a big jump that it made and that caught people's attention and the important thing was that you could use it for many things you could do machine translations you could do and you could do english concept constituency parsing and well there are many many things that you can do with it then came right afterwards a bird paper and then the rest is history once transformers came in 2018 just about everybody knew that they're looking at something foundationally different and actually I would venture so far as to say that we are only, we are even now trying to parse why exactly is attention so remarkably powerful. We know how it works. It seems like common sense, but somehow it seems more fundamental than you thought. And the things that it causes, like the way the large language models are successful, and in a way they're successful beyond the wildest dreams sometimes. They take everybody by surprise. Why is it so? I would say that we are only slowly beginning to understand. We don't quite understand. So we are in an interesting era the only closest equivalent i can think of is during the industrial revolution people created the steam engine the thermodynamics as a physics subject was not yet developed people had some antiquated views about heat they thought that heat was some invisible fluid that used to migrate from object to object, from fire to things and whatnot. So they had antiquated views. They didn't have a well-defined physics of it or the mechanics of it. Yet steam engines were the rage. Steam engines were causing trains to hinder across hundreds of miles of territory or thousands of miles of territory and steam engines were creating the whole textile mills and many many things manufacturing was uh happening at the breathtaking pace so the revolution of industrialization was in full progress it took substantial amount of time for people to really understand why is it that the steam engine or these engines work at all. And I would like to, I think, maybe I'm wrong, but I think that today we might be in a similar situation with generated AI. We sort of know why it works, but we don't quite fully understand it. We build things based on intuition based on empirical experimentation and so on and so forth and when they work we get delighted but there's a lot of experimentation and seeing whether it will work or not that is there in this so anyway the original paper takes this. It is in this spirit that a majority of American governments have passed new laws since 2009, making the registration of voting process more difficult. So it's a sentence, a pretty complex sentence, but notice how it is paying, words are paying attention. These are the query words. Let's take making as the query word. What should it be making more difficult you would agree that it is paying attention to the right thing quite a bit of it isn't it and these are different attention heads with and making will of course pay attention to itself that is understood and 2009 is relevant because that was the year so this was a remarkable feat actually there are many such examples and I will post this uh well I don't know there is no mailing list for that otherwise I would have posted so now I would like to make the next strike towards diffusion models, which is the UNET paper. The UNET was a very interesting paper that came, as you notice, if you look at the date, it is almost a fast follow. Actually, this one is a fast follow to 2012 and 2014. What was happening at that time is computer vision or convolutional neural nets were doing amazing. As I mentioned the last time, the handwriting recognition was getting to be really very good and a lot of image recognition tasks, you could give it a house and it would say it's a house, you could show it the picture of a horse and it would say it's a horse. house and it would say it's a house. You could show it the picture of a horse and it would say it's a horse. People were amazed at the time how well these networks were doing and a lot of activity was there. So this actually predates the transformer but follows those hectic days of convolutional neural networks. So it uses a convolutional neural network in a very interesting architecture that almost looks like an encoder decoder that we just talked about what it does is suppose you have an image you should draw something interesting in the inventory maybe this is your cat well that looks quite a realistic cat i hope and so this cat it would so i would just put it as this. It would go through something called pond convolutional layer, and then a smaller convolutional there, and you look if I put it on it still see through. I was trying to play. Sorry, is that I mean, they kind of do. Yeah, it's like a other box. Guys, is somebody asking a question? Okay, so it would do that smaller but and this isinks but the number of features that you have found increases that they're called channels so there will be lots and lots of those and then this will be even more lots and lots of features you have extracted this would come and finally you would come up with even more a whole tower of features that you have extracted from this and then so this look this looks somewhat like your encoder decoder and then uh those of you who are familiar with that it it is reminiscent of encoder decoder right and this is of course your hidden state z or hidden state that you produce from this with so these sort of architectures were there the encoder decoder was there but what these guys did and which explains the shape you they also put and this is a technical detail I won't go into but basically what they did is the data not only flowed from this path this part is the future part but what they did is they put some short circuits these are called residual connections they would leak out some of the information of the original encoding to this stage and this one they would feed it to this so they would these are called residual links or skip connections and the there is a very interesting reason why they did that they said that by doing this you the original pictures when you extract features from them like you extract a feature sound like very primitive features would be edges or. You know little tiny shapes and so on and so forth, when you extract those from that in a way you lose context, you lose position information. And so when you decompress it or like re-decode it in the, I wouldn't say decompress, but sort of decode it, then when you pass in not just the features, but also be any one of the things, for example, you could train it to end. This why had what you can do is let's say that this is X, you can look at X and y hat the difference between the two. and say that if the difference of this something called a loss function. I wouldn't go too much into it, but it measures the discrepancy between what you produced and what was the input. If you minimize this, then what will you get? This network will learn to produce a cat, something that looks like a cat, right? A very good cat, pretty much the same cat, right? In spite of this bottleneck and in spite of the data along the way getting destroyed and reconstructed, right, from the hidden state, it will still be able to produce pretty realistic replica of the original. If on the other hand, so this is like, why would you do that? Because this hidden state is in some sense a latent or compressed representation of the cat. The other thing you could do is, and which was very useful in those days, in fact, that is the use case that this author, the initial authors of UNET pointed out, that this architecture is amazingly good at discovering something called image masks image mask now what is an image mask what you do is suppose you have a picture that has let's say a street there is a street a road road going somewhere and somewhere and then there is a house here next to the road. I hope this looks like a house. I'll make a chimney also there. And then this is a tree. And here is a ball. And here is a kid And here is a kid playing with the ball. And here is a tree. So what a mask is this? It is saying that, hey, let me. Let me. This. This is the region of the picture that belongs to a tree. This is a well, I should have given it green color, but I apologize. This is the region that belongs to a house. This is a house. And maybe this is the kid. This is the kid. And maybe this is the ball. And let's say this from here to here is the road. So this is called, it has many names. is the road. So this is called, it has many names, you call it image segmentation. This process of discovering these regions is called image segmentation. And when you do image segmentation, what it does is it produces image masks. It says this thing, it will produce a label. Say it's a house and this thing it will say a ball and it will say a person and it will say tree. It will create labels. But the first thing is just create the mask. Just go find objects and create the mask, right, and this is the role. find objects and create the mask right and this is the role it turned out that this network was can be used to create a very very effective way to create masks and in fact it has been used for a long number of years for that because what you can do is instead of giving a loss function like this what you do is you send this picture into this unit let me just call it unit but it you don't expect it to produce this picture back for you but instead produce the mask masked picture masked or masks you expect it to produce these colored masks. When you expect it to produce the colored masks instead, then the thing that you optimize is somebody goes and hand colors the pictures or masks, creates the mask, and then you see how well did this neural network do, and then you teach it to do it right the way the human has taught it has done it right so this is this is therefore an example of supervised learning now that will look like fun exercise you're sitting down with a neural network teaching it to play with crayons to color a photographic crayons by putting masks or crayons all over the page but But these things, as always, what looks like fun, have tremendous application, as in this particular case. And by the way, this is the architecture, the way it is formally mentioned. Notice that the red color here, that this is the actual journey of the normal data processing. Encoder, decoder, this journey. But you also notice that in gray are given this let me use another color do you notice that these are your short circuits short circuits right or they are skip connections that is why it is shaped like a u and they called it the unit this architecture why are we talking about some obscure neural architectures? Because it turned out to be amazingly effective at practical tasks. So, for example, here is a differential interference contrast. It's sort of a microscopy image. You look at this image and one of the things that people would want to do is find the cells in there. So you're looking at a picture of cells. When you do, and obviously these things have tremendous relevance in medical imaging. And so you can give it the ground discovery of the masks, the cells. The white areas are the cells, the black areas are basically the not cells. It's the interstitial fluid. Now you have to look, I mean, I suppose, if you think about it and its impact, those of you who are actually working in the medical domain, you would realize that this was actually quite a remarkable result. Its qualities were that this algorithm is extremely fast. It can do and discover masks very rapidly. Unlike the previous methods that used to be computationally more expensive, this is cheap. And it was also very accurate. It beat well compared to other algorithms in those days. If you pay attention to... Give me a moment. Give me a moment, guys. Lost my pen. Yeah. So if you pay attention to this, you would see that it is actually, even with such a simple architecture, it is doing quite well. In fact, it's meeting the state of the art, though the best model, it's only by a tiny amount, but it's still doing quite well. Not at everything, but it's still, it was doing, or it was within a distance of the state of the art in most of the cases. So you notice that the best is 0.189 and unit was 0.382. So this one obviously needs a bit more. And then, if you look at this, so this is how you compare the effectiveness of ideas in this field so it is within air shot of the within throwing distance of the best models basically and this is even more illustrative right observe this this was the sorry this is the input image, input image, and one second, I'll move this image to the center. Yeah, input image. This colored image is what, this is what UNET found. the yellow boundaries that you are seeing, yellow boundary is the human drawn and if you look at it you would agree that it is pretty accurate. It did almost a perfect job of discovering the mask. So this was only one use case but this use case doesn't really relate us from the perspective of this diffusion models or this DALI 2 kind of models. There was another property that it could be useful. What you could do is you could give it an image. Let's say you give it an image of a child and what you did is you get you ask it for and let's actually let me take an image of a flower, a hazy flower, low resolution. This or a flower. And you ask this unit to produce, of all things, a high resolution image. High resolution image. Now, how can it do that? Well, you say, well, how can it just conjure up information that is simply not there in the picture? In fact, a few years ago, this would have been an unthinkable thought. Today we call it super resolution. And in fact, this is at the heart of this some of these diffusion models super resolution. The reason is that these convolutional networks and these units, they have learned by looking at thousands and thousands and thousands of images. What it is so once they know that it is a sunflower, for example, what can they do? They can put the statistically most probable details into that picture. They can sort of inject statistically probable details. And so you will end up with a high resolution flower. And that is a remarkable thing. That's one of our building blocks that we will use. So that is the unit. With that, I will move on to the sort of the next idea. I apologize, guys, that today is becoming a bit of a longer session, but I'm almost there. Let's bring the third idea together, and then we'll do that. This is where, and this paper came out not long ago if you think about it it's just a year and a half ago right it is towards photorealistic image generation and editing with text guided diffusion models quite a remarkable statement i mean just think about it it is claiming that you can make photo realistic image generation right and editing on top of it to work along with the text guided means you can give it prompts right you could prompt it and it would produce photo realistic images. So just looking at the title your first reaction is wow. Can they really. And of course we know that they can. But this was also the time, if you remember, I think by now and the initial Dali was out. out or not i forget the exact chronological history of it but this which was based on gpt not based on diffusion models today the state of the art are based on diffusion models not based on gpt so uh and in fact that is what we are going to talk about today uh in the next session i'll talk about more focus on gpt class of models. So what this does is, so first let's see what kind of results it produced. Today, we have gone far past it. Like one year later, we can do much, much better, but let's see what this paper could produce. This was something that, for example, DALI could not do. DALI could create using GPT, cute cartoons, like for example, a turnip taking a dog for a walk, all in cartoon form or sketch form, or an avocado, a sofa shaped like an avocado and things like that. But it couldn't create photorealistic images. and things like that, but it couldn't create photorealistic images. What this algorithm could do is produce photorealistic images. So I'll let you observe how well it does. I'll sort of... Can I zoom even more? Yes, I can. So I have put it in front of you, a hedgehog using a calculator. And obviously these are sort of unrealistic things. When you look at this hijab, it's a low resolution image, but still, well nowadays we can do much higher resolution. It is pretty impressive, isn't it? It's fairly photorealistic. a curgie wearing a red bow tie and a purple party hat so remember that no curgie picture was ever input you were just given this sentence that go draw a dog a curgie dog like this and this is what it came up with the next one i find very funny those of you who have been to mindfulness retreats that with personal retreats would remember that you are supposed to sit quietly in groups in absolute silence in these retreats so somebody gave a very sort of interesting prompt saying robots meditating in a vipassana retreat so somehow the system already knew what a vipassana retreat is and what meditating is and it made a bunch of robots to sit there think about it like this sort of things were unimaginable a couple of years ago unimaginable a fall landscape with a small cottage next to a lake you see and i won't go too much into it i suppose on the funny scale you have an einstein illustration of albert einstein wearing a superhero costume so next time you see einstein flying past your window it must be this guy this one and if you look very carefully you do find a little it's not perfect things are getting better and better but these things are not perfect for example when you look at a oh by the way this is a painting of a fox in the style of a starry night this is an interesting prompt first of all it has to know that starry night was mango's painting it has to know what a fox is and it has to paint it together it's pretty impressive there are a few uh subtleties that you may miss i don't know if you notice that look here there is another fox face hiding in there right and maybe you may notice that the bush's tail is a bit too big to my taste i don't think foxes have bushes i mean a foxy bushy tail that is as big as the body itself. Maybe it has, I don't know. But so there were a little small artifacts here and there. You have to look at it carefully to know that something is off. And this also brings about a very interesting ethical dilemma. What do we do? We are creating very exciting technology that can do all of these amazing things what's the ethical implication of it right what does it do how do we differentiate between fake and reality it's getting harder and harder and that's the peril of generative ai i'll leave it as that and this is is it. More and more and more. Now, I'll just give you guys an idea of how it is done. Very simple idea, because we are running out of time today. Oh, it just happened. More. Yes. So the idea is quite simple, actually. Suppose I were to give you an image. And this is where the non-equilibrium physics comes in. Non-equilibrium systems come in. Suppose I give you, let me take something very simple. What should I take? Let's take a surface, and on the surface is a jug. Does this look like a jug? Like a jug, right? And what we do is you take this picture, which I'll call X, and the first thing you do is you add just random noise, a normal Gaussian noise. What is Gaussian noise? Gaussian noise is noise whose distribution is like a bell curve. In other words, most values are small. Very tiny bits of noise are more common and large deviations or large values are uncommon. So if you add this, what you will get is obviously the same jug, perhaps. Oh well, forgive my bad art, but you'll get it with pixelation, some things moved around. Pass it to the next one, to the next one, and at the end of it, if you keep on doing it, the end of it, if you keep on doing it, you keep on injecting noise, what will happen? Gradually the noise will drown out the image, isn't it? The image will gradually get destroyed. So that is, you will end up with nothing but noise in the infinite limit. So you reach an equilibrium state in which this is just nice. So this is the process of diffusion. It's like adding ink or color to a drop of color to water. In the beginning you see these beautiful shapes but gradually all those shapes disappear. Why? Because the same thing happens. Those molecules come and they keep juggling and shaking those ink molecules around. The water molecules will come and so the ink molecules will shift a little bit and then a little bit and then a little bit and soon they would have lost structure and they're all over the place. And so you get a homogeneous distribution of ink and water. So in the same way you take this jug, you perturb it, and then you do another perturbations, and you do another perturbations, add infinity, so that you end up with nothing but just Gaussian knots. You say, well, what's so great about it? You just, it's like, you just erase the picture. But then you say, no, what if we could just erase the picture but then you say no what if we could reverse this process somehow reverse diffusion so diffusion process reverse diffusion process so you would say are you nuts how can you go from complete noise from randomness how can you ever go back to a jug right and that is the context of this paper it's quite interesting how they do it what what you do is you train the machine to add a picture let's say that what you do is you add noise to this picture so you get this picture let me call it a b you get b you feed b as input b as input to a network a neural net call it a unit let's say that you pass it to a unit. And remember, we talked about super resolution, adding details back to the picture. So you take B and you ask it to produce, one would have imagined to produce back A, but it doesn't produce B. It actually produces noise mask. Let me call it N. let me call it n so you would agree that a plus noise is equal to b right you ask the network to predict the noise so just come back with the noise mask because if it can do the noise mask then you can say a is equal to b minus n and so i can reconstruct a higher cleaner a well you say all right that is very good now what well you keep on doing it so you keep putting one train one unit here one unit here one unit and you keep stacking units each of which learns to reduce just a little bit of a noise from the picture and there's some more technical detail what you do is at each stage you don't take the entire mass but you take an epsilon times the n minus there's an epsilon here but anyway forget those technicalities logically speaking think it, b minus the noise would be roughly a. And you train the network, these units, to do small, tiny reversals, because tiny bits of noise are injected. So a little unit can learn to undo that tiny bit of noise. And so lots of units are stacked together, and it becomes a continuous process. This process is also a Markov process. Markov process is that the next stage depends only on the previous stage. It's a Markov chain, which is by definition true, right? Because you're going sequential. Now, you say, well, that is all very good. But from noise, utter noise, how in the world are you going? Oh, by the way, I said, you keep on doing add infinity. But in noise, utter noise, how in the world are you going, oh, by the way, I said, you keep on doing ad infinitum. But in reality, there is no such thing as ad infinitum, unless you want to rake up a massive, massive cloud bill. So what you do instead is your practical definition of ad infinitum may be, let's say, 50 or 100 grams, hundred steps. By then you can easily go from a beautiful picture of a jug to what is essentially like a Gaussian noise. The signal begins to disappear relatively fast even though you're doing it in very tiny steps. So what you do is if you train the units to undo it, now comes a beautiful part. You take the unit and remember the unit was, and just to better recollection, the units were this conf, and then conf, then conf, then this, and then conf, then this conf, and this conf. Forget about the too many technical details. And there were the skip connections also. And there was this direct data flow what people did is they started putting attention layers in between attentions while we are at it because people realize that whatever you do don't forget to throw in some attention everywhere the whole question is paying attention to what? Because attention makes sense only when you have a context and that brings in a place for your problem. So what you do is you take a transformer and you take your sentence like your what was the sentence robots meditating in a vipassana retreat you feed this into the transformer you get the hidden token states hidden states even all the way to the t retreat all the way to the t retreat robots now what you do is you have each of these pay attention to these tokens and then you have this also pay attention to each of the tokens and you have this also pay attention to this and then you have this also pay attention and so on and so forth so all of these attention heads are paying attention now they have a context in a way right they have these tokens so what happens is that when you are trying to generate so imagine that you want to generate the picture for robots meditating in a vipassana retreat when you are doing reverse diffusion guess what will happen when you are doing reverse diffusion guess what will happen as it is denoising that one particular unit is denoising that picture which looks mostly noise right so basically what you have started out with is noise it will it could have randomly subtracted some of the pixels, shaken up some of the pixels. But because of these attention layers, this text, it has to do a noise removal in the context of this text. So what it will do is it will produce a picture that is more, which has some little outline that may be of a jug how would you know why because the layers the units in between all the unit sequences they are continuously paying attention to the sentence so they will start doing this so you produce a output this and now this paper talks about different techniques they're clever tricks but one clever trick is that two clever tricks it mentions one is that you can take this picture created so-called clip embedding and then compare how close this picture is to the text so there is a way actually to see the closeness of the picture to the text. It is not yet done? Okay, go do it again. So at each stage you want to make sure that what the picture means a shape because of this and then clip is not the only technique actually there's another technique mentioned which is even smarter i'll just talk about it a little bit it is let's say that this sentence it can be somehow converted into a context vector let me just call it context vector so there is such a thing as an embedding space and let's say that the context vector is here. C vector lands here. Then what they do is they will pass another thing, but with an empty sentence. Nothing, no context. So no context vector may point to, let's say, this guy. And let's say that this is the Cartesian plane. This is the context vector. And this is a random vector as it goes through it becomes this or deciphers into this so then what you do is you play this very clever game you say that if this is the context vector and this is this and what we have produced the image that we have produced is, let's say, in this particular space, let us say that the image that you actually, I'll remove the context vector for a moment. Let's say that the image that you produced is this. So far, the intermediate image is this, and this is the image that you would have produced if it was random. Let me just bring in the context. So what it is saying is by looking at this delta delta vector which goes from random to image and it will the random rate from the image, push it up. Right. I've raised the difference to it and move it in the other direction. And when you do that, you get closer and closer. You get an image. You make those changes to the image that will make it closer to the actual context vector. And you sort of keep repeating this process. Right. Now, what happens is that in the second thing, you never really compute the context vector and you sort of keep repeating this process right now what happens is that in the second thing you never really compute the context vector you basically say i'll take the random i'll take the image and whatever the difference is i know that if i go opposite to the from the image i know that i'm heading in the right direction and so you keep doing that and when you keep doing that it turns out that you end up succeeding quite well so there are different approaches mentioned but anyway i'll stop here guys these are the core ideas now there is one more idea by the time you reached the the full diffusion model there is this whole idea that first you play this game on a low resolution image in other words let's say that you create a good low resolution jug so the text or in this particular case robots meditating in a personal retreat let's say that you create a low resolution image of robots and then what do you do you start super is resolution of it you keep on blowing it up and filling in statistically most probable details into it and soon before you know it you have a high resolution image a very photorealistic image of robots meditating in a personal retreat or in our particular case you'll have a very photorealistic image of a jug on the surface and so so that is how, I mean, if you have ever been curious, how does this work? How do these generative AI, how are they able to produce such a realistic pictures? And how come they're getting better and better? And now they're doing, by the way, this whole thing has gone, is moving very fast. You can do realistic voices, realistic videos, and many different things. But in particular, today I thought I would focus on the diffusion models. And I've taken quite a bit of time, actually, an hour and a half. So I would like to stop here and take questions now. I hope you folks found it interesting, but before I take questions actually, let me just sort of recap what we learned. Today we covered a lot of territory. So we covered, oh, this thing has again frozen. Okay, so I will touch off. Let's see. All right. So anyway, my writing board has frozen. So I'll just verbally mention, we learned about the the influential work, which was the transformer architecture, which said that you can build an encoder-decoder framework, sequence-to-sequence model, just using attention without using RNNs, etc. That is why the title, Attention is All You Need. That led to a whole revolution in natural language processing, in image, people applied then to computer vision and to many things. When you start hybridizing a transformer with other things, like for example, in encoder-de-coder kind of thing, or a unit, or in diffusion models, you start seeing what wonderful things happen when you hybridize many different neural architectures together. Because UNIT is a neural architecture, diffusion models, all of these are very interesting ideas. You start getting very, very good, like a diffusion model is just putting attention, convolutional neural networks, attention, and together, right, and text together. So you start bringing many different areas of work together. And then all of a sudden, we're looking at a remarkable, remarkable synthesis, which is generative AI for prompt to images. And that's what we learned today. We learned the unit. We learned the glide. It's two different pieces of the puzzle. And we'll stop here. I'll take questions now. Kate, if there are questions on chat or theater, would you mind speaking them aloud? No problem. Everyone, I do not see any questions on chat so much as some resources were shared, like the issues of artists and musicians not being thrilled with having their work appropriated for training the AI models. So everyone, if there's questions feel free to post them to chat and also we'll be happy to help answer them and go into depth yes and thank you for bringing out this issue yes it is indeed true artists are not at all happy because you train these ai models with existing art and then no one artist can compete against the collective creativity of all artists in the world. So if the work of all artists are taken and to train this AI model, it would be natural to assume that as this mathematics gets better and better, this AI art would exceed the work of any individual artist. And as you know, there has been a lot of protest in Los Angeles. There was literally a strike amongst the creatives who work in Hollywood on this topic. This topic was one of the reasons for the strike, from what I understand. So it is true and it is raising fundamental questions of the jurisprudence who owns this digital art created by AI if it has learned from your work and my work. Okay so many things would have to be rethought. For example you know property rights today in every country defines every every culture defines its property right. For example, the spectrum is pretty wide. If you discover, for example, load of gold, a vein of gold, gold mine in your backyard, does it belong to you? Does it belong to the government? Who does it belong to? And well, every culture, every country has to make a decision i believe in the united states and i may be wrong actually somebody told me that the law is anything below 70 feet belongs to the government anything above that belongs to you well if you are in a communist country nothing belongs to you everything belongs to the government and so on and so forth so every country has a different definition of rights rights are what we get in exchange for agreeing to certain law and order, like laws of the law and questions of law and frankly justice system itself needs to do a really big catch-up uh on this topic and figure out where exactly the the rights belong ownership rights belong gopi please go ahead there is oh yeah go ahead if you have a question yeah so the question that comes to my mind is when you're talking in the towards the end able to go in a in a loop until it reaches the level of resolution no no it's a guided process remember attention is involved it is attending to what the context the context is the prompt okay so what happens is say given random noise you can you can take a step in infinitely many directions. But it is forced to take a step in that direction, which will make the resulting denoised image or whatever, the emergent image, a little closer to the context. And then the next unit iteration does it even a little bit more closer. And you keep on making closer and closer to the context. And then the next unit iteration does it even a little bit more closer and you keep on making closer and closer to the context. That's it. Without the prompt you couldn't do that. So imagine if you just had white noise and you say go do something. Well it doesn't know what to do. Because if it takes just random noise out of random noise, you would be still left with random noise. So the prompt is the guiding process that that are the context that helps decide what noise to remove from a from that noisy stuff. So that explains to me that each prompt triggers a cycle. But within the model, you know, are there any interventions to make the model richer for some iteration and less richer for some? You know what I mean by you're having so many conversions in your encoder and decoder, right? When you're drawing the funnels. So are you able to do some initial ones which are a little uh lesser um not I don't have a reason to to say why I want that but I'm just asking is the model variable or is the model kind of there are tuning parameters like for example how aggressively you want to remove noise etc etc are parameters but generally what we have found is the more steps we do and smaller tinier steps we take in other words the slower we go the better one of the lessons that we have is um is that slow small steps generally beats fast aggressive aggressive steps in many, many algorithmic training, neural network training. So you take a lot of big, tiny steps in this process. Thank you. I got it. I understand. Okay. There's another online question follow up. Asif, in the past, you've spoken about how AI models can be poisoned with certain data. Well, there's now a program called Nightshade for artists to use to basically poison their data when they put on the web so that if big models scrape their data without their permission, it will warp and impair the model like it'll see yeah it'll see like a toaster is like a suitcase or something like that when it's prompted so someone was asking could this be considered an illegal counter-attack in a way i'm like well yeah i don't't know. Who was illegal first, right? Let's unpack it. So first of all, let me answer the last question first. Is it an illegal counterattack? It is absolutely not illegal. If you created your art, you have absolutely every right to inject whatever you want into the image because the the it is the principle of first ownership you own it you can do what you want with it you can put it there and people you did not allow people to use it i mean a fair use says people can put thumbnails of that image they can look at that image uh it is still a gray area whether they can use it feed it into an ai and the laws have to catch up but till then of course you can do what you the topic that you bring up is called adversarial attack adversarial attack is actually something and defense how do you protect your models from getting poisoned against adversarial attack actually i give an entire workshop on that it's a it is quite literally a two-day workshop on adversarial attack actually i give an entire workshop on that it's a it is quite literally a two-day workshop on adversarial attacks and defenses if anybody is interested you guys can reach out to me but it's a sort of a very specialized topic if you are doing a lot of ai it's a very fun topic to give you a flavor of it the first paper which was i believe in goodfellow diane goodfellow was itun, I forget, one of the great legends in the field, pointed out that you can take a picture of a panda, and you can make small perturbations to it, that to the human eye is imperceptible, you can shake up the pixels a little bit, and what happens is, now the model doesn't recognize it as a pada, but it recognizes it as a gibbon. And so you ask, oh my goodness, I can't even see a change in the image. It's so tiny, but the AI model is completely fooled. Well, and there are various hypotheses of how it happens. One of the hypotheses is the dimpled manifold hypothesis which and the other is high curvature the curvature manifold curvature hypothesis basically what it says is that the decision boundary between a gibbon and a panda is a surface and if the surface has little dimples so that you say on one side of the surface is gibbon and other sides as panda then you can stay in panda land make it look like a panda but just where the dimple produce uh the given part of the uh surface produce into the panda part right there plant a point and if you plant quite point right there you would have crossed the boundary even though for all practical purposes you're in punderland you have crossed over the boundary decision boundary or the manifold surface and so the neural network will therefore consider it to be a given and it is true adversarial attacks are a big topic and its defense is a big topic of research. I am actually quite actively engaged with this problem. I help organizations deal with these issues and put protections and safeguards around there, around that. And of course, if that interests your organization, reach out to me, we can talk about it. But a very genuine point, that is very genuine. But I don't believe it's illegal or the legality i mean what what the artists are doing using nightshade so by the way thank you for telling me about nightshade i didn't know that so i learned something but what i'm doing is perfectly legitimate however what uh and the topic is adversarial attack they are doing an adversarial attack on ai the only thing is that for every adversarial attack there are. The only thing is that for every adversarial attack, there are always defenses. And who has more computing power? So it's just a matter of time before there will be a defense. See, I don't see any more questions in the chat. If anyone has more questions, you can unmute and speak now. I guess they feel their brains are full. I guess they feel their brains are full. Okay. All right. So let's end today. Thank you for being here, folks. And with that, I'll conclude today's session. Okay. See you on Thursday. Okay, i'll go ahead and end the meeting then I suppose so let's just look at chat if anything else came. But if nothing else came, I suppose it's time to end. I haven't looked carefully at the chat. Are we are you fine with the chat? Did we take care of everybody? Let's see I saw a bunch of thank yous. Oh okay all right. Nice that's about it yes. Yeah okay. I'll go ahead and end then.