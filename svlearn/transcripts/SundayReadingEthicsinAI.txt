 It has been a question whether science is a force for good or evil. For the longest time, people have wondered, are we doing the right thing when we apply science to create technology? Science in itself is a neutral body of knowledge. It's a pursuit of knowledge for its own sake. But its application leads to all sorts of things. It leads to the nuclear bomb and it leads to the nuclear energy. It leads to travel to Mars. It leads to all these robots. It leads to many things. And there has been been continuous adjustment in society to technology. Now, the technological pace has increased to such an extent that we don't even get a choice these days to decide whether we want a technology or not. Very few technologies we are able to say no to. For example, human cloning is a no-no. We caught it in time and there were laws that were put in place and agreements and so forth, but a lot of the technologies that are coming out nowadays, they're coming out from corporations. Those corporations are moving very, very fast. We are entering, or we have entered what is called very very fast we are entering or we have entered what is called surveillance capitalism driven by machine learning which means that these giant machines now huge farms of machines whose main job is to steady us put us under the microscope see every of our behavior and capture the data and using the data now they very easily manipulate us. I cannot help thinking that this sort of the sort of things that we have had in the last 10 years in US politics for better or for worse it wouldn't have been like this in the 1990s before the social media came about. I suppose we would all agree that one way or the other, the society of today is a product of the social media. Social media is deeply informed by AI. It feeds to people what they want to hear. It panders to the confirmation bias. It creates society of similar thinking people, whether that thinking is right or wrong. So as we enter the new year, I thought we should reflect upon, and this was an unusual paper to take up. Usually we take away technical research paper. We cover the paper, but today it wasn't really a paper. It's actually a website, webpage from the Stanford Department of Philosophy on the ethics of ai and the i will sort of go through some of the topics that it covers uh in broad strokes but what i want to do i want to do that in the first part just quickly cover those topics but then more broadly open it out like i want to know as a discussion how do you guys feel about the contribution that you are making to society do you feel individually whether you have been a force for good or evil it's it's a it's sort of an introspective question and i wanted to gain everybody's perspective so if you look at this document, the first thing that it says, first of all, in philosophy, there has been a tremendous debate. What is the definition of moral? What is moral? For example, we say stealing is not moral, but a stealing on grand scale is capitalism. And to the ex capitalism seems to be the only successful economic paradigm we have all of this seem to sooner or later get into trouble so what is moral that that question has been there it used to be derived from religion the religious doctrines the various religious doctrines would say this is moral and this is not isn't it in the western hemisphere it has been from the Bible and the Torah of the Jews and then in the eastern, for example in India, the Manusmriti has been pretty influential and then the moral code that the Buddhists and the Jains have are strong influences. So morality was derived from religion but to the extent that we realize that religion can be a dangerous thing and lead to wars, the whole secular movement or this renaissance, the departure from deriving everything from religion led to the questions, fundamental questions. What is morality? What is ethics? What is ethical behavior? I mean, it starts with philosophers like Kant, talking about the so-called categorical imperative. One definition of good could be that action which if everybody did, it would lead to the benefit of society. So those are fundamental questions. We have to now ponder over it. We are asking this question, AI technology, is it being used ethically? But we are not very clear on what ethics is. We are not very clear what morality is. These are not quantifiable things. You cannot encode it. But there are companies which are gushing around and saying, we can create artificial intelligence that can ensure morality. How can you do that? We ourselves don't have a clear definition of morality. So what are these things doing? Besides the debate, what are the problems we are facing? The first problem that they speak about, and it's there, is that of privacy and surveillance. The reason we have all this internet services free is because they are not free. We are paying for these with our lives practically. We use these services and we are under the microscope. Every of our movement is tracked. Our in-depth profile is built. And those profiles are far more detailed than what even our most intimate relations know about when it comes to us. They can predict our behavior. There is a statement that when you enter a grocery store, the results of your shopping cart are much better predicted by an AI than by your shopping list. You always deck it with something else. So this is the reality we are facing. And so there's a question, and this was in this bestseller book by Harari, the Homer Duce, he asked this question and to quote him, what will happen to society, politics and daily life when non-conscious but highly intelligent algorithms know us better than we know ourselves. And we are seeing that, you know, this question he asked in 2016. I suppose he must have asked that before the elections because the election itself, all that, what was that, Cambridge Analytica and so forth, it. They just assume that machines would manipulate us. Now these machines are then manipulated by foreign powers. So what then is democracy? What is the point of democracy then? Is it still alive? And those questions are obviously very real if you're in the United States. obviously very real if you're in the United States, we are all facing an imminent danger, potential, some form of violence or potential civil right, a civil war, because 70 million people believe one thing and 80 million people believe something else, right? And the two cannot be reconciled because what they believe, what are facts to one is fiction to the other. what they believe what are facts to one is fiction to the other quite literally the two sides have different facts so as rational human beings if they reason from those facts they will come to entirely opposite conclusions which they have come to so each side is absolutely convinced that the other side is wrong and to a large extent i believe that the blame is not in this or that politician. I think the blame squarely falls on us. We as engineers have not cared, I believe, about the ethical issues and we have let it happen. So anyway, that's just a thought and I thought I'd start the new year with it. We are ending this course and you are by now, hope very empowered very enabled you have learned a lot of ai you will be using it and i felt it would be good if we end these workshops at least towards the end we talk about these issues the manipulation of behavior is rampant, we create things, you know, there's a concept called hooked. You deliberately try to create addiction. You want to make sure users come back. Is it any surprise? I mean, just as a remark somebody made, there are only two industries, two sectors that call their clients users. One is the drug industry or the drug cartels and the other is software. And I think it says something, users. So, you know, there's a very interesting connotation and we try to give them the same habits of addiction that the casinos try to give. You make these people to come to your site again and again and again. And we are doing such behavior and such interesting analysis. I learned somewhere, and I believe it's true, that a Pokemon, the Pokemon game in which people were roaming around with their cell phones. Do you guys remember the Pokemon game? Pokemon Go. Right, Pokemon Go, I believe. Yes. So apparently that was a deliberate experiment created by Google. It was the first experiment that asked this question, will human beings, can we just change their behavior? Quite literally, can we control their behavior? And they did, they would put these characters, what are those called? Pokemons, whatever, I'm not very familiar with it, but apparently they would put them in front of a cellular phone store, just to sell some cell phones, in front of some, you know, shopping, some shop front for them to go there and while they are catching their Pokemons, they are also implicitly doing window shopping. And as a social experiment, as a manipulation of the human beings, It was a tremendous success. And it sort of goes on. We know obviously about Cambridge Analytica and what it has been doing. We learn every single day that governments are hacked. Apparently US government, we don't even know how many departments have been hacked. Certainly our military. I mean just the thought of it that our nuclear weapons, the department that controls and manages our nuclear weapons has been hacked. Everything seems to be hacked and behind a lot of these things with the data that they steal, they seem to be fodder for AI agents to then use to manipulate us it seems. So it's fairly disturbing. That is an issue that needs to be addressed. The other is the opacity of AI. We are entering, and this week is about interpretation or explainability of AI. It's very core and central. It's not a marginal topic. It is rather a tragedy that most textbooks on AI, and most of these books on deep learning and you know TensorFlow and Keras and whatnot, none of them seem to have this as one of the core topics. We seem to be caring only for the accuracy of our predictions and interpretability be damned. Why is it making those predictions? With it goes accountability, completely goes accountability about this. So biases that are there get perpetuated. So there was a system created to decide whether somebody is going to be a repeat offender, recidivism. It turns out that they created such a system and it was actually put into production. Then somebody pointed out, some researchers pointed out that its accuracy is no better than random people, just random guesses by random people. And it was deeply infested with bias against the blacks. It had all sorts of problems. So the other issue that it brings up is the exuberance with which non-technical people and the overconfidence with which they adopt AI. We create hype, frankly, our industry creates hype. There are movies coming about, everything happening, that AI is so powerful and people believe that it is way more powerful than it really is. And they use it with catastrophic results. We know about the Amazon's experiment. Amazon tried to, Amazon had two failed experiments, I believe, in this regard. about the amazon's experiment amazon tried to amazon was had two failed experiments i believe in this regard they tried to hire people based on an algorithm and it was a disaster it was terribly discriminating against women and other protected classes why did it do so if you really think about why that happened the the causation seems to be that it read from data of past hiring in Amazon. And what the AI did, logically, is understand the pattern. And it turns out that if you look at the historic data, there was endemic racism, there was endemic discrimination against women, unacknowledged. And so when you feed that data into it, the AI learns to be racist and misogynist in equal parts, I suppose, I'm just sort of putting words there, but sort of like that. And I didn't think Amazon would be the only one, it became famous. I'm sure that lots and lots of companies which would be guilty of using software like this and coming to or having biases. So the fact that AI, we are not caring that AI must explain itself. We are just so enamored by its accuracy, by its ability to do things. Asif, leaving deep learning aside, right? Any Bayesian model would have done that. Yes, it's when I use AI, I include all of machine learning in it, not just deep learning, all of machine learning in it. So our biases are basically a manifestation of past observations. Exactly. The data had biases, you're feeding that it to, you're teaching the AI with that data, which has bias. So of course it will learn the biases, right? And you don't acknowledge the biases because what has been our strategy, I mean, we always believe, I mean, see this country has made a tremendous progress when it comes to Black rights, right? With all its flaws and blemishes, we are in a far better place than we were in the 1960s or 1950s. But while that is a positive news, it is also true, and I believe it's globally true, it is also true in India, it would be the discrimination against the Dalits, which is absolutely horrendous, and the Shras are absolutely no different and in fact many degrees worse, many orders of magnitude worse. So in spite of progress in both the countries against the underprivileged people, the discriminated people, it is also true that we like to claim that more progress has been made than has actually been made. People would like to believe that the problems are solved. In India, there are so many protests that let's get rid of reservations. The problem is solved now, but it isn't solved. And in US, we don't have the system of reservations. There was affirmative actions, or sort of something like that. But if you talk to the Blacks, they will assure you that the situation has not improved as much as people would have you believe. Likewise for women, you know, like for me, it was very eye opening. When the MeToo movement came about, it seemed that like I was under the belief that people who molest women or mistreat them in the workplace but they're like maybe one in thousand or one in ten thousand or something they're just the sort of uh very very bad people and then the me too movement comes about and it seems that if i were to look around at 20 in a room of 20 i could fairly be sure that somebody is mistreating women in the workplace or has done something terrible against them. And that is a shocking realization that when you enter a room, you face that reality. So progress is far less than we would like to. All the data that we have is, and when you feed it into AI and you train the AI with it, AI will learn what you teach and it will learn the biases. I think as if I was making a little nuanced point that there are biases in human beings. If we have to call out AI as specifically something with a problem, the basic data that we need to see is humans are evolving faster, but the machines that humans created are evolving slower. Is there evidence to that fact? There is evidence. For example, in the US at least, after the METO movement, there's a huge bit of concern to remedy these situations. I don't know how much will happen, but we are doing that. But the data that we are using is nobody is realizing that the date, if you look at 20 years worth of data, then during those times, our social modes have changed. There's a lot of bias in previous data that you don't have in today's data and so forth. Okay. Yes. AI will learn from that. And so, I mean, see, the point is not so much whether you can fix AI, the point is you can fix AI. But how will you fix AI unless you acknowledge the biases? And you have your eyes open for the biases, right? So that is it. And the other point that these people make, which is that they call it the algocracy, there's the plutocracy, you know, the rule of the rich. There is the aristocracy in which aristocrats rule. Democracy is supposed to be this. But algocracy is all about the rule of the algorithms and we are living in the reign of algorithms. Algorithms rule our lives. Everything we do is controlled through algorithms. And there was an excellent book that they referred to. By the way, that book is very good. It is called The Weapons of Math Destruction. If you get a chance, it is a four-year-old book, I believe. Read it, Weapons of Math Destruction. I don't know if anybody is familiar with that book. By the way, Kate, you are very socially aware. Would you agree? Would you concur, would you concur with what I said, or would you like to say something on that topic? Oh, yeah, I agree that, you know, if we're using data that encompasses humans and human experience and history, naturally all the biased acts of humans and our judgments and our actions is going to be baked into that data. It's kind of unavoidable how we counteract that and correct the bias is a huge challenge. Right. So, all right guys, so this goes on to talk about, for example, bias and decision systems. There was this whole thing called predictive policing, which is going on, by the way. You can predict where the drug exchanges would take place and so on and so forth. But it also brings about the potential that you would perpetuate, like you would mark certain neighborhoods as perpetually bad. Right, and so on and so forth. So there are a lot of things, many of you must have watched the movie, Minority Report, right? In which you can know that a crime is going to be committed and you can catch it before it is committed. It's a terrible idea, right? That algorithms can actually be used it is committed. It's a terrible idea that algorithms can actually be used for such purposes. And so what does it mean? You could be arrested. If you really think about it, you could be arrested because the algorithm thinks you're about to commit a crime. And you could be charged of a crime because an algorithm thinks you were going to commit the crime, just the thought of it. And so there are all of these issues that we talk about. There are issues about robotics, robots, what can they do? In Japan we use robots to interact with the older people, a lot of the aging people. We give them warm skins, they apparently are warm and fuzzy, they have human expressions and people are trying really hard these days to give robots a very human expression when they are designed to be caregivers. Perhaps that is good but it also asks this question that is it really a very comfortable thing to do? There are people who are proposing to Alexa and to all of these, whatever these things are called, assistants, Google's Google Voice or whatever. Because these lonely people at some point have no one to talk to. So when they talk to these machines, these machines give intelligent answers apparently. And these people get so touched by it that nobody has talked to them so nicely. They actually propose to marry these people because they're sure behind it is some intelligence, some human being actually there. Right? But so far it is all fun but what happens the day somebody starts manipulating this emotions this sense of falling in love with the machines and many place you into buying a lot of things into spending all your money or giving all your money to them or whatnot or maybe God forbid commit a crime right so uh all of those are potentials you know so it sort of talks about that uh other question that uh is increasingly there that they talk about is the sex robots and what does it do to human beings already um human beings are being objectified with respect to this i mean when i look at the movies now maybe I'm a bit old fashioned, but I sometimes have to just walk away from it, because I feel that it is sort of degrade. So it's sort of, you know, the way to objectify as human beings is a little bit too gross. It wasn't like that 20 years ago, right. And to some extent, a lot of it has come about because of the technology and now you create these robots. And then what does it do to human relationships and so forth? So this book talks, this sort of article talks a lot about that. It talks about the effect of automation. If automation is going to get rid of all your jobs and not create new jobs, then is there a moral imperative not to use that AI, not to use that automation? It's important because we all collectively own the earth. The guy who has the money and can afford the automation, if he can do that, it will be a winner take all society. If he can do that, it will be a winner take all society. If we know for sure that new jobs are not going to be created and this will only eliminate jobs, how is it moral to allow those automations to come in? And it is a question that has to be asked because if you look at it, people talk, and this article points to something called the dumbbell economy. The dumbbell economy that they talk about is the economy in which there are high tech people, highly talented people who are in great demand and paid a lot. Then there are very low tech people, people without skills, who are in high demand to do, you know, those hourly wages or basic service jobs, and they are paid very poorly. But the in-between world that used to belong to, you know, qualified jobs in factories and offices, the white collars and so on and so forth, they are disappearing. You know, that's the dumbbell is the rod in between the two belts, I suppose, the two sides. And those are disappearing. So you are either in the category of highly paid people or you're in the category of people who are just, what is the phrase they use, burger flippers. Go ahead, Kay. Living check to check living check to check yes and uh that's the invisible poverty it's invisible poverty i mean it's a question worth asking that has homelessness increased since all of these things came about right has the disparity of wealth increased it has increased it's not a question worth asking. But the question is, are we responsible for it? I mean, if you have to pin the blame to somebody, would it not be the tech sector to pin the blame to? Would it not be on our foreheads that the blame should be stuck? So those are questions sort of worth asking. The reason we ask that is ultimately, these are questions that we engineers don't ask. We work for this mega corporations and those mega corporations certainly are not asking. They are profit making machines. So who is going to ask those questions? Everybody else seems to be disempowered, right? Or not capable of asking these questions. So somebody has to, somebody has to be a full human being, not just an engineer. Realize that they have children and grandchildren in this world, and who will inherit this earth, and they will inherit what we leave them. So those are the questions here. And so in this phrase, this article obviously goes on to other things. So for example, autonomous vehicles and automax. I just saw a cartoon, which I found very funny. A dog is looking at a Roomba, one of those automated vacuum cleaners. And it is asking the question that if I poop and you spread the whole poop all over the room, who is to blame? And I suppose that brings out the dilemma about the whole thing. So for example, when a car comes and hits you and it was in full automation, who is to blame? Were you driving badly or was the car to blame? It's a machine. Can you take it to court? And what are the implications? We have to work that out. There's a whole question of automated weapons, as you probably are aware. and greatest war technology, one of them I saw, would literally rain down small watch-sized little drones. And each of those drones would be programmed to find human targets. The moment they found a human, they would just come into the face of the human and explode. Terrible. Just destroying the person. So these technologies exist now and the AI in them is capable of knowing that this is human and not, for example, a box or a stone or something like that. And so when you destroy people like that, what are the ethical implications of that? Is it okay to destroy your enemy like that? How do you know that those are not civilians and those are truly enemy combatants and so on and so forth? So those are the issues with the automation that this article raises. And then comes the whole question of whether machines should have ethics as they grow and move more towards developing intelligence even very narrow intelligence the question therefore is what how much of ethical concerns they should have so apparently Kant made the statement that the more reasonable a person is, the more well-reasoned or logical a person is, the more ethical he is likely to be. Well, I suppose the years after Kant have proven otherwise. We know that some of the worst human beings, Hitler and whatnot, they were extremely analytical people. They were very well-reasoned people. And with cold calculation, they could just go and throw people into gas chambers. So that kind of reasoning simply wouldn't fly today. But so then the question is, what do you do? What is it? There's this article mentions the Isaac Asimov's proposed three laws ofics of 1942. It says the first law is that robot may not injure a human being or through inaction, allow a human being to come to harm. Second is a robot must obey the orders given to it by human beings, except where such orders would conflict with the first law. And the third law is a robot must protect its own existence as long as such protection does not conflict with the first and the second law. Very interesting things. People have debated this. The whole thing is that is it time to encode these things into the machines? When will it do? We are already talking about the singularity and the super intelligence and right? And what will happen? But even before that, we have to ask the other question. We use AI as tools, as objects, but can there be subjects as these things grow in intelligence, do robots have rights? Is it okay to like, is some behavior towards the robots unethical? So the one example that is given sometimes is, you remember the Boston Dynamics has this big dog and so forth. Have you guys seen the videos of that? Those robots? robots yeah so those are amazing machines but they behave like you know animals four-legged animals they can crawl they can do things and they can't fall uh they like behave like mules or dogs and so forth and you see videos of people kicking them and they are able to survive the kicks you know they regain their stability but one of the questions that comes somewhere along it to the extent that we can project sentient feelings onto machines, we do feel and wonder whether it is fair to treat a robot so badly, to push it around so hard and so on and so forth. And these questions will become more and more pertinent as these machines begin to look more and more human or at least living. We human beings have a tendency to project our emotions onto other things around us. The fact that people propose to Alex and all this Google assistance, etc. is clear evidence of that. Many people are totally in love with their car and they talk to their cars and this cars are not even intelligent at this moment, right? And so what happens when these robots become more and more like humans in the at least the project the appearance of being like that. And then obviously the last question that this article deals with is that of super intelligence. Truly what is the implication if there is a super intelligence around? That reminds me of a TV show, like very much actually, A Person of Interest. It is an old TV show. Some of you may have seen it. Anyone has known about that? Person of Interest. It must be there on either Netflix or Prime or somewhere. Check it out, see what it is. It's about a super intelligence that has been created. And it asks fundamentally those questions. There's one super intelligence, which is a force for good, and there is another super intelligence, which is a force for evil, as always in these TV shows, this war of the good and evil and so forth. But I believe that the TV show, as I watched it, I felt I was quite amazed at how well it articulated some of the fundamental ethical issues and concerns we have with artificial intelligence. And it sort of seems to be coming. And at the end of it, actually this article towards the end, it asks about a very interesting question. These days we talk of the so-called great filter. A great filter is the time when, past singularity, when these robots, these machines have become truly intelligent and once they have become truly intelligent they have gotten rid of us completely and humanity has completely vanished and is that the logical end of ai is that what we are all heading towards right creating the ai that will end humanity and then it actually um says that maybe the great filter explains the Fermi paradox. So the Fermi paradox is this thing, the world is filled, the universe is filled with gazillions of stars and there must be gazillions of planets and whatnot. How is it that we don't seem to find intelligent life anywhere? We don't seem to find intelligent life anywhere. So one explanation would be that all life form ultimately grows in intelligence and then they create their own artificial intelligence and those artificial intelligence finally kill the life forms. And so life forms can't be seen because what you see is the graveyards of all these life forms. The AI has destroyed all those life forms can't be seen because what you see is the grave, graveyards of all this life forms. The AI has destroyed all those life forms. It's just an interesting thought actually that could the great filter be an explanation of the Fermi paradox, right? And is there something as likely, the great filter where intelligence, super intelligences will get rid of us. Right, and all life forms after that. So that is that. And so that's the gist of this paper. It ends with such thoughts, it doesn't go any further. Not a paper, this sort of long article from the Stanford philosophy Department. And well that is that. So guys, today I've sort of been speaking for quite some time. What I would like to do is just ask this question from all of you. I want to hear your views like and see how much you guys, what you guys think. I'll sort of go in the order in which your name show up in this Zoom. Let's have a discussion of what it all means. Balaji, what would you say? How do you feel about the technologies we create and the work we do? So I think it's, I mean, in my personal life, I use Google, there's a Google I talk to to switch on the lights, really exciting. I mean, there's a small things I do. And then I saw this Netflix series you suggested, then I saw how things, how are these things controlling us to a point where the whole population could be made to think in a certain way, without we knowing about it. So there should be a ethical boundary needs to be drawn for this technology. Technology is like a tool. Without a screwdriver, you can't pull out a screw easily. The tools have come for that purpose. And, you know, we need to use it instead of misuse it. That simple thought in my mind. Nice. But do you feel that overall your life has been a force for the good? Can you repeat that? Like, do you feel that the technical work you have done in your lifetime has been a force for the good? Yeah, I mean if I do a depth first search, I mean at the top level reliability. So the reliability means it goes into the car to make it reliable. But if car itself is a good thing, I mean if I go and deeper to see or the work that i did at the sufficient level it has done good but if i go deeper and see is it serving the bigger cost i don't know answer this question nice thanks to you thanks for your input dennis what do you say what was that paradox you were saying uh the name fermi's paradox right uh so there's this book uh it's like a new sci-fi uh rude actually told me to uh read it and then i never did but i read the summary uh actually president obama like in many occasions, said he recommends reading the book because it's pretty forward-thinking. So it's called The Three-Body Problem. The Three-Body Problem. Okay, I'll read that. Actually it says the universe is like a dark forest. Intelligent species actually view each other as threats. Oh yeah, dark forest theory, yes. So the moment we send signals outward, we're kind of asking to be killed off by a sniper. Which is kind of unsettling since I think there are reports that we received some signal from a planet four years ago, just recently. But inside measure, I think we still need to sort of accelerate where we are, or we won't have anything at all. So there's another side of this, I guess. So we need to compete with the aliens, I guess. Yeah, it's here competing with the aliens at this moment for survival right yeah yeah so for others people who haven't heard of the dark forest theory dark forest he says that the reason the forest is completely quiet in the dark is because if you make noise you make your presence known and predators will come in essentially, you'll be food. And the way people apply it to aliens and this concept is that they say, okay, look at what people do to once they know there is a land, for example, they often, one example in this movie, which was that movie Arrival, a general made is that the reason we are scared of these aliens who have come is think about what happened when we went to Australia. Well, we destroyed all the original people, Aborigines, and enslaved them and took over the land. And so I suppose the point he was making is he believes that if aliens come in any form, you should just assume that they are for evil. They'll conquer us and enslave us. And there's another thing. I'm pretty sure it's probably crazy. Basically, this guy, I think from the former Israeli government says like aliens has been contacting the United States for decades or whatever it is. And there's like a space federation and aliens say like, we're not ready. And what I think is that, I think as a species, our resume should be how well we take care of our planet and other species on the planet. It's an indication whether or not we are civilized, I guess, in the intelligent sense. we can use ai for you know environment protecting you know uh animals see plants or whatever you know uh i think it's it can be good you know there was a movie called transcendence i don't know if anybody saw that that was it there the ai took over the responsibility of uh protecting the planet and did an exemplary job of it. So anyway, see that movie. Harini, what do you think? AI, presently when I see it is helping, but then deep down I feel worried about what it can do, not just for the humans, for the planet. And I think we are moving at a very fast pace. at a very fast pace and so that that is a threat for all our resources and the human beings and even for our emotional well-being that's what i feel yes it is helpful in the you know making us connected or healthcare and all that but in other words you're concerned. Yeah, I am. Yes, remember that when you go and get a job, you contribute. Yes. Kate, what do you think? I think at times that, especially the events of the past four years especially, that it might not be a bad thing to have robotic overlords, that it might be something that humanity deserves. If we can't prove we can't take care of things ourselves, we might need better replacements. Oh, so you're inviting the singularity. I'm wondering if it's not the worst thing given people. Yeah. Yeah. Interesting. Well, we need, well, on a more serious note, we need to make sure that we have government performs its proper role of being able to regulate, that we're not just ruled by mega corporations and oligarchies, that democracy means something. Yes. And there's a lot of practical actions that can be taken on that. So I have hope for that in the short term. I don't think the singularity would happen in my lifetime anyway. No, this democracy, in my view, is something worth cherishing. And I'm very concerned that we in Genius would be guilty of getting rid of it. We practically are guilty of getting rid of it, seeing the events of the last four years. If blame has to be put somewhere, it has to be on our heads. Yeah, well, to make up for Cambridge Analytica, I did hear that Zuckerberg, as maligned as he is, a lot of it deservedly so, is putting money into making sure local various low-level electoral offices had money to run their elections properly given the lack of the funding should of course come from the federal level but we know that the federal oven has been really hampered by having a mobster in charge. Yeah, I'll say it. You saw the headline news on New York Times today, isn't it? The interesting phone call that's being talked about. Oh, yeah, it's just so mobster. It's the same as like with Ukraine. It's like, definitely quid pro quo. It's like here, find some dirt on my opponent, you know, or we'll yank your funding. I mean, it's just so improper. Yeah, we need a lot of cleanup in this country and attacking misinformation disinformation in general globally. That's something that's something we can with ai functions i mean when they've attacked the problem and really wanted to solve it instead of just focusing on the dollars uh social media companies have been able to youtube's been able to clean up i was reading wired articles that were youtube has been able to you know lessen people going down rabbit holes of conspiracy theories because they would recommend another even more radical video and they've they've actually squelched that pretty well so you know they're kept accountable it it can be fixed yeah i hope so it was terrible actually when i see the youtube recommendations that pop up it's quite uncanny in how well it anticipates what is it that you want us to watch. In my case, it keeps recommending me all the AI video, you know, one presentation, one seminar after another. So that's how I keep up. In a way, it's become the newspaper, because what's happening in the AI world, somebody would post a YouTube and then youtube would come and recommend it to me that's been happening for some time premjit what do you think i i i think at the core of all this is the the human desire for wealth, right? And I don't fault like a large population of engineers with the responsibility of having to save the world and not doing well at it, right? It's the few people who drive the corporations who determine what the engineers work will go ahead and do. Engineers did good work long ago, when you say supply chain management and the technologies that i worked with right that's you're using mathematics to optimize and reduce wastage that was a good use of engineering mind right you're figuring out algorithms that will optimize the supply chain and reduce wastage effectively know, you're squeezing money out of the system and making it available for good use. I think in the recent past, when the focus was all around advertising, and you're gathering a lot of human, you know, attributes to be able to target them well, that's where this phony thing of when the products like Gmail and Google Maps and so on, the actual product is us. We became the products. We became the products. But there's huge money in it because the money that was otherwise going in television advertising and billboards and all those, there's a large amount of advertising money that got channeled into what facebook and google revenue is right so that kind of changed a few things but at the same time if i look at now the amount of innovation that's happened now we're able to have you can speak to a computer and it's pretty much able to recognize your voice and you can understand the nuances between the different people in the house all that is advancements that happened because engineering moved forward so that's all good see some people believe fringe it and i think with merit that if we just say that we are like engineers often say that these are big companies they they're powerful make the decision and they make it based on the need for money, for the greed for wealth and so on and so forth. But it is also believed that, see, they are powerful and they get away with things because we let them get away with it. Because engineers are not taking... As human beings, they are rather deficient in their social and political responsibilities. Human beings are a political species. And if you just completely abdicate social and political implications of your work and don't stand up for it, then of course, workplace will be designed in such a way to squeeze you to just maximize profit at the cost of society, which is what is happening. There has to be more social and moral sort of a backbone to the engineer, which in my view is sorely lacking. Most people, for example, if you ask them to talk about anything, just economics, anthropology, sociology, basic things that are the core of human existence. They wouldn't be able to tell you, most engineers would be, forget about even humanistic things, even basic economics, ask them to differentiate between the case in economics and maybe the Chicago School of Economics and different parts of economics, like how do they differ? Most people can't tell you, right? But should they? Yes, they should. We as human beings do. See this is the thing, if you step out of engineering departments, you go and do, I don't know, a bachelor's in arts and sciences, you will be forced to take courses in which you become a much more well-rounded human being. In engineering, we have always made the excuse that the course burden is so much that there is no time for humanistic learning. At the end of it, we are producing people who are absolutely feel no sense of responsibility of the implications of their work for good or for evil. They would rather believe that the work they're doing is for good. The basic definition of a corporation needs to change. There's great new ideas of like certified B corporation, where social goals, social good goals are written right into the expectations. Exactly. social goals, social good goals are written right into the expectations. But your average corporate, the standard legal definition now of a corporation is that financial, you know, the quarterly profit is the bottom goal. In fact, they want to punish executives who don't seek that, who actually try to meet social and environmental good goals. That's something that needs to be fixed because there's been a long standing attitude of check your conscience at the door when you go to work for people at all levels. Yeah. And you know, some of these business models work i'm reminded of costco costco apparently as i don't know if you guys know it makes no profit on its on the things it sells you and they have no intention to make profit or become the next amazing but they make their money from the membership annual membership fee so i felt that in way, they are trying to bring the best value to their client base, not sort of treat them as things to squeeze money out of, but serve them at the end of it. And I don't know, maybe Costco is doing something evil. It's not that they don't make money. They have very strict rules for their merchandising department in terms of how much you're allowed to charge a premium so that's basically upper limit is 13 percent i looked at the case study it's 13 percent now 13 margin as you know in business by the time you account if you up mark a product between the wholesaler and your price by 13 percent it barely covers your costs it puts a challenge on the merchandising team to go find good products yes they can source it at such raw bottom price rock bottom prices they can still survive and actually they're doing well yeah they're doing well but if you look at their revenue model they're making most of their money from membership not from the selling of things so and they have a strict rule they don't want to mark up anything more than 13 percent i believe is their feeling so anyway so i don't know if such business models can take off or whether and about costco of course we don't know the whole story whether they are also doing some evil but the when i read about this case study in detail i was quite impressed that somebody's thinking like this and not just trying to be a hockey stick growth curve like a maison right so that's that sh Shankar, what do you say? I come from a completely different background, environmental sciences, oceans. Yeah, things are in the tech sector, things are moving so fast in ocean. The sensors that measure temperature have not changed the last 50 years. And then there are a lot of, even in 2000 people used to see that, I used to see, analyze sea surface temperatures, oceans and estuaries we used to see that high temperatures on a even on a normal day even power plants used to come and tell us that oh what we are discharging is not making an impact it is the temperature rise you see in normal temperature due to the warming is more impactful than whatever temperature we are discharging into the ocean. So that is the theme there. But things here, it's all click through rates. I work for a book company. It's all based on click through rates, the revenues through click through rates. So that's the way it is yeah things are very rapid here so that's the way the business runs and especially as many of many others talked about this pandemic the small business is completely operated the big corporations have completely gobbled up their businesses. Yes. They don't have, the big businesses have the AI, all the AI, they can do whatever. They want to. So basically, yeah, that is, so a lot of people are unemployed and the small business is completely gone down. As the owner of a small business, I can speak to the pay. As the owner of a small business, I can speak to the pain. Right. So, no, but so Shankar, to your question, the question was, for the work that you have done in your life at the end of it, would you feel that you have a clear conscience that it was all for the force for the good? Yeah. So to be honest, no. Yeah. Yeah, so because I come from a country, that's why I started with a completely different environment and coming from oceans, atmosphere. That's a completely different idealistic world out there. Yeah, compared to it, I would say that the work I did in the ocean atmosphere field, that I much bigger, I feel good about it than the work I'm doing for the last 10 years. Shankar, you would agree, right, that engineers shouldn't abdicate their political and social responsibilities. Yeah. They should be engaged. They should be engaged and seeing how they are in the world, no? I think I also come to that point. I don't know like how many engineers have the power to do it as Premjit also pointed out. Lot of, even in oceanography, a lot of people wanted to save the planet, save the oceans. There are not many opportunities. They, all of them, they are in this click business now. Yes. No, but see Shankar, it's also the thing is, you, power is never given to you. Power is, is just taken. If people like democracy is people taking the power, right? The Kings didn't just give power to and foster democracy by any means. In the same way, if you want to have more empowerment of the engineers, first the engineers have to be socially and politically active and caring for the causes that's a lot of responsibility for the engineers i would say all of the human beings all of the people are doing it people graduate from sciences they are far more socially responsible and engineers are like in their tunnel vision responsible and engineers are like in the tunnel vision there needs to be more civics and also thinking skills taught at lower grades before college yes but as if i mean i would say that that applies to the whole human population right i mean there's nothing specific to engineers here and specifically people working on ai are not the reason why all the things are going wrong no we have a different influence on the world right we have disproportionate influence on the world at this moment no i would argue this way as if you take a guy working in monsanto every research that they do they know what they're doing right and so if you're looking at every research that they do they know what they're doing right and so if you're looking at let's say spoiling the earth putting in chemicals there and you know the whole the pesticide model by which how some of those Monsanto pesticides work there is an inherent flaw in all that so one can argue everybody was working in those yeah no definitely everybody working in a tobacco company you know what you're doing right if you're working in those. Yeah, no, definitely everybody. Working in a tobacco company, you know what you're doing, right? If you're working in a leather industry and- You know what you're doing, yes, very true. I wouldn't single out AI engineers as people who have to have extra responsibility. It's like everybody, and I- Responsibility. What I'm saying, Premjit, is scientists these days, as they get more and more specialized in any area, whether it is computer science, whether it's biotech or anywhere, generally the academic curriculum tends to be very focused on their specializations. Along the way, two things have happened. They have gained tremendous influence in shaping the world and they have also along the way they have practical illiteracy of social and political implications of their work and if there is any hope for the planet that needs to change i mean i'm going back to plato's statement he starts by saying, man is a political animal. And it is that. Power is, you know, the power structure is shaped by people. If people are not willing to take the power in their hands, they become powerless. Then the guy who is willing to take power, usually the rich, acquires all the power and controls everybody. rich, acquires all the power and controls everybody. So what are scientists doing in any of these disciplines? What are they doing? And what are we doing? As people who are learning AI, we have a potential to do a lot of harm. I say that, I mean, from my personal experience, for example, I had a choice to work in the, in a sort of a weapons industry at one point in life and I was eminently capable of that. I was a physicist and a computer engineer and I could have really been utilized consciously. At least I had the sense as a young man to not go there, not to bring home money that may have blood on it. So I don't know, but if I still have that kind of consciousness, for example, the work that I'm doing, I deliberately chose an area of work, which is HR, you know, things where the potential to do harm is very, very, very low. That was a conscious decision. I consciously chose not to work for the big, the Googles and so forth of the world. I chose companies where I could walk home with a clear conscience and say, this work has not harmed. My work is not harming people to the best of what I can make out. It's more a force of the good. But is it? I don't know. Even then I'm doubtful. but i think we need to think a little bit about it though the ethics is that's my feeling where i would kind of take that thinking process in this conversation in the context of this conversation as if is i think with the ai we need to have a way to inherently measure the bias that is going into all our AI. It's happened not just with AI today, it has happened long ago also. If you were building a Bayesian model which will do a recommendation, the recommendations are a function of something in the past. So as engineers, we need to devise ways to control the behavior of the model such that when you have the right set of management folks who want to make that control happen, the control should be easily doable. We shouldn't leave systems in a way where that becomes the constraint why it cannot be controlled. That is a contribution we do as engineers. Yeah. See, that's a very good point. And it speaks to the bias, but it doesn't speak to the control. A completely unbiased AI can still be a force for evil in the hands of the people who control it. So, for example, a completely unbiased system can essentially be, its goal can be to make you spend all your money, hard-earned money, and it will efficiently go into it. Because it's controlled by people whose entire motivation is to make you spend money. I mean, what is Google's entire motivation, for example? I fight with my daughter every day telling her that YouTube is kind of drawing her deeper and deeper into it and she has to let go but it's hard yes yeah not only YouTube from it like even any game it look at video games yeah all add it to you and then the mid with the power of AI yeah there I curse the AI that's doing it right I can't control her because she's enjoying it that's why she's doing more and more of it You actually get a dopamine kick every time you look at, you know, a message comes onto your cell phone. Yep. So, there's so many gates I can't tell. So I can see Arithya. Arithya, would you like to speak up? What do you think? Yes, if so, I'm also coming from a little bit different background. So I'm more in the coming from the hardware side of things so yeah so i think my work is partly responsible in developing the chips that kind of um enable all this know, I don't feel like I have the power to change things. I think like, like many others here are kind of going this similar kind of thought. It's more of like, yeah, you do what you have to. What you have to earn your money your money see we engineers have always given that excuse that we are powerless we we do what we are told to do but see power is always acquired nobody gives it to you it's one of the things you learn if you get educated in the humanities you take a course in political science or things like that you They're more aware of it, right? So women are not, for example, getting rid of sexism because the men are handing it over to them. They are standing up for themselves. Kate, would that be a fair statement? Definitely. All the women's marches, all the everything. Definitely. All the women's marches, all the everything. Power is acquired, never given, never given. But think about it. When was the last time somebody offered you an extraordinary promotion just because you worked very hard? If you notice how promotions are made in these companies, it is the guy who is asking for it, demanding it. And among people who are demanding it, only in that small subset, they look for the most, the guy with the highest contribution and give it to them. But what about the guy who is quietly slogging on and producing great work? You know that they don't get promoted very easily. Everybody wants to have such a guy under them so that they look good. Nobody wants to promote such a guy under them so that they look good. Nobody wants to promote them as the equal. Indeed. Right. That reminds me of a very interesting statement. I think someone told me, like, I think it's probably Winston Churchill or someone who said that he went and he saw that there are two lines. One line is for people who want to do work and then there was a second line which is for people who want to take credit. So the line where people were standing for taking credit was so long that he decided to stand in other lives. Nice. Thanks for your input. I think Shiva, Shiva, you are here, right? I think you're hiding as one of the kaits. Shiva? Premjit? No, Premjit is a kait. There are three kaits. So one is Premjit is a cake there's there are three cakes so one is framed yeah i think who would use the link that she yeah kid kid you sent the link so i clicked the link and i came in so we all uh assuming your identity now okay so what can your picture look different so your picture looks different all right let's hear from you from me yeah so i think this is a very interesting topic and in a way i'm deeply deeply perturbed by what is going on and uh if you ask me about the work front um about about years back, I was trying to develop something for intelligent contact centers. And like I was doing a conference where Microsoft, Google, Amazon, Cisco, everybody is fighting for that, how intelligent we're going to do and the main thing was how many agents we could replace. That's the measure of success. and nobody's talking about it easily but then everybody's saying okay this could i could reduce my capacity by this much and i do not need to put my contact center in this country or that country and i could just do it something on online and then i was just thinking like are we taking every jobs from people who could have gotten the job are we taking away jobs from people who could have gotten the job and then there's this topic coming up of this universal basic income yes and it kind of kind of irritates me like at like we have to think that and I feel by the time our kids in next like seven ten, they may need the UBI, you know, some basic income. Yes. Because it is so rapid and so exponentially, things are getting advanced. And then the way I see the wealth and the digital divide getting so big, the chasm is so huge. Unless there's UBI, people may not be able to survive. And so is it like hyperbole that is it like a hyperbole or is it like I'm thinking too much I just do not know I worry and one like and the thing is I was thinking about what can I do about it this what I was thinking about is let's talk about it let's discuss about it and then like in a way i think there has to be a fix with some kind of um policy making at this at gender if no policy um if you just leave it to the corporations we are there like we we are a part of cooperation and our primary responsibilities towards stakeholders not to the environment not to the social responsibility people think about what is the number one goal make money for our stockholders and that's the goal people all the companies live by whatever they say unless they're forced to so there has to be some kind of policy thing and this is a capitalist country and then a socialist is not any better this is like but the thing is unless there is a safety net that is mandated i don't think people are going to get it that's why i think like um if if not as an engineer but at least as a voter or social influencer, what I try to think about it, at least communicate. And then, but again, like what I see there at some point, the AI is a blocker because we operate in some kind of echo chambers. Like you get recommendation because you look at the AI and similarly the religious zealots, they get that kind of narratives all the time. how come your religion is victimized and xyz is molested and then this and that it's kind of like makes you angry angry angry so these are kind of groups the AI is doing it perpetrating it like and that whether it is like the here the elections happen and people don't believe who won similarly like whose god is real god like that kind of limit happens and there are hundreds of proofs and hundreds of the instead of the ai and the internet being source of knowledge people have just faked it and so when you had this uh experimented wisdom of cloud and i was thinking about when you're doing this one okay that may be the right first time but the ai is going to manipulate the whole system by virtue of advertising and mind mapping my brain and giving me sources such a way yeah i will start believing something which is which is fake but i will start believing it to be true because i'm repeating it that's right subconsciously remember the wisdom of crowd works only when the crowd is each uh you know thing in the crowd individual in the crowd is uncorrelated with other individuals yeah he's doing is making them all correlated so it becomes the mob of crowds rather than wisdom and then the example you talked about like the drones as a reality like it happened in recent war between Azerbaijan and Armenia. Are you serious? It was already used. Yeah, so it happened. So the drones from Israel and Turkey were used. So there were the Israel, are called kamikaze drones, which is what you're talking about. It's kamikaze, you go to the suicide mission. They can go 8,000, 10,000 feet up in the air and they keep coming and till they realize it's accurate and more, if you don't find a good target, they go back for charging. But the moment it fights and then realize it's enemy pattern pattern they come and blow themselves up so that's reality and similarly the turkish drones turkey is now good for nothing but now they're good at doing drone manufacturing and so these things so armenia lost battle in one month despite the fact that they had a huge battery of airplane and military couldn't do much they're sitting ducks all the drones were coming and killing them left and right after one month Armenia surrendered and yeah and the war was lost so now I see that happening in this year south China seaside India, India, China border, the dark side, people are trying to still manage the battles with eyeball to eyeball, but with this kind of augmented reality, augmented drone swarming, whatnot, this is going to be kind of bad stakes are against you if you are weaker the thing is the who did who can destruct more there's a race towards that and one small mistake like nuclear chain reaction was one thing but now you've got this AI chain reaction could be the other one where I could destroy you if you destroy me right and so that I kind of like if you want to think about it, it just gets me gloomy. Kind of like sometimes you feel like there's no hope, but then I say, okay, it's up to us. I know like at my home, we don't put Alexa or Google voice. Phones have it, but then I'm trying to kind of like turn off as many smart features as possible, unless it is absolutely critical. But then again, this is like a losing battle because their phones and like everything knows you well, like they try to know you, make it really easy. At the same time, you give away all the rights. Absolutely. We can't even log into our office computers without getting a code on the phone. So the phone is always nearby. Yeah. And so this is where there's a curse. And this is what I think that you or somebody mentioned, right, religion. Religion probably was supposed to be the good thing when the whosoever started that thought process right that person may have like hallucinated that he's like a messenger of god and then he may be thinking in all his wisdom he may be just saying the best thing out there seemingly like initial good this could have done some initial good but now you see it's all echo chambers and same thing where i see like yeah i could do that kind of harm that religion has done on humanity already nice guys it was thank you anybody else has something to say this is a i think this is a great discussion we as engineers need to have right i think yeah i think only if we talk have right i think yeah i think only if we talk this thing can be surfaced because we're conscious about it yeah anybody has a thought guys by the way did you guys like today's session or you thought this is completely a waste of time to uh different from because we are not covering a technical research paper we are covering something more on the humanistic side i worked as a hardware engineer and then i had my own green gift business that was all about trying to be ethical business so it's very relevant to me oh yes okay definitely yes are, actually I really admire, what happened to your business? You didn't carry that forward? Oh, the gift business? I mean it was fun to have an online green gift business focused on ethical, organic, fair trade. But the grind of the retail side and 2008 was really rough. Nobody was buying anything, So retail was just terrible. So it's more that I didn't, that the retail got old rather than the green and ethical got old. That I keep. Okay. Nice. Asif, I think for this session, it'll be good to have one more follow-up on the AI for good discussion, right? I haven't done any kind of resource gathering on that but i know of a few friends who went off oh you would know the name steve ty do you remember steve ty yes yeah so steve ty has retired and he made his money in hyperion he's retired and he's kind of gone off into uh he's he doesn't call it AI for good. He's gone to technology for good. So he's basically investing time in building things which will help the society positively. Would he be willing to come and speak? Steve? I haven't talked to Steve in a while, but I can reach out to him. He's right now doing some stuff with education, right? Basically working on creating technology that will make sure absenteeism in poor neighborhoods is decreased. Being able to measure absenteeism, create incentives for kids who frequently abscond from not coming to the school. It has a lot of benefits, right? The school gets funding when the kids show up. Kids get education only if they go to school lot of benefits, right? The school gets funding when the kids show up. Kids get education only if they go to school, all that. So I think from an AI engineer perspective, if everybody had a side project that you're contributing on AI for good, then that's real positive impact each of us can do. Yeah, that would be something really good actually i was surprised my daughter wants to only she has already decided that she'll give her life to using ai for geriatrics for old people because apparently she researched and not many people not enough care is being taken of the old people so she has for many years it's not a passing thing for many years since the last five six years i'm seeing she has been doing a lot of things for the older people and i think it's good to have a humanistic side to the engineering well i i will send a link here on our chat which you might want to share with your daughter, Asif. I'm sure. It's a company which it's actually a startup where the guy, Andrew Nigg was his guide and he's kind of gone off and created a company. I mean, I'm actually interested in it because my brother's in the same space in India. So this guy's company is basically focusing on vision detection, basically using AI for vision, AI for a bunch of things to create an operating system for a home and he's focusing on like elderly care as one area. Oh, okay. For the company's casper.ai. send me the link yeah it's there on the chat yeah okay wonderful nice guys so i think um this is a typical way to start for this year so this week we are going to cover just as a heads heads up, we are going to do explainable AI. But in the explainable AI, if you remember, a lot of you have already been through some of it. I don't know how many of you remember those of you who are the past students. You remember Shapely and Lime and so forth. Oh yes. PDPs. I may cover a little bit of that. Actually, what I want to do is I want to cover that, review that, I want to do a special session, all free sessions, one day to Shapely, one day to Lime, and one day there's Lime and PDP, partial dependency plots and so forth. Can somebody create an interest list for me if you are interested in registering for that? This is a course in deep learning, so I feel compelled to focus much more on deep learning aspects of explainable AI. But I think those other aspects are also very important. So an interest list for those who want deep learning on explainable AI? Explainable AI covering topics like, you know, that are agnostic to deep learning, that cover deep learning also, but they're agnostic to it. They cover things like the Shapley and the Lyme and so on and so forth. So just to give you an idea, Shapley was was an economist of all things, a game theorist who got a Nobel Prize for a very simple idea. He created a rule of how do you decide that if a team wins against another team, let's say a game of football or something, a baseball, then how do you apportion credit? How do you measure each person's contribution in winning in a fair way? And for that, for the way to do that, we've got the Nobel Prize. Now, how is that relevant to machine learning? If there are 10 different factors that are implicated in predicting something, you know, maybe whether something is a cat or dog or whether something is, or whether, or you know the credit score or something, how important was each not very robust ways of doing it. It is the same thing. How much did each feature contribute to the decision or to the score or to the prediction? And the right way to do it is using Shapely. There's an excellent Python library that does it. I'll try to cover some of it, but I think these things, they deserve a whole day of their own. So is there anybody by the way, who strongly is interested in this? Me. Very much interested. Yeah, let's have a proper day for that. I'll see how much I can cover this week. This is going to be a packed week. I'll try to cover as much as I can. All right, guys, That's all for today.