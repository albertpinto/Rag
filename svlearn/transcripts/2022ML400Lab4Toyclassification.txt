 Okay, so for this lab session, we'll be doing classification on a simple data set. It's a toy example and for which you need to download this lab4 folder from the course portal, which is under hands-on labs and solutions, and download it, unzip this folder, and just copy all its contents and paste it in lab three, wherever you saved lab three, just paste all its contents, because we will be using the same training loops we created last lab session. And we'll be using auxiliary.py to move our, like if you have CUDA then to move it to your GPU, like the model and all the tensors that we are creating. That particular file is under auxiliary. So all of them are interconnected and therefore we just copy all these files and put them in lab 3. Labs, lab 3 folder do i just unzip it right there yeah and just don't keep it as a folder just uh copy all its content and place it right next to, I mean, that the contents folder so they should be listed together. Right, so it is classification visualization.py, toy classification.ipynb, Jupyter Notebook file and whirlpool dataset.csv. Yes. Okay, when I extracted it came at the same level. So it's within lab three folder. So that's perfect. Okay. So I think we can start with today's session. Was everyone able to do it? Or should we wait a few more minutes? Can I get a thumbs up? Yes, no. Can I get a thumbs up? Yes, no. So you said download the lab 4 and copy the toy classification notebook to the lab 3. Is that what you want to do? I am saying copy all its content and just place it in lab 3. if you take the zip file and put it in the lab 3 folder and then just say extract okay so the three files within will be in the lab 3 folder so it should be perfect okay thank you okay um all, so let's start with today's session. I see that Amrit has done it. Okay. So it's working. So now, for this session, we'll start by importing all the necessary modules and libraries. So we have torch, torch.rnn, torch.tutors.data. These are standard ones. This one actually is not needed. This was for another problem. You can delete this line actually, if you want. It's not- Or comment it. Yeah, or comment it. So then we use matplotlib to plot we also use um data set classes i mean this is also we don't we don't necessarily use it because we define our own data set here then training loops sklearn metrics and classification visualization so this is the new uh bit of code you're using for this for this problem so again these are just some plot styles these are good to use when you're using with matplotlib some standards that you set and just copy to all your notebooks so that all your visualizations are you know very similar right they follow a standard so this is for that okay so um we are going to load our data set and first we are going to load them into a pandas data frame. And then we are going to convert them into NumPy arrays and then to tensors. So here, my source is Whirlpool data set. And if you've attended ML 100 or ML 200 or data wrangling any of those courses, you know that this is how we read a file into a data frame. It is easy to work with data frames, right? So, and then we're going to drop one column, which is unnamed zero. So if you don't drop this column, let me run this for cell. Let's see if it runs without an error. I don't see the simple dataset. Sorry? I'm getting the same error. From dataset classes, import simple dataset. Okay. Cannot import name simple dataset from dataset classes. Okay. Can you show me your folder structure? Sure. Let me stop sharing. Sure. Let me share that screen. So I am in lab three. I had the zip file, I have the notebook and the data set, but the Whirlpool data set, not the one referenced in the notebook and- Oh, I don't think there's simple data. Just comment that line. Okay. Yeah. All right. Does it run now? That's easy to do. Amrit and... Yep. Yep. Okay. So yeah, my, my dataset classes has extra class, which I created. So, uh, not to worry. Okay. Let's, yeah, let's load this. Okay. And so we run the cell without this df.drop, right? So we get this extra column, which we do not need. And it's just easy to work with Pandas data frame. And you can easily drop this column. Okay. And you just say unnamed 0. And you want to drop this column. Okay? And you just say unnamed zero and you want to drop along axis one. So this is axis zero horizontally and vertical is axis one. So we say axis one. And we also say in place equals true, which means this change will happen to DF and it is not returned. And please remember the changes is what it's telling it. Yes. So now we have this data set and we can see we have X1, X2 and T. Here X1 and X2, they refer to the input variables, right? These are the features and t is the prediction okay so we can do one more thing we will see t dot sorry df and within brackets t dot unique so this will tell me what are the different classes that I have, how many classes I have and what are the different classes. Yes, so we have this 0 and 1, right? So there are just two classes. They will be our predictions. Now, what we will do is we will split our data frame into features and target variable, right? So the standard way to do is capital X for features and small y for labels okay so this is how we do it now let me run this data and see how it looks. Okay. Is this cell running for you properly? I see the graph fine. I'm realizing I need to edit the Python file to add the learning rate for cells down below. I'm not getting the plot either. You're not getting the plot? No, it's actually a pretty long error. But it says, okay, okay, it's a runtime error. Failed to process string with text because latex could not be found. Oh, you need to set to false up in the imports okay yes guys you just by default keep this false okay everyone um only if you have latex if you've attended previous courses you might have latex installed yeah i have otherwise otherwise Otherwise, otherwise, yeah. So by default, just keep set this to false. Okay? Okay, it works. Yeah, and I remember making this change, which Kate, you're right. I'll let you make this change. So. Yeah, I need to remember that change. Okay. So, you see this visualization, everyone? Can I get a thumbs up? Yes, it looks nice. I mean, a thumbs up or raise the chat anything anything okay uh so i see amrit has raised hand all right so so we see this data set and this is how it looks so we have two classes um red we have one red and one we have one blue plus okay and they are pretty intermixed right so we want to classify them and. We can naturally see what the classifier is supposed to be right wanted to be something like this so let's see how it works. create a data set so in in previous lab or in the labs before we had a separate function to create a data set so but this is the simplest way to create your data set right so torch utils data and you say i want to create a tensor data set you as the first argument you pass what you want as your input second argument is what you want as your labels right so this is basically what you do and then you pass it's a data type okay for labels it's generally torch.long and then x torch load 32 if it's a number. So these are that. And then I say training loader equals data loader data set. So now I created a data loader, which will, like in the previous lab we discussed, it will throw out my different indices of my data set one by one and in a random order till it exhausts all the data points, right? So that's my data loader. And here I'm just going to do it one by one. So it's gonna be a stochastic gradient descent all right so let's let's see what it should be now uh this is what is important to note in this lab uh okay guys were you not able to see my screen till now my screen till now we can see okay all right okay so the for in features how many in features do we have um if you notice it's x1 and x2 so here y doesn't y is not actually you know uh something that you can plot it's just the color right so x1 and x2 refers to one point and so we want to pass in a feature vector which contains two features right x1 and x2 so we have in features 2 so now why do we expect the model to output without features of you. Two categories. Yeah, correct. So the model has, it does have one y value, but it has two classes. So we wanted to give us some sort of probability of saying, okay, I want a probability of it being in class one or class zero or plus one right so that's why our out features is two so it actually is the number of labels that are available in our data set i mean in the on the labels okay so that's what it is okay and so we do this same thing again here we have our input we have our hidden layers right and input and output features and we use tan h activation okay so for loss functions if you remember um i think last monday asif went over cross entropy loss pretty much a lot of details so it's for classification we use cross entropy loss because we want to minimize our unpleasant surprise so um that's the loss function we'll be using so but then the rest remains the same, except, okay, I made this small change because by default learning rate was 0.01 and 0.001, which is too slow for this lab. So let's just go to the training loops and you just have to make this change. If you see train simple network the first line is optimizer you're defining an optimizer and here there would be a default learning date 0.001 just note that go to train the arguments and create a new argument saying lr equals 0.001 which is your default okay and then just say lr equals lr all right sorry could you repeat that The only thing we're changing is… So you add a new… I don't think you'll find this there in your training simple network. An additional line. Do you see LR equals 0.00… 0.01? In line 20… You won't see it, so add it there. OK. And in line 21, you'll see as arguments to SGD, you'll see LR equals 0.001 or something like that. So just change that to lr okay okay so probably you'll have to restart okay restart your kernel and run all cells okay you can what you can do is to here click on the cell and just restart going on. And then sell run all about. So you. You'll be back here. I think there's some other lines that need to be updated. Okay, what are they? Let's see, train simple network, it says LR equals zero, oh, online 17, where it says train simple network model, last func. model last funk oh yeah that's just in the jupiter notebook cell where it says train simple network model and it's handing it so let's see it needs to see that in train simple network maybe i didn't okay let me run and see if my set mine. Okay. Training loaded. Oh, I didn't run this train simple network. Oh, I think that needs it added to online. 15. Line where in training loops dot pi. line where? In trainingloops.py. You are loading train simple network here, right? In your first cell? Yes. I guess I'm looking at the code in trainingloops.py. Okay. pi okay on line 15 the parameters to the function train simple network let's see they well they invoke the optimizer torch.optimizer model lr equal but that should be that should be able to be overwritten right oh oh Oh, no. The LR needs to be on line 20. It needs to be LR equal LR. I think I missed that. I don't know if you went over that. LR equals, it should have a default value. Yeah, this should be 0.001. But in the optimizer call. Yeah, optimizer, it should be LR equals LR. Did you make that change? Yes, I'm making that change. I think I did that. Okay. So you can run the cell now. Run model and then this cell number. I mean, under data loader, cell number i mean under data loader right second cell under data loader section uh is that cell running properly for you and uh amrit you may want to to comment out this line i just made it cpu okay and it runs yeah okay i get a loss of around 33 at the very end so okay yeah okay good how do you how do you it's busy running now kyle uh how did you know yes your loss was at loss was at the last epoch? So I made some changes that it's not showing up here, but you know, in this, I have commented out the print line. I've uncommented, I'll also see the same. Okay. So same okay so okay it's very nice all right so let's then do the model prediction so here i'm just passing in a tensor of two comma two okay uh which is somewhere which is somewhere here. So we just want to see what is its prediction or what exactly does our model output before we do anything else. So we see these numbers. Okay. And they are nowhere, like they're pretty similar right we see minus 0.22 and minus 0.26 so it looks like the model is pretty confused as to where to classify it but also we see that these numbers are negative and they are not like probability they're not adding up to one so we want probabilities out of us out so do you remember what we do to like convert these numbers to probabilities soft max yes we do soft max uh yeah so instead of log we take the exponential right so if you remember exponential function it is for as i mean for any like uh power right so uh if the powers are in negative it's like really close to zero and then the powers like increase beyond zero they exponentially shoot up so that's the function that we want to use and then and then divide by the sum of all pro i mean sum of all of them so that we get a probability in the end okay uh so that's what soft mac does so we want to convert this and do a softmax right and then visualize the results so let's go to this visualize 2d softmax so this is the function that does it for us let's see what it does let's open classification visualization dot by yes can i continue have you guys open this file kyle it's hard to keep track because you're explaining and also asking us to do so we can either do all right this or that that's what i feel okay we can do it slowly if you want because okay uh or or actually you don't need to open this file because yeah you're not going to run anything here i'm just opening it as a simple text file just to look at it as opposed to using PyCharm. Yeah. So you don't need to open it. Just you can watch it here because I'm just going to explain what this code does. So this function, it takes in inputs X, Y, model, density, title and device. OK, so X is our input, Y is y is our labels model this is the model that we trained okay which which is going to give us the predictions and density is like sort of um the the granularity of your model and how clear you want it right so uh in the notebook i have used 50 so that you see a lot of lines in the visualization you'll see next um you can play around this with this uh right and you'll see a difference in your out in your visualization and here is the title for the plot so this is going to return a plot it's going to show us a plot and this is device this is the device so let's uh these are some manipulations that i do here so i say x1 i i take out x1 and i take out x2 from my input features then i calculate its range okay so this is a technique that rc does and it's pretty it's recommended as well so what we do is we calculate the range of x1's type and range of x2's and in our plot we want uh we want we don't want our plot to just end where uh where you know where we have one data point. The data points will be like at the extremes of your plot. We don't want that. So we create an X min, which is the minimum minus 10% of your range. So then we sort of expand our plot, like in the X axis and Y axis by 10% of your range. So this is a technique to do that. Then this is this is to create a mesh grid. If you attended the visualization course, this might be familiar to create contour plots. So NP dot mesh grid sort of creates a grid of points okay so we want to evaluate the we want to make predictions for the points in this grid okay and and with those predictions we can actually create a contour plot right so we'll see how that works but uh just know that np.mesh grid returns a grid of points that we've made from x min to x you know x min x max y min y max okay and num is density right so these are the number of points that are created in the x axis and y axis and then they are like meshed together to create like so if there are 20 points here and 20 points here there are 400 points created right so the next is uh so we have these 400 points and then we make them we stack them together so we want to create a pair we want to create an x1 x2 pair that we can pass with the model which the model will okay will return a prediction out so this is x1 x2 right so this is a this is this is like a sort of a you stack these two rows together then uh with start start no grad so we are going to do some we are going to create some tensors we are going to like basically the model is going to make predictions for these values okay and it's going to be returned and we're going to store it under logics okay and then we say what exactly our y hat is is f dot softmax so this is the softmax function we pass in the output from the model here okay and then we say dot cpu dot numpy so oops okay so if you notice uh the model these these are tensors okay but what we want as output is a numpy array and uh that's why we say we first move all of them to CPU and then convert them to number. Okay. Move all these things. Yeah, what is that CPU exactly does here because is it we are running this on the GPU or like why would the CPU is required? Yes, if you're running from cpa gpu we move uh move those stances back to cpu okay and then we uh do a dot numpy so that we can convert it to a numpy array so the thing is when you plot your um when you plot right you want them to be numpy arrays or you can use stencils also not a problem uh but you will want them to be in the cpu because plotting is done on the cpu it's not a gpu how we will know whether we are running on gp because my laptop has like how we will know if you see the code everywhere you see that you are if you are pushing things to the gpu it's not like automatically that it's happening uh we are manually doing it you set the device yes the model to the GPU, right? Okay. And then we also recursively move all our inputs and labels for each iteration of the training loop. We push them to the GPU. So we push everything to the GPU like constantly. But looking at that code right there, right there, the default is CPU. Yes, but you see that we say torch device CUDA, if you remember. Then all the CUDAs means GPU. Yeah, so this is what we said. And then we pass this device here. So by default, this is what we said and then we pass this device here so by default that's the the default but you overwrote it in the notebook with cuda yes okay i overwrote it and it doesn't work for apple right yeah you're gonna have to figure out how to use that M1 and... You have to kind of comment that line or remove that parameter. That's what we did last time. Yes, you'll have to remove it. Remove the parameter altogether because by default it will work with CPU. So why do you need it? Why don't you just stick to the defaults? Is there an advantage of using the device then? It's faster okay only for the speed okay yeah so that's that and here and then we make the predictions right so now what y hat will be is it will it will still be uh a say a vector of length two right so it's going to give me predictions for both my zero class and one class okay so here in this uh okay so here we saw that it returns minus 0.22 minus 0.26 so it will probably be something this would be 0.45 and this would be 0.55 it will return a numpy array like that okay so that would be my numpy array so now i will i will i'm going to make uh you know a plot and so for the plot i'm just going to see what is its prediction for zero for uh for the zeroth class okay so that's what i want to see and this is a code to create a contour plot, but not just a, you know, contour with lines, but we wanted to shade the entire region so that we see how it looks for the whole region. So instead, so if you use just contour, you won't see all that colors and all that, you just see lines, but since we use contour ref, we see a beautiful sort of background for the plot. Oh, it looks very nice. Yeah. So then we say x1 v, x2 v. So these are the points for which I want my predictions. And I'm going to pass in this so this would be the color the color would denote what the prediction for x for this particular cup for a particular observation is so we see how it looks okay um so that is that plot contour F and then levels. So how many levels do I want? How many levels as in how many contour lines do I want? You will see that as well. And CMAP is RDBU. Okay. And I've used underscore R. So this would actually reverse my color palette. So earlier it was zeros for red and one for blue. But in my plot, I've used red for one and blue for zero. So I'm reversing the color map. So this was plotted with matplotlib. And with seaborn, it's actually easier to you know uh plot this way so i'm using sns c bond i mean it's scatter plot you can still use matplotlib and use the same code we used here um here see but then this is a little bit more complicated and so i it looks better with seaborn so yeah oh when you're done with that file i would like to go over a function in the other file okay all right so here x1 x2 and then i pass in a hue. Hue is the prediction for the zeroth label, right? And then I'm going to style it by Y. And then this is the axis. So let's see how this plot looks okay so that's pretty good right so you see these lines over here so there are around so in my in my in this for this function I pass in density as 50. So, there are actually 50 of these lines 50 contour lines right. And if you change it to 20 you see the difference right. See the difference this is sort of the granularity of sorts. So this is how the model would look. And Kate, is there something you wanted to discuss? Yes, I would like to see in the training loops.py file what the parameters for your train network with scheduler look like, because I'm getting a, you know, it's not recognizing classify as a parameter argument. You just remove it, is it there in my notebook? Ah, OK, then just delete this whole part, I thought I would. Just remove this whole thing, this don't run any of this. Oh, okay. So you just wanted to end with the... Yes, yes. Okay, because the classifier is not there. I thought I- Yeah, I'm still working on it. I've not got it to work, so. Ah, okay. I'll, by Monday, I think, so while people are practicing this, by Monday I'll have a notebook so that we can test with all our score functions, right? So at this point, I'm not able to make that into a, as the function isn't working properly for me. Okay. Oh, what's there so far looks nice. Yeah. Okay. So, this is the lab note for today. Now we'll give you a short break, around 10 minutes, and then we'll give you some data sets. And you will do the classification. All right? OK.