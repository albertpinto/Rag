 Repeat, today's session will do a topic called Multilinear What is it? that affected we'll talk about something called multi-collinearity multi-collinearity in your book is just called collinearity it is the same thing we will talk about outliers and leverage points and we are going to do all of this from a very practical perspective to lab at some point so we are going to talk about all of these things we are also going to talk about something that, you know, we talked about the Gauss-Markov theorem. Gauss-Markov theorem and assumptions. Again, we'll do from a very practical data. We will say this. And that will finish our world with regression. Today is the last day for regression we would be done with it after doing some labs likely this will eat up most of our time we will do a quiz in class quiz that each of you will get online after this regression and then time permitting will start the new topic of classification. Now one thing I wanted to ask, I've released the solutions to all of this experimentally data analysis. Does anybody have any questions on that? Do you guys feel that I should walk over this or it is unnecessary. Go with the assumption that it is unnecessary, but if you folks feel that it is needed, what we do is give an extra session. Let's say Wednesday evening or something like that in which I'll just walk over the solutions that will that be something you guys would be interested in last time I offered extra portion nobody showed up so interested how many people are interested we will do a walkthrough session of the exploratory data analysis. Today I might talk about more tips, more tips and tricks from real life experience. So that would be our scope. Yeah Wednesday will work. Sure yeah. Sure sounds good. So we'll go with that. So you know when I talked about, I'll start with this thing. I talked about Gauss-Markov thing and i said that in one dimension it just comes back to the simple statement the line should be essentially going through the center of the data the data point should be scattered more or less around the line uniformly the important word was uniformly now when you go to multi-linear or many many predictors now when you go to multi-linear or many many predictors and predictors when they come in let's write it out let's talk about multi-linear regression expression what does it mean let's go to the example of our sale of ice cream on the beach ice cream how much ice cream are you sent without why let us say that we have to access now one of them was temperature remember this was an X 1 now and suppose you have another factor which is how windy it is. Why would the wind matter on a beach? Let's make a narrative that if it is windy the waves will be coming in pretty high and it wouldn't be safe to take kids into the water. So obviously that is going to affect how many parents will show up with their kids on the beach. And so your sale of ice cream would be affected. So you would say that your ice cream sale depends upon, Y depends upon a beta naught plus, it will depend upon this one, this being the temperature. It will depend upon X will be wind does this look like a very natural generalization there I'm getting a lot of static in the background scratching sound can please mute you if you the scratching is coming from you all right so so far so good are we getting this guys it's a very simple generalization but what what does this equation represent? We realize that in one dimension, equation, I mean, when there was only one predictor, it represented a line. Regression represented a line. But in two dimensions, what do you think the regression equation will represent? Can somebody guess it? A plane. present. Can somebody guess it? Plane. Yes, it will represent a plane. Equation. Geometrically, this is a plane. Is a plane. And these are the partial slopes, like slopes in the x, x1 direction and the x2 direction of of the plane so it will be some plane rising up from here so actually it will be rising up rather let me use some other it will be some plane rising up which represents the relationship of y on x1 x2 so to be able to do this you are writing your first multi-linear regression people don't usually use the word multilinear regression unless they want to make the meaning clear. So rarely they use it. They still call it linear regression. Are we together? Now, this is your basic term of linear regression. Now. For this to work, everything remains the same. Your sum squared error, your gradient descent, everything remains the same your sum squared error your gradient descent everything remains the same why because our error term is simply y minus y hat i if you remember it is the sum of squared of mistakes so suppose this is the prediction let me take this you realize that at this given value of this point, which is X1, X2, what is the prediction? Let me use a more bright color. What is the prediction? The prediction is this. This is Y hat. And what is the reality? Let's say that this is the reality. This is why. And therefore, what is the residue? The mistake? This is the point on the plane and the reality and the residuals remain the same so in other words all your theory of linear regression that you have learned so far applies for multi-linear regression they just when you have many many variables a few factors become important and i'm going to mention those factors. In fact, those are the famous, Gauss-Markov assumptions. So one assumption is very basic. It is the random assumption. Random assumption just says that your data, when you take the data, it should be a good random sample of reality. Means don't take data points such that they are skewed for whatever reason. They are all on the optimistic side or they are all in the you know the lower bound side or something like that don't put bias in your data truly take a good random sample of the data are we together the second condition of gorse markov is linearity it's common sense which basically says that your equation should look like this which basically says that your equation should look like this. Whatever I do, I'm writing it for two variables when I'm writing it for two variables, you can assume that it is for any variables. You can have more. Actually, P variable, let's say XP. I'll follow the convention that is in the text linearity condition then there is another condition which is common sense again see these are just common sense quantified present here do you notice that all the points all the errors are around the line you know this the real data is around the line which means that the residues are all small and if you remember we use the word that if you if you make a frequency of the residues the residues are or the errors are or residuals residuals rather they have a distribution like most of the errors you can have errors close to zero and then you're much more likely to have small errors and much less likely to have this is the this is just a think of it that if you make a histogram right think of it as a histogram of errors. It should basically look like a bell curve. So why should it look like a bell curve? Like what it shouldn't look like is like this. Suppose this is the zero. It shouldn't look like some weird thing because that wouldn't make sense. If you have a line in which all the data points is here do you think this is a good representation of a reality it wouldn't be why because all of them are skewed to one side and sometimes what happens is you have yet another problem which is that here see if you can identify what i'm doing i'm doing something very funny and here this looks like a line but imagine it's a hyper it's a plane suppose data points are like this do you see something weird happening with this data what will happen is as y rises y rises in this you will realize that the residuals they become bigger and bigger right do you see that the residuals are becoming bigger and bigger the very like the residuals are spread out more and more you see the envelope here the errors these are the error boundaries right the where the data is sitting so these are your residuals and what you notice is that They will show a corn like structure on like Structure when you see this you don't want to see this because it violates Assumption looking the assumption is something called homo a that oh boy this is rather a big word what does it mean you i keep telling people that if you are familiar with the mary poppins the the story of Mary Poppins. There is a word which is really very big and children are taught and when they know that word, they feel pretty grand about themselves. I would say that when you start with machine learning, this word homoscedasticity and its opposite heteroscedasticity are words in that category what homoscedasticity is the errors if you plot the errors so by the way i will not plot the errors in terms of y itself and these residuals are there residues what you will find is the residuals are like uniformly the residuals are uniformly there. So if you draw an envelope around them, they will be pretty uniform envelope. But heteroscedasticity is if you look at the errors along the y axis, if you do it, you will see this cone-like behavior. behavior so guys do you see the difference between these two? What is the difference? How would you say that word? So this is residuals. I'll just use the word errors, the error terms, errors. What can you say about the errors in the first situation on the left, the homoscedasticity versus the heteroscedasticity? curiosity versus the heteroscedasticity stem is constant it opens out like a cone geometrically isn't it yeah so what is a measure of spread when you look at the spread of a variable? How do you measure it? See, if you look at this value at any given value of Y, the average would probably the residuals will probably average out to zero. But what is different between this excellent the standard deviation or the square of standard deviation which we call sigma square sigma square of error is constant isn't it guys more or less whereas what about this sigma square of error sigma square or people just write it as a variance the same thing as variance variance of the error of the error is proportional to why it depends on why the response isn't it guys you see that as Y increases the variance becomes bigger so for example let me call it sigma 1 square sigma 2 square sigma 3 square at the third point and this is y1 y2 y3 so what can you say about the sigma what if you were to compare sigma 1 sigma 2 sigma 3 what will you see sigma 3 square will be greater and of course sigma also will be greater than sigma 2 square will be greater than would it be something like this guys but as you increase y you increase y, the sigma square keeps on increasing. And the cone could have been in the other direction. It doesn't matter. In this case, it seems to increase with y, or it could have been decreasing with y. The fundamental thing is that it is related to the target variable itself, the variance of the error. Whereas, what can you say here? Here, if I take three points one two three in the y-axis would you be able to say that Sigma 1 square of the error is approximately Sigma 2 square is approximately Sigma 3 square does this Does this make sense? Like, would explain it again. This is a very important concept. And the reason I'm mentioning it is most books that talk of machine learning actually miss that. the fact that linear regression does not work unless your model is proven to have homoscedasticity. You have to check after building your model and if you don't check, well there is a better model that can be built and in fact you are in violation of the Gauss-Markov assumptions. So they are randomness of the data, linearity. The error residuals must be in a bell curve. So this is called the normality of it. Normality of errors. Why normal? Like what is abnormal otherwise? The word normal in mathematics stands for the bell curve it's a very interesting thing whenever you hear the word the normal distribution it doesn't mean normal in the general sense it means the bell curve or the gaussian distribution and then so the errors must have a gaussian distribution and more than that the variance of the error should not change. The spread of the error shouldn't change as you change the value of y. It shouldn't depend on that. So these are the fundamental, I think I did capture all of them, randomness, linearity, residuals, homoscedasticity. I get the feeling I'm missing out on one more. Can somebody tell me what did I miss out on? Multicollinearity, I think. Multicollinearity, of course, the thing that I was going to talk about. Yes. Thank you. Multicollinearity. So, blue, blue, multicollinearity. So what is multicollinearity? If it is present, it should not have multicollinearity. Now, multicollinearity is something that needs to be understood. So I'll write the equation again. Y depends on beta naught plus beta 1 x1 plus beta 2 x2. And guys guys we'll do a lot of code walkthroughs in practical data so you will see what all of these things mean so see you expect Y and X to be related right so for those are good things isn't it but what is a bad thing is bad if x2 is very cool is has a close correlation is correlated strongly correlated to x1 can you guess why that is a bad thing or why what will the two variables in a model that are highly correlated what does it mean for two predictors to be highly correlated move together isn't it so for example I'll give you an example suppose you use two instruments one to measure the temperature in Celsius and one to measure the temperature in Fahrenheit. So up to some small errors, instrumentation errors, what will be the do you think that we need both of those readings to predict the sale of ice cream on the beach? Would you rather that we wrote an equation like this Y is is this good beta naught plus let's say 1 for beta 1 this is the wind speed plus a beta 2 X 2 which is temperature in degree Fahrenheit and temperature in degree Fahrenheit and this suppose somebody has given you data like this temperature in degree Celsius or let's say the degree Kelvin or your senses let's say the European versus or yes and see if the European versus the Imperial standard the metric versus the Imperial standard of notation now just common sense wise what would you say if a for a model like this exactly there is redundancy because X we can combine itself and there's a beta new beta yes yeah I'll explain that's exactly what I'll explain so let us say that x3 is approximately lambda times x2 isn't it highly collinear means if there's a very strong correlation means one can be represented in terms of the other which is true right for example x3 what is the relationship of x3 temperature in fahrenheit is in centigrade is 5 9 over x2 minus 32. this is the relationship isn't it yeah sure yeah up to some error just some error term because you'll have some instrumentation error so what what would it mean if you look at the correlation If you look at the correlation and people often use the word, this peculiar symbol, do you see me writing up P? But it's a very funny P. It is called Rho. It is actually a Greek symbol. Greek symbol is the symbol for correlation so let me just introduce that it's in correlation or 90 something like 95 percent so you realize when you when two variables are highly correlated you don't need both of them quite likely one is enough are we getting the point guys because if one increases the other will increase and so why do I need to keep both of these variables so now comes the question then what is the harm in keeping it and therein is a problem so this problem the fact when this is true, this is called collinearity or your book calls collinearity. The more general term is multicollinearity. So first of all, guys, do we understand the meaning of collinearity or multicollinearity? Would somebody like to rephrase it for me what does it mean for you to have amongst the predictors like for example the inputs to are telling what is the sale of ice cream on a bitch predictors they have they exhibit multicore linearity what does that mean one is a linear transformation of the other yeah one is a linear and that happens when they are strongly correlated. Strongly correlated will be that, remember strong correlation would be that the relationship would be something like this, x3, x2, which is what it is between temperature in Celsius and Fahrenheit so that is multicollinearity is it a good thing or a bad it turns out that multicollinearity gets the simpler machine learning models into a whole deal of trouble in particular linear models don't work well and remember this is true only for the linear models and you have to look at the situation on a case-by-case basis but in general linear models like linear regression will learn about classification linear then a logistic regression and so forth they they sort of hate multicore linearity in the data your model will not function well why does the model not function well the answer to that is quite geometric actually and i would like to give you an idea but this explanation we will talk about later also but i would like to finish it today with this explanation. So remember we have the error surface, right? Let me call this beta one and beta two. Why is this so fat? Yes, this is it. And this is the error surface. You guys remember what did we talk about the error surface looks like a bowl with it with the best solution sitting here where it achieves the minima is that the error the sum squared error achieves a minima at some point that we considered a solution the best fit line the best fit surface and so forth now something very funny happens imagine that you're looking at a bowl or a plastic cup which is shaped like a bowl and then as kids do you start squeezing that plastic cup so that instead of being round and so let's look at the projection of this on the ground you notice that this looks sort of concentric circles these are what the projections of these points on the ground right these contour lines something very interesting happens when you have multicollinearity in the data something this next to it what will happen is i should use green here when you have multicollinearity of the data this the best solution that is there around it these ellipses become you know these contour lines become maybe I should have used white just to be sorry I want to stay with the same convention Now guys, when you look at this and you can imagine the error surface rising up from it. What can you tell about the error surface? It is in one direction. You notice that in perpendicular direction, it very very squished if I see what is happening it's the beat on we data are moving so close to each other they are almost equal when they are equal there is we don't not really what happens is see here right this is your beta 1 this is your beta 2 your solutions becomes a bit hard to find because this bowl is it begins to look like a canyon see ideally you would want the bowl from every side to look like this isn't it if i say you look at this bowl it looks like this but this bowl the way it looks is it in one direction in one direction it will look like this we're together and in another direction weirdly enough you know what it will look like it will just look like a flat canyon. It means on the other direction it just looks like open, completely open. Imagine a bowl that you squeeze from the side and this is where I wish we were in the classroom I would have shown. Imagine a plastic bowl and you are a bowl made out of silly putty. Take a nice symmetric bowl and start squeezing it. What out of silly putty take a nice symmetric bowl and start squeezing it what does it begin to look like very narrow you get a nice Canyon in the center isn't it it it sort of becomes to look like this through this surface you see this it getsished. So here there are so many places that have that look as though they are the minima. Ashif, you can show it through your video like if you want. Oh the video. No actually that is, I don't have that bowl with me so I can't show. no actually that is i don't have that bowl with me so i can't show okay okay i wish i had that okay so keep this as an item guys at some point i will create a i'll create a video just to demonstrate what it does but basically the the problem that it creates is at the bottom yeah you have a big flat region so when you have a big flat region. So when you have a big flat region, now, which of these points is the best solution? You know, it is like ending up in the Yosemite Valley. Right from the from the hills. Imagine your air surface looking like the Yosemite Valley and the Yosemite River is going. Well, you know what? Every point looks like the minima, isn't it? And so your solution becomes very unstable based on your data whatever data you have it will randomly pick sometimes at this point will get fixed sometimes this point will get picked so what happens is very small changes in data will lead to vastly different solutions so i will write that down very small changes data sample so you take a different sample of the data solution changes data solution changes greatly we together and it changes very drastically actually and we'll see that in the next few labs what happens is suppose you have X 2 and X 3 sometimes your model will say X 2 matters and X 3 doesn't matter and sometimes it will say X 3 matters and X 2 doesn't matter so in other words Fahrenheit temperature in Fahrenheit matters but Celsius doesn't matter and sometimes it will say Celsius matters but Fahrenheit doesn't matter so this is it another way of putting it is another observation is another observation that you'll get is between two x2 x3 which are correlated related related highly correlated correlated sometimes so well it's something only one factor will look and the other won't look important and other look unimportant important and you change the data just a little bit and it will flip over small changes flips the solution. So this is a problem with linear and remember this is limited to linear regression models. Our basic what people will call the standard linear regression models the way we have written. I think your book uses the word standard and this is actually pointed out by the TA in our class. This is the book called standard linear regression but generally linear regression models of pulse at standard linear regression. But generally linear regression models, which have this particular property, if they exhibit collinearity in the data, the model is up for a toss. So just to summarize, and this is very important, people blindly use linear regression models because it's something that everybody sort of knows or learns in the beginning of machine learning. So the basic assumptions are randomness. Data must be right. Equation must be linear. Normality of errors, normal errors. and what else did we have? Collinearity. Absent. And what is the other thing? Between homoscedasticity and heteroscedasticity, which one do you want? Let's go up and see. Between homoscedasticity... Homo. Homo, right? We want this situation to be there. This situation is called the Marco assumptions. It's surprising, this whole thing was worked out already by about 1816 or 1812. Isn't it surprising that it's so long ago, all of these things were well understood and proven. It's a theorem actually. And so if all these assumptions are met, then your sum squared error, error term being just this, y minus y hat, will be, and minimizing this would be the best way to approach the problem. That was the blue theorem. That Gauss-Marco theorem says that if all conditions are met, then all you need to do is take the square of it. Remember, I put this in context by saying, why not take the absolute value? Why not take other, lot of other terms to it and so on and so forth so that it is a theorem now are these always obeyed it turns out that they don't have to be obeyed when they are not obeyed you need to make more sophisticated models all is not lost but you can't be using just the straightforward linear regression models so we will talk about that today so for example if one very simple generalization we talked about you can generalize it to polynomials right you do not place it a 1x square suppose it is in singular dimension plus X2, X square plus and so forth. This is the polynomial expansion. We did that for one dimension. And the same thing applies to multiple dimensions. You can go to higher dimensions. The other thing you can do is you can say, in the case of multi-dimensions, you can have other terms that is like that. X1 plus beta 2, X2.2 now let me bring something strange here x1 x2 now what is this this is strange you notice that it doesn't depend on either x directly on x1 or x2 but on the product of the two. So when will this be? I'll give you an example. Suppose you are looking for the price of a house, the value of a house in a certain neighborhood. All other factors being the same, the school district being the same, and the crime in that neighborhood being exact. Hello, my son then still have a desk you know Kate we can hear you so given a neighborhood in which there are many houses district is the same the crime rate is the same people more listed within a narrow band. The house price, suppose you measure, and a very simple example, you measure house prices. And what you get is, suppose this is a house, I'll contrive an example, you get the length of the house length you get the width of the house and you get let's say how many floors it has yours let me call this x1 x2 x3 right so when you look at the price of the house price approximate price of the house would you say that it is beta 1 it will depend let us say that you are given data like this X 1 X 2 which is the length with number of floors x3 and the price 1 so with length floors and price you get a spreadsheet of data like this. Now you're trying to predict the price in terms of these three variables. You may do that. You will get certain degree of relationships plus beta 3 X 3 but you would realize that actually there is a another factor which is the dominant factor it is not the length and the width and the things they do matter a little bit but much more important is the product of these two in fact the product of all these three let me call it beta 4. what what does this signify Can somebody tell me if I take the length of the house, the width of the house and the number of flows? What do I get approximately? Square footage exactly. You will get the square. And you know, that the price is actually sensitive to the square footage of the house. So for example, if you get a house, which is only nine hundred square feet, or if there's a house, which is four thousand square feet in the same neighborhood, which is likely to be. What are you doing? You have to create that predictor. You are effectively creating a new feature by multiplying original features by the product of by multiplying some original features are we together guys and this sort of multiplication are called interaction terms. This is an old word that comes from the statistical literature. It's a reference to these terms as interaction terms. We have one term, like width and length interact and floats interact together to create a new important feature called the square footage. We understand the concept of interaction terms guys? Anybody? Is this way? I hope this is simple. Is the interaction terms of calculated observations or it comes with the data? No, it comes with the data and what you do is you create these terms by, so for example here, you get this data but you should keep in mind that sometimes more important than the original terms can be the interaction, the product of the terms and you treat it as yet another variable. You can literally think of it as X4. You can define X4 which is square footage as X1, X2, X3. Isn't it great? And so then you write the equation in terms of these things. In fact, X1 and X2 may not matter that much. You may keep them in the equation, but predominantly, the most important feature will become your x4 feature. This is just extending the linear model, the standard linear model, with interaction terms. We previously saw we could add polynomial terms. Now, they are interaction terms. It's very simple, simple guys that's all there is to it and in the code it becomes very simple when you do interaction terms like as you will see today we will do we'll walk through the code for linear regression some simple examples we'll do it in R and we'll do it in Python. And you will see the value, perhaps today or perhaps tomorrow, the next time, next week, you'll see the interaction terms. But this is the concept of an interaction term. So you should ask yourself, do I need to add? So this is a question to ask. Do I need need add interaction terms right number one right number two a question that you have already asked do I need to add polynomial terms you realize that polynomial gets even more interesting because you can have for example x1 square you can have x2 square and you can have x1 x2 as a interaction second-order term and you can even have x1 square x2 you can have x1 x2 square and and so forth you know you can talk of so many polynomial terms that you can add and now you begin to ask yourself that well that is a whole lot of questions to ask how many terms should i add in this regression the the answer to that usually is you start with the simplest model you see see if that works. If it doesn't work, then gradually you complicate it. You experiment it. There are no sort of recipes on which approach to take, where to stop, and so forth. So this has been a problem in linear regression. In the simpler machine learning models, like linear regression, it is a sort of it comes with the territory that a lot of experimentations have to be done by hand to make it work as we progress through the machine learning course you will realize that they are much more powerful algorithms later on that you encounter where you do need to do this which are smart enough to figure it out in some sense magically they sort of figure it out and they adapt to the data and they figure out what's going on they sort of know that they are what the real degree polynomials are and so we'll come to that later but we are starting with this linear regression. This is it. Now, this is a limitation of linear regression that you have to do these experimentations by hand. So far so good guys. Are we together so far? Just on the one of the conditions for assumptions of this thing is the random thing. Can you a little bit elaborate on what is a random thing when you say it? Very simple. It just means that when you gather the data, make sure that it is a truly random sample of the reality. Like data shouldn't be biased or skewed. Let's say that you're supposed to find the height of children who are fifth graders and the school has a hundred fifth graders. A random sample would be that you take a sample of children, some are small, some are tall, etc. A non-random sample would be you find the tallest kids in the fifth grade and you bring them and now you try to use that. Because that second situation is not really random it has a bias isn't it avoid bias in data it's common sense thank you see you can never really do it what you can do is you haven't seen the reality somebody has brought you the data in a business situation you don't have the luxury unfortunately most of the time to ask the question is there bias in the data no you can ask that question actually is there bias in the data and you can look at the input data and see what is going on but suppose you look at the data and everybody's height seems to be six feet onwards just looking at the data you wouldn't know that the data is biased very hard to tell you need some external information you need a domain expert will tell you that you know you have just caught hold of some basketball players here these are not normal people it It's a bias data. So bias is a systemic problem in machine learning and avoiding bias, discovering bias is one of the crucial things. For example, I work in talent management and when we do research, one of the fundamental things and it is required by US law that you have to ensure to the best extent possible that you are not discriminating based on there is no bias based on the protected classes the protected classes being gender race you know age disability and so on and so forth. That your data does not have underlying bias so that you end up with results that is favorable to one versus the other. And do biases happen? Do they still remain? That is your worst nightmare that in spite of your best effort, there may be a hidden bias in the data somewhere. That you will discover later on. It easily can happen. We gave... Yes, so there are many ways of doing it. First is that, see, if you can control the experiment that produces the data, if you are not just a person who receives the data, but are on the ground, at the grassroot level, gathering the data in the field, then you can control for biases. The second thing is, you can take a lot more data and hope that it is harder for more data to have bias. So imagine that you just randomly pick three people. It is possible that those three people may all be very tall but if you truly randomly pick 100 people and the process was random, the probability that they all happen to come from the high end the basketball range is very very low so size of the data certainly helps you sometimes though you don't have the luxury you see what happens in and we will do a lot of these experiments see those data sets that I asked you to analyze in the exploratory data and this is will carry them forward throughout this workshop we will do machine learning exercises on them so we will predict the California house prices will predict one of them is breast cancer actually haven't released that but you will do that predict whether somebody does or does not have breast cancer based on the predictors. And you will encounter a lot of these data sets. Some of these data sets people have tried a lot to remove bias, make sure there is no bias. Sometimes you can't avoid it. So if you receive data and you were not there producing it, you should go with the assumption that there may be bias. Are we together? One more question is assuming all the other conditions meet except the collinearity, let's say it's present, can I drop that particular parameter and go with the rest of the observation? All you do is, and that is why you should first do exploratory data analysis because if you do it, if you look at our nodes, what is one of the first things we do we find correlation isn't it pair plots and correlations so in the correlation matrix it will immediately stand out that two predictors are highly correlated isn't it and the moment you find that you know that linear models will go for a toss. So you pick one and ignore the other. You don't put both of them in the model. You pick one. That is exactly the way. And we will do not today's lab, but the next lab. Next week is all labs, guys. So we will walk through some lot of code to understand this. So that is what it is. Now, I must make a point that is important. See, traditionally in the field of statistics, people did hypothesis testing and confirmatory analysis. They would start with data that they knew or were assured or had some confidence is unbiased. And then they would check whether a hypothesis is true or not. The world that we live in is the world in which data comes at you. You don't get that much flexibility to control the experiment in a large number of situations. For example, you get Twitter feeds. You can't control what people are saying or writing, isn't it? You just get the data. You get vast amounts of data but most of the data sort of emerges it comes at you you can pretty much try to grapple with it and it's there what you can't do is set up an experiment in many many real life situations where you have ensured that bias is not there so you are in in a world in which the thing that becomes most important is exploratory data analysis and that is what we have been doing in the first labs, the first notes that you got, lab notes, that is what it was doing. Today exploratory data analysis in the world of big data is dominant. The confirmatory analysis is there still the other half of statistics but you don't get much opportunity for this in many many real life situations sometimes you do sometimes you're lucky you do and that is a big shift in the field of data science machine learning we are in a world in which you take data as it as it is and you try to make predictions and build models and find patterns in it as it is so all right guys that that is the Gauss Markov assumptions and remember that you should respect that you should check whether data follows these assumptions or not if it doesn't then there's a word of caution, your models may not be good models. And if I were to point out one thing that many, many textbooks in machine learning fail to emphasize, it is this, and how do you systematically check in your data analysis that you are not being misled, and we'll do that in the maps. Now there are other things that can mislead it besides multicollinearity and so forth. So let me talk about two more culprits or criminals in the space you can think of it in the data. One is outliers. One is outliers. What are outliers? We all know what outliers are. So suppose you guys are all standing there. And what is the joke in India that Amitabh Bachchan comes by, and he's an extremely tall actor? So then he practically looks down on all of us. What would you call his height when it is very different from the population height that is looking at him you see that he's unusually tall isn't it the word unusual comes to your mind or out of ordinary out of ordinary out of ordinary consult in your mind isn't it so if you plot people's height most people's height let's say is there or in your group will be and then they will suddenly be this guy sitting like very very tall whose height is like this what somebody sitting here is or somebody sitting even far out let's say we have a people's height like this. What somebody sitting here is or somebody sitting even far out, let's say we have a people's height like this. And this goes off to and here is a guy, you are here somewhere, let's say that you're somewhat tall, but here is this guy who is very tall. What do you call him? You call him an outlier. he's outside the the mass of or the most the the basic population of the data there's the intuition makes sense guys or let's say that you get a very very short person and that person is an unusual dwarf right let's say that you get a two-foot human being and that person is let's say 50 years old now you would say that well that's unusual they're very very few such people most of the people their heights are I don't know between grown-up people have heights between a four feet and let's say six and a half feet or something like that but occasionally you'll get a seven foot or seven and a half foot and you'll get a two foot or something like that so they are unusual people in terms of the population with respect to height so another question is what's a more technical definition in one dimension outliers are easy to find. What people did is they all took, there's a guy who did the first exploratory data analysis book, I think, to my knowledge, Jukier. He's quoted in my notes, very influential. So he said that if you make the points, which are one standard deviation away, one standard deviation is sigma and this sigma one standard deviation this right and then you find things that are two standard deviations away here so this this is another sigma so up to this he said are inline data so minus two sigma to two sigma he called inline data inliners or liner liner not linear inliners and outside the range greater than 2 sigma right and less than minus 2 sigma right so here this region the next sigma that is here next sigma he called it the greater than 2 sigma less than 3 sigma less than 3 sigma this sort of data he called the soft outliers like they are outliers and then things beyond plus minus 3 sigma he called like strong outliers are we together does this make sense guys so I'll give you an example of what an outlier is in very practical terms. When I was in IIT, we had a particular class. The class was very hard. To make matters worse, the professor gave negative marking. And so most of our marks or grades were, we all scored somewhere around zero quite a few got negative marks quite a few got like six seven eight or nine or something like that but in our class there was one guy who absolutely loved that subject he just wanted to do that something guess what he got he got 100 plus 100 so that would be an outlier as simple as that so guys have i conveyed the the notion of outliers simply for one dimension it is uh you just look at the standard deviations and you get a sense of the outliers for higher dimensions 2D and higher, it's a little bit more tricky. In 2D, you can still do that. So suppose you have data like this. Let me take data like this. Data is here. Any data set is here here let's say and suppose there is a data here what would you call this data do you notice that it stands out the nearest neighbors are a little far off this would be called an outlier in two dimensions an x1 next it is an outlier maybe it is yeah are we together guys and you on the same two-dimensional or one-dimensional can give examples real life examples of soft soft outliers yeah soft outlier would be on see a simple soft outlier is let's go back to the beach suppose that you are looking at the wind you know the tides and how high the tides are so suppose it's a pretty stormy day, what will happen? The tides will be quite strong, isn't it? That is an example of a soft outlier. The sea is responding to the winds. What would be a huge outlier? Something like a tsunami right because the Tami is unusually high like 30 40 50 feet high or 100 feet high tidal wave but any tidal wave that comes and hits you would be stronger strong out now yeah and it is very practical in naval tradition. All the ships are designed to deal with soft outliers very well. But their big fear is what if a strong outlier comes, what if a gigantic tsunami or tidal wave comes? Then all bets are off, completely all are completely all bets so that's an example of soft and hard outliers so that is outliers and then I'd like to finish this with one more concept so outliers you know they stand out good lovely thing about outliers is they're easy to spot so these criminals you can in the data you can sort of spot oh there you are. Do you notice that you spotted the outlier just by doing a geometric visualization of the data. In higher dimensions also there are techniques that you can do that. You can look at the distance to the nearest neighbor or some means it gets more sophisticated outlier detection and an anomaly detection actually becomes a very sophisticated field now why is it important in higher dimensions and in complicated situations this whole business of outliers detection is important because for example crime most people let's say imagine that you have a network and most of the people who log into your computer systems in your network and they have a fixed pattern they log in check their email work and this and that so if you look at their behavior they will all be in line data I mean in other words their behavior will look like other people's behavior but then comes a hacker and his whole pattern of behavior he'll hop from machine to machine to machine in a quick succession he would have gone and compromised like 30 40 machines that is unusual a normal employee doesn't go and work on 40 machines in a day unless he is a system admin so there is a very anomalous behavior that will stand out as an outlier and so this whole business of outlier detection is very vital it's a core activity in machine learning it's sort of a specialization in its own right and entire companies make huge amounts of money they have business based on just one specialization ability to find anomalies and outliers in the data I will be special people use the word anomalies outliers novelty I'll use the word some what's synonymously that the subtlety is there in that and detecting it is quite a game it's a cat-and-mouse game actually and for medical for example many many diseases the the lab test results will stand out as outliers and we know that something very unusual is going on so that is outliers but there is another class of things which are slightly different. They are called points of high leverage. So high leverage points. So high leverage points are like points, which for whatever reason that you can't tell is sitting somewhere hiding somewhere in the data. But if you remove this point. Your model will change. It's very interesting. So suppose your model is like this and if you remove this point, your model will become like this. Hypothetically, this is what happens. these are points of high and it is very specific to linear regression when you solve the problem it turns out that for whatever reason these points when you just visualize the data you can't see them but they are sitting there and they hijack your modeling exercise they make your models not as accurate in prediction. These are high leverage points. You can't see them. So now you need mathematical tools to do that. And those mathematical tools you'll see in the code. Let's do it by example. We'll actually do a data analysis and see it with that. Are we together, guys? So these are points of high leverage. see it with that are we together guys so these are points of high leverage and there's a use mathematics to find them now why do these things matter the reason they matter is look at this outlier what is it doing without the outlier your model would look like this isn't it we together this blue line is what your model would look like if this outlier was not there but because this outlier was there it is tilting the model towards itself it's making the model go like this. Does this make sense guys? Because this is also pulling the line. Do we understand that? Just a few outliers can distort your model and make it much worse. So outliers and high leverage points, they spoil your linear model. And you have to watch out for them. When you build linear models, you have to check, were there any outliers? Do I need to remove them? Were there points of high leverage? Do I need to remove them? So those are the questions you ask in linear models. And this is, again, very specific to linear models. Watch out. Leverage points, high leverage points. High leverage points but you know outliers have a very interesting behavior see this guy is an outlier isn't it but i can have another outlier here and you realize that if these two outliers are there they may effectively cancel each other out and you may get a model like this this yellow line which is very close to the blue line are you seeing that guys the the outliers on both sides of the fences they may end up canceling each other out you know the effect and they may pull the data the solution towards the line that would have been the solution if these outliers were not there. So outliers may or may not screw up your analysis, but certainly it's worth finding them. And generally, it's a good idea to see what happens when you remove them. High leverage points are actually much more dangerous. When they are present in the data, you're pretty much screwed. You know that your model will be impacted. The quality of your model will be impacted. There is no getting around it. And the moment you find points of high leverage, first thing you do is take them out. Are we together? And the word leverage is very apt for it. It's somewhat, if I have to give you an analogy imagine that there is a decision-making body and there is one guy and whatever he says has unusual influence on all the decisions for whatever reason what will happen that person has unusual I mean you might as well just have that guy in the meeting room isn't it so one way to get a consensus or you give everybody a voice is to essentially take that guy out of the meeting so that is the concept of high leverage are we together guys so we'll take another question together guys so we'll take another question go ahead from an outlier perspective do you think at at any point outliers are useful like but do we have to always remove them no not only for linear models remember i said that these are the problems that you worry about only in linear models worry about only in linear models so linear models like the linear regression model and logistic regression and so forth we'll do later linear models have a lot of limitation one of them is they get hijacked by outliers and leverage points may get hijacked leverage point certainly outliers maybe so you'll have to treat it ask should I remove it what would the model look like if I remove the leverage point I mean the outliers but outliers and themselves are good things because you know sometimes you are in search of the outliers that is the signal you are looking for for example a lot of fraud detection is simply based on that credit card fraud is a search for outliers in data so let us say that you do most of your purchase in your hometown then all of a sudden you start buying Apple a MacBook or Apple watch in let us say Oklahoma that data and then you start buying a lot of fancy expensive electronics there that data should stand out as an outlier because normal behavior is you stay in your hometown and any given day you don't splurge on too much too many electronic items you might buy a iWatch or you might buy one day an iPad but in the same day you don't go buy all of them can outlier kind of help us in also determining what the upper and lower bounds of our our data's of our whatever we are looking at is it is so for example if you are doing I'll give you an example if you are making a building very simple example you're making a building and you have the stress that the building will go through you have data on the stress points the vibrational data it is an industrial zone and you're looking at the vibration you know the wind shakes the building and many other things you you don't want to structure the building the structural strength cannot just depend on the normality conditions you have to factor in the earthquake which will be an outlier data so when in the data you see this suddenly massive stress you't say that let's ignore that data point. I will build a model and predict. I will use the amount of steel if I'm predicting how much steel and how strong the steel and concrete should be. I can't make the prediction but the strength of the building depend based purely on the inliner data and remove the occasional earthquakes which are all sitting as outlier stress points. See that, right? So you can't always ignore outliers. You have to take the outliers into consideration. Can we also say based on that, that if we encounter an outlier and based on that thought process, if we find that outlier to be important, we have to go away from a linear model even though it makes sense. Yes, certainly. Certainly, you have to do that. That is why the outlier treatment is very important and we'll do that. As we move along in this workshop, we'll do that. As you know, in the boot camp, we have an entire day devoted just to outliers. Remember that. So, we'll come to that in due course of time so so guys at this point I'll just recap what we have done because I'm multilinear regression and the univariate linear regression is a part of it people often don't use the word multilinear they just say linear regression so do we know now what it is would it be fair to say that we now know what it is guys let's review would you say that we know this yes and what are the factors that affect it so collinearity or multicollinearity outliers leverage points they all affected what is multicollinearity we saw when two predictors show what what do they show what is multicollinearity who would like to phrase it for me either increase or decrease yeah when two predictors are highly correlated more basically dependence to the output or another put it in correlation between two predictors xi and xj is approximately one very close to one zero point nine zero point nine is close to one that is a sign of multicollinearity what are outliers who would like to explain what outliers are guys observations which lie outside the 3 sigma. The other population of observations. In one dimension, soft outliers are beyond two standard deviations. Hard outliers or strong outliers are beyond three standard deviations. In higher dimensions, it is that data point that stands away from other data points. That's outliers. When we say when we use standard deviations here, we are assuming that it's a normally distributed. No you don't. You don't have to. That normality in the data is not necessary. It may show up points inside distribution or any other distribution. For example, suppose you have a distribution, which is very common these days, like this, long tail, or like this. Definitions of outlier still remains. Beyond 3 sigma, it is outlier. Beyond 3 sigma, it is outlier beyond three Sigma it's offline and in fact the modern economy is based like it so the whole question is what is outlier in these distributions right it's a very interesting question it turns out that there is a tremendous amount of data that is sitting there and sometimes in long tail you don't quite get an outlier because the tail is very heavy it's a very interesting topic let's not get there but at this moment I will just say that it is not necessary for it to have a normal distribution normal distribution is the intuition we're together but for example this guy is an outlier if you look at people's salaries by the way in a in a university this is real data by the way because i happen to have done this this is how the compensation of employees in a company look like but guess what the compensation of the executive staff looks like it's out here it's typically one or two extra zeros added to the normal employers compensation so what would you call the executive salary that is a classic example of outlier very few people with that kind of salaries in the company compensations in the company percent yeah one person or two three people the executive staff so those are outliers together that's what our players what are points of high leverage guys who would like to recap before we take a break take a break? Yeah exactly they don't they don't look obvious they're hiding in there in the data but they have unusual influence on the model and so you have to use the right mathematical tools to discover them and we'll see in the lab how you do that with data. And finally, can we say that outliers will also be leverage points? No, they're not. They're never. Leverage points are always in liners. They're sitting, hiding in the middle of the population. Are we together? They are in, think of them as, got there in disguise sabotaging your model there's some odd tears looking normal and basically screwing up your models what are the who would like to tell me what are the five gosh Marco assumptions for using linear regression anybody would like to name them your sample should be truly random because you know you shouldn't have bias tells anybody somebody else linear equation yeah you should have a linear equation very good somebody else gives me the third one it's a homo is cadastric yeah it should have homoscedasticity means the variance of the error shouldn't change with the value of the target variable that's right right in other words you should not have this cone shape it's sort of a cone shape that you see here or when you plot it against the residues or this kind of residuals they should not exhibit the error shouldn't exhibit this cone like structure right we should remain constant what other factors are there in a gosh gosh Markov assumption guys cool in here it should be absent cool linearity should be absent excellent did we miss anything else no pattern in deciduous basically that is the homoscedasticity the errors must normal normal errors well perfect so that is great guys it's a very interesting actually when people come to interview in my team and usually I get a mix of people with masters just a side people with masters from good universities and a lot of PhDs come. And people these days, they are very fixated on what is hot. So everybody would know what is there at the cutting edge of research, because everybody has attended the latest meetup meetings, meetups and so on and so forth. latest meetup meetings, meetups and so on and so forth. But when I start interviewing people, I go back to the foundations just to see how well people understand the subject of machine learning. And it is quite depressing how few people actually know the field at all. They just practice the field, they don't know it. They know sort of by practice and mechanics experience, but they don't have a good theoretical understanding of what exactly is this field doing? When can I use a linear model? Very simple question. Go to your place and ask somebody, when does linear models work? They will say when the data is linear. But it isn't just that. Linearity is only one of the criteria that needs to be met. So guys, I'll stop here. What I would like to do is Prachi will give you guys a quiz. Take a break of 15 minutes and in that break, let's make it 20 minutes. 20 minutes break. It's 8.40. We'll regroup at 9. Also take the quiz. Prachi, have you posted the quiz to slack? No Asif I'm just doing it right now. Please post it to slack and guys all of you take a break go drink water get some dinner if you have to meet your kids come back do take the quiz it will give you a bunch of basis of how much you have understood the reality check please take the place those words I'll stop the recording we'll take up the recording again when we are you guys seeing my screen here one oh yes yeah i think you're still recording all right guys so in this record in this iris data set which is the simplest of all data sets like i said everybody starts more or less with iris in the target. We have a simple data set for regression, but at this moment we are not doing regression, and we did exploratory analysis. We have four, five features. One is what is the species of the flower, and then the sepal length, sepal width, petal length and petal length. Out of those four features we do the exploratory analysis and you can see all the code it is there in your notes also and here is the notebook, the HTML export of the notebook, the R markdown. I've posted all of this in the R markdown so that you can use this code. And likewise for weather dataset, weather dataset I've done in both Python, all of these, this is your weather dataset. I've given out the solution. See guys, if you haven't done the homework, I would highly recommend that you study the solution, give time to studying it and gradually catching up and trying to do it and study the nodes. So this is for the weather data set, and this is in R. And then you can do the same weather data set in Python. And it looks not very different, the analysis in Python. As you look at this, you realize that it is practically the same. I hope you have read this in the notes. It is the weather data set. Now the one data set that you haven't quite studied is the California housing data set. I asked you to do on your own. So here is the solution to that. I've done it here. So once again, you read the Pandas data file for housing, you tabulate a few rows. This is just applying a good style to it to make it look pretty. Then you draw it on the map. So for map there is a lovely library called Folium. Import that library and with that library you'll be able to project data into the map. What am I doing? I'm finding the center of California and then I'm making that the position of the map and zooming out from that zoom level then you get essentially the part of the map which is focused on California and then a bit of color, a splash of color and so on and so forth. So this is the data. You notice that just by looking at the data, let me see, what can you tell looking at this data? Can you make out the two population centers guys in California? So for people in California, this is pretty obvious. You can see the Los Angeles population center, the metropolis, you can see the Bay Area metropolis here where my mouse is and you can see the Sacramento and you can literally see the Central Valley and this route 5 and you can see some populations around that. So this is it. The data is housing data. This was collected in the 1990s, I believe 1995 or something like that, the house prices. So what I have done after that is I have projected this data onto just a scatter plot, as simple as the scatter plot of the points, longitude, latitude. And what do you see here? The darker the color, the more expensive the house. Clearly, the house, it is no surprise that metropolitan areas tend to have very expensive houses. They are also the bubble here, the size of the bubble, gives you a sense of how much population is there. The more the population, the more . Now, you notice that there is a lot of code that go. This may look like a lot at this moment for you. You're creating a scatterplot. You're doing all this label, aesthetics, et cetera. So it is the nature of data visualization. Soon, the scatter plot or the scatter function of a matplotl look very easy to you. It is just one line. You start by just making a rough and ready graph. Then what you do? You try to improve the aesthetics of the graph. You notice that I've added some things which are not quite necessary. I've added some things which are not quite necessary. I've added a color map which says that what is the color gradient to use to show the sand dunes, median house values, sorry. And then s is size of the bubbles in the scatter plot. Alpha, this is transparency. There's a lot of data here and it begins to look rather cluttered and hard to make head and tail out of so one of the very common tricks that we use is you sort of make most of the data points only like very very transparent all the data points they are only 20 percent opaque so that at some point there has to be a lot of data for the color saturation to take place, which you see here. So, you'll also see that I use some of the latex syntax, not necessary for you to use, but generally to create production quality. Perhaps it is a common practice to insert latex syntax in my notes. I mentioned that. If you don't use it, of course don't use it. LaTeX has a very steep learning curve, but the rewards are really more. Here, by the way, what I didn't show is that I've saved these two images, and then I wanted to put it in a notebook side by side in the lecture notes. So that is there. and now what was I doing here and why is it saying this I will fix and repost it something has happened here so We'll have to see. A w plot color is some color. This is wrong. Let's check on that. Data is not defined. Anyway, I need to go fix this code. I'll do that in a minute. So then we look at, first thing we look in the data is that the ocean proximity has only five values. You're either near the ocean on an island or near the bay or inland. So those five values, you convert it into categorically, as type and that is something we learn in the next lecture. You look at the data you draw the normal histograms then you you make the pair plots by now pair plots if you have been reading the notes they should be pretty familiar to you. These are the pair plots you make you can make category plots you know pair plots and how many data points how many houses are on an island very few how many houses are near the bay again this is a concentration of houses near the ocean lots of houses in california near the ocean and then a lot of things are here and many houses are within an hour of the ocean. There are two plots which are very informative. One of them is called the violin plot. They give you a sense of where most of the data is, at what value. Like example, you notice that where the bulge is, where the height is, that's where the data is. Most of the data points are concentrated. It you a nice smooth representation of that so if you're looking at median age of the house from this you can pretty much see that houses that are near the ocean they tend not to be more than 50 years old. Houses on the island can be 60-70 years old. So can anybody name the island in California? Catalina. Yeah, of course. Yes, very good. So there we go. So this is it. and this is the box plot that gives you the standard you know the two sigma deviations and then the outliers that you see here mentioned. So these are box plots. You are all familiar with box plots. What is what I've done here is shown all the box plots, nine box plots in a grid. And try to make it, see when you make graphs, it is important not just to make the graph, but to make it aesthetically pleasing. I haven't done too much effort, but a little bit, because then if you make too much effort, the code becomes a long complicated code. This with very limited effort do you notice that this graph looks very I would say fairly presentable you can put it in your document in your report and so forth to the extent that in machine learning a lot of the work that you do is complete mystery to people in the business side you have to tell a story and your graphs will tell a story. You may wonder that how did I produce those lovely tables in the document? So one of the, and this I just kept it as an illustration, one of the lovely things that Pandas has is that you can convert any data frame into LaTeX. It will emit it out as a beautiful LaTeX table. Those of you who know LaTeX would love to see this, because it is terrible to key this in by hand. And of course, if you don't know LaTeX, just ignore this. The correlation matrix, so you can see all the correlations. You'll find notes about what you can observe. For example, house median age is highly correlated with population, with total number of new homes and so forth. So, in other words, the older homes used to be bigger homes. Now, as the concentration, as the population gets more and more dense, there seems to be a tendency to have less big homes. Smaller homes are more popular and then after a little while we'll go into more stuff we will do machine learning on this for example we learned regression so the next thing I would invite you to do and it's a bit early but I remember we'll do it one day suppose I ask you based on all these features can you predict the house price? Longitude, latitude, median age of the house, total rooms, bedrooms, population, et cetera, et cetera, and proximity to the city. These are all factors. Can you predict the median house value? By the way, data here is at the level of one block. So if you see a huge number of rooms in a house it is not a house each data point represents our entire city block so the goal here is to predict what would be the price and it's a Zillow does that right and all this Julia and all of these things do that so we will do a similar exercise based on these features. We'll try to predict the house price and see how accurately we can do that. It's a very real world example. This data is a little bit old, but it's a fun thing to do. We'll do it in due course of time. But I highly encourage you that as a warm up to that, you do go and do this exploratory analysis so that when we are doing that analysis or machine learning, we only focus on the machine learning part, not on the exploratory analysis part. So all right, I won't do. And by the way, these maps, do you notice that I can zoom in, zoom out? These are live maps. This is the beauty of FONIA, which is based on leaflet. And the R equivalent of this is literally called leaflet. So that is that. I won't go into it and then what are the weather data set once again I've given you both versions of the data. So here is the data in R the notebook So here is the data in R, the notebook. And here is the, and I posted it all to the discussion group. And here is the same notebook, but now in Python. You would realize that not much difference. Both these languages look, the notebooks in both the languages look almost identical. One reason why you should learn both the languages why not and joints and so forth so i won't walk through it because we have explained this in the notes what i would like to do today is focus on the linear regression so this is your next lab i'm going to post it now yeah as a google share in a little bit so you guys will all get it So, this is your next lab. I'm going to post it now. Yeah. As a Google share and a little bit, so you guys will all get it. So, linear regression and friends, and here I defined linear regression as with polynomial terms and with interaction terms and all of that. But we'll start slow. Are you all able to okay now? I need to share this, sorry. I haven't, I'm talking with my sharing. Let me share the other screen. Application, application share. Let me know, guys, if you can see my screen. Can we all see this? Yeah. And so in this, let me make this even smaller. This is, we'll do linear regression with five very simple data sets. I've created these because i've deliberately created this to illustrate the various aspects of linear regression analysis so we will do this follow it up with real world examples like california housing is this clear enough guys is it too small on your screen is it looking clear enough yeah so one of the things that I like to highlight it's is it's a truism in the field and I think it broadly applies to all of science itself. People often say, which is the correct model? When you build a machine learning model, a hypothesis, the question often comes, now which hypothesis is correct? now which hypothesis is correct now in machine learning there is no such thing as correct type or in science in general there is no such thing as correct hypothesis the only thing is you don't know the data is there the forces that produce the data the generative forces you don't see it if you could see it there was no point in doing machine learning on it anymore. You have to infer it, you have to approximate it. The whole goal is to approximate whatever produced the data. So the question is, how good is the approximation? Is it effective? Is it useful? That's the only question you ask in machine learning. And George Box was a great, what we would call a statistician and a data scientist today. He said, he has made major contributions to this field, one of the great giants in the field. And his statement stands there to always remind us that all models are wrong. Whatever hypothesis you build is probably wrong, but some are useful means just because it is not the generative force doesn't mean that you can't use it so long as it is a close enough approximation it is useful it makes good predictions and therefore it is useful so the measure of modeling of machine learning is the model metrics, the accuracy, the prediction error, the how close it is and so on and so forth. So we measure by that. We don't ask the question, is it the correct model? The correct model is the simplest effective model. It's sort of the Occam's Razor Principle. Given data, if you can build a very simple but very effective model, that you can sort of define as the correct model if you want. It's called the Occam's Razor Principle. So these things, by the way, guys, in the lab, and I offer these R words. I encourage you to use it. If you haven't started using RStudio or Python and Jupyter notebooks and you are a bit hesitant, by this time, there are a lot of people who haven't started. And I highly encourage you to come to these extra sessions that I offer in the evenings, where I'll walk you through the setup, where I'll make sure that on your machines these things work I'll be together we'll do WebEx sessions and I'll guide you things when there TAS here will guide you thing and guide you through the whole process so use these facilities so not much I'll say about here by By now you know that this is it. This is splitting the data and so forth. You'll get to read it. But we'll look at the first data. So, here is the journey that you'd go through when you do data analysis. First, you do exploratory data analysis. we have to get into the machine learning part. So start with the EDA all that we did in the first lab and then come to this. So what do you what do what do we do in the EDA part? We load the data, we investigate the data, we summarize, visualize the data, we see how it looks. So here we go we look at the summary of the data and we plot the data. Are you guys seeing this plot of data where my I don't know does this mouse let you yeah do you see where my mouse is moving guys yes so when you look at this data it's a one-dimensional like it's a single variable X and Y is the prediction what can you say do you think it's a linear relationship a straight line is a good approximation What can you say? Do you think it's a linear relationship? A straight line is a good approximation? What could you say guys? Straight line is a good approximation. It is a good approximation. So let us see whether that hypothesis works out. So the syntax in R and in Python both is very very simple. Look at this. You need to, and this is the beauty of it, I can't think of any other framework where things are so simple. In machine learning you don't write a ton of code. Usually one-liners are very very powerful. So the only code here are these two lines. You see what I've highlighted? Two lines. The rest is the output of the code. So the first line says build a linear model. Actually LM I'm told it doesn't stand for a linear model. It stands for the name of the two people who created it. I won't go into it. for the name of the two people who created it I won't go into it Levenberg market so it says that Y depends on X you see this tilde here it says Y depends on X in this line of syntax and what it is saying is build a model where Y depends on X a linear, and save it in a variable called the model. And then the summary. Summary is a general purpose function in R. When you say summary on anything, like here we say summary on the data, it will give you a summary of the data. If you say summary on a model, it will tell you all the parts of the model, the beta naught, beta 1, and so on and the parts of the model the beta naught beta 1 and so on and so forth. So when you look at this the first thing that you start with is actually here at the bottom. And by the way there is multi look at these two things multiple R squared and adjusted R squared today in our modern world I just ignore all of these different subtleties we'll come to it I'll explain it someday but just look at the adjusted R squared as the R squared that we talked about in our lectures what is the R squared about what part of the data can be explained by your model right a TSS my RSS over TSS remember total error null hypothesis error minus the error of your model divided by the null hypothesis error if you go back to the notes you'll see it so good big good R squared and R squared goes from 1 which is very good and then goes down to zero and can even become negative unfortunately so um it means your model can be even worse than the null hypothesis you can be totally misguided if it gets negative so here a big r squared is good or bad anybody it's good it's good right it's good uh the? It's good. The bigger the R-squared, the better. But one thing about regression and anything is no one measure you can trust and say, all right, it's a good model. You have to look at many aspects of it and then tell. It's very much like a physician. When you go and meet your physician or family practitioner he doesn't just take your temperature and declare you to be in perfect health uh he or she she will also take your um you know blood pressure will look up your throat and do many other tests look at your blood test results and if everything is normal then she will declare you to be healthy otherwise if any one thing is wrong, then what happens? If for example, everything is normal, but the blood pressure is high, will your physician declare you to be normal? She wouldn't. She would say, we have a problem. And the same applies to the output here. This output that you get, you have to look at many aspects of it and all aspects of it have to be good so I'll just cover what those aspects are the R square has to be good which seems very good then let's look at this part we are not going to focus on this part right what it says is the intercept, the coefficient of the intercept, in our language it is the beta naught, isn't it? When you write the equation y is equal to beta naught plus beta 1 x, this is beta naught, right? This 3.45. Let us see, look at the data and see if it makes sense. What is the intercept it is the height Y at X is equal to 0 does this look to be about 3 give or take it does look to be 3 3.5 isn't it look here this is where it meets right so it does look right. This is it. Now, the beta 1 seems to be this. Slope seems to be about a 2.7. So let's approximate it 2. So what it means is that if you increase by 10 units, the y should have increased by how much? Approximately 21 or 22 units. Let's see if that is true. At this value, is y approximately 21 or 22 units. Let's see if that is true. At this value is y approximately 21, 22? 22 plus 3.5 because the intercept is 3. So 25. Is it approximately 25? It seems to me. Does your model agree with the data, guys? Are you able to interpret it see if the slope is 2.7 slope is what the increase of Y with respect to X so if X increases by 10 unit Y should have increased by approximately 20 units actually 22 units and then the intercept is 3 so 25 Y should be around 25 25 is here let's go here and see is that what you get as X is equal to 10 it seems to be right along the x-axis X is 10 maybe the fonts are very small you're not able to see it let me zoom in in this and see one page at a time single page is this picture more visible guys now even more if you look at this picture more visible guys now? Even more. If you look at this picture, can you see that at X is equal to 10, Y is approximately equal to 25? Anybody would like to confirm that? Yes. And you would agree with that so this this value that the model is predicting makes sense what is the standard error standard error is the like how sure you are about this like taking different samples what is the value of beta naught and beta 1 that seems to emerge from the data I'll give you an intuition of standard error so let us say that you go to open grocery what is that farmers market and there is a there are two farmers one of them is selling you apples for let us say five dollars five dollars for ten pounds right that seems like a pretty good deal perhaps 50 cents a pound so you say well i'll take it but he says you know the bags are approximate it may be 10 pounds plus minus five pounds right then the other farmer says, no, my apples are $11, like not $5 a pound for 10 pound bag. Mine is actually $6 for a 10 pound bag, but it will be 10 pound plus minus half a pound. It can be somewhere between nine and a half pounds and 10 and a half points. Which farmer would you feel like buying your apples from? somewhere between nine and a half pounds and ten and a half points which farmer would you feel like buying your apples from the guy who's selling for five dollars or the farmer who's selling you for six dollars make a guess and justify that the six dollar one and why would you do that because the um chance of uh the error is very close to what um paying for yeah so you're much more sure what is it what is it that you're paying for whereas with the five dollar guy you might end up with just a five five pound bag instead of a 10 pound bag or on the other hand if you are really lucky you might end up with a 15 a pound bag though knowing shops it is unlikely to be true right so you might end up getting shortchanged so you prefer a more precise answers there's always an error bar there's always a margin within which the value falls. And this is the measure of the margin. So when you see a value 3.45 and it says plus minus 0.24, does that look to you fairly reasonable? It's not bad. It could be 3.6. It could be 3.2, isn't it, at most. All of these look pretty good estimates of the intercept likewise for slope it's even better it's 2.17 less minus 0.4 well that looks pretty good that would be considered good so the p-value is it is actually the ratio of the value divided by standard deviation standard error sorry so if you look at the three point four five when you divide it by 0.24 point two four is approximately one fourth which means you're multiplying three point four five by four let's take a three point five that will come to approximately 15 so you see this T value is fourteen point two eight it's just the ratio of these two you see that guys yes and the next one is 2.17 divided by 0.04 the t value is 53. so this is for people who can't take ratios etc see this results that you are seeing here is a old, it's a celebrated result in many, many fields. People have used these tools for many, many years in social sciences and in, you know, in psychology, in many fields, you know, in economics and in of course science, the strongest sciences, medical sciences, and STEM, the hard sciences, physical sciences, and so forth. Everywhere, and what you are seeing is, or being acquainted with, is something that you will find, this result, quoted like this in many, many journals and papers, articles, and people, your company will show results that will look like this. That is why I'm explaining it out to you so yes so so why why are those good results the intercept nx how can you say that those are good results see this is the thing it is a it is a way to judge it is literally when a value way to judge it is literally when a value has error bars which are very close means you have a good you you compare all of these together you have a good r square you are getting values and the error bars around it are pretty small so you look at the t value this is literally the two generally t values of in my experience a rule of thumb above five is pretty good so somebody gives you a five apples and says plus minus one you say all right I'll take it isn't it well somebody else may have a stronger standard it depends on the context see in scientific journals physical sciences physics or chemists physics physics for example, people want the error bar to be very very small before they accept a new theory. But in some fields, let's say in psychology, data is by definition mushy, it's soft. Human beings are not so easy to quantify behaviors. So you tolerate a much wider error bar so it's a judgment call what is the key value that you'll accept generally I would say that anything below four five or four five is really not good a good ones would start at let's say ten and if you're looking at a very significant research that will have a lot of impact, your p-value should be quite big. The error bar should be quite small. And then comes a thing which I will teach you, but I hope you'll forget after that. It is called the p-value. It is something that has unfortunately been abused a lot. What is the p-value the word for that is statistical significance is the name statistical significance what this says is it is 2 into 10 to the minus 16 it's a scientific notation into 10 to the minus 16 so is that a big number or a small number? Very small. What is this p value? Roughly speaking, it is the probability that your model is actually fooled by data. Null hypothesis is true. What is the null hypothesis? There is no relationship between X and Y. And that's a null hypothesis. If the null hypothesis is true, then your p-value will be very high. probably obviously one means 100% sure that the null hypothesis is true but if the likelihood that the null hypothesis is still true in view of this data is very very low what does it mean it doesn't mean that your model is the best model but it all it means is you might be on the right track are we together you might be on the right track now this p value has a natu has become notorious because for many many years people used to think that a five percent p value like if your a probability that the null hypothesis is true is below five percent you would feel pretty good you would feel that okay you are seeing some relationship between the predictor and the response and so that is where this convention comes from if your p-value is very small like less than a 1,000th of a person and like 0.1 percent then you for people in different fields who have a bit difficulty interpreting it what they do is they just look at the stars here they see three stars say oh great I found a predictor that really seems to matter if it is two star it means that p-value is one person there's one person chance it may still be wrong and a single star is five%. If they see a single star it means it's around 5% or less. A lot of fields say it is perfectly fine. Then a dot means maybe you know it is 10% chance that your hypothesis is the null hypothesis is true and if it is just a space there are no stars It means that quite likely your null hypothesis is true And you don't really have a model We together dies. It's a way to interpret how good how how much each of the predictors matters So an example I'll take if you're selling ice cream on the beach And then the temperature matters, the wind speed matters, but probably how many penguins jumped off Antarctica into the sea on that day doesn't matter. So its p-value will be very high. It would not matter basically. Those, whatever estimates you come up with would be just bogus are we clear guys so here the p-value is this does this look to be good or bad good good good huh into the minus 16 is practically zero it means that you are probably looking at a good model. Now, what has happened is the p-value has been abused. In many, many fields, the r-squared can be quite small, like 10%, 12%, 15%. And the thing is, data has a lot of noise in it. It's very soft. How do you judge whether a certain predictor does or does not matter? Is it significant or not and people have always looked at the p-value more and more and any p-value less than five percent and they will say oh we have got even worse than that people would like rig their experiment in such a way to somehow achieve a p-value less than five percent so that they could publish their results they could write a research paper and when we look in hindsight we realize it's a disaster there's a very entertaining book it's called the cult of statistical significance which basically deconstructs all the bad thing I mean it basically says all the bad things that can happen if you just get fated on p-value p-value is still a good measure but it basically says all the bad things that can happen if you just get fixated on p-value. P-value is still a good measure, but it's one of the measures, don't just trust it. And some people believe that it's a useless measure. Let's give it some credence, it's there. The Frequentialist, it turns out that the machine learning crowd is divided into two camps, the Frequentialist and the Botin's and the frequency is like p-value still the biotin's are very distressful in the pre-value so what it is worth it is there so when we look at this model is there anything alarming that you see anything that makes you believe this is not a good model F statistics is related to p-value it is a measure of how good your model is we'll just leave it in there. And degrees of freedom etc. we'll talk about later maybe. We have 99 points. We have not beta 1, two parameters. And basically if you subtract two from 99, you'll get 97. Right? The three degrees of freedom. It needs a little bit of interpretation, but it's really not worth going in now. We'll go in later when we have a bit more maturity. But so here, the adjusted R-squared looks good. Think of it like a patient's temperature. Oh, this looks good, and this BP, et cetera. Everything looks good. There's nothing alarming here. So from that, you may think it is a good model but it is not enough. One more thing we need to do is we need to plot the residuals. Remember our Gauss Markov assumptions? One of the things it says, what does it say? We must establish that all those assumptions are met by a model. Linearity is simple. Data, obviously we have taken the data and we know what it is. But the one thing that we need to know is this. Hang on, where am I gone? That is important. See, when you plot the residuals along the model, the y hat or the y doesn't matter then what should you see in the residuals they should be uniformly spread right homoscedasticity you should not see the spread more spreading the error spreading out in one direction or the other more than more than at different places of light simply put what it means is you shouldn't see a distinct pattern in the residues when you look at these residues do you see a pattern guys no no so this is just take it as a fact absence of pattern in residues is good as you scan your eyes from left to right. You should not see a significant change in the of the residue as you move your eyes from left to right. Just one question. So. Just one question. So the pattern that you're mentioning, what you said as you scan your eyes left to right, that means that was a straight line, your residual data should not be aligned to that line. Because to me, it looks like there is a pattern. So could you clarify what you mean by not a pattern? The data point, so here's the thing. Suppose along this point, let's say minus 10, around this region, residuals are mostly in a very tight band. Let us say that they were between minus 1 and plus 1. They were all here. These points didn't exist. These points which are far off didn't exist. Here, residuals were just between minus 1 and plus 1. But on this side, they're between minus 4 and plus 4. So you distinctly see a behavior, right? That here, residuals are not so spread out. Here, residuals would be much more spread out. Are we getting that? But if you look at this, residuals seem to be equally spread out everywhere. In other words, the variance of the residuals does not change based on the value of Y. Y had actually, they seem equally spread out in both as you move on the left as well as the right. Did you get it, Irfan? I think you asked. move on the left as well as the right did you get it if i think you asked no i i got it because the when i originally saw this when you said there was no pattern all i saw was the circular uh data on the left and then i thought there was a pattern but that's fine i i get it so you're basically saying there there shouldn't it should not be uh dense essentially to to show that there is no uh um that's saying it should not be dense, essentially, to show that there is no. That's right. It shouldn't be dense in one place and blown out in the other end. You shouldn't see a funnel-like effect. So far, so good. Our residuals look good. It doesn't still mean that we have a perfectly good model. There is one more test you should do. You should plot your predictions on the data. See what the data is saying and what your predictions are saying. So there is a bit of code, R code, and usually it's very interesting. Do you see that the machine learning code was much easier? We did the machine learning in one line, two lines. Where is it? Let me go up. You did the machine learning in one line, two lines. Where is it? Let me go up. You did the machine learning here in just two lines. But when you try to visualize the code, plotting code, it tends to be a little bit longer. Here, we are plotting the model on the data. We are taking the predictions of the model, and we are going to plot it on the data. Then you have to write a few more lines of code. It is actually very easy code, but you need to get used to the plotting library of R and Python and so forth, which is why you should start early, guys. Those of you who haven't started doing your homework, it's high time you started on it because you have to practice these things. These things have to gradually become second nature and these things essentially cannot be done you know it is a lot of it is just monkey see monkey do and read the documentation the API the the plotting API and do it look at examples and do it and that's all it is in other words there is not big theoretical depth to it you just see understand and do how do i learn about any new plotting library i just read a lot of examples then go read the api or figure it out and then do it and then it happens i forget it then i go back and look at examples look at the api and get it back that's it so now here the maroon line is the prediction and the blue and the green are the upper and lower bounds of the prediction remember I talked about the standard error so they are this like upper bound and the lower bound so when you look at the maroon line do you think it is a good representation of the data guys yes yes it does look like it so this is a good thing at the end of it when you reach this stage then you feel that all right we do have a good model so what all things we did we loaded the data we did exploratory data analysis we summarized and visualized the data then we built a model we looked at the model diagnostics. They looked good. But we did not get satisfied with that because that itself can mislead you. We looked at the residuals to see no pattern there. There was no heteroscedasticity. That looked good. Then we moved on to finally making the predictions and plotting it on the data and even that looks good so this is good now in your career you won't get many situations where you build the first model and it succeeds so enjoy it like when you are looking at this exercise and you do it enjoy it while you can because most of the time life is more complicated and we will see complications in our very second analysis. This is where everything worked the first go itself. Real life is complicated. I have a quick question. I saw something like a confidence interval in the last the error chart? Yeah. Is that on the right side? Basically what it says is, hang on, let me make this confidence interval. Let me explain to you visually what it means. What is the plot in the next thing? See, when you look at it right it says that with 95 or 99 percent confidence you can be sure that your prediction is between the blue and the green so suppose this band is narrow it means that you have a you know it doesn't matter whether you pick the blue line or the maroon line or the green line they all seem to be good maroon is slightly better than both blue and green but they're tight but when the lines are far apart, means you don't know with confidence what the actual value is for a given X. I'll give you a real example. Once I was dealing with a rather complicated problem and I built a linear model, not a linear model actually, a complicated model. It was different. I was doing it in spark and it was big data and it had taken hours and hours to run next morning you know you it finally finished when it finished we were overjoyed that the model has finished and we asked it to make a prediction it predicted a value I don't remember what the values let's take the value of seven for something regression. Then we asked, OK, with 95% confidence, what can you say? It is between what and what? And the answer came out to be, it is somewhere between minus infinity to plus infinity. So would you trust that model? No. No. Because the confidence into the 95% confidence bar is way too wide Right. I mean you you give up at that moment. You realize that you haven't succeeded. You have to try again build a different model But here the two lines are very close to each other. So it's a good thing But here the two lines are very close to each other. So it's a good thing. Okay. Asif, in the same figure I see the green and the blue lines are moving farther apart from the maroon at the edges but they are very close at the center. Is there anything that we can understand at this point or it's... Yes, let me. What happens is when you are near the center right in the neighborhood there are far more data points, isn't it? Opposed to here, look at the edges. Literally on one side of the, one side, there are no points. So data becomes what you call sparse. Less data is there on the edges. is there on the edges when there is less data your confidence goes down when there is a lot of data you make more more robust or more confident predictions that is why these lines are closer to each other it's very nice that you observed who is it who observed and I mean like I was about to say the standard error related to the lower and upper ground. Yes, they are. They are right. This is the confidence interval of the model itself. So, think of it like that. What what the. It is related is derived from that basically in the formula is very simple it literally starts with standard analysis of the data set too so if you look at the weather where are these data sets guys anybody can tell me where is this data set in the github and the github link is there where in your notes that you already have guys so you all have that if anybody doesn't have please reach out reach out to us reach out post the question in slack and so forth and one of you actually Apache or Dennis or Dennis one of you could you please post the link to the gith GitHub on the Slack once again? Just as a reminder. Okay. The ML100. This is the second data set. I won't go into loading the data, it's the same code. But when you summarize the data, it's a surprise. Look at this data, figure 1.3. Looking at the figure, would you say that a straight line is a faithful representation of it Yes or no Alright, in fact, this seems to have two bends Right. So certainly a straight line shouldn't work And this is the interesting thing I see in two dimensions you can see it there's only one predictor you could visualize and see it unfortunately in real life the data sets come with very high dimensionality these days even think of a bit high dimensionality even if there are four predictors you can't visualize data in five dimensional space right So sometimes it is not obvious that the data is nonlinear That you don't have a linear, you know situation So, how do you proceed? When you can visualize in one dimensions great when not then I will here I will help you Understand how you can do it again we do the same exercise do you notice that same code we build a linear model and we look at it we say Y depends on X so what are we trying to fit here we are trying to fit a straight line to the data right and here is the danger of it suppose you had not visualize the data look at this model you get an adjusted r square of 60 percent 60 percent is considered pretty good right you have a pretty good model here does the p value look good guys i see three stars so to me it looks good isn't it yes the t value also seems to be pretty good these actually they call it t value but in the book you'll see it called t-statistic. T-statistic also looks good. But only one of them. The other one is not good. It's good, right? 10 and 12. Only the size matters. Not the sign of it. So this looks pretty good, Robus. The error is so much, right, sir? The standard error is... Oh, that will be also plus minus, right? was everything the error is so much right so the standard error is oh that will be also plus minus right that's right plus minus yeah so actually it's a limit it's just a limitation of the tool I think they should just have looked at the size divided by their size and remove the sign because quite a few people ask the same question that you ask. It's confusing. So if you look at this, in many, many fields, an R-square of even 23% is considered very good, right? Because data is soft. You look at 60%, you may feel pretty good about this. You look at all the other metrics, they seem to be good. In fact, they seem to be even better. P-value, the notorious P-value seems to be so good isn't it but here is the surprise and this is why I feel that most of the textbooks they just stop here and it is wrong when you visualize the residuals what do you see now do you see a pattern in the residual there is a distinct pattern in the residual right and so when you see a pattern in the residual you know that you have left signal on the table you haven't captured the complexity of the data because pattern is information you haven't aligned yourself if you had squeezed the juice out of it the residuals would be just random noise you know when you squeeze the juice out of lemon there is no juice left in the lemon the same way residuals should not have information in them but here it looks pretty distinctly to have patterns and it shows up when you when you put the prediction line on the data look at this you see the maroon line it is the best if you think about it it is the best straight line that you can draw through the data isn't it yes you agree except that straight line is not the solution which is why it is important always to look at residuals and try to visualize the data on the predictions. Because you will know that you may be barking up the wrong tree. There is a scope. It's not that the previous model is wrong, but there is a huge scope for improvement. Are we together? Now, let us go and try to improve upon this model. Sir, one question. So, when we applied linear model, right, so there was intercept has almost 10% of standard error, right, if we see. So, can that tell something because 10% is more, right, if we go up a little bit? It depends on the situation. See, what happens is that the T value I said above said above five right people begin to feel it's reasonably good so both of that t statistic which is the ratio of the estimate over standard error see look at this this is one point two seven plus minus point one many people will consider that pretty good did that pretty good also these are pretty good values but R square is 60 see looking at this you can't tell that something may be wrong with the model which is why I say most of these textbooks are that you find with code in them they do your disservice you have to go the extra length you have to check for residual patterns you have to plot your predictions over the data and see how it works so how would you go about it guys you notice that this curve has how many bends two two two minutes so how many what degree of polynomial do we need to solve this remember i talked about it in the past three three degree a minimum third degree right minimum so let's do that let's try to fit a third degree polynomial to it and let's see what happens this time well the code is not very different actually it's surprisingly the same look at this code what did i do instead of y just well the code is not very different actually it's surprisingly the same look at this code what did i do instead of y just depending on x i'm saying y is the third polynomial of x and guys do you see the expressive power of these libraries can you imagine doing something so so powerful in just one line in any other framework right you are doing pretty powerful machine learning exercises with just one line of code these things mean real things you know in real life in business you end up with results quickly and you can talk about it it means something in the real world so now we do that we have a third degree polynomial pretty good let's look at the R squared is the R squared better remember the previous R squared was 60% now the R squared has gone to 96 percent 97 percent approximately is it better or worse right it is close to perfection it seems to but there is something very interesting the intercept doesn't seem to matter you notice that they intercept the p-value is bad the key statistics is bad the first degree beta 1 fine we do not this seems to be pretty bad beta 1 seems to be good beta 2 second degree point of the second part of the quadratic term seems to be bad the key value t statistics is bad and the p-value is bad but the third term is also good so you don't win that means it means that probably you don't need the first and the third term the first and the you know the intercept you don't need and you don't need the first and the third term the first and the you know the the intercept you don't need and you don't need uh this thing so you know you can iterate over it you can go back and build a model only in x this part the beta 1 and beta 3 right this term the third degree term and try it out and when you do that uh you want to throw in x5 also. If you do go to the fifth term you realize that x4 doesn't matter x5 matters and so forth. So it takes a certain degree of experimentation and playing around till you get better and better models. There is no end to how much you can improve but remember don't there's a thing called overfitting. The two Buddha model is also bad and we'll come to it in a later time. Now one of the things I'm doing here and it's very important, I have not split the data into test and training data. I'm using all of data to basically build a model. When you build a model with all the data you have a problem. What is the problem? You don't know whether you have overfit you have very high variance errors and so we should have split the data 70 30 80 20 or something like that we but because it's a very first exercise in machine learning I have removed all complications and in a way I deliberately kept it over simple so we can get to the gist of the matter you know we learn machine learning part first and then we worry about the nuances so this model what what is the next thing we'll do we'll do a residual analysis isn't it let's look at the residuals look at the residuals here is the residuals looking at this residual space let me zoom in even more when you look at the residuals do you see a pattern as you go from left to right your eyes right no I'm not not very visible pattern it's a significantly better like look at this situation figure 1.6 and compare it to let's see this one 1.4 figure 1.6 is a sea change compared to figure 1.4 isn't it we agree guys this one distinctly shows a pattern a straight line model and this one is a much better improvement most of the pattern has disappeared isn't it if not all would you agree with that guys yes it is giving us a hint that you know so far so good we might be heading into a good model and finally what is the last step we need to visualize the predictions on the data let us do that and now look at the maroon the predictions do you think this is a good like it is a good model for the data yes yes it is it is indeed right and see the lesson to learn here is don't just look at r squared or just p value or one of these things. Remember there can still be scope for improvement. One clear way to see that there is scope for improvement is look at the residuals. If they show a pattern means there is a scope for improvement. Also plot out your predictions. see if they agree with the data they don't then you don't have a good model so there are many ways you can go wrong and you have to you'll never know whether it's right correct or not because there is no correct but you have a good approximation if you pass all the tests on the on the data with so the on the legend the data has the black line, that you mean the data points? Yeah, because of the black are the data points, yes. The circles are the data points. The black circles are the data points. Maroon is the prediction and the blue and the green are the upper and the lower bounds of the prediction and the blue and the green are the upper and the lower banks of the prediction. So far so good guys. Anybody needs a has a question or needs explanation? Asked a trivial question. From the previous graph I see the where the points are dense that's where the confidence is moving moving apart? Quite opposite to my... Yes, it is not. Because there is a bend. Bend needs a lot of information and it is not enough. So how much should the bend be? Should it rise more? Should it be more like a less steep bend? So the thickness of the bend is not quite uncertain through the data if you really look at it you can see it right I could have moved for example I could consider that maybe the right answer is between the maroon in the yellow marina maroon in the green isn't it so it's a little to be more precise like that's how the confidence I am trying to intuitively go at it but long there might be more Martin that is the yeah that is like how confidently in that region can you tell the exact so by now guys you must be feeling that polynomial is the real trick. Let's use polynomial regression. And the history of this field is that, as I said, Gauss first used it in a published paper in 1793. So remember that. Machine learning is a new subject. Remember that. Then 1805, Legendre wrote the famous paper. We use the term least squares, principle, you know, method of least squares for regression. Then obviously, he didn't use the word regression. Later on, Pearson created the word regression, Galton and Pearson, and so forth. But the interesting thing is people already latched on to polynomial regression early on in the early 1800s they started doing it and they were quite successful in many many situations but then let's look at data set 3 are you guys able to see data set 3 in summarize and plot it well how many bends do you have in this data? I see a bend here, but there's certainly a bend here and a bend here. Maybe a bend here. So, minimum before that, say, so you probably start with a modeling with degree for. Does that make sense? Now in this example, if you try to model naive, a straight line model, you will get a disaster. Do this exercise, guys. That's how you develop intuition into data and machine learning. So you do the same code. By now, this code must be looking very familiar to you. You take the model and you summarize it. And then you look at the adjusted R squared what does it say seven percent very low 0.7 it is just a disaster right really it's a disaster what about p-value the only thing you can be reasonably sure of is the intercept and there is no slope to this line you can't be sure and even the estimates are close to zero so when this when the slope is zero means what why doesn't really depend on X why is just beta naught isn't it because beta 1 is approximately 0 what what is another name for such a situation? Null hypothesis. Null hypothesis, isn't it? And that is why you see the p-value is 18, 19%. It's a disaster. Suppose you're not alarmed by that enough. Let's see what the residual looks like. This is the residual. What can you see about the residual? Do you see a pattern in the residual? Right? You see the original curve sitting there which means that the line captured nothing your model captured nothing most of the signal is still lying there on the table isn't it so let's move past suppose you insist on blindly using your model look at your model and look at the data would you in your right mind consider this to be a usable model in practice anybody no sir it's a disaster right in every way in three ways we know it's a disaster the model metric say it's a disaster the residual say it's a disaster, right? In every way, in three ways we know it's a disaster. The model metrics say it's a disaster. The residuals say it's a disaster. And the predictions say, when you plot the predictions on the data, it says it's a disaster. So what can you do? You say, well, we already know the trick of polynomials. Let us use that trick. Let us whip up a degree polynomial. So you can try degrees of two, three, four, right? You see at least three bends, so you should probably start with four. When you do it, you will realize, and you can keep on experimenting. Surprisingly, you'll realize that you need to go to degree seven before you get a reasonably good model. Some people get it at six. I don't know uh it depends on that and at this value what is the adjusted r squared guys 94 percent that looks good isn't it do the do the t statistics look good in terms of values looks good this one looks a little bit worrisome the first order term it's only 5.5 remember in size it should be greater than 5 would be a nice thing but you see this lovely area of three stars just looking at this data you would say well this is a good model isn't it right but you should not be satisfied by that you move past it and what is the next thing you need to do and you look at the residual plots and what do you see you see it is much less pattern than before this model seems to have done a better job but still it is there is pattern there so it's a little bit disappointing so you you say, well, you know what? And not only that, do you see that here, the error bar, like the variance of the error is low here. And here, the variance of the error is high. The error spread out. Do you see that? I want all of you to notice that here, errors are spread out this far on this right-hand side. On the left-hand side, errors are spread out this far on this right-hand side on the left-hand side and it's a very tightly located do you see this guys yes what is the name for this kind of disease it's good it's really density at risk it acidity that is right so you also see pronounced heteroscedasticity literally you you know that even though it's a quite a surprise isn't it you look at the model statistics and all looks well you look at this and you say lovely I'm going to market with it and then you look at this and you realize that there is pattern there is heteroscedasticity there and then you plot your predictions on the model and what do you notice you notice something actually I wish I had this legends were up there because I wanted to show you what happens is in the center of the data it looks good this curve looks good but around the periphery what do you see here and what do you see here you see these oscillations the oscillations on the periphery on the left and the right so those peripheries are a disappointment because what it is doing is sort of trying to overfit to the data and there is a name for that actually those oscillations it was discovered by a great mathematician called ranch and yeah and yes it is named after him it is called the ranch phenomenon so what it means actually is this when you see the ranch phenomena it shows up when you try to model a data with a very high degree polynomial are we together so with low degree polynomial your model was not good with high degree polynomial it seems to give good metrics but it tends to develop these oscillations I actually give it a more figurative no name I call it the wagging tail I have a dog and my dog's tail bags so I call it the wagging tail because it reminds me of my dog scientific name is the ranch phenomenon and ranch discovered it a long long ago. That's when people knew that polynomial regression has its limit. So how do we tame this? How do we go and tame this? So there are many ways of doing it. One is to realize that polynomial regression may not be the best tool to deal with it. And in the very next lab, we'll deal with it with a better tool, which won't show the RANS phenomenon. The other is we can do something called regularization there is specifically an antidote you can think that this particular disease there's a range phenomenon it's called regularization and regularization is a pretty important topic in machine learning we will cover it later in this workshop. Are we together guys? So this is it. That was ranch phenomenon. Then if you do data set 4, you realize how many bends there are? One. What should you do? You can model it with a quadratic equation, isn't it it and quadratic equation will work actually if you take a polynomial you know polynomial degree to quadratic equation it works with 99 percent r squared and everything looks beautiful nothing wrong with it if you plot the residuals even the residuals look good the spread of the residue as you go it looks more or less data gets more sparse here but that's the nature of the data itself. Let us plot the prediction on the data. The model prediction on the data looks good or bad? Very good. Good. Now here, I wanted to illustrate another point that sometimes you can make this model, and you can say that you know can I make a simpler model this is a quadratic equation if you any quadratic equation it is the center of it you know at the base of it you can represent it with just the x squared term you don't need the order X term you don't need the intercept you don't need anything you just need the x square term it is just a mathematical curiosity and in fact one of the things that I'm using this to introduce this is a very simple example probably doesn't call for it but I want you to use this very simple example to discuss a lovely bit of mathematics called the box-Cox transform or the power transform. It asks this question that let us say that we write a linear equation. How do we know whether it is y or y square or y cube that is a function of beta naught, beta 1, etc. Or suppose it is square root of y. Square root of y would mean it is a polynomial of degree 2 because then you'll have to square it on this side and then here you'll develop square terms. So what is this? And there is a very interesting history and I'll tell you the story the way I was told about it. So a box, the great mathematician, you know, whose quote is there at the beginning of this chapter but he and yet another great mathematician called Cox you know it so happened that they were brother-in-laws one had married the sister of the other one was in England and the other one well I believe Wisconsin or something like that so one fine day so Fox visited mr. box professor box and what do you do in the apparently so the story goes they went out hunting. Mathematicians make terrible hunters because they keep talking all the way. And nothing will be there. And anyway, it's winter. You don't find much. So they weren't doing much. And so they were talking. And along the way, they joked that, see, our names sound familiar. What if we create a paper? We wrote a paper with something interesting, then everybody will be talking of the box-cox result. So what started out apparently as a joke or a discussion actually amounted to one very significant tool for machine learning. It is called the power transform or the box-cox transform. It asked this question, what is the real relationship between y and x? Is it quadratic, cubic, is it log of y is a function of x? What is it? So we will use this box-cox transform. I wanted this opportunity to introduce you to it. We will find what is the real relation. Now box-cox transform works only with positive data. So we like to throw negative data out and then play with it so when you do that it says that see in this equation y to the power lambda is equal to beta naught plus beta 1x where does it achieve a maximum days approximately at right 5.5 so what does it say it says that the square root of y is a function of beta naught plus beta 1x in this equation. So y is a function of what? X squared terms, isn't it? So that is a way to confirm, you know, when you have data that you can't visualize, you can't see the curve right away in higher dimensions, and then it helps to do the Box-Cox transform, which is what I have explained here. And I just took this opportunity to introduce Box-Cox because it's a significantly useful tool that you should use and you don't really find it in most boxes. Another way to do that, to know that you need a box box transform is if you take a frequency plot or a histogram of just the target variable y, does it look symmetrical or does it look skewed? This blue thing. It does look significantly skewed, it is right skewed but when you take the square root of it what does it what does it do to that what is the square root like it is much more symmetrical isn't it quite symmetrical but absolutely symmetrical but certainly more symmetric would you agree that the maroon is more symmetric and blue is more skewed? And so the statement geometrically is the right relationship of y to predictors is that relationship, that function of y or transform of y that makes it into a sort of a symmetric or semi-symmetric distribution of frequency plot. There's a bit of mathematics and thinking about it but I thought I'll tell you. It's one of the things most people forget to do. They forget to make a you know a plot of the frequency plot of the target variable just to see whether they should proceed as it is or they need a power transform in the data and so i'm more or less done so you do that and with that you get a fairly good model even with that i won't go into the rest of it you can read this now we go to the last data set which is actually what happens if the data has almost no noise or zero noise and you do the residual analysis and then what happens well something peculiar happens so here is this data you plot it what is the first thing you notice in this data there seems to be almost no noise, isn't it? It's a nice smooth curve. Whatever function y is of x, this data looks extraordinarily clean data. Would you agree guys? You don't see data points scattered all along the line. They are all sitting in a nice orderly March so you try to build and this is sort of a warning here if you try to build a model well how many bends are there how many bends do you see guys well one maybe one here but when you try to model it you'll realize that you'll get a reasonably good model at 4 at 2 you don't get a good model and you wonder what is going on so look at at 4 you got a fairly good model right adjusted R square is 99 oh boy it's pretty good model would you agree that just looking at the model diagnostic would you be impressed anyone yes looks very impressive isn't it but then or you try to look at the residual plot you haven't done the residual product you should have a residual plot is very will be misleading and it's something to know that when the data is very clean you get strange residual plots. Those residual plots do tell you that your approach is wrong. Sometimes you can ignore the residual plot because ultimately if you look at the prediction on the model, the predictions of the model and therefore the model curve, it is not that far from the data. Perhaps for practical purposes it is quite usable would you say it's usable guys yes it's pretty usable right and so even though there are strong patterns in the residuals it can be quite usable it's a lesson but the fundamental problem is why did it not work data was so clean why did polynomial regression not work if somebody like to guess an answer is the last data set for today we have eight minutes not reducible later no any other answer overfitting overfitting no anyone else I hope everybody hasn't gone to sleep non-real observation. So I'll tell you what it is. You guys are in mathematics, a function. There are two kinds of functions. Things that can be represented as polynomials of finite degree. Let's say here the fourth degree. And there are a class of functions which actually cannot be ever represented as a polynomial. If you try to represent it as a polynomial, it will be an infinite series. It will be a polynomial of infinite degrees. These functions are called transcendental functions. Transcendental functions. Another one. Transcendental functions. It turns out that you'd say that, gosh, why do we need transcendental functions? Actually, transcendental functions are one of the most magic things in the universe. Everything, most of what is beautiful around you and the laws of nature are written with transcendental functions very interesting for example the ripples that you see when you throw a pebble into a pond you see ripples isn't it what are those ripples they are sine and cosine waves right they they propagate a sinusoidal waves but what is sine wave it's actually a transcendental function if you expand sine wave in del expansion it is an infinite series x minus x cube over 3 factorial plus x 5 over 5 factorial minus x 7 over 7 factorial and so forth it keeps on going it doesn't stop it cannot be represented as a ornament you realize when you throw a pebble into the water a close to the pebble like close to the center the height of the ripple is high but far off the height of the ripple is less isn't it you remember that Remember that? Believe it or not, that also is given by how the height varies from the center is given by a transcendent function. And I invite you to find out what it is. I'm just creating a situation to investigate. You play the drum, your musical instrument. You play a drum. The vibrations of the drum are a transcendental function in an atom you have the orbital structure electrons buzzing electron clouds buzzing around the nucleus and it turns out that they are also spherical vessels function as sort of transcendental functions there are different modes of a transcendental function they're literally a vibration source of sorts of a transcendental functions it's very very beautiful you know those of you who remember your chemistry remember spdf you remember the spdf in the orbital structure of the atom that most of you have forgotten, they are actually transcendental functions. And transcendental functions are everywhere. And then, so therefore, much of the data that you see around you, there's a transcendental function behind it as the real force producing it quite often. And so you need technology to capture that complexity, to capture the transcendent the to be able to deal with it and obviously it is a good thing otherwise machine learning would have ended in the 18th century with polynomial regression isn't it I'm joking of course but imagine that a polynomial do everything then you need all you need to do is a polynomial machine and it could do all regression. Which it can't and so the data set is just to give you guys an example of that. And there is a bit of historic note, you know, you learn regression for quite some time, almost 3, 4 lectures. We have been talking about regression and there's a bit of history about where all of this comes from you guys can read and that is it these notes I'll share it with all of you guys and do read the notes do the lab I will give lab hours again along with the TAs reach out to them they will they will help you reach out to me I will find time and I'll give some official lab hours clinical arts for people to walk in and do the labs with that I will stop our next lecture will start with guess what what will we do in our next lecture We'll go to the next machine learning algorithm, which is classification. And I need to be able to. All right. Can I stop the recording guys?