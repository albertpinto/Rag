 So this is a week two quiz. We have about 25 questions. We'll go through them and review them. Stochastic gradient descent refers to, well, as we learned, when we have a loss function, the loss function computes the loss or the amount of mistakes in some sense depend from a certain number of data points. So how wrong was it, was our model in making predictions over certain data points. That is a large component of the loss function. The other component is of course the regularization terms. So in that sense, now the question is how many data points when you learn one step of learning is learning from just one point, then it is called stochastic gradient descent. So that one epoch would have as many steps as the number of points in the data set. So that is that. So guys, do ask me questions if it is not clear. This is a question that is sort of thought-provoking. You see that the model has fit to the data, though you could argue it has perhaps a little bit overfit to the data, but still. So you observe the loss plot on the left. And what do you notice? That the loss, it shows a lot of variation. It doesn't stabilize and stick to a low value, right? So what do you conclude from that? stabilize and stick to a low value right so what do you conclude from that you conclude that you're probably doing stochastic gradient descent because in stochastic you sort of never see there's every one data instance or will have some amount of information but it will also have some amount of noise so if you learn from one data instance at a time, you're not only learning the information, you're also learning the noise, you're also being misled. So your loss function will keep fluctuating because of that. It will never sort of stabilize. This is true for stochastic and also true when your gradient descent is too small, because the law of large numbers won't come in. Those noises from the small number of points in the batch, mini batch, will not cancel each other out. As you make your batch sizes a little bit bigger, then you start seeing stability. You expect that those noises, if they have a normal or Gaussian distribution, they will start canceling each other out. And so you'll see more stability. And I think there is a graph for that a little bit below so certain batch batch descent it will be a hyperbola like graph no no this guy you'll see the hyperbola in other words you don't see this huge amount of fluctuation that you see here in that yeah in in stochastic gradient descent right so let's see when we come to batch in a moment you see that suppose hold that in your mind so suppose you we come to a batch in a moment you see that's a point. Hold that in your mind. So suppose you have n points in a training data then the stochastic gradient would have n steps right because each point is a step. Now this is interesting. We talked about it. The target space of a regression problem can be a d-dimensional vector space, rd. Now generally to simplify things and to have a good intuition, I always say think of a target space as a scalar field, just a number. If it is a quantity, if it is a measurable, it's a regression. But a measurable could be a vector also., for example, one easy example is think of wind velocity, which when you talk of wind, you talk of how fast the wind is blowing and you also ask about the direction. So if you want to predict the wind speed, wind velocity, you have to predict the whole pair, magnitude and direction. Right? So that is it. So it could be d-dimensional vector space. Now comes this question. So this is what you were asking, Sukhpal. Do you notice that compared to the previous picture, this has much less fluctuation, isn't it? So what do we conclude? First thing we notice is that it sort of stabilizes in 5000 iterations 5000 steps. So that's the right answer. Sajeevan G. It doesn't stabilize in hundred it's still fluctuating. It doesn't stabilize and thousand 1000 is somewhere here in the loss is still pretty big. Sajeevan G. But it has tend to stabilize at five. But other thing you notice is that the variation band is much less here, isn't it. Look at this. It is a much bigger band of variation of the last function and the solid color that you have blue. It is thicker. Thao Yeager â€“ PM, Continuous Integration.: Yeah, it is much narrow band of fluctuations, you see around zero. So this implies that your bat size is This implies that your batch size is reasonable. You know, it's sufficiently big that the noises are more or less canceling each other out. There's still a bit of noise. They'll never go away in mini batch gradient descent. But you're at least seeing a mini batch gradient descent here, if not a full batch gradient descent. That's what you learn from this. And so this is mini batch gradient descent, actually. If you go back and look at the code, you'll see this example where I took this thing. Now, this is the bit of code and I just, I'll review it because it will answer a set of questions. The last function in regression is mean squared error. Remember? Yes, sir. The square of the residuals you add. MSC. Yeah, MS C and you take the average. So that is that. Now, can somebody remind me, why do we need to zero the grads. Is because you want to reset, you know, the beginning of each step you want to compute the gradients only for that step. the gradients only for that step. So you reset it. Then this is your prediction step. Do you notice that this comes the prediction? This is computing the loss. This is computing the gradients and this is doing the gradient descent. So it's very logical if you understand the theory. What you do is you predict forward step, then your predictions will be wrong partly. So you look at the level of mistakes, the gap between prediction and reality. That gap you use to compute the loss. Now, given the loss, you take its derivative, your gradient, because you need that. And once you have the derivative, and now you can update your parameter weights, because your parameter weights is w next is w minus alpha, the learning rate times the gradient, right? So that's that. So with that, these questions do get answered. Which of these perform the gradient descent step is the last step. So we do it with this step here, optimizer step, right? The last step. And if you guys understand these four lines, guys, essentially you have understood the core of the machine learning loop the learning loop in all machine learning algorithms you always predict compute the loss take its gradient and back propagate right you back propagate the updates gradient descent in other words um now is it preferable to have a large learning rate in a model? No. Why is it not a good idea to have large learning rates? Because you will. What will happen if your learning rate is large? Yeah you know you will keep bouncing around the minima minimum. That you have very big legs. You'll keep bouncing around the minimum point. You won't stop there. Isn't it? Yes. That's the point of that. Next question is, consider that the training data set is of size n. If you're using a batch gradient descent approach, then the number of steps of gradient descent per epoch is one, because the entire data set is one is used to compute the loss, isn't it? So it's one step, one epoch is one step. Next question, a mini batch gradient descent refers to, you look through the data and you take the gradient descent from a small batch of data, not the whole data set, not only one, but usually a small batch of data. And the implication is that that number is between one and N. It's usually a small number. Typically people start with like 4, 8, 16, 32, 64. If you have really good hardware, 128 to 256 and things like that. Usually you don't exceed that. You don't make it a thousand or something like that usually. So that's that. In the context of machine learning, an algorithm is considered a universal approximator. This is practically a metro definition to review if you understood what universal approximators are. It can approximate any regression, for example, it approximates any arbitrary n-dimensional function like this. Now in the case of regression, we are literally looking at that function. In the case of classification, that function is your decision boundary. The surface, the hyper surface that that function represents is your decision boundary. So that's how it works. The purpose of an optimizer when training a data is, of course, it does the gradient descent step. It updates the parameter based on the gradients of the loss. That's what an optimizer does. And in the case of PyTorch and TensorFlow, the good thing is that when you do the forward pass, because those tensors are auto, they have automatic differentiation built in, the framework has already computed the derivatives, you know, it computed the gradient, or given you the possibility of computing the gradient of the loss. So when you compute the loss, the gradient gets computed. So, tanh or logistic activation functions. So guys, I've used the word logistic to be very precise, but as I mentioned in the machine, in the deep learning community, people often sort of, it's a convention to abuse the terminology and they call this logistic function the sigmoid function. Mathematicians will frown upon it and they'll say well tanh is also a sigmoid function, but for better or for worse it's become the language there. So whenever in this course, and only for this course, when you see me use the word sigmoid, I will unfortunately have to use the same convention that your textbook uses and refer to the logistic. So anyway, these tanh or logistic activation functions for a node perform a nonlinear distortion of the input in the output. This helps in capturing nonlinearities in the data, such as a nonlinear decision boundary. We talked about that. What does it do? It distorts. These activation functions are distorters. They will distort your input space and therefore you now have the nonlinelinearity that can actually fit to the non-linearities in the data. While training a neural network, an epoch refers to, well, that's what it is, it's literally the definition. You have completed an epoch when you have gone through the entire data set once. gone through the entire data set once whether you do batch gradient descent in which case your epoch is one step whether you do many batch gradient descent in which your epoch is many steps or you do a stochastic gradient descent where your epoch is made up of n number of steps where n is the size of the data question 14 consider just a second what's the difference between the step and an epoch a step is one gradient descent step so think about mini batch gradient descent suppose your mini batch size is 16. one step is you take 16 instances of the data One step is you take 16 instances of the data, you compute the loss, you compute the loss gradient, and you take, you improve your weights, you go and update your weights. Every time you update your weights, it is one step. Update your parameters, it is one step. So in batch gradient descent, it is one step and one epoch. Yeah, because you take all the data points to compute the loss and therefore the gradient. So one step becomes the whole epoch. In the case of many batch, there are many steps in our epoch. In the case of stochastic, because each data point is a step. You learn, you do a gradient, update the parameters with gradient descent for each instance separately. And so the number of steps in an epoch is the same as the number of data points in the training dataset. Nice. So consider a binary classification problem where the two classes are linearly separable. So this was a trick question and some of you got this wrong. That's why if you notice I gave it double points I expected. So remember guys if you have a neural network which has an input x1 and x2 let us say and your output is you have to compute a linear decision boundary. Vaidhyanathan Ramamurthy, What is it, can you do it with just a logistic logistic unit. Vaidhyanathan Ramamurthy, Logistic regression and logistic regression draws a linear decision boundary isn't it Sajeevan G. Yes, sir. Vaidhyanathan Ramamurthy, So if you just need a logistic unit that is just your output layer you don't need any hidden layers at all but to you the question says what's true for neural network so to try that try a neural network in which there is no hidden layer just output layer so I thought the assumption was to apply the approximate universal approximation theory which assumes that there is a hidden layer of size zero so there is a joke about Geoffrey Hinton who is the godfather, I suppose, of this field. So they say that every time Jeffrey Hinton enters a room, all the nodes hide and the layers hide. That's a good one. So it's a straight line, sir, right? It's a binary classification of straight line, right? Exactly. It's a straight line. That's why I use the word linearly separable. So there was a lot packed into the wording, the way I worded this problem. Where is it? Yeah. And there's an allusion to things that I have taught you guys in the past. Linearly separable should remind you of the picture that I typically make of the blueberries and cherries. Do you remember? In a straight decision boundary. And if you remember, when we started out, even ML 100, we learned that a logistic unit is a linear classifier. Logistic regression is a classifier it's like cow and duck yes and so forth yes which of these is an optimizer used in neural networks for gradient descent yes adam and sgd these two i just put it for confusion this is this is a loss calculator it's the you know mse quantifies loss it will not do the optimization for you. It will just tell you this is the loss and module. Sajeevan G. Module is the base class of everything in neural network. So your hidden layer is a module your Sajeevan G. Even regularization dropout is a module and so forth. So module is the fundamental class. If you think of object oriented programming, it is your root class or the base class of everything in PyTorch for neural networks. Almost everything. All the building blocks of neural networks, the base class is module. So STDs stands for what? Stochastic gradient descent. The universal approximator theorems prove that the ability to approximate functions is a property of? Yeah, this is important. This was actually a bit tricky because the first theorem that was proved, the classic theorem, if you go back and look at the papers that I posted, the original papers, the first theorem showed that it is a property of a feedforward network with a hidden layer using a sigmoid activation function. The second paper said that it doesn't have to do with your activation function. So long as it is a feedforward network, it will work. It will just work. And that is the important thing. That's where we are today. And this is not correct. A feedforward layer only if there are a reasonably large number of hidden layers. This is unbelievably, this is a misconception amongst people. They say that if you create a neural network that you must add a a lot of layers in it otherwise it won't solve your problem that's not true depending on the complexity of the problem a pick a neural net i think in tensorflow playground we did this experiment if you remember most of the problems we could solve with just a few just one hidden layer with a few nodes and even when we went to more hidden layers we didn't go out to very large number of layers two layers input usually was enough to solve most problems in three layers but then there are situations which are hard you can't solve it two three layers you need to go many layers deep but but remember that your networks are more powerful than you think quite often start with the simplest solution. Try out one hidden layer with just a few nodes. Then you complexify it a little bit, add a few more hidden layers and a few more nodes and so on and so forth. Don't immediately start out with a really complicated neural network. So Asif, one quick question there in that context, right? So the theorem basically says, as long as we have enough nodes, it will be able to approximate any function, right? That's basically the theory side of it. Now from a practical aspect, there is a reason why you choose a lot of nodes and there's a reason why you would want a few hidden layers. Now, in your experience working with it, are there some certain guiding principles which kind of govern when you are facing a certain problem, you try to estimate the number of features in the problem, and then you decide how many nodes to start with and how many hidden layers to slowly build out. Is there a method in the madness or there's a lot of trial and error? Dr. Raghuram G. There is a method actually to the madness. But before I give you my personal experience, I'll state it in more general terms. See, people have studied this complexity theory. See, the basic rule and common sense rule is the dataset is generated by some generative force. The dynamics of that generative force has a certain degree of complexity, certain quantified complexity to it. So to solve this problem, to approximate it, you need a model that has the same order of complexity. If you choose lower order of complexity, you will underfit. If you choose a higher level of complexity, you'll tend to overfit. So that's a basic statement. Now the question is, how do you estimate or get a rough sense of what level of complexity to use? So there are two ways. One is what I do from my experiences. I deliberately start with a non-neural network. I'll start with just let's say classification problem. I'll see how much does logistic regression, what is the efficiency I get with some of the simpler algorithms, just very basic naive bias, logistic regression and so forth, simple ones. Once I have seen the accuracy and compare it to the desired accuracy I want, then it gives me a clue. The clue that it gives me, and you know I'll add a couple of polynomial terms and so on and so forth. A little bit of complexity to very simple models. I'll try that, then occasionally I'll throw a decision tree to see how deep the tree goes and so forth. Then with random forest., gradually you get a sense of the data. Then usually I go to neural networks. People these days right away throw a neural network at it and sometimes it works, sometimes it doesn't. Because what happens is if you throw a very complicated neural network at a problem, you overfit. And overfit is the big bang. See, the only time you can avoid overfitting is when you have massive amounts of data. Real life, you'll never have massive amounts of data. It is very good to talk about it in research papers, in theory. In practical life, data is gold, and getting data is the hardest part. Once you have mastered all this AI, you'll realize that we are all beggars. We are brilliant beggars. We are just begging around for data. May somebody give us the data so that we can do a brilliant analysis, but data is king. And people hold data. They don't share it easily. So when you get data, you have to ask, how can I make do with this amount of data? So there are multiple ways you prevent overfitting with regularization and techniques that we learn about. But generally, don't start with really complicated models. It will go over with the data. Start with something simpler. And the other answer that one can give is, we live now in the world of automated machine learning. So now that we can do neural architecture search, sometimes you can ask this system to find out what the right level of complexity is, discover it and create the right architecture. A third possible answer is, see, when you take a related problem that has been solved, you do transfer learning. So here is a very complicated model. Let's say that you take a model that is a VGG model for image classification or one of these models. Now those models are extraordinarily complex and they have 500 million parameters or some ridiculously large number of parameters, inceptions and all of these are 100 million parameters. If you were to train it, let's say that you want to distinguish between cows and ducks, and hypothetically let's say that either cow or duck is not part of the ImageNet dataset or CIFAR, whatever, on which it has been trained, pre-trained. So then there is a problem. What do you do? You go to business life, you get the data, and some businessman or some client, you ask them for data, and I'm giving you a practical experience. They will feel proud as punch if they send you a few hundred data sets, a data set whose size is just a couple of hundred. It might have a hundred cows and a hundred ducks. So now you realize that you can't train from first principles a neural network that has hundreds of million parameters with just a data set size hundred. That? That is, that arguably would, there would be infinitely many models practically that will fit to the data. And none of them would be valid. And no amount of regularization, heavy damping, in my view, would really rid you of the problem of overfitting. So what do you do? You realize that you have trained something like one of those things that you dealt with in your first lab, RestNet, or this or that. They have been well trained. All you need to do is somehow train it to recognize cows and ducks, which it hasn't seen. So what do you do? It understands all the geometric primitives. It understands almost everything needed to do it. So you go to the tail end. First of all, you'll have to put, it becomes a binary classifier problem. So you'll have to screw in a head that has, let's say that you do softmax, it'll have two nodes. Or if you do just sigmoid, it will be one sigmoid node. So that you have have to screw in there but then what you do is you just open out the last layer before that the the last hidden layer the head part you and you sort of they are all fixed weights but you make them learnable trainable but all other weights remain frozen so then what happens is the number of parameters that you opened out for training is very, very small. Even though the model has hundreds of millions of parameters, you opened out perhaps 20 parameters at the very end for training. You see that, right? And then you can do your last mile learning or your what is called fine tuning on this particular data set. And then you get away with it. So there are many, these are the many approaches that you take when you deal with a data set sizes and complexity of a problem. Thank you. Asif sir, you said SGD is an optimizer, right? But is it? Like how did it become an optimizer? The definition of an optimizer is that which does the gradient descent, update of parameters. It's by definition. Optimizer means what is it optimizing? The values of the parameters. At the end of the learning, you need to have optimal parameter values to make prediction. And who is doing the optimization? Who is updating the weights gradually step by step and improving it? The optimizer, the guy that has the gradient descent. That's the way to look at it. So the learning rate in gradient descent modulates the size of an update to the parameters of a model from each step of learning. This is true. That's literally what it is. If your learning rate is too high, your parameters will get updated by huge amounts. So for the same gradient of associated, let's say that there is a weight W, W i, and then the derivative, the gradient with respect to, or the partial derivative of the gradient with respect to or the partial derivative of the loss with respect to wi is whatever let's say it is one for the sake of argument now the amount of update you make becomes alpha the parameter goes w next is wi minus alpha so the size of the update is controlled by alpha the learning rate that's that while training a neural network a mini batch refers to well that is by definition a small bunch of data training data and the implicit assumption is it's between one and the size of the data usually it's very small for 8 16 32 64 stretching it 128 and that's about it but you don't make many batches of let's say 1 million even if you have a billion data points that is usually not considered a common practice why is it not because then your video card will get overwhelmed it won't have the space for it that brings up ideas about how do you optimize and so forth what is pin memory and whatnot those are topics we learn more like in the 15 16 7 17th week of this workshop later on on, somewhere around November, December. If the activation function with Q, by the way, I made a mistake guys. So some of you may have got, will probably have taken quiz with a mistake. I said identity function means Z remains Z. For as a mistake I said if a Z goes to one, that will be a that will be a mapping to a trivial thing that would collapse the collapse the input space to a point namely one that would be wrong so there was a typo there it is z so if the identity function doesn't touch your input thing so bias plus weight dot input it remains so that is the affine transformation so I introduced the word affine transformation without using the word in the lecture and I occasionally do that in the quizzes because I thought this would be an opportunity for you to read up what's an affine transformation so would somebody like to tell me what's a refined transformation? It's a it's one way the relative distances are preserved. Parallel lines remain parallel. Yes. A two parallel lines in the input space will remain parallel lines in the output space. So what it means is if you say think about it this way, suppose these two lines are parallel and if i translate it can you right they still remain parallel isn't it if i move them all to the left together the same amount then in translation they still remain parallel isn't it guys do we agree sure right and then the other other other transformation that we can do is if I linearly multiply every point in each of these two lines with a factor lambda, right? Or I just tilt it. So suppose it is x, I just tilt it a little bit, right? So if I have two lines like this and I tilt it like this, will they still remain the same? Yes, sir. it like this will they still remain the same yes so if I is a fine transformation I I don't know can I tell you something silly when I was very young and I heard about a fine transformation I had a bit of a difficulty remembering it because textbooks give you a very formal definition. They'll say that translations and linear transformations are affine transformations. So I needed something more intuitive. And so then gradually I realized that it is equivalent to saying parallel lines remain parallel. So whenever I would see affine, I would deliberately write it as A-L-L-I-N-E, because then there are two lines which are parallel literally in the writing of it. Isn't it? Right. So I don't just a little way or a mnemonic if you want to, to remember it, that's sort of the gist of a fine transformation. And again, guys, see, whenever you come across this sort of mathematical terms and abstractions, mathematicians use these words for a reason. They're creating something general and for eternity. We are being very specific to our field. So always find practical intuition that captures the generality of the statement. And when you you think it through you'll realize that what they are saying is something very trivial and very intuitive and beautifully said so when now you go back and look at what they are saying parallel remain lines remain parallel what they are saying is actually pretty elegant that it remains invariant any transformation that is only translation and linear transformation is a near fine transformation you say well yes obviously that's how you should think is only translation and linear transformation is an affine transformation. You say, well, yes, obviously. That's how you should think about it. Next is consider that a training set is of size N, a mini batch is of size M, where one is smaller than M is smaller than number. Select one. The number of steps in the epoch is, yeah, this. Actually, if it is not a proper division, then it will be N divided by M plus one, because the last batch will have the remainder amount. Let's say that you divide 10 by four, 10 datasets, and you have four points for many batch sizes four. So how many steps there will be? Four plus four plus one more step that contains only two data points. The last mini batch will have only two data points. So it will be either n over m if it divides come perfectly or it will be n over m plus 1. So it will be around capital N over m. Which of these could be an appropriate loss function for regression? Yeah, mean squared loss, cross entropy loss? No. Remember, y log log y hat was the cross entropy loss. We can't use that. Now this is directly from the code. It is just understanding the code. Which line is the prediction? Remember, first you make the prediction. This is the code. It is just understanding the code. Which line is the prediction? Remember, first you make the prediction. This is the prediction. Then you get the loss. Then you do the back propagation of the gradient. And then you take the gradient descent step. That's all learning is. This word learning and machine learning essentially refers to these four steps. learning essentially refers to this four steps and so this is the prediction step which line which of them performs a computation of gradients that is that back prop step this step now we getting there so this is something we talked about in the class so guys when you look at the picture in your mind how many straight lines you need to draw the decision boundary so therefore in your hidden layer what is the minimum number of notes you need two notes in the hidden layer and that's all you need you can try it out and we did that remember we did that and that is it and that's all you need you can try it out and we did that remember we did that and that is it and that folks finishes your review of the quiz all right guys so i'll stop the recording and post it Thank you.