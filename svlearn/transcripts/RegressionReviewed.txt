 All right, welcome back everyone guys and I wish and I hope you had a good Dashera and there was one more Indian festival I believe Eid in South India so and the navratri and many things in between so uh welcome back after all of that i will start today by reviewing what we did the last time by last time i mean two weeks ago now in the previous week which was which we didn't hold a session because of the Dashena slash Navratri festival, we were supposed to do a lab on multivariate regression. It means how do you do regression when there are many predictors involved? Today actually I'm not going to do that lab today. I'm instead going to do classification, which is an important topic. And in the next two weeks, we are going to do labs on both regression, multivariate regression and on classification. So we'll have two subsequent weeks that are just labs. After that, we will eventually have a little bit more on classification, and then we'll deal with clustering. And that will sort of sum up the scope of this particular workshop. So coming back to what we did last time, let's have a quick review. The previous time we talked about regression and understanding regression a little bit more in detail. So we said, if you're seeing my screen, that a regression model is sort of like a machine. You give it as input a set of features, x1, x2, all the way to xd. Let's say d different different predictors and example could be on a beach it could be the temperature at the beach the wind speed of the beach the day of the week and then the output is you're trying to predict how much ice cream would be sold by your shop if you are an entrepreneur how much ice cream will you sell on that given day to the children on the beach? So keep that one example sort of in your mind and it will help you concretize our discussion. Now regression is considered part, it is the quintessence of predictive modeling because you are predicting something. The target variable that you are predicting, the output that you are predicting is a number. So it belongs to the field of, so this y, now a little bit of notation, I will just enter this, this capital R with an extra bar attached to it, with a sort of unnecessary bar attached to it. This is in the field of machine learning and in mathematics in general, this is a symbol of real numbers. Real numbers. Real numbers are any kinds of numbers, rational or irrational, negative or positive, fractional or whole, between minus infinity and plus infinity. Any number. Basically, your concept of all that is a number. Basically, your concept of all that is a number. The word real stands for the fact that it is all along from minus infinity to plus infinity, but it does. But it excludes complex numbers or imaginary numbers. It's only real numbers. So when we take a regression model in the simplest form, you can think of it as a machine that takes inputs and manufactures or somehow magically grinds the machinery inside it and then comes out with a number. Are we together? Like for example, how much ice cream would an entrepreneur sell on the beach? That is a number and that's what it comes out with. Now with that conception in mind, we became familiar with many words that people use in different textbooks. The inputs are called, well, I call them inputs. They're also called features. They're also called predictors. They're called independent variables, the regressors. And the response, the output, is often called the target variable, the output, the response. These are the three words that you will see me use for output. In statistical literature, you also see the word dependent variable. Very rarely do you see the word regressant used, but you might. So these are all the words, more or less they are synonyms, and people in different traditions use different words for that. And the input side, same as to features, inputs, predictors, I would be using them quite often. Very rarely would I use words like independent variable, and almost never use the word regressor and things like that. On the other hand, classification we realized was exactly the same kind of machine except that what you're predicting is not a number. You're identifying the object, wherever you're given features, you're saying these features belong to an object that is, for example, a cat, a dog, a duck, a cow, or something like that. In other words, you're identifying a type or predicting that these features belong to an object of a given type. So you're identifying a class and that is classification. That's the word classification. Both of these classification and regression, to the extent that they predict, they're called predictive models. They are also called supervised learning algorithms. The word supervised learning algorithm comes from the fact that you have to, this machinery will not work till it has learned, till you have trained it. And to train it, you need to give it training data. As we saw in the lab, you give it training data, it learns from the training data it fits to it and then it figures out the relationship between the input and output it comes up with some internal conception of it and then uses it to generalize to be now able to predict the value for any given input that it has not seen So such algorithms are supervised learning algorithms. As we will learn later on, there are other classes of machine learning algorithms. For example, there is pattern recognition. Pattern recognition is not in the business of predicting anything, but it's looking at the data and it is looking for some interesting pattern in the data. The quintessential example of that is clustering. It happens to see if there are clusters present in the data. A quintessential example of that is clustering. It happens to see if there are clusters present in the data, so the data is not randomly distributed, but it's sort of forming clusters. It will detect that. Another form of pattern recognition is, I mean, sorry, yeah, pattern recognition would be dimensionality reduction to notice that the data actually belongs to a lower dimensional space, and so on and so forth. And then there are generative models and many things, very interesting sorts of model. So these sort of algorithms are called unsupervised learning because there is no giving training the model. The model gets the data and recognizes patterns and tells you about it. It does not after that go and make any predictions as such. So that is unsupervised learning. There is a third form of learning which is called reinforcement learning. It is the sort of carrot and stick learning that we as children are used to receiving from our teachers in the early school years. Good results, positive behavior, we get rewarded. We get carrots. And then if we don't behave ourselves or we do something that is unacceptable, then usually there is some sort of penalty. We are made to stand up on a desk or I don't know, there's a timeout or whatever it is. So it's a reward and penalty mechanism, carrot and stick mechanism. So when you teach an algorithm, you give an algorithm and say, go play this game, but you don't give many rules. But what you say is, if you do some things right, if the outcome is good, you get a reward. If the outcome is is bad there's a penalty and then the algorithm learns from it that is reinforcement learning now all of these things are very obviously these are at the heart of this is machine learning these three the broad areas of machine learning uh they are just about everywhere we look and breakthroughs are happening all the time. In the two weeks that we haven't met and we are meeting now, some of you may have heard, Tesla, one of the makers of, they're trying to, the electric car company, actually here in my city, it's very close to my house, they make these lovely cars and they strive to make self-driven cars fully automated cars now fully automated is a distant dream still but recently they had a quite a big breakthrough and these cars are able to drive in the city on their own weave through the traffic come to stop lights avoid dangers avoid parked cars and so forth and they're able to do all of that on their own. And of course they're able to drive on the highway on their own. So it was a huge step forward in the field, in the space of, or in the journey towards automated driving. Now, when you look at those breakthroughs and you see, and you ask which form of machine learning is being used, you'll realize that there's a very complex beast and there's a lot of learning that's happening, supervised learning that is predictive modeling or pattern or object detection. It is looking at the road and it is detecting the presence of cars, the presence of people and the empty spaces that it can drive through. It is deciding that yes, the road is free, the street is open, and that it can go. It is detecting the traffic light. And not only detecting the traffic light, it is able to figure out whether the traffic light is allowing you to go move forward or not yellow green red and so forth whether you should get whether you should turn left right and so forth it is making a lot of decisions you give it an end point and it is weaving through the traffic figuring out a path from here to there uh through all this traffic using the maps and going there when you do things on this grand scale obviously it is not just a little bit of machine learning, but a whole lot of machine learning that goes into it. Manoj Mistry, Ph.D.: If you stay with me. I mean, well, I guess this one. I don't know whether you guys will continue or not, but the bash that is with me, for example, on with me, for example, on Mondays and Wednesdays, they are, for example, going to be doing in just in just the next month, object detection and seeing how you can train a neural network to recognize given a picture of the street, for example, it can recognize all the objects in it, it can recognize the animals, everything in it, in any picture. And you begin to then decompose or see how these very complicated AI machines work. In the few weeks that we are talking about this, all sorts of breakthroughs keep happening. One person has trained an AI machine to detect whether a person has COVID, this coronavirus, by just recording the sound of the cough, the sneeze, and passing it through an AI neural network, basically a regression model. And the regression model will score how likely it is that you do have COVID and things like that. So breakthroughs are coming all the time, and it's really good to stay in touch. Speaking of which, I'd like to remind you that every Sunday at noon California time, which is actually brutal, I suppose, for India time, it's 12.30 at night on Sunday, we do have a research paper reading. Every week we read one research paper. I announce ahead of time which research paper we'll read, and we then discuss the breakthrough. So this may not be of much interest to people who are in India because the hours are rather brutal, but for the California people, in case you're not aware, just as a for your information, we do have a research paper reading section every Sunday. Also at this stage, if this is your first engagement with machine learning, it may be a little premature to start getting involved with that, but whenever you guys feel confident, you're welcome. So we we talked about regression and now we took the example of a linear regression in the linear regression we try to fit a straight line to data when we try to fit a straight line to data but so suppose you have data like this there can be many uh straight lines that can fit now the question is how do you find the best fit straight line? And so that brought us to the concept of data and the parameters, the hypothesis space and the parameters there. And how do you quantify the error? If you remember, we talked that the gap between prediction and reality is the residual error. And you need some way to accumulate or aggregate these residuals to quantify the error and the two ways that we learned about was the mean absolute error you just take the absolute values of the errors or you take the mean squared errors you square the errors and you take it when you square the errors uh it is the most common way of doing it, mean squared error. For many reasons, it's a preferred way. In fact, I mentioned this mathematician, great mathematician, Carl Frederick Gauss. Gauss is of course considered the prince of mathematics. He's a person obviously He's a person obviously of the same caliber, but in a different area as India's Ramanujan. Ramanujan was perhaps the greatest number theorist in existence, who ever existed. In the same way, Gauss is considered to be the prince of mathematics. He made prolific contributions to analytical mathematics, the calculus kind of math. But anyway, so one of his results was he proved that if you have to choose a way to quantify error, then under certain circumstances,. That is the least square method, the method of least squares. And that actually happens to be the Gauss-Markov theorem we talked about last time for anybody who is mathematically inclined, but we won't get there. So given the error, the question is, how do you get to the bottom? How do you minimize the error? You can't just be drawing random lines and checking which one best fits your data. So what you do is you actually go into the hypothesis space and you do something called gradient descent. So to understand gradient descent, I talked about function. We talked about the concept of slope. The slope is nothing but how much height you gain or climb up if you move unit distance in the positive direction so let's say that you move one step in the positive direction and you gained height of three units of height so you would say your slope is three that's what slope is and that's a geometrical way of looking at it and in a more algebraic way people call it is the derivative of the function or the curve that represents the the the path on which you are walking okay it gives you this of that path or it is the derivative right the steepness is the derivative of that and so people have created a lot of of course as you may have gone through in school, if you did do calculus, there's the whole bit of machinery that talks about differential calculus. And at the end of it, once you put the machinery, the mechanics of differentiating all sorts of different kinds of function, the bottom idea is just a simple idea. The bottom idea is just a simple idea that given any function, if you were a little ant walking along that function at any given point, how much altitude would you gain if you move forward a unit distance? So that is that and we realized that if you want to move to the minima of a function, like if you want to go home which is the point at which the function achieves a minima, the best way to do that is to go against the slope. This is a recap of the last time. We came to this rule, which basically said that your next x value should be your previous x value and then go against the slope and where alpha is the learning rate. And when you do that, you have the famous equation of the gradient descent, because when you generalize this idea to higher dimensional functions, the generalization of slope is something called gradient. And you have the gradient descent. So machine learning at the end of the day is putting together two very simple ideas. It is first trying to create a function that maps the input to the output right and then it says basically that function will have all sorts of parameters then you go into the parameter space you pick some function some set of values for the parameter let's say some straight line or something like that then you calculate how much error there is for For example, in the case of linear regression, you pick the, excuse me, the mean squared error, the sum squared error. Then the next question is, how do you minimize the error? Learning is the minimization of the error as we talked about, right? And so that is the process of gradient descent. And much of machine learning can be reduced to the learn, the word learning is often a reduction of some objective function. In this particular case, the objective function is just your sum squared error or the mean squared error. So that is a recap of our last time. We also talked about this convention that we'll follow. Whenever we talk of data, we will use Roman letters, X, Y, Z, A, C. But when we talk about concepts or parts of a concept, like for example, a straight line that fits the data, a straight line is a hypothesis. It's your idea, it's your theory. And so the pieces that make up the theory, namely the intercept and the slope, those are the parameters of this, of your model. We will use Greek letters. We'll use alpha, beta, gamma, and so forth. In particular, your textbook tends to favor the betas very much. You see the betas here, beta one and beta two, as the intercept,as here, beta one and beta two as the intercept, beta naught is the intercept and beta one is the slope. That's how it uses. And so this is a question that when you look at the error surface, the error surface seems to have a parabolic structure, parabolite structure, and the shortest path home is the path of gradient descent. And you can do that to find the best value of that. The next concept we learned about last time was that of bias-variance trade-off. So what are the bias and variance represents? The two kinds of disease or two kinds of errors that you can have in your model. So we talked about basically errors that you can do something about and then errors that you cannot do anything about. So these errors are the reducible errors. So as you play around with your models, different models, you will have some bias errors and some variance errors, but your model will also have irreducible errors. The irreducible errors will come from noise in the data. They will come from just practical mis-measurements. And it will also come from the fact or acknowledging that there are factors not given to you in the data that are effective. For example, if temperature is the only thing that you are given in a data, in a spreadsheet and the amount of ice cream sold, it is very hard because under the same circumstances, the same temperature, how windy it is will determine how many children will play on the beach. Whether it is a work day or a holiday will determine how many children come to the beach because if the parents are busy at work and the children are busy in school they are not coming to the beach right so for the same temperature you'll see a variation of readings how much ice cream you were able to sell right and so suppose you don't have that data you don't have other data like day of the week and the wind speed etc then in your model you will have irreducible error acknowledging the fact that the model that the data does not capture the whole reality right so Vinesh Pramlalli, In a way, it is that which the model does not know at all because the data doesn't are three so the removing the irreducible error which is coming from those sources the reducible error the error that you can do something about by picking better hypothesis making better models those your model errors fall under two types the bias errors and the variance errors i give you guys an intuition of bias and areas so if you look at this picture, let me call A and B and C. A is what you would ideally like. Suppose you're shooting at a dart boat, you're hitting very close to the mark to the target. B happens to be what you call the bias errors. In other words, you're hitting actually very well, except that you're shifted, you're hitting at the wrong bullseye. To you, you're hitting at the wrong place or aiming for the wrong place, but you're getting to that wrong place quite well. So those errors are bias errors. And then you have the variance errors when where you're hitting is all over the place. Like you have a huge variability in the location or the prediction of your data. So it is all over the place and so that is high variance errors. Like the C represents the situation of high variance errors. So high bias errors tend to appear in models that are overtly simple. High variance errors tend to be in models that are overtly complex. And so we came to, it is worth reviewing, this famous diagram in machine learning that keeps happening all the time. By the way it also happens to be one of the most asked interview questions in data science interviews. For some reason, it's a favorite of people. And perhaps for a good reason, because it just validates this core idea of machine learning. It basically says that as you make your model very complex, your bias errors will come down, but your variance errors will go up. It will start overfitting the model and your way. But because your total error, which is the green line here, is the sum total of bias and variance errors, you will reach a point of complexity at this point that we have drawn, where you have the optimal error optimal model a model in which you have the least total error right in which the forces you're neither too simple not too complicated and if you inspect your data if you go back and if you happen to know what your data looks like uh or what the force behind it is you'll often find that this point of lowest total error, the balance between bias and variance error, builds a model that pretty much resonates with the ground truth. And so that is that. Now, there's another last thing I talked about. So bias and variance, you tend to have sort of a trade off. Variance is overfitting, making overtly complex models. Now, let's come to a principle, the last thing we talked about was the Occam's Razor principle. What was the Occam's Razor principle? It said that suppose two theories can explain a data and maybe make equally good generalizations from the data, then science defines the, has a definition for the correct one. It says, because in the absence of any, there is no such thing as, see mathematics is correct and not correct right two plus two is four two plus two is not eleven and so forth in in ordinary arithmetic there are systems where that could be true in ordinary arithmetic two plus two it happens to be four right but not eleven you say eleven is incorrect four is correct science is different in the sense that you can tell if an answer is wrong but you can never tell if an answer is right. Dr. G R Narsimha Rao, Ph.D.: There's no right in science. So in science we defined right by construction, but we say that if two models are better than all other models. Dr. G R Narsimha Rao, Ph.D.: But they are and they are equally good in terms of their predictive power and so forth in terms of generalization or explaining data, then the correct one that is defined as that one which is the simpler of the two. So that is the Occam's Razor principle and that's very important. So whenever you build models you have to ask yourself that is there a model that is equally effective, yourself that is there a model that is equally effective, equally good at making predictions and generalizations and so forth, but which is simpler than what I have built? Because if you have, then you hop to that and say, well, this is a better model. This is a more correct model in some sense. And one way to illustrate that is something like this. Suppose you have two models for helping people manage their diabetes. One model says if somebody has diabetes and this is the amount of sugar level they have, they need to do a whole complicated regimen, wake up exactly between 6 and 6.30 and then do this much of food and this much of exercise and this much of walk. And then it's a very complicated regimented system that the model predicts or prescribes. So imagine going to a doctor who gives you this very complicated regime. The second model is, and let's say that the another doctor is using a simpler model, and that model basically says if you have diabetes, you better exercise more and eat less, cut down on food and sleep more. Exercise more, sleep more, eat less, less carbs. Now, which of these would you consider a more likely advice to be followed? You would agree that if a doctor gives you simpler, understandable advice that follow just three things, sleep well, exercise more than whatever you're exercising, and eat less than what you're eating, and that will make a huge improvement on your type 2 diabetes adult onset diabetes you would say well that is a clear instruction i can go follow but if the doctor gives you a very long and complicated regimen that must wake up at this time and eat this and so much of spinach and so much of rasam and no more than this then you would agree that you would you would be able to follow it for a bit, but ultimately give up. You'll get completely lost in the details. So that's the difference between simple and complicated models. So always simpler is the preferred one. All right, guys. So that is a summary of what we did last time. I believe I also gave this example of the solar system. The Kepler solar system puts the Sun at one of the focal points of an ellipsoidal orbit, ellipse orbit, and the planets are in elliptical orbit, which is much simpler than the old Ptolemy's astronomy, which put Earth as the center. And all these planets and stars, they seem to be somehow wobbling around the heavens, you know, in sorts of these epicycles. So calculations were a lot more complicated, whereas the Kepler model made the calculations a whole lot simpler. So from a science perspective, which is correct? So the thing is, definition. So you can say that it's just a matter of perspective. In the universe, there is no stationary object. The sun itself is not sitting quiet. It is just a star in the galaxy. And so it is moving, spinning around in the galaxy. Then the galaxy itself, right, is not stable. It is moving around in the universe and so on and so forth. So everything is in flux, everything is in motion. So what difference does it make whether you take Earth as the center or the sun as the center? And so the scientific answer there is that, no, it is preferable to put the sun at the center of a planetary system because it leads to much simpler models, which makes calculations much easier, much simpler. It is a conception that helps you reason about our solar system and the universe in a much more elegant and simpler way than using the old model of ptolemy, right, where the earth used to be stationary and everything is moving around the earth. And that is how you look at science. So that is a summary that we did the last time. Now I've taken about half an hour, 40 minutes to explaining regression. It was worth doing that. Today, what I would like to do is now move on to another class of predictive models called classification. Are we together? Classification. Before I move on to it, I would like to take any questions that you guys have on regression before we close the chapter on it. We are closing the chapter on the theory of it guys, but not on the practical. We will do one more practical lab on regression. Any questions guys? You're all very quiet. So one announcement to make. Anil Pandey is here. He's a very senior architect in Silicon Valley. He has made a lot of contributions to a lot of very important projects in his career. And he has graciously agreed to be essentially a guide to all of you and help you with your labs. So if any one of you are having problems, please reach out in Slack to Anil Pandey, he'll help you with that. All right, so I'll repeat what I said, Anil Pandey is here and he's graciously agreed to be to help you guys with the lab. He's the teaching assistant. And he's really very senior here in Silicon Valley. He has achieved a lot, made major contributions to many, many important projects. He has actually contributed, I think being the leaderboard of Kaggle competitions and so forth. And so it is reach out to him is an excellent resource. He's here in the in this session and you can reach out to him for help. Yeah, thank you, Asif. Yeah. Yeah. So you can reach out to me like if there are any questions. so you can reach out to me like if there are any questions thank you okay thank you thank you thank you all right guys so with that i would like to give uh exactly five minutes break it's 10 how much is it 11 16. could we just take a five minutes break before we start with the next topic? Make sure, just think about regression in your mind. Close your eyes. Think about regression. See if you basically have the concepts right. See guys, libraries will come and go. Today you're doing the lab with scikit-learn. Tomorrow it would be something else. Today you're using Python. Quite likely in 10 years you won't be using Python. You'll be be something else today you're using python quite likely in five in ten years you won't be using python you'll be using something else but it is that it is the conceptual understanding of a subject that stays with you for the rest of your life programming or there's programming in data science is anyway easy but even to the extent that it is it keeps coming and going in my generation i used to do programming in what is today called machine learning or data science. Guess in which language? Can anybody guess? Any guesses, guys? What one? Exactly. I used to do, I spent a lifetime doing my life in Fortran. And despite what people will tell you, Fortran is actually not dead. As you can see on my desk is a book on Fortran, modern Fortran. The word modern should give you an idea that Fortran is not dead, despite what people say. Most of the mission critical computations today are still being done in Fortran around the world, though it's not much used in commercial space because you don't expect people in the industry to be that deeply or scientifically trained. So when you do scikit and numpy, you may not realize it, you're doing it in Python, but actually you're doing it in Fortran because your Python code is just falling down to the Fortran and C libraries. So a lot of the code even today is always written in Fortran C, C++, right? And these libraries that we learn in data science, the Python, the R, or the Julia, the three popular scientific computer, the data science libraries, in many ways they are layers on top of the mountains of work that generations of scientists, thousands, armies, like tens of thousands of very, very talented researchers and scientists and mathematicians and physicists have contributed over the last close to 50 years. And 50 years of intellectual property has accumulated. So those traditions are not going away. But the one thing to know is that while C, C++ and Fortran are sort of there forever in many ways, languages come and go. For example, SAS used to be very popular for statistical analysis or what we call data science today. It was a proprietary language. It's more or less fading out outside a small circle of commercial shops. In the same way, there is still a very popular language, two languages, MATLAB and Mathematica. They were very popular in academic circles and in the industry for doing what today we call data science. But now you don't hear that much about it outside academia. And what were they? Were they, was SAS or MATLAB or Mathematica just completely new frameworks from the ground up, new languages? No, they were all sitting upon the same Fortran C, C++ libraries that people in my generation were creating and are still those libraries are still going strong. Today we have dominant was R and Python. Julia is the young kid on the block gradually gaining mind share and in my view it will take over after some time. But these libraries come and go. The foundational concepts remain the same. For example, the notion of expressing error as sum squared error or mean squared error. This concept was created by Gauss, the mathematician, in 1793. Just think about that. Then Galton and Pearson, when they use the word, they coined the word regression coming from regression towards the moon, a concept that they observed in biology. So we are looking at close to 200 years ago. So these ideas have stayed and mathematical ideas, deep ideas come slowly. And when they come, they come sort of with a ring of eternity to it. So it's important to understand the concepts. Libraries will come and go. Are we together? So what I will do with that long explanation, I would suggest that you take five minutes to just reason through in your mind what is it that you have learned. I'll take a break of five minutes, I'll drink some water, come back, and then we'll start on a new topic which is classification. And so I will stop this particular video because this was a review and we'll start a new topic after this.