 Welcome back everyone and a warm welcome to some of you for whom today is the first day. So we are going to do the, we are starting the third week of this workshop. So far, and I'll go over the material we have covered so far for the benefit especially of those who are joining today. Today's topic will be something quite interesting. We did a correlation last time. Today we'll do it do the mathematics of correct and after that one regression we learn the principles of regression your regression polynomial regression and so forth so today uh the machine learning part of it will start in a proper way Now just to remind you that our syllabus stays these things. So the main topics will start from today. Everything we have been doing so far has been building up your background. We will talk about covariance and correlation, causation we already talked about. We'll do regression, regularization, classification, clusteringustering and dimensionality reduction so if you want to get a sense of what's coming next week or the week after that you should go and look at the website you will find all that information now besides that please make sure that you all have access to the course portal which I myself seem to have lost so let me log into it you should have received an email with the address of the with the web address of the course portal in this portal this is a LMS and learning management system. In this you'll find all your important links, the zoom links for the class right away the session, our slack channel, our labs and homework. And also, if you have missed any sessions, remember that all the sessions are recorded and the video recordings are here. There's information about textbooks, there's a lot of helpful tips and so forth. We'll be posting projects and many things out here. Now I'll be releasing one more quiz today. So that's where we are. All right. So with that background, let us now go and review what we did so far. We started this course by, and I'll do a very quick review. We started this course by saying that machine learning is a quantitative term, unlike artificial intelligence. We don't know what intelligence is in a true sense. We don't know what thinking is. The closest definition that we can give to intelligence is that intelligence is the ability to learn from examples and to generalize. So generalization is a property of intelligent entities, whether those are living forms or whether those are machines. And at the heart of that generalization is you start with a certain hypothesis. That hypothesis may be wrong. For example, if you're trying to fit a line through the data, your line may be entirely wrong, but you can figure out the errors that you are making. Once you quantify the errors, then you can reduce the error. So machine learning is the reduction in the error. And a subtext to that is, if you have to reduce the error and a subtext to that is if you have to reduce the error and learn you want to have the most efficient form of learning in that context we learned about gradient descent the the most popular and the dominant way to do reduction in error so there are two sides to machine learning first you quantify the error the error, the error function, and its generalization is the loss function. And the second part is that you use certain techniques of calculus and then you do gradient descent, which in very simple term means that if you're on a hill, you take the path that will essentially tumble you down the hill as fast as possible, right? That is gradient descent. So in that case, we took a few stories. We took the story of a young entrepreneur. The young entrepreneur is trying to sell ice cream on the beach as an ice cream shop. If you buy too much ice cream, the young entrepreneur has to go to a wholesaler and get supply of ice creams. And ice cream is a perishable good. So every morning, let's assume in our story, our entrepreneur goes and gets ice cream from the wholesaler. Now, the entrepreneur has to hope that all of it will sell on the one hand. If he gets too much ice cream, then it will go waste. On the other hand, if he gets too little ice cream, well, he'll just be sitting there and a lot of customers will come and not get ice cream, right? So both of those are not good situations. The optimal situation is he has just the right amount of ice cream. So to do that, what he does is he has data. He observes that on warmer days, there are more children on the beach, more ice cream cells. On not so warm days or windy days, etc., less ice cream cells. And so he starts plotting the data and then builds a hypothesis that there is a linear relationship between the temperature of the day and the amount of ice cream that gets sold. And that gives him a sense of it. Now, we plotted it out in this figure. So in this figure, there's little black dots all over the page are data points. So this is a data point. This is a data point and so forth now based on that if you make a linear hypothesis that there is a straight line there are infinitely many straight lines in this page which of them is closest to the data which of them is the best hypothesis of all the infinitely many lines that you can draw or the infinitely many hypotheses that you can have. So towards that, the two steps come in. First, we quantify the error. So you make a prediction and you see how wrong was the prediction. You may say that today is 70 degrees centigrade and I need, let's say, 110 pounds of ice cream. But it turns out that on that day, only 80 pounds of ice cream sold. So you had an overestimation. You were wrong by 30. You overestimated by 30. Someday it could be the opposite. You may notice that while you didn't sell enough, you bought only, you estimated and you bought maybe only 80 pounds of ice cream, but because the temperature was 90 degrees, it so turned out that the total amount of ice cream sold between you and your neighbor was closer to, let's say, 140 pounds. So now you have a pretty substantial gap, a negative gap between what you hypothesized. You had only, let's say, 80 pounds of ice cream, but 140 was needed. So you could have errors both ways. You can overestimate or underestimate. Now these errors, intuitively, you feel that if you could aggregate these errors, you would have a pretty good sense of how much mistakes, what was the total size of the error. The question is, how do you aggregate? You can't simply add up the numbers because the overestimation and the underestimations, they can cancel each other out. So what you do is you can take the absolute value that will make it add up to a positive number because what you are concerned with is the size of the error. Now when you take the absolute value then there are many possibilities. You can take the absolute value, you can take the square of the error which will again make it positive and so forth you can go to the kth power now which one should you take in different circumstances um different answers work and this is one of the peculiar things about machine learning that there is no one correct answer there is a there's a famous saying by box which i, that all models are wrong, but some are useful. So when you're trying to build a useful model, the data ultimately determines and picks the right model as the successful or the viable model. So even here, when you're trying to quantify error, should you take the sum of absolute errors or the sum of squared errors? Well, it depends on the data. If the data has a lot of outliers, then taking the sum of absolute errors is a better idea. If the data does not have a lot of outliers, then it turns out that in most normal circumstances, sum of squared errors is the idea, and that is the so-called blue theorem or the Gauss-Markov theorem. So with that, again, this is a very quick review, and I'm doing a little bit longer because we have some folks who are new. So regression, the word, we went over the history of the word, of Galton observing that there is an excessive generation of people there is a regression towards the mean children of extraordinarily tall parents tend to be a little bit shorter and the children of extraordinarily short parents tend to be a little bit taller than the parents right and so they regress the extremes regress and come more towards the normal slightly so that was his discovery in the paper the regression towards mediocrity he observed then the question remained as to why it happens and so on and so forth but for historical reasons the word regression has stayed. It's a negative word with negative connotation outside a field. But in our field, there is no negative connotation. It simply represents a model in which the input is whatever data you feed in, and the output is a prediction. It's a number. When your prediction is a number, or generalization of a number is a vector, when it is a vector, sometimes it happens. For example, you might be predicting the wind velocity. Now you're predicting not only the speed of the wind, but also its direction. So that makes it a vector. So the input given input, if you predict either a number, either a simple number, a scalar or a vector, then you're modeling a process is called regression. That you have a regression model. In contrast to it, given the input, if your hypothesize identifies a type, a class, for example, with the other story we took, you take children to a meadow. In the meadow, all we have are cows and ducks. And you ask the child, what animal is this? Is it a cow or a duck? The child picking an answer is, in a machine learning sense, you would say your model is making a prediction because the child has some mental model in mind which it is using. Some is beginning to grasp the concept of a duck or the concept of a cow that it will use to decide whether the animal that she is seeing is a cow or a duck. So that sort of a process when the target is or output is a type, is a class from a finite list of class, you call it classification for obvious reasons because you're identifying a class. So these are two important things we talked about. We talked about the history of it, Galton, and regression towards the mean. We also talked about irreducible error. Irreducible error represents in your model an acknowledgement of things you don't know. That is, for example, if you build a model, if you try to sell ice cream and estimate it purely based on temperature, you would be wrong quite a bit. There will be a certain band of values you'll get because for the same temperature, if it is a workday, parents are busy and they're not getting their kids to the beach. So you will likely sell less ice cream. Whereas on weekends and holidays for the same temperature, parents would be free. They would bring their children to the beach and you're likely to sell more ice cream, isn't it? So to the extent that your model did not know about day of the week, you will have a ban, you'll have certain errors that you can't get rid of. That comes from absence of crucial information, right? And so that is one source of irreducible error. Another source of irreducible error, of course, is the instrumentation error. Try standing on the scale to take your weight every morning, which some of you probably do, and then come back 10 minutes later and weigh yourself again. If your scale is like mine, the values will change. And if you want to be happy, then say I will take the least of the five values. I'm kidding. So all right. We also in passing talked about the Flynn effect. I just mentioned that what is true of individuals is not true of the population. Actually in the population, we observe that the opposite we observe that the human population is in general growing stronger taller and more intelligent more capable and that is called the flynn effect what used to be the olympic record of 30 40 years ago high school kids achieve that regularly now right the same is true in many fields of endeavor. And that is because successively, our nutrition, our quality of life is better and better. And so it leads to the next generation growing up with a lot more advantageous environmental conditions. And that leads to sort of, in in some sense the betterment of the population now we talked about gradient descent which is the process and I will keep that aside because that will be a long discussion but simply put gradient descent is the process of tumbling down the hill and coming in the hypothesis space and finding the best solution. So remember, I talked about two spaces. For every line hypothesis in the real data space, we know a line has a slope and an intercept, beta naught and beta one. But those two things can be thought of as an abstract space, the hypothesis space, so that any particular in that plane whose axis are beta naught, beta one, any point that you take represents a hypothesis. It represents a line in the real space. Now, associated with this hypothesis, you can compute the error given your data. What would be the total error? And so the shape of the error in three dimensions, if you look at it, if error is your vertical direction you get a beautiful bowl shape for linear regression this is true only for linear regression you get a nice beautiful bowl shape so marginally we talk that we consider such bowls like this bowl we call these bowls convex convex are points such that at any given two points if you connect any two points in the bowl together, then one side of the bowl will be, it will never intersect the line. Whereas a non-convex surface is like this. There are points that you can connect A, B, but when you connect, you end up crossing the surface itself or the curve itself, right? The segment crosses the curve itself. So those are non-convex surfaces. A little bit of a mathematical aside, we won't go into the gradient descent any further at this particular moment. Then we talked about how regression happens, and we talked about correlation. When we talked about correlation, we talked about in a very intuitive sense that things are correlated. Like, for example, I mean, we took many examples in that sense. And we said that correlation is not causation. So that is obviously a cliche now, except that we often fall into the trap and make the mistake anyway. So if two things are correlated, then one may be causing the other or may not be. You need to further explore. One may have no relationship to the other. It may be an accidental correlation, and the web is filled with websites that find really hilarious correlation. Something like the number of PhDs produced in a particular subject and the number of, I don't know, the number of PhDs produced in a particular subject and the number of, I don't know, cows dying or, you know, the dolphins jumping into the sea in another place or something like that, completely unrelated events, but you can create a correlation curve. You can see that the two things, the curve of both of them go together. Those are adventitious correlations. A third form of correlation is the correlation is there, but one is not causing the other. There is an underlying cause that's causing both of them. So, for example, if the population of India and the population of China, the curves are, or any other third world, let's say, Thailand, or I don't know such countries are showing showing a growth curve that is fairly similar. You may wonder that, oh, this is a positive correlation. But obviously, it would be foolish to believe that India's population is causing Thailand's population to grow or the converse of it. But the underlying cause is both of these used to be European colonies. So when they became free, the government put in a lot of effort and did a excellent job in pulling up this countries from a state of beggary to its current economic development. So when economic development happened, there was more food, there were more resources, and it's a it's a phenomenon. It's the mouth is law that when the resources are abundant, all species grow in population. And so there was a population growth everywhere after that. And therefore, there was a correlation. And then there is a fourth kind of correlation. You are seeing a correlation, but the explanation is in some confounding factors which you are not seeing, right? It is not there. We took some examples. For example, we took the hormone replacement therapy for women and people concluded that there's a strong correlation between that and affluence. Sorry, not affluence. Between that and general vigor and good heart condition, cardiovascular health? Well, there's a confounding factor. Only more affluent people could afford hormone replacement therapy, and affluent people have the leisure time to exercise, to do things, whereas less affluent people, they commute, for example, in Bay Area, they commute two hours to come to work and then two hours back and the whole day they work and after that they have to take care of kids there is hardly any time to take care of their health to the same extent that a little bit more affluent people can do which is why you see a preponderance of diabetes and obesity in the poor people in the united states because they're literally working all the time, right? So you have to uncover the confounding factors just because one shows correlation with the other doesn't necessarily imply that one is causing the other. Another example we took was the breakfast industry. They showed that people who have nice breakfast, and in US, of course, because of all the marketing that goes on, breakfast invariably means the sugar-coated flakes and carbs. And to their glee, they noticed a correlation between people who do take the time out for breakfast and, again, health. out for breakfast and again health right and once again you you have they obviously implied that having a good breakfast every day or having a nice taking the time out for it leads to health whereas there is no such reason to believe that surely common sense says that filling yourself up with a lot of sugary carbs early in the morning is not a recipe for good heart condition. Right, the confounding factor once again is socio economic conditions right, so you have to always look for the socio economic conditions. So you have to always look for the confounding factors that may be involved when you think about these things. And it is quite amusing, actually, knowing that these things happen. Observe some of the findings and news items, and you will develop a very healthy skepticism. As a growing data scientist, you will look at the world quite differently. You will listen to the news quite differently. And you will always be wondering what are the confounding factors. Or could there be latent causes behind certain observations? And can the explanation be completely different? And things like that. And we took also the example that regression towards the mean fools people a lot. We took the example of those pilot training that pilots who did extraordinarily bad in a learning lesson one day, the instructors chose to shout at them. And then the instructors were pleased to observe that the next day those pilots did well. And so they came to the conclusion that this whole idea of giving people only positive feedback, patting them on the back when they do it right, but not being harsh when they do it wrong is not right. What you should do is be harsh. What was the flaw in that? When people do extraordinarily bad, it isn't because they don't have the ability. They're just having a bad day. Something terrible is happening. Or for some reason, they they're sleepy maybe they had too many drinks the last day or whatever it is they're very likely next day to do better because their innate ability is there and that will pull them up it's just that too many factors pull them down on a particular day those were adventitious factors or random factors right so the flaw in that study is that those pilots would have done better anyway. So there was no control group. If you wanted to do that, you could have shouted at one group of pilots and not shouted at a control group and then see whether there's improvement in both or only on the group that you shouted at. So studies like that are very common. People often come to, they ascribe causation to situations where it is not causation doing it, but it is the nature of random factors that is sort of creating the perturbations and you're over-interpreting the perturbations in the values. So to keep that. And then in this course, we gave some time to doing what we called a supersonic flight over the statistical land. We gave a week to statistics and we kept it fairly small. We talked about something to be a random variable. For example, height is a random variable because it can take values within a certain range of values. Any one value it could take. So such a thing is a random variable. Common sense. We decided that we'll use this nice, beautiful calligraphic D for our data set. It will represent all the data set. Then came the fact that what is, why the word statistics is a plural. The singular of that is statistic. A statistic is a measurable way, a measurable way to describe the data. For example, given a bunch of numbers, the height of people or the weight of people, let's say the weight of giraffes, if you say this is the range, minimum is this, maximum is this, this is a range of weights, you have just created three descriptive statistics. statistic. Maximum is a statistic. Range is a statistic. Now, if you say the average weight of the giraffe is this much, well, average is a statistic because that describes the entire data set, which is more meaningful than just enumerating the weights, just parroting out the weights. Likewise, if you could find the median or the most common weight, these are all statistics. They're telling something about it. Then we went to a little bit further and we talked about the skew and kurtosis. So skew, whenever the histogram of a random variable, right? histogram of a random variable, right? And it's sort of a, when there's a whole lot of data, then, and you normalize the histogram, you call it a probability distribution. But in simple terms, just consider histogram, frequency plot of the data. If it looks like the one on the left, right, then you say that it is right skews. And the intuition is, just draw a duck there. and when you draw a duck if the duck is pointing right it's a positive positive or right skew if the duck is looking left it is a negative or left skew and if the duck is looking at you it's symmetrical there is no skew right then we talked about kurtosis kurtosis is is a thing that you measure in a way relative to the bell curve. So you know that a bell curve smooths out. We are all familiar with the bell curve or the normal distribution more formally. It extends to infinity. There's some outliers. So kurtosis measures relatively in your distribution, do you have more outliers or less outliers? Is the mass, if you think of your distribution as made up of sand, you know, children make sand hills. So if you think of it as a sand hill, is the sand hill, the mass of the sand hill pulled in or is it pulled out? If it is pulled in, it has negative kurtosis. If it is pulled out, this is leptokurtotic. If it is pulled out, it is positive kurtosis. And I believe that is aplatic kurtotic, right? So there are fancy terms for that. But let's think in terms of negative and positive. So it turns out that this mean standard standard deviation, skew, and kurtosis, they have an elegant representation as a single formula. And that formula is called moments of the Z value. So what was Z value normalized? You take a number and you say, how far is it from the mean? So is it from the mean? So is it bigger than average and by how much and smaller than average than by how much? And then you scale it by the standard deviation because then it becomes dimensionless and also it pulls in the scale. So when you take Z values and you take Z values because suppose you're measuring giraffe and their temperature and their weight, you would imagine that the giraffe's weight would be a pretty wide distribution. There'll be a baby giraffe and there'll be a fully grown giraffe and there'll be probably a thousand parts, a thousand or two thousand pounds apart. But the temperature of the giraffe would be like, if giraffes are anything like human beings, it will be around 98 degrees to 105 degrees, just a seven degree variation so one varies only in a seven seven the range of values is only seven for the other it is thousands but common sense says that it that that thousands is simply an artifact of your unit so instead of measuring it in pounds if you were measuring it in metric tons well now now your numbers will become single digit a giraffe may be one ton i don't know how much giraffes away half a half a ton quarter ton three four ton or one ton or something like that right so so uh in other words the values the raw values that you get is hostage to the to the yardstick that you use, the units of measurement that you use. But when you normalize it, you sort of strip that away. So irrespective of whether you measure the giraffe in pounds or you measure the giraffe in metric tons, the Z value is dimensionless, right? And because it's dimensionless, it will be the same Z value distribution. The Z value of a giraffe's weight would be exactly the same irrespective of whether the raw data was in pounds or metric tons, right? And so the value of, so the so the i mean the advantages of using z value z values are predominantly used in machine learning there are other ways of standardizing the data min max and other things but z value happens to be a leading favorite for that reason now with when you take the z value there is a concept concept of the moments of the z value, which is this. Moments is you take the, well, you take the z value. I'll just put it simply. Let me forget all this. So the normalized moment is the z value to the power k. And if you take its expectation value, expectation value means the average over the data you will get the moments and it turns out that the first moment second moment uh second moment would be one but the third moment is q fourth moment is kurtosis so we took a little bit of a mathematical digression just to show that there's a very elegant formulation but it is all basic high school a very elegant formulation but it is all basic high school algebra nothing fancy here then we came to one of the crown jewels of statistics this most remarkable result which i'll do for only a couple of minutes which says that irrespective of your distribution if you sample from the distribution then the mean of the means will show a bell curve. It will have a bell curve. So this theorem is the linchpin. This is what helps you trust samples. Because quite often, you can't get, if I ask you what's the average height of the giraffes, you don't have the luxury of going and measuring all the giraffes in Africa. You simply can't. And maybe while you're doing that, more giraffes will be born and some are dying. So it's not feasible. What you do is you take a small herd of giraffe and you measure them, and maybe you find another sample of giraffes, another herd of giraffes, and you measure them and so on and so forth. You go about it. After a little while, you have enough samples, and you start looking at the average in all the samples. And what the center limit theorem says that the mean of the mean will be very close to the true mean, the actual population mean. And that is why we are able to do learning with samples itself. Then we talked about two things. We talked about biased and unbiased estimators. Mean is an unbiased estimator. It means if you take a sample mean and you keep on taking enough number of sample means and average them, you will get very close to the true mean. So to be mathematically precise, of course, you have to take infinitely many samples. In practical terms, take a reasonable number of samples. If you're measuring giraffes, maybe 10, 20 samples are enough, so long as you move around a little bit and look at different herds. So that's that. But they are biased estimators. It turns out that while mean is an unbiased estimator, variance is not. Standard deviation is not. The reason for that is any sample standard deviation will always be less than the true population standard deviation. I gave you an explanation because any sample that you take will not capture the entire range of values and therefore it's likely to have a lesser variance. So average of mean of variances, each of which underestimate the variance will lead to a total mean which will underestimate the total variance estimate which will be below that of the population. That is why you say it is an unbiased estimator. So it's a biased estimator and the way you fix it is that for samples, you do this extra crucial factor. Unlike what the high school books teach you, namely that for given a data set, take the population 1 over n, the subtle trick is don't divide by 1 over n, divide by n minus 1. So it will boost the value of the variance or the standard deviation sufficiently so that it comes much closer to the true value of the population. So if you do this, then this begins to approximate the population variance. So this is a recap of the sort of things we did. Today, we will do a little bit more we will talk about two uh relationship between two variables of course correlation is a relationship between two variables it mean is a univariate statistic now we are looking at bivariate statistic. Now we are looking at bivariate statistic. We are looking at the way one, two variables sort of behave in relationship with each other. So let me draw some pictures for you. Suppose you get data. Take these three cases of data. In this, you see data is going like this. In this, data is like this. I'll make a few more. Is it visible on the screen guys? Yeah. Yes. So suppose data is like this. And then suppose data is like this. Let's call this A, B, C. If I were to ask you, describe what is, how would you describe the difference between A, B and C? Like what is how would you describe the difference between a b and c like what is different between them between them what would you say a is posturally correlated b has no correlation c is negatively correlated yes so in other words you say but what do you mean by correlation in a mathematical way how would you quantify it uh so as if the x increases the y will have a y will also increase in the b case as if x increase there is no effect on y we like anything can happen but in the case of c as x increase y will decrease good so this is it guys see if you notice in this space as x increases y increases if x decreases if you go in this direction you notice that this also starts increasing y value starts increasing if you go in the negative direction then y also starts decreasing isn't it in b you're never too sure there are cases in which it increases it decreases at no one point can you make any you can see any relationship and in this C case you see the opposite as you move along to the right in the X direction you notice that the Y decreases you notice that the y decreases and the opposite so they go opposites right so the word that you use is co-vary here they co-vary or very very together right or co-vary right and this you would say uh and just to coin a word just for now you can say they go opposite so they sort of contra vary would you say that and this you would say are unrelated isn't it so now let us try to come up with a mathematical way of describing it it so turns out that galton was thinking about it he was looking at a lot of data sets that had relationships like this and the story goes an interesting bit of history, he was going to visit some one of his friends castle, whose grounds and in Britain, the castles used to have lovely, practically beautiful parks in the within the campus. So pretty much like the US universities or corporate campuses. So he was roaming around there. And suddenly, maybe there was a rain, and he hit along a wall, and this apparently in a flash he got this idea of how to mathematically represent it. That was around the 1880s. So it turns out that this idea is fairly recent. It's just 140 years old. What he observed is that if you take the values here, anyone x1, y1, x2, y2, observe something. The x1 times y1 is positive, isn't it? Likewise, x2 times y2 is positive. Is that true, guys? If you multiply, because here x2 is also negative, and y2 is also negative. Are we making sense? If you multiply, and I'll remove the multiple just to say. This is just for distribution a just for distribution a I'm talking only of distribution here all bets are off but look look at this here x1 y1 is negative smaller than zero as you can see and the same is true for x2 y2 i mean let me take any one point as x1 y1 let's take this as x2 y2 do you notice that their products are all less than zero folks is this i need some feedback yeah to unmute themselves and speak up yeah whereas here so now observe one thing. There is, of course, certain little bit of a point where things are wrong itself. But if you take this average, if you take one over n of all the points, x1, y1, plus x2, y2, et cetera, xn, yn, generally you expect this number, the average to be greater than zero for a, isn't it? And for c, the same number, and I'll now write it in mathematical notation, for all points, xi, yi, you would expect it to be, in this particular particular case to be less than zero on average right and for this for b you would expect this summation to be approximately zero because for every positive point there is a negative point if there is a x1 y1 here there is a x2 y2 here this is positive this is negative this is positive this is negative and they equal they seem to be equal number of points in each of the quadrants right and so the first and the third quadrant will contribute positive points the second and the fourth quadrant will contribute negative values and the end result would be that the sum will be will sort of cancel out right and so he realized that for cove and he called this expression covariance so this is the derivation of covariance in statistics covariance is therefore 1 over n, summation i up to n, of what? Of this. But there is one catch to it. You notice that I cheated. I made them all centered around the origin. But data may not come centered around the origin. So this is actually not the real thing. Suppose data is starting from here. Now you would be in trouble so let's say that d case is there now you would be in much more trouble right because between this data and another set of data which is also just here x1 y1 you notice that this formula even though this is positively correlated and this should be negatively or contra varying together, you still will get a positive number. So what do you need to do? The one thing you have to remember to do is don't take the absolute value. First, draw your coordinate system by sitting in the center of the data. So fly to the center of gravity of the data. Imagine that you have a spaceship and you go and sit really at the center of the data, center of mass or the center of gravity of the data, and draw your coordinate system there. And when you do that, and what is that point? That is, of course, your mu's. So you are saying that whatever the average of x is minus the mu of x, the average of x center, multiplied by yi minus the mu of y, the average of y, right? So this is just moving to the new coordinate system, because if you think about it, relative to, and this point is mu x, mu y, the average of x and the average of y is this center of gravity. Guys, is this intuition clear? The coordinates of the center of gravity is literally the average values, right? Yeah. And so if you put your coordinate system there, you are sitting there, and then from that coordinate you're looking at the deviations from that from the mean. This is what you're measuring, and then this expression becomes true right. And this is the therefore this is the definition the mathematically correct definition of covariance. This covariance, though, you realize that I am using the raw variables. What is wrong with using the raw variables? Need to standardize. Yeah, all you can look at is the sign. It will tell you whether it's positively correlated or or negatively correlated but the absolute magnitude tells you nothing because the magnitude is the host is hostage to the units so whether you measured your giraffe in pounds or in metric tons will determine how big a value you'll get isn't it so for example x is x is the, let's say, height of the giraffe. And this is the weight of the giraffe. And suppose you take the height, let's say case one, in centimeters and this in pounds. So you will get a big number in centimeter pounds. If on the other hand, you took this in meters, meter and tons, then what would happen? You would get much smaller values, right? You know that the height and weight will be correlated positively. Bigger giraffes tend to be heavier giraffes but depending on your unit of measurement the value that you will get for covariance will be different so obviously what we have learned so far tells us that it is equal to, if you think about it, Xi minus mu over sigma. And this would be YI sigma of X, the standard deviation of X. The standard deviation of X and the Z value of Y. Z value of Y with respect to I would be Y I minus mu over again sigma Y. So it would be better if we took the covariance, not of the raw variables, but let's take it of Z value. So this people often write this thing as variously as cov x, y, x, y, right? Or sometimes you write it as x, x, y. All of these notations are common, right? But suppose you do this, as we said, look at the covariance not of x and y, but zx, zy, the standardized value. What does that become? Let's plug this in. It will be zi minus, now what is the average of zi? If you standardize the values of x, what will be its average? of x, what will be its average? Mu will be at zero, isn't it? See, remember, it is xi minus mu, the mu x, right? So by definition, once you z value something, its average is zero for that data set, isn't it? So minus zero times z of y minus zero, right? You're doing a summation over i, right? Which is basically, now, if you plug in your equations, it is xi minus mu, right? yi minus mu over sigma x, sigma y, right? So people often write this as this is they call this they have a new symbol for it they call it the row and this is the popular term correlation when people say they see a correlation they i mean mathematically people have standardized or decided that they'll represent correlation to be the covariance of the standardized values and rho. So you say rho x y is equal to this. And it is often in fancier language. You would say it is the expectation value. And so this is it. This is the sum over one over n, over n summation over i and this this thing this part as we know we write it in a fancier notation we say that it is the expectation value of this is just mathematical notation we say using the e thing more succinctly writing it like this this is y i minus mu right divided by sigma x sigma y right which also people if they want to go fancy they can write this is equal to the denominator as expectation value of um x expectation value of y. So now you get an expression with all these big expectation value operators sitting there, which just means that add and divide by discrete values. So this is correlation. All that we talked about intuitively, it is as simple as this. I've just represented it with a few expressions so that finishes our discussion of statistics at this particular moment so now i will before taking a break i will let you with a puzzle suppose i have data set one and data set two think about this and uh if you happen to have it in my class in the past and you know know the answer, then don't speak up. Suppose you have two datasets or three datasets, as many, but all their statistics match. Their mean, their median, their standard deviation, their, you know, all of these, they all match in the data. Would you say that those two data, pieces of data, are probably representative samples from the same population? They are reflective of a population, right? And as samples of data, they're pretty identical samples of data or nearly similar samples of data. Would you say that? So in other words, what is the point of developing all the descriptive statistics? If two datasets have exactly the same descriptive statistics, what does it tell about those two data sets? Are they essentially identical in terms that their values may be slightly different, but they are basically describing the same reality? Or is that not so? What can you conclude from that? It's not so. So guys, if you have taken a course in statistics, then you cannot say that. But you say it is not so, you have to come up with a counter example. Well, the reason is it could be just a coincidence. You could have a data set about stars and about goats, which have similar distribution. Doesn't mean that they, these are abstracted numbers, right? This is what we have derived from actual data points but the data points are the actual numbers that relate to reality these are just sigmas and things so think about it so i'll try to confuse you by saying suppose i have data like this the distribution is like this i take sample sample S1, S2. So those individual values may differ, right? So for example, I take a sample, one sample of data, let's say X1, X2, Xn. And the second sample I create just by doing random errors I add to it, random perturbations, X1 plus epsilon 1, positive or negative perturbations, so that in aggregate, they cancel each other out. Now, you realize that the moment you do a statistic mean or something like that, because these errors might tend to cancel out, the statistics of the two data set, D1, D22 will be closely related. They're very similar, isn't it? You expect them to be very similar. So in this case, you would say that, yes, if these two data sets have very similar statistics, it seems plausible to believe these two data sets represent essentially the same reality up to perturbations. So like you said, Raj, that by accident, there would be, but what is the likelihood that something very, very different in shape would have almost identical statistical description. So think about it, and I'll give you guys a five-minute break, but before that, I will ask you another question. Suppose two variables, x and y, they show zero correlation. Do you therefore conclude that there is no relationship between them? Like look at a, b, c. You see that see that in b a and b the x and y are completely unrelated it doesn't matter what x is b takes a different set of values a range of values isn't it so would it be so you know that when the when the correlation value is away from zero positive or negative there is a relationship between the two. They vary together or they contravary if the covariance is negative. But when the covariance is zero, like in the example of B, they are unrelated. But I'll ask you this question. Is it at all possible that two things may show zero correlation? Well, I'll pose this as a question as, would you therefore, can you definitively conclude there is no relationship between them? So ponder over these two questions. We'll take just a two, three minute break and get a glass of water if needed, but not long. Today we have a long session. So just ponder over these questions questions. We'll take just a two, three minute break and get a glass of water if needed, but not long. Today we have a long session. So just ponder over these questions and we'll start. So, in the correlation equation that is y i minus two right and uh oh I'm sorry there thank you I I need to be more while I'm talking I'm absent-minded thank you for correcting that good and here also I should be particular why I this is Sigma Y right y i this is sigma y right mu x and mu y that's right and sigma x sigma y the denominator i hope you got some time to think i would like to hear some answers. Guys, make a guess. First question was if two data sets, they exhibit almost identical statistical, all of the statistics are identical. What do you conclude from that? Almost identical. What do you conclude? That one is one up to a perturbation. One is the same as the other. Would it be reasonable to conclude or they represent essentially similar realities. How many would say yes? Can we have a third option that their behavior could be similar, but the realities could be different? I mean, you could use some numbers or some methods to identify the next step or the next point. But they represent, they may represent two completely different systems unrelated to each other. Okay, create a counter example yes so create a counter example and the second one would be on the correlation if two if something exhibits two variables exhibit no correlation whatsoever therefore can you conclude in your data that there is no relationship between them uh i think no and what the square plus y square equal to one circle perfect example right that is an example where the correlation would be, if you take the whole circle, all the points in the circle, but there is a relationship. There are many, anytime there's, see, a presence of a correlation, presence of correlation implies relationship, correlation implies relationship. But the converse of this is not true. And this is something you should always remember that absence of correlation does not imply absence of relationship. So take anything, any function you take that sort of turns back onto itself. For example, a sine wave. If your data is like this, just visually inspecting it you can tell that there is a there is a relationship but if you were to observe the correlate the correlation here between x and y you will end up with zero right so the con remember this this is a very important thing to remember absence of correlation is not evidence of absence of a relationship right this is an important point please please bear this in mind now comes the question of the data sets what about what about data having the same statistic it turned out that this is a question that used to lead to a lot of debate and so in a way there were there were statisticians who would argue either way many people believed that for example you know there is no need to visualize the data it just creates pretty plots or maybe intuitive. You can explain it to laymen. But for mathematicians who are well-trained mathematicians, it is the descriptive statistics that is sufficient to ensure or to say all that needs to be said about the data. So you don't have, you know, it is sufficient, essentially. While this was going on, a great statistician showed something very beautiful. And I want to show that. Let me see where it is in my notebooks one of the notebooks that i have speaks to that point oh this is just the data would you please give me a moment to pull that up all right All right. A statistician, a data scientist named Francis Escombe. He, and I'll just read this out because this is crucial, what I wrote here. It used to be a prevalent belief that data is sufficiently well described with descriptive statistics. The visualization of data was often trivialized as mere eye candy that does little to further the understanding. The datasets we explore below provide a cautionary tale against such a belief. They show the power of data visualization and the insufficiency of mere statistical description. This is an important thing. So what he did is he created the, the X is fixed, but Y values, he created four set of Y values, right? Y one, Y two, Y three, right? And in the fourth one, he changed the X also. And then he said, look at the descriptive statistics of these four data sets. When you do that, this is a little bit of a basic code. You create a data frame, you ask for its statistics, and you plot it out. So you will observe. And by the way, we'll walk over the code in the lab part, but today, just observe. You notice these four data sets, their mean, their standard deviation of x, of y, the means, the correlations, the intercept, the slope. And r-squared is something I'll tell you about in sum squared error. It means if you plot a straight line and we talked about the sum squared error for the best fit line, do you notice that they all agree? So many statistics all agree. Even the best fit line agrees. It's the same best fit line to them. So one would be led to believe that you're talking about data that is essentially the same. Points may differ, but they're speaking to the same reality. But when you visualize this data, you'll be in for a surprise. See what it comes out to be. Are we able to see this data on your screen? Dataset one, two, three yes very different you're very different they're entirely different data sets they're not just small variations of the same they're describing different realities they're if they are samples they're sampled from different realities and so therefore the observation that you should never just trust statistics, use visualization, right? As much as possible, even if data comes in high dimension, find some way to visualize it by taking sections, doing something, doing dimensionality reduction, and we'll learn powerful techniques of data visualization. So in fact, I do give a workshop on purely on data visualization, where we focus a lot on powerful and beautiful evocative data visualization. If any one of you are interested, you can let us, one of us know, me or the teaching assistants, and we'll do that. So if you now start looking at, well, anyway, there is another dataset that's even more remarkable. This dataset is made up of 13 datasets. All of those datasets have, let me show you, again, pretty much the same statistical properties. And yet when you visualize the data, the first dataset is, what does it look like to you? A dino, right? A dinosaur. And this is the first dataset. And what do the other datasets look like? Do they look anything like a dinosaur here? Nope, nothing like a dinosaur. Nothing like it. And so, and therefore the lesson that dinosaur is here? Nope, nothing like a dinosaur. Nothing like it. And so and therefore, the lesson that never trust only computed statistics, it is not enough. It's never enough. And so with that, I will end our journey into statistics. I'll revert back now to machine learning. So while we go, actually, now would be a good time for us to take a 10-minute break, a proper 10-minute break, but no more than 10 minutes, guys. By my watch, it is 8.09. Should we please get back here by 8.20? Sure. Would you like me to pause the recording? Yes, let's pause it. So we are going to do a project for now, the first machine learning project. We will start by gathering data. It's a simple project, but please do it. It's a simple project, but please do it. It will give you a sense of the entire machine learning. Pick two species of trees. Go to those trees and underneath you'll find leaves. Pick at least 50 leaves from the tree, hopefully more. Now each leaf do three things measure its length, measure its width, and then take a picture of that leaf. So you will end up with let's say that you picked up 100 samples of one leaf, 100 samples of the other leaf or a smaller amount, then you would end up with 100 heights, 100 images of the leaf. So the first part of the project now is you'll build a regression model to predict the width of the leaf in terms of the length of the leaf. That is, you will use the length to predict the width of the leaf. And then you'll do a complete notebook, as we will illustrate on Saturday morning, a systematic way of doing it, in which you'll do the descriptive statistics, you'll do the data visualization, you'll build a model, and so forth. You'll do all of that and later on to later part of this course you will take that image and use that image to classify the leaf as belonging to one species of tree versus another species of tree. So for example, is it a oak tree leaf or is it a weeping willow leaf? And can you use a machine learning model to tell which species of tree it comes to? And that is what we'll do in ML 100. Of course, some of you are aware that in a much later course when we do computer vision, we will do a much more involved version of it. Great. So that is your project. Take your project seriously. And we also do Sunday reading, Sunday evening. I haven't done it for the last couple of weeks. I've been very busy. But I do intend paper reading that paper is one of the classic papers in regret i'll announce that paper in a little bit so i would say that the more you stay engaged the more you participate in more things like theory the project the quizzes the paper reading sessions and the more you engage with the teaching faculty to understand things, to get clarification and help, the better your learning would be. It sort of goes without saying that engagement is a strong predictor of the amount of learning. So the project will be released on Sunday or Saturday during the lab? Oh, project, I would like to release it tonight itself. Tonight or before morning, I'll release the project. I've written it out. I'll release it tonight. So it will be on the class portal and I'll also put it on Zoom so you guys can get a head start. But this is the description of the project gather leaves measure the leaves and and those of you who don't like i'm told that nowadays even an iphone could measure the length and width of thing so you can use to use that to do it if you did but do create your own data and then it would be a pleasure for you to do your first data science project with it building a prediction model right all right so now i will move to new territory let's get back to regression regression. Regression, just to recap, in machine learning does not have a negative connotation. It actually stands for a model that emits out a prediction remember predictions are y hat that belong to either r a number in simple numbers a number by the way numbers are real numbers as mathematicians call it the r this is called a blackboard r it is a r with the unnecessary extra bar right it is a symbol for number in real numbers in mathematics right so it could be r or more generally it could be a vector in k dimensional space right so it could be like a two three seven x is equal to two y is equal to et cetera et cetera x one x two so it could be a vector but generally in in the whole course that we do we will limit ourselves to just a number for now. And input must be numbers. So you have x1, x2. These are called predictors, if you remember. These are things, for example, for the leaf, this is the length of the leaf, right? And that is it. There's no other predictor. And we are saying, predict the width of the leaf so when you predict the width of the leaf because you know the answer you will know how much mistakes were made so let's now do the whole process more carefully you take a data set you divide the data set into two data sets train training data and a data set which is for testing. Why do you do that? Remember what I said, you don't want to show the whole data to the model. The model is like children. For example, if children go and see cows and ducks in a field and you ask an animal, is it a cow or duck? How do you know that the child understands what a cow is or what a duck is? The child may just have photographic memory and may remember that, yes, that thing was identified as cow, so I remember it. So that is not learning. What you want the child to develop is to a generalization beyond just the instances the child saw, right? Comprehend the notion of what is the cowness of a cow in some sense, or the duckiness of a duck, to use a word, the concept of a cow or duck must form in the child's mind correctly. And then you say that the child has learned. So one way of doing that would be to show the child cows and ducks in one section of the meadow then move over to another section of the meadow and show the child cows and ducks that the child has not seen and ask what is this now what is this and if the child is right you feel good if the child is wrong you then tabulate how often it is wrong and so forth. So what you do, first thing you do is split the data into the train and test set, which means both the input data, X train, input data is often represented as with an X, and output data is often represented with a little y and this convention be familiar with is in this literature you'll often see people say input so suppose you're looking at a giraffe and you have the height and weight of a giraffe and you have to predict the age so let's take this we will call a machine age predictor. You enter, sorry, height of the giraffe, x1, x2 would be the weight of the giraffe. And what you're trying to predict, y hat, is actually the age of the giraffe. Now, I don't know how accurate this model would be, but it should be fairly accurate when the giraffes are growing up. So what you see is that x1, x2 are a vector, are the vector x. Right? X is this. And when you take a specific instance of the vector, of course, the first data point, the second data point, and so on and so forth. But x, the input is always a vector. It's always represented with a capital X. And when we do the lab, you notice that it's a convention we follow. In data science, we follow a lot of convention during programming. We don't name our variable anything we want. There are certain well-established conventions and we follow those conventions. We call our input data with a capital X and the output data, remember, this is the output, real output, actual output. It is always written with a small case case y the prediction wears a hat that's how we know it's prediction and notice that we are using all Roman letters. Whenever you see a Greek letters like, for example, beta naught, beta one, etc. You can rest assured that these are these are the parameters of the model. Parameters of the model. Of the models, right, for example, this. Or in other words, artifacts of your, parts of your hypothesis, of your hypothesis. So we'll follow this convention throughout this workshop. Just to be clear, so if you see anything Greek, well, it's part of your hypothesis or parameters of your model. If it is Roman, then you're talking either of data or some real prediction real data or some prediction now coming back to this question of let's take one variable at this moment again let's get back to the simpler we'll come back to giraffes after a bit let's get back to our entrepreneur for a moment temperature was the only variable we took X one, let me call it or rather just X and why was your target variable and you had some data that went like this. You try to fit a model. One model and you had another model and you, so the part that I won't repeat, but I will summarize what we did, is that the total error of this is equal to the sum squared. We took the case of a sum squared as a measure, or the average mean squared. Doesn't matter whether you put the average or not. Then for each point, this is y minus y hat. It's the gap between the reality and the prediction. And you can either take absolute value or square it. I'll just square it because the sum squared error is the most common error method, right? Now, for reasons that will become clear to you later on, actually let me just continue to use E. Now what do we need to do? We need to minimize, we need to find what? Each line has a slope and an intercept. Isn't it? Slope, sorry, this is the, beta naught is the slope. And this is the intercept. Now, if you remember in high school language, you would say mx plus, I don't know, c. So beta naught is your c and beta one is your m1. There's nothing fancy here. It's just that data science or machine learning people tend to use Greek letters. They don't like to mix up the data with the parameters m and c intercepts should be greek so we have that and if you were to plug it into this equation it would become i y i minus what is y hat prediction the prediction of your model is y hat is equal to beta naught plus beta one x. This is the equation of your line. So you plug that in, xi squared, and you will realize that if the data is fixed during training, the only thing that you can play with, the only knobs that you can play with, the only knobs that you can turn, dial in is beta naught beta one. In other words, going back to our picture, you can wander around the beta naught beta one, this hypothesis space. You can go to different points in the hypothesis space. And for each point, there would be an error function. And because it's a quadratic function, has to be positive and just as a recap this would have the shape of a bowl right with a best minima so there will be a beta star which which will be beta naught star beta one star this will represent the point at which the error is minimum. Amen. So you often say that what are you searching for? What is the learning process? You say that you're learning, you're searching for the beta star. Beta star. Learning is the search for beta star and not just search but to find beta star and and this beta star's definition is you say that it is the arc min and i'll write it in the technical jargon that people write in case you see it argument beta naught beta one where for the error right so you realize that error is a function of beta naught beta one So you realize that error is a function of beta naught beta 1. So you find that beta star, which minimizes this value of the error function. Common sense, right? It's just a fancy way of writing it. If you want to write it in a vector notation, you may even say beta star is arg min beta vector for e, which is a function of the beta vector. That's a error function. And this is essentially regression with a straight line. But a straight line may not be your only hypothesis. It may be a curve. It may be something else. We'll come to that later. But for now, we'll stick to a straight line. Now, this can be generalized from one variable to multiple variables, x2. For example, if you go to the giraffe now, the height and weight of the giraffe predicting the age, everything remains the same, right? The only thing that will change is in the case of a giraffe, your hypothesis would be the way the age of a giraffe is beta naught plus beta one times x1 plus beta 2 x2 where this may be the weight this may be the height there are two predictors now x1 x2 and you're using that you're creating a plane now this is a plane equation of a plane and you can generalize from that to higher dimensional data, more variables of the data in which you say that linear regression. And we are using the word linear because they are like line or plane. is the search for the optimal hyperplane. Whenever these words hyperplane come in, you can always simplify to, in your imagination, two dimensions, and it becomes a line, right? So I'll give you a little bit of a background. At one point in my life, I found myself. You know, you wake up one day and you notice that, oh, you are doing graduate school studies in theoretical physics. So theoretical physics is a subject in which people as a habit talk of infinite dimensional spaces. So it turns out that these are the so-called Hilbert spaces and a very interesting world. And it turns out that these realities that we describe, these wave functions, which are underlying electrons and so on and so forth, and these wave functions, they live in infinite dimension. And for the longest time, I used to to think how do i visualize infinite dimension and then i would see these people doing relativity and they would glibly be talking about four dimensions and then you would see string theories out there and they would be super string theories and they would be talking in 11 dimensions and in the beginning i was absolutely lost, how in the world do you imagine in high dimensional space? So finally, I figured out a trick. Whenever people would speak in high dimensions, in my mind, I would reduce the problem to two or three dimensions where I could visualize it. I would think of a result and then I would generalize it. I would ask, is there any reason this result will not hold true in higher dimension? So keep your visualization to real experience where your intuition is. And once you have thought through it, then even though you're seeing in your mind in two dimensions or three dimensions, you can also glibly not talk that as is obvious in 11 dimensions, right? Of course, it's not obvious because nobody can see 11 dimension but it is mathematically obvious right and similarly for infinite dimension spaces and so forth so it turns out that there's a small caveats uh one of the hardest dimensions to deal with is four for a variety of reasons beyond four uh problems get harder up to four dimensions but beyond four there's just too many dimensions and problems actually simplify themselves. So a lot of knots, they sort of unravel themselves in higher dimensions. So there's a lot going on with dimensionality. And today in machine learning, one of the very active areas of research is higher dimensional analysis. It's all getting very fascinated. And so I look forward to the day in which a data scientist will be walking around also saying, as is obvious in infinite dimensions or something like that. I will hope, let's see when that day comes. But anyway, this is it. So keep your intuition simple. Do not be intimidated when you see people talk of hyperplanes and so forth. Reduce it in your mind to a line or a plane, something that you can visualize. But now let's come to the rest of the matter. Given this, you can quantify the error. What was the error? This was the error. Now, how good is your model is a question. You would still be left with some total error, even at the best beta star, there will be an error associated with beta star, isn't it? And that is the minimum error. Which error is that? Where is that error of ours? We drew it somewhere. Oh yeah, look at this bowl. When you have this bowl and you have this, you realize that this error cannot be removed. Why can it not be removed, guys? Would someone like to volunteer an answer? We talked about it earlier today. What does that error represent? That minimal error that remains even when you have the best solution. You have discovered the best line through the data. Both measurement error and factors you haven't accounted for. errors, measurement errors, random effects and things like that, as well as genuine effects, genuine causative factors for the response variable that you did not take into consideration. Right? So that is it. That is one factor. So for example, if you were to plot the age of children with respect to, or maybe let's go back to our ice cream. You know that in reality, there is a band gap. Based on the day of the year, this band on a given same temperature, temperature Ti, X is equal to some temperature. And the amount of ice cream you sell has a band. This band represents such factors as, is it too windy? Windy, weekend or not, holiday or not, et cetera, holiday or not, things like that. There are many factors that this represents. Perhaps it even represents the economy, right? When the economy is doing well, a lot of people feel confident, they're having fun. When the economy is tight, people are scared, they don't want to spend. So it represents all sorts of factors that you haven't accounted for. And that even remains. But then here comes a question. Gradient descent is a method to go there. But suppose you were to forget it. How would you justify that this line, this red line is better than, let us say, another hypothesis like this or and better than another hypothesis like this? Right. You would say that the red one has the least error, isn't it? But there is actually a special hypothesis which we look at and we always ask, how good is your model compared to the error of that hypothesis? That hypothesis is called the null hypothesis. The null hypothesis says something quite interesting. Null hypothesis says there exists no relationship between output or response, or all fancy words for saying why and inputs input features right so for example i'll give you an example you have data the data is how many penguins today penguins today jumped off a glacier into the sea, right? And you have that value in Antarctica for, let's say, a year's worth of data. And then you also happen to have the precise time in the morning that you woke up. That's your target variable. Now, do you think the time that you wake up, so suppose you wake up at 7 a.m. and assuming that you don't have an alarm clock, a plus minus half an hour, one hour. Some days you wake up at six, some days you wake up at eight or nine on Sundays, right? So you know the exact time. Now, do you really think that when you wake up is being influenced by how many of the penguins decide to jump off the glacier into the sea on that given day? That given morning? Common sense says that there is a relationship or not? No. There wouldn there is a relationship or not? No. There wouldn't be a relationship. But how would you know what you have been given? A machine is given data as input, output. And you're supposed to build a model, y, as some function. Some function need not just be linear. Some function of x. So the first question to ask is, what about the fact that there is no such f? There is no f that describes this coherently, right? And the two are completely unrelated. If the two are completely unrelated, right, what you're basically saying is, suppose a data is like this. What is the best prediction that you can make? This is the number of penguins that are jumping off and you have lots of data, and we ask you, when will you wake up? Would it be common of what value there is of x just make this prediction every single time that would be common sense right because that would be the least strong otherwise if you if you were to draw a line here then you would get huge errors and the square of those errors will be big also if you do this there'll be a lot of points below that you want to have the coin go straight to the data and that will go through when your prediction is the average y that is the null hypothesis it says there is no relationship if you're looking into some linear language like if you say y is equal to So linear language, like if you say y is equal to x, you're saying beta 1 is equal to 0. This is the only relationship that you can have. And the only meaningful beta naught that you can have is actually beta naught has to be the average of y. So I need a symbol. I don't want to put bar because I use bar for, I'll just put angle bracket to say it is average. So angle in my world means average. Make sense for now? Average. So y is y average, right? So beta naught is y average. This is null hypothesis. Now this hypothesis will make some mistakes. The error of the null hypothesis, it is called the of the null hypothesis. Null hypothesis is also written, null hypothesis, people sometimes write it as this. The same symbol that you use in set theory for a null set. So this is the null hypothesis. You can compute the sum squared error. And now what can you do? Suppose you build a model, a really good model that you're proud of. You can take the model. Let me take this a little bit bolder. Let's say you have a model. How many, what colors did I use for the model blue red and green so green was the null hypothesis and okay it doesn't matter i'll use different colors uh e model one of a particular model whatever it is total the error sum squared error total the error sum squared error error of of your model y hat is equal to beta naught plus beta 1x so you actually have a genuine line let's say that you are claiming this is the relationship so you will get with this now you know that null hypothesis could be true or your line could be true but both of them cannot be the better answer one has to be better than the other isn't it am i making sense guys and if your data is truly like this, and this is uh does it make sense so how much better or how much less it is compared to the null hypothesis is a measure. People have created a number. They say that you do this just to make it dimensionless. Again, R is equal to, there's a name for it. We'll go to the name. For historic reasons, it's called R squared. And the formal name is coefficient of determination. It's a coefficient. It tells you, determines how much better your model is compared to the null hypothesis. So you say E5 minus EM. Now, if this number is greater than zero, it's an improvement. How much is the improvement over the null hypothesis as a proportion of the null hypothesis error? Now, in your textbook, let me just align it to the textbook. In your textbook, this is written as RSS, residual sum squared. This is written as TSS, and this is again written as TSS. So I'm just aligning it to the notation of your book. But I like to use E as a symbol for error. So this is it. So what it means is, suppose your E total is something. And E m, suppose the model is perfect. And there is no error. suppose error of the model is equal to zero right let's case case one e phi will be equal to whatever it is so then what will be the r squared r squared would be e phi minus 0 over e phi and that will be equal to one one so you have a model that is giving you a coefficient of determination of one now should you be elated if you see one or should you start worrying uh you should probably start worrying because that might mean that the model is overfitting. Excellent. So what happens is this the only predictor so there is no other explanation or effective factors this x is the only factor that causes this right then you get r square one so for example i'll give you one easy example where r squared will be one is suppose i give you the weight of the same giraffe in pounds x is weight in pounds and y is the weight in ton metric tons now what will happen common sense says that y is just some multiplicative factor times x, isn't it? It is just some factor times x, right? Some fraction of x. So in this particular case, because you have different gauges, your gauge is different. Once you are measuring it with pounds and another time you are measuring measuring it with tons what do you expect your r square to be of the model this is truly all your data points will line up exactly as the poundage increases the metric turns will increase and you will have a situation like this. So then you have to ask yourself that if truly a straight line describes it, are we even learning anything? Or are we just looking at the input from a different perspective or using a different gauge in some sense? So you shouldn't. In reality, what would happen is, this is reality. So what will happen is, if, let us say that you have less errors, your r squared will be less than one. Now I'll pose you a question. Can r squared be zero? Can r squared be zero? Can R square be zero? And look at this example. If you were to find the best fit line, what will your blue line look like? Your blue line will look like? The blue line will look exactly like the green line, isn't it? Does that make sense? Any good machine learning model should come to the same conclusion that there is no relationship between input and output. Are we together, guys? Yeah. When genuinely there is no relationship, your model should come to the conclusion that there is no relationship. In other words, in this particular case, E of the model should be more or less equal to E of the null hypothesis. Because null hypothesis is true. And your learning should take you from a wrong hypothesis to the null hypothesis. In that particular case what will your r square be r squared would be e of the null hypothesis minus e of of your model divided by e phi but then e of your model is equal to e of the null hypothesis so this answer would be e phi minus e phi there's no gap over e phi and that's equal to zero so it happens when your hypothesis is true this is true and by the way does it happen in real life very much it happens uh in fact in in the company that day job that i'm working for there was a situation many years ago in which we were trying to predict whether asking a certain question to a set of questions to applicants for a job, call center job, how determinative they were in predicting whether or how long those employees will continue to work in the company. So people leave. Could you predict how long they'll stay in the company before they leave? So people leave. Could you predict how long they'll stay in the company before they leave? And there was a belief that it could. One of our work was to show that actually the R-square is zero. There is no relationship. Those questions were not good predictors of how long employees would eventually stay in the company. field called industrial and organizational psychology and psychometry that tries to devise these questionnaires to predict certain things, right? And in this particular case, the questionnaire happened to be wrong. It wasn't effective, right? So R-square can be zero. But now let's take another situation can r square be negative when things go wrong yes look look back at this situation if the null hypothesis is true right what is likely to happen to a hypothesis like this Right? What is likely to happen to a hypothesis like this? This, look at this line. Actually, I should use a different color. Let me use, which color should I use? Maybe I'll use this in big bold, this color. What about this hypothesis? You're claiming that this is the relationship. Is it obvious that for this hypothesis, you will get far bigger errors than the null hypothesis isn't it so you will end up with a situation where em is error of your model is greater than the null hypothesis and so your r squared can actually be negative you don't usually see that but sometimes when you're trying to be fancy and the computer emits out an R-squared that is negative, that is quite a wake up call that you're absolutely barking up the wrong tree. You're absolutely wrong. So it can happen. So R square is there. This is an important thing to remember. Now what I would do, I would again give you guys a seven minute break, maybe 10 minutes, nine minutes break, then we'll go into a few more things about regression. So we'll go beyond just a small line or a plane, and we will expand our understanding to a bit more complicated situations. Let's take any questions before we do the break. Is this all clear, guys? Are we understanding it? This is model diagnostics. How to determine, are we trying to determine how good is the model. Right? Questions, guys? Any questions? Yeah, I have a question. Can you scroll up where you have this abstract space with two parameters, X1? Beta naught, beta one. Yes. Yeah, but there are two of them uh x1 x yeah so here right yeah the giraffe thing that you circle this yes so what happens to the hypothesis plane very good question how how will it look because it has two variables now yeah not one so remember what did i tell you when thinking of so this is a three-dimensional plane. The so-called plane is a hyperplane now. The hypothesis hyperplane, right? And so mathematicians will glibly say, okay, there is beta three, beta two, beta not, beta one, beta two. imagine that this plane is a three-dimensional plane you say well three-dimensional planes are volumes i said no no no think of it as a three-dimensional plane and the error surface rises out of it right now i mean that i can imagine what what i'm having trouble imagining is that the parabola the bowl up above that plane how will that look yeah yeah it won't look the same right because yeah it will look the same why because mathematically this quantity even if you do y i minus beta naught minus beta one x one i uh x one right i minus beta two x two i the square of this is still a quadratic function right and quadratic functions greater than zero quadratic function and so it's guaranteed to still look like a hyperboloid in a higher dimension yeah so how do you visualize that hyperbola in oh how do you visualize my way of visualizing is i always think of the the plane the hypothesis plane as two-dimensional and even when data comes to me in hundred dimensions mental picture that i have is in two dimensions and i think of it as literally my nice brass bowl at a surface hanging hanging in the air above it. That's my visualization. Okay. So I used to have a ritual, by the way. This bowl comes from my hometown, Benares, what I see, and made by artisans for thousands of years. And so, well, we don't do it now because you guys are all remote, but I'll do this ritual for once. What we would do is we would announce the end of the break using... Can you hear it? Or is that a- It wasn't as loud as usual. Yeah, I mean, I deliberately didn't hit it too hard. Oh, that's nice of you. It's very really makes you alert. Yes. So we use this to draw people back from the break room. And here. Alright guys, so we'll gather together in a few minutes. Drink your water, have your snacks. All right, folks, I'll repeat. We have created a model that predicts a linear relationship between input and output. When we have just one variable, it's easy to imagine it's a straight line. It's the simplest hypothesis that you can build beyond the null hypothesis. But can you think of situations where the linear hypothesis itself is entirely wrong? In other words, there is no line that describes the data and yet there is null hypothesis is not true in the sense that um you know there is a relationship between input and output it just so happens that it is not a line circle parabola polynomial like x square like x cube or something right there many situations i was thinking in terms of real situations but yes go ahead raj yeah i was thinking there could be more than one variable that is true and so yeah it could be a hyperplane so i'll give you a few examples. First, let's go back to our example of the young entrepreneur on the beach. This is the temperature. This is the amount of ice cream. And so you have a relationship like that and it looks linear. But guess what will happen after a little bit? Temperature gets too high. It will start plateauing off because and then it will start turning down. Isn't it? If it gets too hot on the beach to be comfortable, then what will happen? Your ice cream sale will start dipping. People will start leaving the beach. Or maybe it's too windy, too stormy, many other factors. But anyway, since we're just looking at temperature. So now what do you think of the relationship? Is it linear? It isn't linear. And so if you try to build a straight line, the best line that you would be able to build will be over the entire region. If you were to build a line, you realize that the globally best line would be this. And yet you know that if the entrepreneur were to follow this line, most of the time, he would not have enough ice creams. And sometimes he'll have too much ice cream. Right? Am I making sense, guys? Yes. But what you would like to have is for our entrepreneur to build a model that is faithful to the data that looks like this a better model isn't it this model now the question is how do you build such a model is how do you build such a model? Now, and to build such a model, we will now start taking baby steps. First question is, can we still use linear, a line, or a hyperplane? It is quite interesting, actually. This is x and this is y. And the way you do that is you say suppose i have x and i have to predict y in between suppose i take x square also as a predictor the same same x but i take the square of x as a predictor so what have i done instead of a one dimensional predictor two dimensions i've just expanded the feature space i I'm saying input is two-dimensional, made up of x and x squared. And now I'm going to fit a plane, supposedly, through that data. So this is a plane x, x squared. Think of this as x1 is equal to, the first variable is this, x1 is equal to the first variable is this, second variable is this, and you are looking at x1, x2 plane and y. So the relationship now you imagine is a linear plane, y is equal to beta naught plus beta 1 x plus beta x1, beta 2 x2, which is the same as beta naught plus beta 1 x plus beta 2 x square now you say why would that work well it goes back to the theorem of algebra so i'll tell you a trick uh it's a pretty useful neat trick it it follows from the fundamental theorem of algebra but uh but without going into that i'll just tell you whenever you get data count the number of bends so a straight line how many bends does a straight line have zero so here's a remarkable insight. I wish these things were mentioned in books, but I use it quite a lot. Bends and degree. I'll use the word degree. Now, degree is when you write y is equal to beta naught plus beta one. What is the highest degree of power of x? One. It is x to the power one. When the bend is zero degree is one in a parabola to represent a parabola what do you need you need something but ultimately there will be a there has to be an x squared term isn't it you need something like beta naught plus beta one x plus beta two x plus beta 2x squared. That is the equation of a parabola, isn't it? Yeah. Right? How many bends does a parabola have? One. One. When there are one bend, you need degree two. Now, how many bends does this line have? Two. Two. And you can convince yourself that the minimum number of polynomials that you need to represent it is three. Polynomial of degree three. Do you see a pattern here, guys? Yeah, bend plus one. Yes. Bend plus one. Degree is bend plus one yes bend plus one degree is bend plus one so what you can do and that is why i use this i saw one bend and i went to the highest degree of polynomial that i used is x square so this is called the term that we use is you expand the feature space in the language. Expand the feature space input or feature space through polynomials. I hope I get my spelling right. polynomials. I hope I get my spelling right. Poly, no, polynomials, right? So what you do is you can say, oh, y is equal to beta naught plus beta 1x plus beta 2x squared. And I'm still staying with one variable. But of course, if you take height and weight also, then it gets more interesting. X cubed plus and so forth. A beta. And let's stick to only one variable for the time being, Xn. So you realize that if I have a curve that goes like this. One, two, three, four. Four bends. You should take a polynomial of degree. Five. Degree. Minimum five. And you can take any more than that. But what happens if you take a polynomial of degree 10? What will happen is your hypothesis needs to bend at least nine times. Right? So let me just write it this way. Degree 10. What happens then? What will happen is, using again the fundamental theorem, it will try to create a line that has at least 10 degrees. So it may do... It may artificially start imagining bends right so now look at this and now let's go back to our degree one one which is that of a straight line. And let's go straight line. Now look at the three models, the degree one model, which is a straight line, the degree of five model, which is the green line, and the degree 10 model, which is bouncing around. Which of the three models would you prefer to be the best predictor in your view degree five degree five so it's sort of the goldilocks region right at degree one your model is too inflexible it just doesn't it's not willing to bend at all isn't it it's very inflexible at degree 10 it's too flexible isn't it it has almost become like a thread you can bend it any number of times that you want like almost like it has too many bends so there is an optimal degree of polynomial that best represents your data a model with that degree would best. So this is an example of something called a bias variance trade-off. Fancy name, a bias variance trade-off. What happens is when you create a model that is too flexible, you will have systemic bias errors. A bias error means that generally your model will, the average of your predictions will be off the average of the data. You'll have a lot of bias there in the data then generally it will tend to be off on the other hand if you have this a very flexible model do you see how big the sorry let me do it with the red color because i use red here so do you notice that for all these data points oh i should use green how much the error is how much it is bouncing around Oh, I should use green. How much the error is, how much it is bouncing around? Right? The errors are pretty large. So remember, variance is variance. It's a square of standard deviation. What will you notice in such situation? The errors are bigger, more values, right? Some errors will be small, but the range of values will be more. Are you getting that? So imagine that you have data like this and you have a curve that goes like Do you see how big the errors are? Error values are? And the squares will also be bigger, of course. So what will you get? Your errors show a huge variance, isn't it? Some errors are small. Some errors are big. They show a much bigger variance. So what happens is less, let me put it this way, less flexible model and less complex model. And this is a more complex model. More flexible or more complex model. Complex, why? Because it's a higher degree polynomial, isn't it? Are we together? So what happens is in the beginning, if your model, so there is a ground truth. The ground truth tells that green line is the best line, but you don't know. So what will you do? You will start with model of degree one, degree two, degree three, degree four, and you'll keep on going how do you know when to stop what if the optimal model is degree 400 you need some way to stop and say okay let's do that and the way is this the way it works is quite beautiful actually when you plot out the bias errors and the variance errors and there is a mathematical expression. I will write it down. The total error is made up of three parts bias and simply because of mathematical notation reasons to make it the same thing you put a square there then it is in the same units. Plus, variance errors. The variance error is the bouncing. How much? The actual hypothesis is bouncing around the data rather than adhering close to the data. Error. Variance error. And people often shorten shorten so I won't write variance error, let me just say var you'll often see this notation var plus oh our familiar epsilon, what do you think this is. Irreducible error. Vaidhyanathan Ramamurthy, The irreducible error. Vaidhyanathan Ramamurthy, So irreducible error doesn't go. But in any model, total error of a model, right, is some. Now, these two errors you can play around with by dialing in the complexity of the model, making it less complex, less flexible, more complex, or more flexible. You're dialing it in. When the model is simple you have and this plot is beautiful actually if you plot and so let's say that this axis is complexity and i'm generalizing it in our particular case of polynomial is the degree of the polynomial right what will happen is you'll see something interesting the bias error will start out at n is equal to one or whatever it is from a maximum value it will go like this the more flexible you make it the less bias error you'll see the variance error will be like this for in the beginning obviously you'll have very low variance errors so this will go like this and it will keep on going up and this bias error will keep on going down but when you look at the total error the total error which is the sum of these two, it will go like this. So what does it mean? If you keep on 1, degree 2, degree 3, and this was degree 5, degree, let's say somewhere in here is degree 10. So what happens when you reach 5, you notice that your error is decreasing, total error. But once you start going to six seven eight what happens to your total error it starts shooting up right so once you have evidence that your total error is not decreasing but increasing as you dial up the complexity of the model then you can stop you can say enough now i'm sure that complex I'm getting, I've made my model too complex. I need to stop. And then you go back and look at the table of your errors for each level of complexity. And you say, aha, this is the model I want. This is my Goldilocks. So Asif, why is the variance, you don't have a square there and you have only the square for the bias variance or is is the standard deviation square already okay you know variance is built in okay thank you it's just a notational thing it just so happens that you describe bias as the deviation from the mean variance is the square of the deviations from the uh from the mean right so and uh one more question so you know you earlier you showed x2 is equal to x1 square yes how did you how how does how did you get that i mean is that a mathematical thing no no you just suppose have temperature data right suppose you have temperature data and ice cream how much ice cream you sell temperature is your x ice cream is your y and you realize that to uh to make this ice cream data has a bend now look here it has a bend one. So what you would do is you would expand this into another table, temp, which is your x. This is the temp square, that is the x square value, the same x. So suppose this was 16 degrees centigrade, then you would make it 256 degrees centigrade, okay this is your y as simple as that okay thank you right and you would build a model then you would predict the y hat from the model and then the error would be y minus y hat you know these two difference between these two columns and then you can square the error and then finally you can sum up the square of the errors. This will be a total error. As simple as that. It's just a table. I have a question. Can you scroll up just a little bit? Sure. Yeah, right there. Why do you have that beta zero, beta one, beta two, all that that even when you have let's say two bends and you have a degree 3 no throw away the the earlier because no you can't because if you throw away so it's a good question why do i not just keep the highest degree polynomial let's take it suppose you take the highest degree polynomial y is equal to something beta 3 x cube you know what that function will look it will look like like a sigma yeah this but that does not universally represent reality isn't it that is why you need other it has certainly two bands but you don't your data doesn't go through the uh go through the origin so you can't throw away the lower order terms the lower order includes a straight line and everything yes yes yes what you are basically saying is that a higher degree point norm is the shape is influenced by linear quadratic and other factors. That happens. For example, have you noticed that when you have a car, the mileage is inversely proportional to the number of cylinders it has and the size of your engine yeah right and the more fun car you have unfortunately the worse the mileage yeah yeah so it's an inverse relationship and when you work it i will do it actually let me not reveal the secrets because this is one of the lab exercises we'll do you'll see something very interesting right right i mean my doubt is when the ice cream sales are curved right here why do you need a straight line now now we know that they are curved yeah so what you are saying in the language that i would use see do you notice that this started out like this and this is this if you were to think of it as a perfect parabola like this right so so imagine a parabola like this uh this one let me erase this one now from this this is this parabola actually why am i using the same color let me use this color this parabola is y is equal to something a negative number times x square let's say minus minus x square i'm taking an example now do an optimal transport of this shape to this shape how would you do that you realize that first you have to lift it up right you need to lift the red one to at least this height you have to go from the red one to this height what will that do that will introduce a beta naught term because you need an intercept you will also have to move this align it here right you'll have to move it to you have to move it to this point right so you'll have to bring a shift to bring a shift means you're doing x minus x naught like you're adding a little and you're doing quadratic term of that now look at what you're doing the moment you do this what have have you introduced? When you expand this out, because it is off center, it's not around the origin, you have introduced an x order term, isn't it? When you expand this out, it will become beta naught plus x squared plus x naught squared plus 2x naught x, you introduce a x order term. So whenever you look at a curve, which is not perfectly centered and balanced, what the off centeredness and the balance, that geometric fact algebraically represents itself as you just saw as lower order terms. Right, but in this equation that you wrote just saw as lower order terms. Right. But in this equation that you wrote, there is no beta 1. Oh, I just took. OK, so let's say that. Suppose I took minus 1 here. Right. Let us say that I made it beta 2. Right. Now write this equation. Yeah. OK. Got it. Yeah. You'll start seeing that effectively. This is your beta 1, 2x0 two x naught beta one so terms pop out that's why that's why anything that is tilted and translated its algebraic representation comes from lower order terms compared to the completely centered and balanced shape for example in a second order thing it would be a parabola y is something x squared now you're shifting and tilting it okay thanks so uh if i have only one question so i agree to this benson degrees theory only if the coefficients are what you have to say like one was negative other was positive then only we can create a bend let's say all the equations are positive all the equations are negative then this theory fails right that is true so this this goes back to the actually i didn't get into the mathematical too much it is the fundamental theorem of algebra it says that the the maximum number of roots distinct roots of a polynomial of degree n right will be roots are places where it intersects the x-axis the solution that uh the values right the number of sorry, where y is equal to zero, x-axis, right? The number will be the same as the highest degree polynomial. So when it is a straight line, think about it this way. When you have a straight line, any straight line will intersect the x-axis only once, right? Like now any parabola will intersect it at most two times it can intersect it only one time for example this parabola is intersecting only at the origin so it has only one root this has two solutions so and you know quadratic equations have how many solutions at most two right and then it's a generalization so this is actually one of the things, see, the unfortunate thing is that school education is so utterly mediocre in every country that things like this fundamental theorem of algebra, we probably were taught in high school who knows in school but we never were made to appreciate its value that when you can use it later on you see shapes and you can describe you know how to describe those shapes right now i will put a caveat here i said all this to describe to show you the the big message here is the bias variance trade-off right that you can build models of different complexities and try to find the optimal the machine learning will learn the best the best parameters for the model but the the complexity for example the degree of the polynomial here it is is a hyperparameter of the model. So let's introduce one more jargon today, a jargon of the day, hyperparameter. Hyperparameter. So n is the hyperparameter because the machine will not learn L. If you tell that I'm taking a quadratic equation, your gradient descent or the learning process will find the best parabola that it can fit to your data, isn't it, of square and so forth. But what it will not be able to do is tell you what is the right end. That you have to hunt around. So there is, and just to give you a taste of the state of the art, today we build a lot of models using a massive, these are massive neural networks. And can you guess in some of the modern machine learning models, how many parameters are there typically? Here we are dealing with two, three, four. What is the typical number of parameters in a modern machine learning model that you have to do gradient descent in? Kajalian. Yes, you have to be worth it. And Kate, you can't answer. You're in the ML4. Anyone? Make a guess, guys. How many parameters do you think exist in contemporary models? 20 or 15. 20 or 15. How would you feel if I told you that the latest models that are emerging, they are all in 1.2, 1.4 trillion parameters. So you are doing gradient descent, the same thing that he just saw, except that you're doing it in 1.3 trillion dimensional space. And if you think that is not possible, that is exactly what is making a lot of the modern world possible, the translations, language translations, and you know, this lovely images possible. So we are in a very interesting world in which this insanely complicated big models, they're able to do things that even one year ago, last year, even AI experts didn't think was possible. If it is any fun, in the lab, I'll show you some of those models. Saturday is going to be fun because all this theory that we learned, we are going to reify it. We're going to make it real. And then it will be a bit more fun and i will just give you a preview of where the state of the art in machine learning is and how insanely smart it has gotten recently there was a news that one particular model a google employee who is a machine learning expert he talked talked to the model, the model talked back with such good first simile of being a genuine human being that he wrote a blog saying that the AI has finally become conscious, it's finally become sentient. It's supposed to be the point of singularity in artificial intelligence, at point at which they'll be as like us and he wrote a blog saying it has become that Google was not pleased they put him first on suspension and the latest is he was fired right for his belief so yeah that's an interesting thing you probably just to give you a measure of how wonderful and complex models can be uh today alexa i'm told somewhere i read that alexa regularly receives 20 to 30 um uh what is it called engagement proposals every single day there are a lot of people who talk to Alexa and to, I suppose, Siri and Google Assistant, and these things talk back to them, and they ascribe philosophical wisdom, they ascribe empathy, they ascribe intelligence to these machines, to these AI models, to such an extent that they're sure that it cannot be a machine. People are just fooling you that it's a machine. There must really be a lady in the call center who is talking to you, but pretending to be a machine. And there's a real human being out there. They form pretty close relationships and they actually end up proposing to these machines. It's a reality right it also i suppose speaks to what our definition is of consciousness when do we think that something is sent sentient or conscious when do we ascribe what does it take for us to ascribe qualities like empathy like wisdom empathy like wisdom right like intelligence to these machines it's a very interesting world but now coming back to where we are i'll summarize this so you may say given this bias means trade-off given data see the data has a ground truth See, the data has a ground truth. Data is the consequence of some generative force, isn't it? So, for example, you have an apple falling from a tree. You have measured the velocity and you have measured how far it has fallen. And velocity can be written as a function of the distance from the tree. And somewhere in there is the wisdom that there's a gravitational acceleration happening. But it's a linear model because the velocity of that apple is the initial velocity which is zero the beta naught is zero plus beta one times distance that it has traveled x which in this case is the well i'll let you figure out the equation let me not do that elementary physics right the time let's say let say, change the distance to time actually, how many seconds it has been falling. Then it becomes simply that g times t, gravitational acceleration times the amount of seconds that it has been falling will be the final velocity. But suppose all you had is time that it has been falling and the velocity, you know that that this table this data that you got data set that you got behind it is a generative force you just don't know the force your goal is to approximate that force or create a model that pretty much makes prediction as good as the underlying reality which you don't know so suppose you start creating an equation in which you put multiple quadratic terms third order terms and so forth you have created a model that is way too complex in fact the there is a the well anyway this gets into physics i won't do that but one of the great physicists mathematical physicists v.i arnold he went so far as to say that the whole point of newton's second law was to define force right because force is nebulous acceleration is observable to say that force is proportional only to the acceleration mass and acceleration and not to any other term not to to the second derivative of you know time derivative of location not to the first derivative not to the third derivative those order terms are not there in its sheer Simplicity it has only a second order derivative term so this speaks to Raj what you're saying. Why not just that? And the sheer beauty of Newton's second law is that he's what VI Arnold says is that it helps you define what force is. Very interesting. But anyway, I'm just trying to connect these things, real life things to what you what you face is data, because what you'll face as data is data. There was some force behind it. There is an underlying truth. There's a certain complexity to the truth, the ground truth. You don't know. Your job is to discover it. And when you try to discover the truth, you build models of different complexity. And then you'll hit upon the model in this particular data set of complexity five. And that will give you the least total error. And now you can say that if I must model it by polynomials, it is this. And that brings me to the last question now. Can every reality, suppose, just think one dimension, right? Let's not go to higher dimensions, we'll generalize later. If there's one predictor one input variable and one response variable and i can visualize it it's some curve some data distribution and in my mind i can draw a curve is it true by counting the bends i can therefore pick a polynomial of appropriate degree and model it. And it will be perhaps the most effective model that I can build. Can every curve be represented with polynomials? In other words, best represented by. Because what happens is the moment you see the data distribution, in your mind's eye, in your imagination, you can draw a curve. If the data is on a graph paper, you'll immediately pick just as we did. You will take a color crayon and draw a curve through it. But the question is, what is the mathematical function that describes the curve? I just told you that one of the basic things you can do is count the bends and take a polynomial of appropriate degree. That's a minimum degree you need. You can increase beyond that and then see through hyperparameter tuning where your best, what's the Goldilocks value for that, right? What is the best value for that? Now, I'll pose a question. Polynomials are great. So I have a complex situation in one dimension. I can always use polynomial and we are done. Could there be a problem with this statement? Yes, power fitting. You cannot predict the next thing correctly. You will fit the existing line very much perfect. No, that's not the problem. Think about it guys. Think of the curves that you know and think of what represents them mathematically. Think basic high school or sub high school, middle school algebra. Well, if it's a curve like function, anything can be any curve can be described by a polynomial but if it's a graph like a nodal or a circle or something it's still a curve but yeah then you have i mean then i don't think it can be described. No, no, I'm not talking of a circle because then this model wouldn't make sense in that particular case. Imagine that it's a well-behaved relationship. Then it should. I would believe that any curve can be described by an equation. Okay, that's a good answer. Anyone would like to improve upon that or disagree with that? Not people who are repeating. Integration, right? You can integrate the values and then you can find the area under the curve, right? Well, that is another function, right? And that function itself can be represented as a different curve so for example the integration of acceleration so suppose you have been driving your car right and your acceleration has been going up and down and up and down and up and down right so what is your velocity your all you have to do is at each given point integrate. And you will have like over small intervals of time as you keep on doing it, you will start figuring out using the appropriate relationships, how far you have gone, how fast you have gone and so on and so forth. So not that. gone and so on and so forth. So not that. Can't you have relationships which like aren't, can't be described by a polynomial for like, example like exponential decay or exponential growth can't be described by a polynomial appropriately? Yes, that's a good answer. Anyone else, can you think of any other examples? Think the most simple functions that are not algebraic that you learned in school log our sine and cosine sine and cosine and log is also another so when you try to expand sine cosine log exponential decay like someone said said all of these functions have one quality. They are called... Isn't it continuity? They have continuity and differentiability. So let me, by the way, speak to these words. Since you spoke of continuity, see a function that doesn't have gaps is a continuous function. In machine learning, you'll always model continuous functions, generally. And differentiable means it's a smooth curve. This is not differentiable, not smooth. Because why is this not smooth? There is a crease here. So imagine if you have folded and ironed it, now it's not a differentiable function. So differentiable and smooth are geometric equivalents, right? And always, guys, you'll notice that in the workshop, I will use geometric intuition to explain things because human mind can visualize geometry. algebraic things equations can become pretty unwieldy after some time so let's stick to you will see that at least in this case i will stick to geometrical intuitions it is somewhat unfortunate that almost all machine learning textbooks they are rather they take a much more algebraic approach. They are much more filled with equations. In my view, it's unnecessary because for every equational thing that you see, there is usually a very good geometric interpretation, which is equally right. In fact, there is a theorem in deep mathematics that says that if there's a problem in algebraic world, roughly, it is a very rough hand-waving way of putting it, you can either solve it as an algebraic problem, or you can go into the geometric world and solve it as a geometric problem. What looks hard here sometimes can be solved easily in the geometric world, and what looks very complicated in the geometric world, there may be some assets in the algebraic world that can solve it. So it's the interplay between the two and there's a sort of equivalence and there's some very deep sort of theorems in mathematics, one of its crown jewels there, that say that you can do that. So my approach will be contrary to most textbooks to take a very visual, very geometric approach to this subject. Anyway, those functions that I'm talking about are trans, transcend, and then tell functions, right? And the earliest transcendentals, that's why these are called early transcendentals in calculus. They're literally calculus with early transcendentals. They'll talk about cosine x, tan, all these trigonometric functions, then log x, e to the x. These are the things you encounter in your middle school and high school, isn't it? Now, what happens is that if you try to expand this as polynomial, you will find, for example, sine x will be equal to x minus x cubed over 3 factorial plus x5 over 5 factorial minus x7 over. You see, it keeps on going to infinity. There is no stopping. So another and why is this true and and geometrically it is true a sine wave. There is no end to it. So how many bends does it have? Bends is equal to infinity in the other direction also. On the real number line a sine wave has infinitely many bends, therefore, infinitely many roots. Therefore, if you represent it as a polynomial, it's a poly of n is equal to infinity. Do you see how obvious and intuitive it is? A function that keeps undulating all the way, and down up and down from minus infinity to plus infinity how many bends will it accumulate infinitely many bends can't you put limits on it from pi to 2 pi or something no no i'm just looking at the nature of the function at this moment but yes you can you can and within the, and so that's a good point. Hold that thought in your mind. So in the real number line, it has infinitely many bends. And you need infinite degree of polynomial to represent it, cosine, et cetera, et cetera. Similar argument applies to logs, et cetera. But with a different, intuition is slightly different. So the point is,ental functions by definition, by definition, expand to the polynomial of degree n is equal to infinity and no less. Right. Another way of saying it is that you cannot represent it as a finite degree polynomial. That is literally the definition of transcendental functions. But then you may say, oh, who cares? Some people have transcendental functions, but I'll get along using polynomials. So why should we care about transcendental functions? Anyone? Well, here is my way of putting it, a slightly cheesy way perhaps. See the world, just like language is written in English language is written using the alphabet, the English alphabet, the 26 letters of the English alphabet. The way I look at it and the way my worldview, if you were to read the mind of God, the language in which this universe is written is a language of transcendental functions. Genuinely, if you want to study how God god speaks or the language of that the creator or something and this is a personal belief it is the transcendental functions you drop a pebble in the water and you see ripples those ripples are sinusoidal isn't it if you see the height how the height diminishes of the ripples the height diminishes of the ripples, the amplitude diminishes of the ripples, I believe that, and fairly, if I'm if my memory is correct, those are Legendre polynomials, another transcendental function. Right? Then, if you look at the atoms, the electrons buzzing around the nucleus of an atom those are spherical uh vessels functions right and they're also I hope my physics is not too rusty that's what they are the so-called spdfs are the different modes of that transcendental function right wherever you look you look at the wire hanging between two telephone poles that is is a transcendental function, the height of that. Describing it. Wherever you see activity, if you look closely, you will see that things are happening, things are described using transcendental functions all around you. The decay of a radioactive material, right? The decay of most things, many, many things, they all are transcendental functions. So nature is transcendental functions written in the language. The building block of this universe are transcendental functions. It's a very amazing fact. I realized that when I was a kid, I used to notice that wherever in physics you look, the swinging of the pendulum, the waves, the decay of the radioactive material, all the time it used to be transcendental functions. Lovely, it's just amazing. And the more you learn about the universe, the more you see transcendental functions everywhere. But that is quite interesting actually, and it's a bit of a historic thing. See, people who are building these regression models, the history is, I told you that Goss's paper was 1793, but he didn't actually reveal a least square method, but he solved a problem using that. He predicted the location of a heavenly body to a far greater precision than anyone else could, the time and the place in the sky. In 1805, and again, I hope my history is right, please Google and correct me if I'm wrong, then this fellow, why am I forgetting his name, Why am I forgetting his name? Le I think. Yeah, Le gendre. Yeah, Le gendre. Absolutely right. Le gendre wrote the paper of least square, the method of least square by eighteen twelve or eighteen twenty six, I believe, somewhere near that within twenty years of that twenty, twenty five years. So that people already knew that there's a limitation to polynomial regression. So what you're doing is you're doing regression, not with linear, but with polynomial terms. It is still called linear regression, linear regression, polynomial terms. You have just expanded your space to polynomial degrees. You can't do that. There are many things that you can't do. Right. And obviously uh imagine if if everything could be described with polynomials all of your machine learning would end with this lecture with this session isn't it you would be done but having said that polynomial regression is still a very powerful technique and rather underutilized apply it guys because know, you don't have to be, there's no such thing as a right model. There's such a thing as an effective model. And this brings us to Raj's question. Suppose your data is within an interval and, in fact, this is exactly your lab. You have a data that is like this. You have to build a predictive model to predict y in terms of x. This is your data. In this data, how many bends are there? Two, one, two. Therefore, you will find that if you try a model of degree three, you're not doing badly. But then if you are mathematically clever, you may also notice that in your imagination, if you extend it, it looks like this. This is a mathematics, we call it an odd function, right? F minus X is minus FX. They're mirror symmetries, right? So when you have these sort of situations what happens is when whenever you expand these functions in polynomial odd functions will have only odd degrees degrees see this is sine x this is basically a little piece of a sine x right look at this do you see only odd degrees present here? Yeah. And likewise, if it was a cosine function, which is, this is even. It is pretty laterally symmetric. When you have this, you will notice that cosine, x for example, is an example. It goes on. It only contains even degrees. So if you happen to know that and you find two bends, what should be your basic instinct? You want to go to degrees, right? You need three degrees. So you will start with x x cubed and x5 right you will build a model in these three degrees at least so you'll realize that it's a good idea to build a model with a polynomial of degree five see that's being a little bit more mathematically uh clever but degree three will still give you pretty good answers right if you don't understand these nuances of even odd and so on and so forth and you can still get pretty good answers but one of the lessons here and i want to give you in machine learning is guys you know what will be your biggest friend it will not be some very esoteric mathematics it will not be some very esoteric code a library that somebody has written quite often if you want to get good prediction models use your real life intuition and use the mathematics that you learned in school itself and that will be very handy for you the only thing is you have to learn how to use it most of machine learning at least unless you're doing research much of the machine learning is actually straightforward. And you can understand all of it using geometric intuitions and fairly straightforward mathematics, actually. It is not something that needs tremendously esoteric mathematics, though it appears so. When you first encounter this subject, it gives you the impression, oh gosh, it's scary, so much math. But actually, there isn't much math. It's pretty shallow from that perspective. So guys, I will end there. So transcendental functions cannot be represented in polynomial. So obviously machine learning, fortunately, is a rich and wide world. We learn about many theories. We learn about kernel methods. We learn about neural networks. We learn about ensemble methods. learn about neural networks we learn about ensemble methods we'll learn a lot we'll learn about neighborhood methods right and that's the beauty of this subject it's fascinating if you think of it as a zoo it's quite a san diego zoo in which there are lots of exotic and marvelous and wonderful creatures lots of theories and lots of ideas and all of those ideas have a place under the sun. They all work well with some reality, some data. I had a question. Well, I'm maybe stretching it here, but it looks like you get the data, you plot it, then you use your brains to see which curve fits and then make the model yes can it i mean you still need a human interaction can it be possible that you just throw data to a black box and let it see which model which is yes the answer to that is yes but there are two aspects to it. So I will teach you, there's a process called regularization, which I haven't, which is a topic that will come in subsequent weeks. There you can have your cake and eat it too. Namely, you can start with a very flexible model, but suppress those oscillations, suppress the overfitting. And so what happens is you don't really have to discover or try to discover the exact ground truth because what will happen is, let's go back to the situation where we have a very undulating data. Where's my data with a lot of undulations? It was hiding somewhere here. Bias, wheels, trade trade off where did that disappear did i disappear that somehow yeah here so what happens is this red line will get replaced by a line which still has 10 bends but those bends will be like around this green line. So now look at this light blue colored curve. You know that it is overfitting, but only slightly. And it is a good enough model for you to make predictions with, isn't it, compared to the green model. Green is the optimal, but the light blue comes pretty close to it. Right? And so there's a technique in which you can start with a more complex model and then suppress the complex. You push down, you put negative pressure and you bring down the variance errors. And then you get a model in which you quite literally have your cake and eat it too. But that is something to learn in the future. So that you can do. But then what happens is, suppose you tell a patient that, suppose a patient says, how will my diabetes improve? Right? What all, like, for, if I walk one mile a day, how much will it, given all other factors being the same, given my diet remaining the same, etc., my A1C is a measure of diabetes, how much will it improve? You say that, you know, there's almost a linear relationship or a quadratic relationship. You walk a mile or two mile, here is this lovely curve you can follow. you walk a mile or two mile here is this lovely curve you can follow and you can estimate or just simply rule of thumb for every mile extra mile that you regularly walk all other factors being the same your diabetes will improve by this much right but that is a doctor saying something that that a patient can actually understand but imagine another doctor saying that, see, you want improvement in your A1C, you need to first have an apple of exactly this size, then do this much exercise in the morning, then do this, eat that food, and then do this, right? I don't know, sit in the sauna. And then, by the way, the relationship is very complex. I can't explain you, but go and do all of these things in exactly the way I'm telling you, right? Do you think that will happen? The patient will feel any level of confidence that he can follow through on that, wouldn't. So complex models, even when they work like this, right? They're counterproductive because they're not interpretability is not there it doesn't make sense to normal human beings and that brings us to the vast topic of the value of interpretability and see in science we don't know science is not a body of things that claims to be true. Things can only be disproved. But we call laws or models, those things which are good models, they need to have two qualities to it. They must be effective. So for example, Newton's law is wrong in the sense that we know Einstein's correction is needed. But for all real life situations on earth, it's a pretty good model. But you can't say that Einstein's gravitational theory is right. It turns out that that too is wrong. It's just that we don't have a better model. We don't have a better theory. So in science, you always acknowledge that we are never right, but we still have enough models, effective models to get our work done. So the second quality in science you have besides effectiveness is of all the effective theories this should be the simplest one and that is called the occam's razor principle right science is made up of a body of things you can disprove it's the falsifiability criteria if you can't falsify it then it's not science having said that you need effective models of reality and simplest effective models so the pursuit of simplicity is important and this is something that is lost when people try to make bizarrely complex models to describe a reality that could perhaps be described by much simpler models interpretability is very important. And it goes to the heart of understanding because Occam's Razor Principle is at the heart of what we call understanding a phenomenon, a data, what exactly is happening there, right? So that is it, always pursue the simplest model. The other problem is the data always has bias. So how about this? I end today with a real story or supposed to be a real story. There is a story that has gone around the machine learning community for so long and I don't think anybody really knows whether it's true or false, but it's quite an entertaining story. The story goes as follows, something like this. I might embarrass it a little bit. One fine day, the military decided that all these AI guys are popping up. Maybe they can help us out. So they came with a basket of, they came and they said that, see, when we shoot at a target and we shoot at vehicles and things like that we want to make sure that we don't hit military we don't hit civilian vehicles we want to distinguish between civilian vehicles and military vehicles right for whatever reason in in whatever place maybe shooting or whatever the cause was for some reason they wanted a distinction between the two so all this ai guy said absolutely no problem that's a easy easy thing to because they looked at pictures of civilian vehicles they look like cars and suvs and they looked at pictures of military vehicles and they look like tanks right and big tanks and all sorts of things like that so this is an easy problem in image recognition so they said, go and get lots of images of civilian vehicle, lots of images of military vehicle. And so the story goes that you can practically imagine some general giving orders to all the soldiers to use their devices, cameras or cell phones to take lots of pictures. Lots of pictures came in the laboratory, ai lab they easily built a model it worked swimmingly right like a charm at work it was an easy problem it could tell then the military just to make sure they asked for a test data they got new images of civilian and military vehicles and they fed it into this algorithm, and it worked just fine. So they said, all right, let's deploy it. But when they deployed it, it was a uniform disaster. It didn't work at all. And now you think a lot about why it didn't work. The trouble is they used a very complex neural network, say the convalescent neural nets and so forth, and then it didn't work. So the whole question is why would something work in the lab, but not work in the field? Ultimately, it's the same model. And as the story goes, the reality when they looked at it is, if you carefully look at the image, when they found the solution, in hindsight, it was obvious. You ask a bunch of military people, soldiers soldiers to take pictures of their military vehicles you know what in soldiers are at their base in early morning and late evening right when there's very little ambient sunlight and so they take pictures which are all dark of vehicles are not too much light and then they go with their military vehicles to the whatever city they're patrolling and they see civilian vehicles all the whatever city they're patrolling and they see civilian vehicles all around it so they take pictures in broad daylight of the civilian vehicles what the neural network captured on is a very simple fact just look at the ambient light how much light there is in the picture the more the light the more the likely it is that it's a civilian vehicle the darker darker the image, the more likely it is that it's a military vehicle. So what did the AI really learn? It learned a simple trick. That simple trick spoke to the bias in the data. There was a systemic bias in the data that no one noticed except in hindsight. So while I can't count to the veracity of this story, here is another story that is really true. Apparently it was Amazon, if I'm right. They came up with the recognitor, the facial recognition system, which even the people were beginning to, they were sort of advertising to law enforcement, etc. Give it a picture, it will tell you who it is, and so on and so forth. Then one researcher, she really pioneering researcher who pointed out the dangers of AI, what she did is something quite remarkable. She took the Black Caucus in the Senate, or in the Congress, all the black members of the Senate and the Congress took all their pictures and fed it through the image recognition system. And what happened is, while for white people it worked well, for Black people, the Black caucus, many of them, or lots of them, were identified as serial killers and rapists and whatnot, pretty obnoxious things. They got recognized as that right so there was a deep flaw in the algorithm and obviously the black caucus was not amused and there was quite an investigation and the amazon had to withdraw that particular thing i don't know what the latest status is but this this is actually a well-studied case study it's a case study now in AI. What it speaks to the fact is that it's very hard to not have bias in data. You could imagine that Amazon in its campus is surrounded mostly with what, white people and Asians and so forth, like doing software development. One would guess that they were just looking at their employee database. And the fact that their algorithm did so poorly with black people probably reflects the fact that they did not feed in enough black people faces to train the algorithm properly so it was making a lot of errors in that space but see these things are obvious in hindsight it is not obvious upfront so black box box models are dangerous. They're very good at predicting, but when they go wrong, they're horrendously wrong. And people realize that these models, they can tear apart society, right? They can perpetuate huge prejudices if you don't bring in interpretability to it and hold these models accountable. So one of the big things that we are doing is, and it's a thrust in ethics, ethical AI is to build only interpretable models or build a black box, but ensure that you can superimpose certain degree of interpretability on it and that there is no adverse impact on people. So that goes to the problem about complexity in this world. And these modern models, as I said, the latest is almost become who can build a bigger model. And I believe the latest one is from Google, which is 1.4 trillion parameters. And it turns out to be slightly bigger than the next biggest model, which I believe was from Microsoft, which was 1.2 trillion, or was it OpenAI, I forget, 1.2 trillion parameters. So these are bizarrely complicated models. We have no idea how it works in the sense that we understand enough, but we are entering into a world in which we are building machines we don't understand. It has a precedent. When steam engine came about, people were building steam engines, using it to do things, textiles, you know, they were building, making clothes, they were making steam engines to run locomotives. They did not have an understanding of the theory. Thermodynamics came later. It came with Carnot and people like that, right, and Rankin and so forth, who finally understood how steam engines really work. So the theory, the understanding came much later than the applications. We are in exactly the same world. We really don't understand how some of these most complex models work. We understand parts of it. We build it. We are amazed by it, but we really don't understand how it works. Theory is far, far behind. It will take a long time for it to catch up. So think about this. We are building creatures. We are building not creatures, but we are building these machines, which we don't understand. And so there's a real danger of creating a Frankenstein's monster in all of this. Anyway, so that is obviously going off on a tangent, but that sort of gives you the spectrum of possibilities. One simple rule, never underestimate the power of simple models. Very, very often, simple models describe the data quite well in many reality situations there are situations where it doesn't you need complexity but bring in the least amount of complexity that you can just enough complexity to get the word to never pursue complexity or a complexity for its own sake. Questions, guys? All right, guys. Thank you for your time. I'll see you on Saturday morning. Today, again, was theory session. Saturday morning is all labs. So we'll start with, we'll do quite a few exercises and coding and all of this will become real in the lab when we deal with real data.