 Good morning everyone. It's a beautiful Saturday morning. And the weather, the temperature is perfect, I would say. So today, other than the projects that you should do a share and intel with uh in terms of learning today is our last session but we'll also have a session in which we'll continue to do a few more paper readings and i will do show and tell of the projects so i invite all of you to show up here in person let's have lunch together Let's have lunch together. And today evening itself, tomorrow morning, I'll be sending you guys your certificates of completion and also a formal invoice receipt for the course so that you can submit it to your workplaces for reimbursement with that. So if I miss you for any reason do please let me know and those of you actually i usually before the pandemic i used to hand out those certificates in person today i should have done that uh we have some uh some of you may recall we have some really good. It looks beautiful, a printed out set. But I'll certainly send you guys the digital copy. And next time you want if you want to print it out, if you're going to be here in person, I do let you know so that I can have a printed out certificate ready for you. Next time you come here. So that is that. And once again, there's a lunch today. This breakfast is already there. Good Starbucks coffee is brewing. We have snacks, we have things. And throughout the day, we'll have snacks and breakfast and tea and so forth. But we today also have lunch. And those of you who are here, they get to choose the items on the menu. And those of you who are here, they get to choose the items on the menu. Lunch we'll do around 12.30 or one. We'll follow the same routine. Today morning, we'll do the labs. We'll do some interesting things. Now, this lab is interesting enough that I would strongly encourage you to go through the hassle of setup. One reason I kept this lab for the last is it is quite interesting, I encourage you to go through the hassle of setup. One reason I kept this lab for the last is it is quite interesting, but it comes with a bit of a bit of a setup on your part. You have to set up a database server. If you don't have one on your machine, you'll have to import a schema with data and so on and so forth. That's about it. If you do those two things, it will work. And you'll also have to install a few libraries to get some of the things done. Today, we'll also deal with this. We will also do sound to text speech analysis using as an exercise in natural language processing. As you know, we all communicate far more to speech than we do to writing. But throughout this course, we have focused primarily on textual written content and before we end this workshop it is worth changing the dynamics it is worth uh looking into video and um looking into audio in fact the project that i'm uh i would encourage you to do would be very interesting i would encourage you to do it as a team so let me first start with the project the project is this and i obviously put the description of the project for you create using either drag io or streamlit a conversational interface but a spoken conversational interface there should actually not be a place to type in any text there should just be a microphone on your interface and the reason i'm saying that is because that is the future. Trust me, in a couple of years, you will realize that interfaces have become a microphone, by and large. And as the user speaks, take in the input, extract the intent of what the user is searching for, and answer the user's question now first understand the question from the speech then find the answer to that that is part one of it part two of it is given whatever answer you come up with render it whatever answer you come up with, render it as a graphic. Convert your answer and associate. I mean, you have to create a whole essay around it, like at least a thousand words of answer. To create a thousand words of answer, you must produce at least one image, hopefully more, for the different chapters of the topic, things in your answer. And you should be able to do it dynamically on the fly. And lastly, once you have the answer, you should also give it a play button so that if play is hit, the answer is returned as speech. So I want you to, as this course ends, I want you to meet the future. And this is the future, guys. Now, there is a bonus part to this project. The bonus part of the project is, can you also render the whole answer, the spoken part of it, not as just audio, but as a video. Make it into a video and do this. So this is an intense project. I would like to give the last week, I would be helping you guys quite a bit in making progress with this. Now we will take two weeks to do it. But throughout these two weeks, every single day I will be here let us continue to talk bring a form your team's guys please do it as a team it's just too big a project for you to do alone unless you're highly highly motivated but if there is one thing you can do that will bring me the most satisfaction you can have a feeling that um not only have you put in effort, that I also put in effort, and it was all worth it, is if you do this project. And trust me, you do this project, you will get tremendous satisfaction, and quite literally, you would have met the future. Go ahead, Albert. Yeah, I will give you a write-up of this today. At the end of, I'm sure in the evening, I will give you guys a up of this today at the end of the evening. I will give you guys a write up of this entire project. I'll repeat what I said about the project. And yeah, thank you for the coffee. The project is as follows. You in Streamlit or Grad.io or your favorite, you want to do it in React, do whatever you want. Do it as a team though don't do it alone form your team and do it but the team shouldn't be more than four people right um and generally one will be a bit hard for you so form the team a good morning Farhan, you came just in time. We are announcing the project. So form a team. The team has to create an application whose interface is just a microphone. There should be absolutely no place to put in, type in any text. All right. All you can do is press a microphone button. Like this microphone, make a picture of this or something like this. And as you, as the user enters the question or asks something, your task is to find an answer to it, a long form answer, in a few paragraphs of text. shouldn't be a one-line answer so uh implicit to this whole thing this project is the is the fact that the question would be something a law you can just assume that the user will say uh now for example uh tell me about how the golden great bridge came to be Tell me about how the Golden Gate Bridge came to be. Who is a genius and so on and so forth. Give me the history of that. Your job is to find the answer. And to find the answer, you have to use the agents. For example, you may have Wikipedia and so forth. The question could also be, for example, here and so forth the question could also be for example right look into the paper attention is all you need and in particular explain what self-attention means and why does it matter right so now you realize that you can't exactly find it in Wikipedia. You will have to use another tool archive. So your project actually has to be receptive to just about any question and should be ready to use. You need to create an intelligent agent, and this is where the real fun is. You do this project and you are looking at a startup. I'm serious. And believe it when I say I am there every day throughout this two weeks to handle you to this. So you do this and capture the intent, use the right tools, make it happen, come up with a few paragraphs of answer but not only render that render it with graphics uh think think uh stable diffusion stable diffusion and use that to i mean right imagine that you're writing a quite imagine that you're writing a really polished New York Times kind of article. Right? So as you create your prompt, tell your system to have a summary, to have a structure, not just to produce free-flowing text, to follow a certain journalistic style or something like that. It should a good form it should have data it should have this and that are prompted to produce things in a proper structured way with graphics and then finally there should be an audio so you should be able to play the answer all right text and audio you should be able to produce an audio a podcast of your answer and the idea is that can we create a machine to whom we talk and in its utter simplicity that's interface. You talk to it in response. But when it does that, it is willing to listen to anything from you, and it will respond to that. And obviously, don't worry about latency. So if it takes three, four minutes, five minutes for it to find the answer, that's perfectly fine, because we are not sitting upon too powerful machines. So respond and also try to create a video out of it. Okay, I captured some of that on Slack. Oh, thank you. So, guys, this is an absolutely fun project. It is not as hard as you think, but it is not as easy as you think. It will take you two weeks to do it. There is no doubt. All right. So when you do it, you will get tremendous sense of satisfaction. And as I said, I will be and all of us here that the TAs, we will be with you every step of the way. That is right. That is right. Absolutely. Just make a picture of a UI should be a picture of a microphone that you can click. And it should listen to you talking. So when you think about what all it needs, except for the stable diffusion part, which is too easy and a lot of fun. And I deliberately wanted to keep an easy part as something I didn't teach or maybe I'll teach it today or release at least a Jupiter notebook with that also in it. Everything that we have done in this, everything that we need to finish this exercise, this project, we have actually covered it in this course. All right. The video generation is the only part. The text to speech and video rendering. I left it as a fun exercise for you. But trust me, it is these days easier than you think. Yes. So you have to paint a whole pipeline. You have to figure out in this dynamic land chain. So what happens is that you have to dynamically construct land chains, so you need an agent that infers what are the things, so that agents should have access to many many things. And you're embedding a few images and as a best and we are playing it as a voice. And also be played as a voice, right? I mean, I don't know. Is generative, is generative. Absolutely. And guys do that. And then after that, tell me if you don't feel the urge to go do a startup immediately, Shani, what do you think? That means that to this moment. So the guys, are you excited about this project definitely yeah and remember that it is not as hard as you think it's not as easy as you think it will keep you really busy for three weeks but it may be the most satisfying two weeks after a long long time you'll get a tremendous satisfaction from this project and this course like see if you don't do this project today we end but if you do this project these two weeks will be highly engaged two weeks that we will do together i am here all day from from 10 30 in the morning typically and usually till 10 30 at night. Every single day. Yeah. So yeah, we're gonna mute. Some of these things can seem simple on the surface, but then it can be difficult when you actually do this. Like we try to do the land flow on Tuesday and we didn't have enough time because we only had a half hour. So I think, I think, you know, know yes streamlit and gradio might have these tools but i think as we kind of put things together we might run into some difficulty so i do concur with your thoughts yes yes yes that is why it will keep you really busy for two weeks but guys it is practical experience it stitches all the different pieces that we have been learning throughout the course it stitches it all together okay so will there be Saturday sessions on the 12th and 20th or is this just during the day no guys uh so there is a bit of news I will be missing uh from this town uh on I will leave on Friday night uh so Saturday, Sunday, so Friday I'll be here, but Friday night I'll disappear. Saturday, Sunday, Monday, Tuesday, I'll be in Seattle. I'll still be looking at the messages, but this coming Saturday we won't have a session. My daughter has invited me to Seattle and I'm meeting after many months so I'll be there but we will we will we'll schedule a time uh but I'm hoping that through the days we stay very engaged like the next tomorrow day after all the way till Friday till I do and then the moment I return like you know the next week the week after that also we all stay fully engaged the only time i might be a little scarce is on the saturday sunday the coming saturday sunday because that daughter wants to take me around seattle i've never really seen the uh i've never done hiking in seattle we have in plan to do hiking in some mountains and see some waterfalls. Mount Rainier. Nice. So the 13th and 14th, you'll be away. Will we be meeting on the 20th? Saturday the 20th. We will be meeting on Saturday the 20th, we start the deep learning. Quite likely we'll meet on Sunday the 21st. Okay, Sunday, guys, we'll meet on sunday okay sunday guys we'll meet on sunday unless you guys are willing to meet on friday and nice we will all do a show and tell and again have a party i'll order good food right and those of you who joined late today we are having, besides the usual breakfast and snacks, we have lunch here today. So do if it is if you are within driving distance, do please drop by let's all have fun, have a quick access to the lunchtime. See, Grad.io is more natural if you want to host it in hub-in-place basis, which they make it available. And they're both competing products. They're both equally good. The thing is, Streamlit has had a lot of popularity, a lot of popularity. One second, let me just increase the height of this. Yeah, it has had that right of this. Yeah, it has had a lot of popularity recently people have been a little bit annoyed with it because there's too much of a push for this. I use the corporate version of the paid version and push things to their cloud and so on and so forth. Grad IOS is still the most good. So I would say that the choices are equally split. And you don't have to use either of them. If you so choose, and if you're good with React, go make it from scratch. Because ultimately, Streamlit, what does it do? It just emits React code under the covers. You just don't know it. Prashant, I expect this project to also include your love is the merest purpose. Seriously, isn't it imagine the wisdom of the world coming through it's ancient wisdom let's immortalize it right and here is something i'll give you guys as i offer i don't get promised give you guys as an offer i don't promise that you know that uh it depends upon because the food matrix is just starting once again after the pandemic and i believe stream was a little bit shaky but i'm putting together the servers service thanks pardon to uh sukpal here who has been making wonderful machines for all of us. Your projects I would like to see. So in other words, I'm willing to at least assuming that we can afford to whatever the electricity bill is, but I'll give you the computing resource and the hosted free for your project. It's a public IP. This place has a gigabit fiber. It's going to be 10 gig fiber now. And the building inside is of course 10 gig fiber as you know. So it will be hosted. So the project that you do will not be lost in obscurity. It will forever be lost in obscurity it can forever be hosted and we will do we will put in every effort to make sure that we mention it in twitter mention it in mentoring anyway do your best guys i would love to show this because this has been a long journey you guys have all given your week saturdays to be here you guys have all gone through our labs that have been not exactly easy they have been a bit of a struggle and you guys have genuinely learned a lot in fact i would say that if you have actually been doing the labs in the material i would push you at par with the top 10 percent of the energy level of this particular model. So you are there. You know everything other people know. And hopefully with more discipline, more rigor, writing better code. So it's time for us to showcase. So please do that. And trust me, the machine on which we are going to put it is not the usual machine that you can easily rent in the cloud without paying to your nurse hey it will be really helpful if we can also if we get our project completed in time see if there is vc interest in it absolutely absolutely guys if you do that i am all ready to uh by the way if you're looking for uh angel uh investors i have enough connections to attract them to make presentations to them. I'm interested, so we can all, yeah, we can all. We can all take you up on that, that's it for sure. Definitely. So guys, do your best job. And here's the thing, the more effort you put, the more effort I'll put. I'm willing to work, like, as I said, just ponder over it. I am saying that for the next two weeks, except for the time that i'll be on vacation two days i'm giving you problems like i'm giving you 15 hours a day of my time and not just giving you there for advice i can help you do this let us all collectively do something really worthwhile make see people make lime chains and little things, oh, look, I could do this, oh, look, I could do this, but let's make a product. See, there is a difference between doing, look, I can do this, to bridging the gap over to a serious product that actually you feel proud of personally, so she looks, I can't see that. So thank you. Are you able to hear me from this distance? So let's do that. Please let's do that. And I'm offering you my time and the full support of the Support Vectors team, everyone. We will be with you. Not only that, we're giving you our compute resources free and free hosting if your project is good. I'm hoping that all your projects are good. Right. And we will spread the word. We will get it out. Also, if you feel that it has potential for investors, we will start and we will all get together, pool in our investor connections. We will invite them here to make this so that you guys can make presentations in the presence of investors. Does that sound like fun guys? Okay, that was that. So obviously, I'm trying to give this basic The other thing is today happens to be in case you don't do your project, even if you do it a couple of people i think um the tuition i may still hit you i have to look at the list but if it is you guys then now would be an excellent time to um send it over if you haven't sent it but then you can just you can go to the website and use that that i lose actually, actually, I don't like that method in now because PayPal is doing something pretty strange that not only can they take a significant cut out of it, but they have started withholding the payment for three to four weeks. It's a new policy they have started they said, Oh, we haven't heard of your business until so long as they know in a history you hold on to your furniture at this moment so you can sell it to me just the pool number suppose your just full number is five one zero two nine nine zero three zero uh let's see does your deep learning course start and one can start registering oh next century oh please do register good heavens if you have not, I assume that the deep learning now that we are highly motivated to Saturday, the Saturday that I come 20th, the 20th Saturday, yeah, literally nice two weeks and giving me for this project. But after that, we start immediately. Right? The deep learning starts immediately. And in that deep learning this time, if we had been deep learning with me before, this is an entirely new course. None of that. I wouldn't be spending time on seeing, you know, RNNs and very little. I'll cover. Let me just put it. Everything that we did before, I may cover it in just one day and get it out of the way. I've marked it. It's an entirely new course that's why is the name has changed it is no more called advanced machine learning or something like that or you can it is called um actually the title is even slightly up it is deep learning foundational architectures not only foundation models but the foundation of architectures. Not only foundation models, but the foundational architectures. So we will do, and much of the time will be spent guys, on the absolute state of the art thing. Like for example, lamination. You know lamination? Yes. Exactly. So guys, we will be doing things that have just come out one week, two weeks ago, right? Things like that. And we don't know what new things will come, but it will be really interesting because we'll cover absolutely the latest stuff. See, first two, three sessions, two, three days, yes, I will build a foundation. I will explain to you what back perturbation is, activation function is, universal approximators, those foundations are necessary. But right after that foundation, as always, you know, there are always two more sections beyond what I advertise. It is advertised as eight weeks, but actually it's ten weeks. As usual, it's ten weeks. And at the end, there also, there is a good project. And the 10th session is actually two weeks later because it includes the project. Just like this, we had six, seven sessions, a plus two week gap before the eighth session. So we'd follow the same methodology. I'm hoping that you guys will come out with a good, great project, and you end up with time. That is nothing like the portfolio of projects. The world has been democratized. I don't know if you guys watched this. There was a new document from . We saw that media yesterday. Okay, there's a few who haven't. Some very senior research scientists did a comparison between Google and OpenAI. And basically said that, see, there's not much difference between what Google is doing and what OpenAI is doing. We are all at the same particular level. We can give our people little points. But there is a new kid on the block which is open source and it is moving so fast and doing so well that the problems that we thought will take us tens of millions of dollars to do as a research project these guys are getting literally hundred dollars yes please put the video on the channel it's really an eye opening so what it does guys is. You. This rapid curve of democratization of the. Remember. The word is very interesting when we started this course. I started with saying that i'm very concerned that there is industrial capture. People like OpenAI, they're not willing to give up their models, they're exposing an API, they're going to make plans and so on and so forth. And we all seem to be hostages to that. Yet, this course has gone on now for six, seven weeks and the world has changed. The open source has responded with resounding force. And literally they have flattened it. They have flattened that. And there is far more creativity happening. And creativity is not coming just from researchers in the open source. They're coming from ordinary people. Kids sitting in their bedrooms are making breakthroughs, they're solving problems that were supposed to be a tens of millions of dollars worth of research problems. We will see something today of that. Actually it begins to, the data science will still be needed, you will see why, but you will see that data engineering is up for toast. It's totally true. I hope that's a lesson you'll see today. So guys, if you're a software engineer of any persuasion whether it is simple whether it is java it is dot net it is uh whatever old for second language It is all over guys. Now we have to reinvent programming languages themselves to be very, very large language model for bear. Yeah, as if I posted in the channel, somebody created for themselves a tool by which they could look at the fridge and it would tell what things are there and tell you what what you can cook with that absolutely wonderful I saw that yes the pictures of it right the items that were there it was very nice very practical very practical and I can't even imagine like this is going to be a transformable change in the way we program just getting started i think people are not realizing people are not realizing if you remember at one point i said that the scale of this transformation this evolution is not the scale of which of uh discovering electricity or discovering the internet or in an event the invention of the internet or the discovery of electricity or even the industrial revolution. This is going to block everything and will be on the same scale as the discovery of the wheel and the fire. It's just, yeah, it is. The world is changing very, very rapidly. It can make poppers a princess and princess of poppers. It should turn the world upside down. These guys, in fact, if you don't, you might as well start applying for unemployment. Because it is coming. Whatever job you hold, it's coming. I think I heard the news that IBM already said that they are making an inventory of jobs that AI can do and they are not going to do any hiring on that anymore, which means that they're, it is just a code word for saying we're getting ready for the layoffs. So it is happening, generally, it's happening everywhere. And the world is glad. Think about this. With all of these things, you can have a guy sitting in the Gobi Desert, right? Or on a tree house in Timbuktu. And be equally productive and creative. Isn't it? fully productive and creative. So I'm actually very encouraged because for the longest time, I have been meaning to go into, see, I'm partly Indian, partly Nepali, and I love this Malian mountains. And for the longest time, I've been dreaming of going on long hikes and living in remote places. time i've been dreaming of going on long hikes and living in the north places now i can and still so who knows my next my next session uh the support vectors next session will be offered from the most remote places high mountains of the mountains yes all right guys so uh with that thing aside I hope guys if there's one message I would say please please please take this project seriously guys and when I mean it that it's a we are a valuable resource we will bow it's not we're not just saying go do your project and come back with I'm saying we are your showpas. We carry you through the process. After all, I am Sherpa, blood in me. So that's that. So with that, with those things, let us get started. Yeah, so let's get started now with today's material. So today, we are going to do, we are going to do a couple of paper readings as usual in the afternoon, in the morning, we are going to go through a couple of labs. And today, what I want to do is, so that I don't get into the ideas of the project, what I have done is I have implemented that, helped you build towards the project, but then I deliberately redacted those labs. I took those labs home because I felt that it's much better. Those were straightforward. You guys are mature enough to rediscover that territory on your own. I don't need to teach it. And it will be much more fun if you rediscover it on your own rather than just blindly stitch the notebooks together does that make sense guys let's leave some things for you to pick up and discover on your own somebody's mic is open or something there's a disturb like a noise is coming in i don't know i keep hearing that music thump of something yeah oh my goodness that's me oh was that some sort of no that is now has it disappeared yes yes it's gone now yeah blame it on me because i have this fancy road podcast stuff so apparently when you're not speaking you're supposed to press it let me see if you hear it now yes that's it it sounds like it's trying to be music yes so i i just disabled it my apologies i didn't realize that i accidentally pressed my press that button on um i'm making my own teething uh issues with this uh very uh fancy uh podcasting digital signal processor for my voice. Is my voice coming out clear, though? Yeah. Very, very clear. Yes, it is. Then that is all thanks to Sukpal Rappal, who has set up this entire audio system for me. Oh, nice. Yeah, yeah. And again, see, guys, this place has run on an ocean of goodwill and volunteerism. And there are so many people I feel thankful for. I feel thankful for them getting the word out about support vectors. I am thankful for them coming here in the first place. I'm thankful for all the help they on their own provide. the help they on their own provide today uh kate for example she has been literally uh a support vector the support vector volunteering and helping us through all of these courses and sukpal has completely voluntarily come and helped us set up all this machine he has helped build the servers he has helped build the um done the machines at no cost built the servers he has helped build the um done the machines at no cost given us a lot of help and and once again it's time to say thanks i don't often get time to say thanks guys but i must say and some of you have written blog articles about this place and so forth um all of this matters guys this, as you can imagine, runs on that. We are not an investor-funded place. It literally runs on goodwill at this moment. All right. So with that, now I would like to... Is my screen shared by any chance? Yes. Okay. Yeah. So today I'll give you a sense of what we are going to do. We are going to, oh no, we are going to, the first, the morning half, we are going to do a couple of very interesting labs, which will be useful to you. Because in the project specification, you will see that if the question has to do some, some of the questions that can be asked by user will be medical in nature, in which case you have to dip into the medical database some of the questions will talk about computing things from the database like for example suppose you have you have structured data in the database you're supposed to find you will be asked to find answers to question how much did this location did my uh branch at this location earn this year? What was the total sales at this location in this year? And you will have to, or you can ask questions like, which location earned the greatest revenue this year? Or which are the top three locations? As you know, if you're familiar with SQL, those are SQL queries. But everything has to be a voice interface. And from the voice and the text, your project has to be able to infer it. Yeah, Asif, can you please share this labs? Share the? Share the labs. Labs, of course. Oh, my goodness. I did not share it. Okay. Guys, how about I do it in the let me do it in the this thing in the break and let's take a break in 510 minutes and then we'll do that. So I should have I should have started the class with sharing the last my apologies. So, see, let's start when you query a database. Now, there are many ways to query a database. If it is a, for example, relational database, you go at it with SQL. Or even if it is not a relational database, SQL has been sort of the de facto language of Frank, so that you can query big data with it. But big query with it many, many systems with SQL, right hive SQL, this SQL, that SQL and so forth the variants of SQL that has extended the applicability of SQL as a querying language, data querying language, or way beyond the realms of just relational database. The pioneers of SQL, people like Stonebreaker, have had a pretty strong point to make actually in the 70s, I believe in the 70s or early 80s, that a completely expressive language like SQL is what is suited for data manipulation and data retrieval. I tested the test of time. But SQL is not the only thing. You have had ways to query XML. There is, for example, XQuery. Now, there are specialized querying language for JSON. Like, for example, MongoDB has some syntax for that. There is Sparkle and all of that. XSLT is for styling and transforming the results. Yes, excellent. So all of those things have been there, but there is a new kid on the block that's very powerful. To the human beings, the most natural thing is, of course, natural language processing, natural language. Can I express what I'm looking for in a database using natural language? Let the large language models be smart enough to translate what I have into queries. Ultimately, that's what a DBA does, database administrator does. You say, I want this information. And the guy says, no problem. Let me go sit. And there you go, crafts a nice query, executes a query, and out comes the result. So well, now that the smart guys are being replaced by the smarter guys, with large language models, it's probabilistic. Will it be able to be certain that it will repeat the same? Repeatable results. That's a very good question, actually. So Patrick here has asked this question. The LLMs are probabilistic. Obviously, you remember that. And we tried to sort of tame it down by using the soft max temperature values closer to zero and so on and so forth but nonetheless they have a failure rate sometimes a perfectly easy uh task they will bomb sometimes they will do it right and it's a it is a problem that is the the crux of the nuisance with large um large language uh, right at this particular moment. And so we are we are in a very fluid situation, I don't think this problem is fixed. All we can do is marvel at its possibilities, and despair at its unpredictability. Right? It's it's our that is the status quo today. So obviously, caveat emptor, use it with caution. Nonetheless, it is worth knowing how to do it. So the way we will do that is, this today needs quite a bit of setup, which is why we'll have a long break. Now, I trust that all of you have at least one database server of your choice installed on your machine or in your cloud wherever you want it to be right um if not the simplest one that i would recommend is mysql go to the mysql website download the free version remember community edition is good enough don't go start paying them right and uh i mean of course if you would like love to then you're most welcome to but you don't have to pay them then there is a there is a schema see typically you have lots of sample databases but i picked a database that had a overlap? Does anyone know what is OLAP? A star schema. What is OLAP? Has anybody heard of this word OLAP? The one that is used for analyzing business data. Sort of. It's used for analytical processes. Yeah. See guys, what happens is that whenever you create a database traditionally, because you expect both read and writes, you expect inserts to take place, updates to take place. So those databases you need to keep in what is called the third normal form. There's absolutely no duplication of data. When you create a schema, a relational schema that is in the so-called third normal form. And forgive me if this jargon doesn't make sense. But in very simple terms, it means that no piece of data is ever repeated. Why should data not be repeated? Because when updates are going on, you don't want two copies of the data, one getting updated and the other not because then there's a cash there's a coherence problem based on which table you read the data from you may get one answer versus the other answer so a third normal form representation of the data says there is one and only one truth about a piece of data because it's stored like that in one place. When you store data in the third normal form, then you look at the schema and you notice that it is just a spider's web of foreign key relationships. One too many, many too many, lots of this. And those of you who have made databases, schemas, know what I'm talking about. Before you know it, it looks like a spaghetti mess of complicated foreign keys and so forth. The trouble with that is any kind of thing that you want to know, top 10 of something or whatever it is, those become complicated SQL queries. You need to join this with that, with that, with that, with that. You have to navigate multiple tables. You have to create dynamic views and what not and you must be seeing that you do sub queries and what not to get your answer sometimes and sometimes you ask didn't i just ask a very simple question right with a few group buys and aggregates should have done it and so there was a there was a rethinking of all of this as more and more analytical queries began to be asked. In fact, the foundation of this whole world of business, so-called business intelligence or data analytics, started with the works of such pioneers as Kimball, who said that the third normal form databases or the so-called OLTP online transaction processing databases are not the right structure for when you want to do analytical query let that OLTP be the source of truth but we need to take data from there and re-represent it in a completely different way called the star schema we need to distinguish between two types of data facts and dimensions In the language of machine learning, facts are measurables. Right. So, for example, you have lots of people, right, on a given day, what your weight is, is a fact. Right. Now the person has a certain age associated with that. The person has a certain location, a certain income, a certain medical history. Those are dimensions to the person. Are we together? So I could ask, what is the average age of people with diabetes in the Bay Area? You see that, right? Or what is the average weight of such people and so on and so forth so I could be asking questions on um facts or dimensions but you distinguish or another way to say it is that dimension is the context of a fact context of a measure you have a number, 72 degree Fahrenheit. Now, what is 72 degree Fahrenheit? You can say, well, in Fremont on Saturday, today, right, at 11 a.m., the temperature was 72 degree Fahrenheit. Does it make sense, guys? So that which gives meaning to a number context to a number are the dimensions the numbers themselves the measurables are facts that's one very rough way of mapping it to data science are we together so what people do is that they make this star schema star-like structures the core of the star or think of it as a hub and spokes. In the center is a table of measures. Those are called the fat table. They are narrow. They don't have too many columns. They're narrow, but they are very deep. They will have millions of rows, a large number of rows, whatever your notion of large is. So imagine that you're looking at a store. Every single item that gets sold, order entry, is for a commercial business, retail business, is a fact. For $30, a particular thing was sold. But that particular thing is a dimension. Who bought it as a dimension? The location where it was bought a dimension. Even date is an in fact a dimension right because you can aggregate over dates and say well give me the sales for this week for this month for this day right the items are dimensions because something got bought so transactions or the facts are vast number of facts will happen lots of transactions a lot of things order entries will be there but those order entries will span a limited number of items a store will have what maybe uh unless it's a mega store it will have a typical store that let's take a number a thousand items that it's selling isn't it It will have that business will have maybe half a dozen locations. Isn't it? And the distinct number of customers would be the number of people in the neighborhood who walk by that store, right? And it's client base, it's customer base. So those are dimensions. So a star. So now in this particular case, the reason we went to is, I deliberately wanted to take a database that has been, the word is denormalized into a star schema, into a OLAP. And one of the, think of it as a popular learning database, it's called the food mart right because food mart is very intuitive people are buying some items and so forth so this is it so we are going to install now what i'll do is on the slack i'll put the entire data as a sql query you run the sql script it will insert the data into your mysql database right and i'll leave this as a group exercise to help each other and we will help you install MySQL and that take this and these are the commands you'll use in the MySQL shell. But before that, let's go and do that. What we will do is we need some installs. Make sure that your PI My is installed, the Python library to connect to mySQL database, the driver library is installed. Then create a user and password. You can pick it to be whatever you want. Here, I picked the user to be NLP and the password to be this. You can pick whatever you want. Create a user in the system and give that user access to this database, the Food Mart database, use the GUI tool, use whatever you want or just use the command line, you know, create user blah, identified by blah. Then grant privileges, all privileges to blah all of those things and I trust you are familiar with that if not we'll help you through then but now see something quite interesting we are going to query this database which is a pretty complicated pretty big database with lots of tables I believe 30-40 tables not a huge database but it has a with lots of tables. I believe 30, 40 tables, not a huge database, but it has a fair number of tables, 30, 40 tables. We are not going to tell this data, this large language model and this land chain anything at all about what the tables are and columns are. We don't tell it anything. We don't say where is what data we say okay somewhere in there is the information go find it now think about it for a moment guys even if you're sql gurus when you go and hit somebody's enterprise database the first thing is it the whole damn thing takes a weeks to just get the hang make head and tail out of the schema isn't't it? Right? It's a nuisance. So now we are saying we don't need to do that. We will do this. So we create an agent, which is pretty good with SQL. So what do we do? We create a tool. Remember, agents figure out how to do it. They use tools. And in effect, agents leverage our large language model to do their thinking. At the same time, use the large language model at every stage of the way and tools for every stage of the way. So what will it need to connect to the database? It will need a SQL toolkit. So it is a SQL database toolkit. It will do it. So if you look at this syntax, I hope the syntax feels very easy. Does it? You create a database toolkit with this database connections, right? DB is just a connection to the database. And you give the toolkit and a connection to that particular database. Then you create an agent. What does the agent need? Remember, a large language model and tools. And we give both. Oh, what does temperature equal to zero? Who would like to enlighten me? Softmax temperature, how predictable, like how much you want to take the most likely solution versus the next most likely and the other one. If you set the temperature higher, it is likely that it will sample the next most next most also to give those people more chance, whereas otherwise it will give most of the chance to the most likely no actually it doesn't so sometimes what people do actually paradoxically because this whole thing is so probabilistically they will rerun a thing by setting the temperature high and they will take the the majority of the four answers or something like that but they will run it three four times and a couple of times it will fail a couple of times it will succeed right so it's pretty uh odd actually uh what hacks people do go ahead the highest probability answer but even then it actually doesn't work like that because it is sampling it is more in the sampling is more likely to pick the highest probability answer but more likely you run it again and you'll still see that sometimes it does something different it'll give you your answer no one it will take one path right so you have to rerun it. And so take this as an exercise. Rerun it with different temperatures and see it. Basically, here it's passing the language model over here, and then toolkit is basically like a database. Exactly. So it's a tool. Remember that in the land chain language, you get some tools, you get an an agent and you get a model and the agent deconstructs the the query into or the instruction into a set of things to do and does it with the help of these things right it's a high confidence all the time if you have zero temperature it will give give you the same answer? No, it doesn't. It is still sampling. It is still sampling probabilistically. It is more likely to pick the highest, the more, the highest priority answer. It is not precision? It's not. There is no precision. That is the stochastic. That is what infuriates people. See, when you write code, every time the code will run and produce exactly the same answer. But in this world, every time you run it, you ask where does the sun rise from? Once it will say from the east, tomorrow it will say maybe from the west, then day after it will say maybe north-ish. So you don't know. So see guys, we are looking at the beginning of something good. At this moment, it's highly imperfect. But we are looking at the possibilities. So see, look at the query. How many employees are there? And then I'm also saying show also the query used to find it. By the way, how many of you? Athira and Sheenath, if you're here, probably not. They had asked me this question, how do we get the query? So we'll come to that. Here we go. I run this query. Did I tell you, did I tell the machine where the employees would be? No, right? It looks at this table observation. List table, first thing it does is it says, common sense, let me get the list of tables. And it gets the list like this. And what does it find? Somewhere in there, there's an employee table. So it says, well, that that must be it, I should query the employee table to get the number of employees right, and so it will create an action query a sequel db. And then, what will it do it will think of it now, do you notice that it is itself thinking of the right prompt to send it it just saying okay let's say select count staff from employees. instruction, it is fighting it up it's coming back with an answer right in the typical data science language it comes with a list of tuples and the tuple is one dimensional because one one five five comma right then it says oh i know the answer now and it says there are 155 1155 employees and the sql query used to find this was because you asked it to give you the SQL query select count star and so this is the output there are 1155 employees the SQL query used to find this was blah. This is probably a simple... Hold that thought in your mind because I was hoping you would somebody would ask that thought. Something so simple, yes, it could do it. What about something more complicated? Then I say retrieve all the min, max and average salary. Now what happens? Then it says I need to figure out where can I get the salary information? It says, oh, great. There's a table called salary. Then it says, okay, I should query for that. So it says, again, a simple one, select min, max, average from salary. Isn't it, guys? If there was not a table with that name, would it still be able to find it? No, it would say I couldn't find it. So you have to not a table with that name would it still be able to find it no it would say i couldn't find it so you have to have a table with that name no no no it doesn't you don't have to call it something else so long as it can infer that it's the closest match it will go for it right you don't have to call it salary so here actually i made it too easy for it let me just change it to income something like that it will still work this is natural language processing exactly take some synonym of salary it will still work you can have like something pretty fast yes and in fact uh there's a company called hexx.ai, which is literally doing this. It's saying, and obviously they have put in a lot more effort than we put in in this notebook. But it is basically this idea taken to industrial scale. Now they're saying the right way to query is with natural languages. And it emits out pretty long SQL queries. And by the way, Srinath, who was in the ML 100 course, he literally is doing this for CloudAira. He came to me, he says, oh, I'm trying to create a thinking. People are creating prompts to do something with data in the big data stack. CloudAira has this too, etc. One of the suggestions he gave is go try it with this. He did it and he comes back and he's smiling. He says that he just announced in the company a new tool called Smart Query. They're actually going to release it. Right. And this is the beauty, guys. You know, you can make smart people like Sheena, they just need a hint. And then they run with it and now they're making a difference to Cloud Data's product, one of the leading products right here, acquiring product. And it can query Hive hive it can create all of these databases and so forth big data databases and soon it will be in the hands of all their customers making a difference that is the potential that's what i say so guys look at this the main salary is this the average salary is this right so now you can be more com sophisticated return the full name and salary of each of the top 20 different highest earning employees. Do you notice the wording? I'm saying top 20 different, right? So the same guy who earns a lot may have earned the maximum amount month after month after month. So you don't want that guy's name all the time, right? Different employees. It has to parse it and understand it. So now you see that the queries start getting more and more complicated. Right? So now it says full name from employees, uh, do that and constructed blah, blah, blah, full name order by descending. And there we go and it says produce it as html and it produces it as html how many of you like it yeah this is really good right yes yes yes it is showing you its thought because we said verbose is equal to true Yes. It tells you what to do. Yes, yes. It is showing you its thought because we said verbose is equal to true. So it is showing. But if you don't get that, it won't. And you can like for privacy, you can also say intermediate steps is false. It won't show you the in-between step. In production, you wanted that really. You don't want to see the intermediate steps. You could be more precise. they said who specifically is the highest paid right so then it goes about querying and do you notice that after a little while the queries are getting a little bit more complicated because now what does it have to do the the salary table only contains IDs you have to go somewhere else to go find the names. And it knows how to do the joins. It does a inner join. All right? How does it know? Well, I hope by now you should have figured that out. This is an NLP course. Interesting, isn't it? Yes. Yeah. But. Yes, exactly. Yes, exactly. This is it. Was there a human feedback in the loop for them to figure out this query or? No, reinforcement learning with human feedback. RLHF is certainly there, but by now all of these models have become very good. By the way, I hope, I really hope that this is the last time I'm using OpenAI. By the time we start with deep learning foundational architectures, we will be using open source models. Yeah, amen to that. We need to move away from OpenAI and not give our hard-earned money to Microsoft. We have a cut of which one? Oh yes, yes, lots of them. In fact, today's paper. So why don't you wait for the afternoon paper reading? It'll be fun. Guys, are you having fun? Right? Yeah. So look at that. Now, suppose I say, consider all the stores. For each store, return the name of the store, the state it belongs to, and the total store sales. Return the results in the following format again HTML like right and see what it does it goes the queries get more and more complicated now look at this query now this time around right do you notice that it's getting, it's smartening up, right? And from that, it comes to something and then it says, oh, we need to do this. We need to do this. It begins to do all of that. And it comes up with this. Do you color yourself impressed? But then see, here's the thing. If you are with databases, averages are easy, AVG, try computing the median, you'll get screwed. Right. And yet, if there's one thing you learned at support vectors, I hope it is that don't ever trust averages. Why? I'll tell Alcuin, I'll state it with a joke. Statistician, an engineer, and let's say a doctor went to the woods hunting and they're all sitting quietly and they see a deer. The engineer shoots, misses by 10 feet on the left. The doctor shoots and misses 10 feet on the right. Now it's the statistician's turn. And he says, I don't need to shoot. On average, the deer is shot already. So never trust averages. More scientifically, remember, averages work only in symmetric data. And most data are skewed. In skewed data, it's a disaster to use averages. There is an example. I was listening to National Public Radio. There was an economist who has written a book. And she said, she was being interviewed, and she said that, you know, we all keep bemoaning that the economy is doing badly and we don't have money in our pocket, but she studied and she found that even in the poorest state of the United States, which I believe was Mississippi, but I may get it wrong, Alabama or something like that. still when you do a cost of living index adjustment with france it is still much more than the the purchasing power of that income is still much more than the french people so guys what is wrong with that i gave you the hint what's wrong with that reasoning hint what's wrong with that reasoning average why yes exactly so even the poorest states actually there are no poor in u.s the rich people are everywhere and they they hold most of the wealth so in though whichever state it was all you needed to do when you do the averages for there to be a few billionaires there and they pull up the average isn't it would have been better choice right asif come again please a median would have been a better choice region would have been better uh the most likely that also so you have to look at all of those you should quantify all the statistics what's the median what's the geometric mean the harmonic mean the mode mode, and so forth. And so what happens is that they give you some sense. And the very fact that the average is way out there should give you a sense that there is enormous wealth asymmetry, isn't it? And I mean, people write all sorts of nonsensical books, I don't mind that. But for NPR, which I used to, which I have a lot of respect for for for them to say all this and be impressed with it it shows the level of mathematical illiteracy in the country it's absolutely abysmal right just horrendous so if there's one lesson to learn don't don't go with median when the data is skewed first ask is the data really unskewed then only use median okay so now then only use average so here what we'll do do you think salaries in particular are ever symmetric do they have a bell curve distribution no if there is one thing we know in human history there is always always yes it's right ske, there is always, always, yes, it's right skewed, there is always inequity. As long as human beings have been there, even before money came about, the powerful had more of the hunting, got bigger share of the kill, right, always. What's that? Isn't true that the small country in England controls the entire world? Yeah, it's always been like that. Yeah, it's true at every level. So now the question is, okay, why am I saying all that? You know that MySQL will give you the average. What about the median? There is no median function in MySQL the last I checked. But suppose I pose you this question. Go find the median. But suppose I pose you this question, go find the median. Now what can you do? You know that your SQL tool will not do. So what should you do? You should create a chain of chains, one level higher. You use one chain, one agent to get you the salaries. Another one to find the median of the salaries. Isn't it guys? And would that be lovely? And so in a seamless way, how can you query a database and get the median, do the data science at the same time? You see it guys, and you can extend it by saying, make me a histogram or whatever it is, right? Or producer. And by the way, I encourage you to do that. And you can extend it by saying, make me a histogram or whatever it is. Right? Or produce. And by the way, I encourage you to do that. The one lovely thing that you can do is you can actually have it write matplotlib code and produce a plot for you as langchain. Right? Take this as an exercise. Extend this and plot the salaries and make a KDE, kernel density estimator. You know that, right? ML100. We've done all of that. Just emit out the matplotlib code to do that. And believe me, you can do that with a very small bit of work here. So we create something called a sequential chain right here is the sequential chain once again i've set the temperature to zero to have some level of predictability and i'm saying fetch the total oh oh i should have written the queries out separately um but i fetch the total sales let me let me do let me clean up the code guys a little better up query but this is dirty code oh my goodness yes i did indeed sorry i probably it shows because I was writing this code at 4 30 in the morning today this is unfortunately how busy I've become these days trying to get support vectors off the ground and Much better guys, more readable. And we'll say query when you do that see what it does first it gets a list of table then i should look at the schema of table to see what column i can columns i could use it comes to the table this is it sales right it says, all right, I should query the total sales of each store sorted by store sales, right? So it wants to produce the thing in sorted order, right? And so it produces this query, right? Total sales. It has put a limit by 10. I'll leave it as exercise for you to remove that, right? Then it says, Okay, I have to compute the median. Right. And then it says, Alright, that is easy, because it has access to the ability to do the median from a list, all it has to do is go pick it up. And it picks it up. Five, four, I believe, because they're 10. It sort of puts these two together, I believe. Now, this and this and this together. Oh, no, this is a medium. This is the medium guy. Okay. So it just picks out the medium from that. How many of you like that? Really good. It's really good, right? That is it. So this is it, guys. You can do interesting things. You could literally make it right for you, the pandas and the matplotlib code to create the visualizations and so forth. And many things. But I thought I'll keep it simple so that when you review it it doesn't feel overwhelming but you can imagine the potential of this a long chain library and how many things it can do with transformers how would this impact like you know what to do today like they should they should jubilate the fact that these things are imprecise. Like every time you ask them the question, it comes up with a different answer. So at least for a few weeks, their jobs are safe. Until there is yet another breakthrough that catches up with it. Yeah, I'm kidding, guys. No, see what happens is all those, they have deep expertise, right? Those database engineers, SQL, they have, they need to move up the food chain. They can't be doing the obvious things. They have to use this and then go up. They have to use these tools and smarten up. Yeah. Yes, and then that's why they are better than both. Yeah, he created the discussion started right over in the last week what we saw was when you were asking how do you say certain things in certain language, so it was constantly changing like the way you asked in Hindi versus in Arabic. That is right. So the base was changing depending on the language. Yeah. So Farhan, here's the thing. I haven't watched the video. I think, Kate, have you shared that recording yet? Which recording? From the last week? What recording? From last week. From last week? I have some sections of it that I can share. Yeah, so I haven't watched what happened last week. But just guessing from what Shalini did, here is the thing, guys. There is no doubt that at this moment these are stochastic machines right based on what like literally there are some people who are moody right based on which side of the bed they get out of they will be either uh have a positive outlook or a grumpy outlook on the day there's something of that with this large language models based on when you ask. But actually, I like to think of it as this thing, Dorothy. What's that story? Wizard of Oz. But I think then, isn't it like they rarely started with this element where they keep the context? No, no, I'm coming to that. I'm coming to that, Paran. Just bear with me. It's a long answer. So just like in the Wizard of Oz, Dorothy goes to the yellow brick road and finally gets to the wizard. And the wizard is pretty erratic, isn't it? From behind the curtains, you never can trust that answer, what it is. And it turns out that the wizard has really no powers. So there's something of that. Unfortunately, the wizard is very powerful here, but it is erratic and so it keeps changing its answers, having said that. Basically, like you know what like the problem was. How do you say, for example, I. Just an example. And then talk to. just an example in english how do i go home right and then talk it into food or whatever that's good right but you say okay how do you say it's done so instead of keeping the context of how do i go home for the same language will say something else and answering it absolutely so that is easily solved that is is very easily solved. What you should have done is not use the large language model directly, but made it a part of a lang chain. Now in the lang chain, I just realized as a significant omission, I didn't tell you about memory, memories. One of the concepts here is memories. So that it is forced to retain the context and always take that context in answering the next and the next and the next question so why do so um now that you guys mentioned that this is what you tried let me create a notebook for that it is a salt you can do that yeah memories is one aspect that I uh yeah yeah so you need to make it a land chain with memories that's it yeah you were speaking the other day right on this agent-based thing like all these agents working with each other yes it's all land chain yeah oh no no sorry uh not that those guys that the simulacra similar paper I don't know whether they use I don't think so they use, I don't think so. They may have, I don't know. They may have used Lanchen. They did not declare it. Actually, I have not seen their actual code, whether they use Lanchen or not. My guess is they didn't, because their project was done before Lanchen came out, or was coming out at the same time. So I don't think they used the thing. But the concept of agent has been there in AI ever since there has been AI. In fact, the word agent is almost endemic to this whole field. It's sort of central to the field of concept of AI. So who is the artificially intelligent thing? The agent. That's how people have thought about it. Even that paper is now obsolete compared to the land. Oh, no, no, no. Not obsolete. That's a landmark work. It's just that would you re-implement it today, including land chain, et cetera? Probably. See, that paper has many things. It was done using 3.5 turbo. 3.5. Now 4 has come up. And there are already YouTube articles that point out that the same work now yields even better results. So it has only reinforced the validity of what they said in the similar crap paper. With GPT-4, it gets even better. Yeah. All right, guys, was that fun? Could we go to the next one? Well, deliberately or inadvertently, it was leaked out by facebook once it was leaked out you can't put the cat in the bag again right it's out and running around and now it has led to a whole set of revolutions and uh for good actually because the open source community took it and ran with it, absolutely ran with it. And they have done such wonderful things to it. One of the papers we'll do today afternoon. They have just done wonderful, wonderful things with it. So guys, I will call in for a break because I need to order your lunch. I'm thinking veggie dum biryani and something like palak paneer and naan. Does that all sound good? Okay, let me go order it for you guys. Let's take a break. Let's take a... Okay, guys, before I do the break, I'm going to put these notebooks on your Slack before I order food. Please go install MySQL if you don't have it. Import the data, run these notebooks. So I'm going to make it a half an hour break so that you can do the whole setup. All right, it will take you that much time. Let me do that and then I'll order lunch and we'll take it from there. So folks, welcome back from lunch. We had a long break in which you got a chance to set up your database server, import the schema and run the Jupyter notebook associated with database queries. The lesson we learned is that you can ask questions from the database in natural language. Just as a database engineer would listen to you and would translate those things into SQL, what we are seeing is an emerging ability in the large language models to take over that role to understand that natural language and translate it into SQL. If you think about it, it is an exercise in language translation. It's more than that, obviously, because you have to understand the structure of a database, the relationships, and also have some understanding of SQL to be able to pull it off. Isn't it interesting that we have trained these large language models with so much of our programming languages, so much of our SQL examples and that, it has more or less figured out, not quite perfectly yet, there are still gaps in scope for improvement, but to quite an extent it has figured out how to translate from human language to SQL and then to retrieve the data. The second thing we saw is that there are things that you don't want to do in a SQL database. You want to do it using things, post process it. And we saw an example of using a math post processor to come up with a median. processor to come up with a median. So this should give you an idea of the possibilities. Now these are very real things. As I said, they're startups already in flight that say, give us your schema, give us the connection to your database and ask questions in natural language. And they produce the right, they retrieve the data for you and write the right sequel. And those things have gotten obviously those effort there is far more intense than our notebook, which is a starter notebook in this direction. So that is that. Now I will give you we will move on to another example. That example would be the next notebook, which is about QA, question answering. Can you give it, now if you remember, we did question answering with the sentence BERT and the sentence BERT models and we were quite effective, this is along the same lines, but weaved into LanChain. Just for convenience I've used the OpenAI, but I encourage you to use to directly use some of the open source models, I will be releasing you another version of this with the using the open source tools. For the sentence BERT, of course, we already saw that. We did even visual question answers. But now we will see how to do it using LandChain. Now to do that, you need some libraries. HNSW lib, of course, you're familiar with we did that in sentence, but one of the first sessions, you need chroma DB vector database, it turns out that the open source database chroma DB is fast emerging as a very popular vector database stores vector, why do we need vector database stores, the moment you do sentence embeddings, you get vectors, you need to store those vectors somewhere a very good place to store the vector is the chroma db there are other ones like pine cone and there are quite a few commercial ones also emerging but in the the truly open source one is the chroma and it's pretty good actually for our purposes And it's pretty good, actually, for our purposes. So here I'll take an example. As always, I tend to take some of the books that I, as a child, used to love very much. This is a really poignant story by George Eliot, a British author. Despite the name, George Eliot was actually a pen name for a woman, Mary Evans. And she is, in my view, one of the greatest authors who ever lived because of her large heart and humanity. If you go to Westminster's Abbey, you find the great people, all little plaques and mausoleums and so forth for the great people who died the great of england and of u.s also roosevelt's there is a place for there for him and from what i hear the new prince has been crowned the coronation has taken place in westminster abbey i went went to Westminster's Abbey. There is Newton and they are great people. But I went there to look for the plaque that is for George Eliot, for her. And there's something remarkable about the plaque for her. While other plaques say, oh, here was this great king, great and noble king, and this and that queen, and this and that scientist, and so forth. For George Eliot, actually, it's just a plaque that has one of her sayings. And I think that saying speaks more eloquently than any praise that anybody could have made about her. And to my knowledge, and I've looked up all the things in Westminsterminster abbey carefully hers is the only plaque in which her words support rather than someone else's eulogy for her and so anyway it should give you a sense of how much i like this author we are going to use one of her stories that as a 15 year old i absolutely absolutely stories that as a 15 year old, I absolutely, absolutely was touched by and had a deep influence on me. It's a story called a mill on the floors about a brother and a sister, Tom and Maggie to level. You know this story? You did in school, is it? Oh, nice. Albert says that he learned it in school, mill on the floor. So I encourage you to read the stories, we are very, very human story. So, what we are going to do. Let's say that, and again, Langtion has loaders data loaders. It has a large collection of data loaders. you would be and this is something I want to introduce you to how many loaders there are document loaders there are. Do you see this long list of loaders? Let's go through it carefully. Oh, I'm Oh, my goodness. I'm not sharing my screen. I apologize. What am I'm Oh, my goodness. I'm not sharing my screen. I apologize. What am I doing? I forgot this. Okay. Any better? What am I sharing now? Okay, so let me to recap. I was on this particular one. Quick, quick. Yeah. So I'm going to talk about Mill on the Floss by George Eliot. So now it's there in Gutenberg. There's a few who are not familiar with Gutenberg. It is the world's largest repository of legally available pre-books. And all the great classics are there. Any book that has outside copyright, and copyright, I believe holds for a hundred years. So any book that's more than a hundred years old is present there. And it is now available. What is most convenient is for our tasks. It is available through a loader. So let's look at the document loaders in Langchain. It is worth looking at the richness of it so i'll randomly pick some look at this youtube transcripts think about it you want to get a youtube transcript literally you can get the text of a youtube video with one liner isn't that wonderful guys YouTube video with one liner. Isn't that wonderful, guys? You can get the video information using PyTube and so forth. And these are examples. And I just started from the bottom. The next one from the bottom is Wikipedia, that great repository of human knowledge. Again, isn't it wonderful that you could literally load documents, you can search in Wikipedia, programmatically and get those documents, just like that. Right, just like that. And you could you could do a where am I? WhatsApp, WhatsApp is very popular as a yes, you could get WhatsApp chat in the chat text. And you could query what in the world the conversation is about. Right. And you could literally load all the HTML from web pages into a document, scrape text from web pages into a document, obviously text from web pages into a document. Obviously, you have to be careful because it needs some post cleanup. But it does a pretty good job of it, right? And it's just a couple of lines. I don't know if you realize that this is a software that is in 0.0161 version. They are not anywhere claiming that they are even 0.1 right and yet it is so feature rich and this whole thing has just come about recently you can get content from any url unstructured url loader and it will go get you that right it will give you unstructured file any kind of a file of any kind it will just extract the content from it um and you can get that any text file for example the state of the union address and so forth uh and i'm just walking back twitter we all know twitter you could get your text the content from Twitter and as you can see the Twitter metadata and data, a terminal file is quite often used for configuration of applications. And so it can read terminal files. You can just ask, is this configuration present in my setup or on my server cluster? And things like that. Telegram is another social media thing. You could do a subtitle. I don't know what it is. Subrip file format is described on whatever it is. I don't know. But you guys can look into that. Stripe is financial software uh again i'm not that into it uh spreetly is a service that allows you to score credit card okay not not my cup of tea slack of course we all use extensively isn't it and so there it is right it is. And a sitemap, files and so forth. And it goes on, we can go on. I just randomly pick some useful ones. Chat GPT data, you can get college confidential, many of you are familiar with this. About it gives you information on 380000 so you can query in case your son is going to go to a daughter is going to go to college now is your way to programmatically ask questions which is the good college and how much would it cost little late yes and epub of course it can scrape through epub through files through files, through GitHub, through Google. And the part that I find actually very useful is the Google Drive, Google Cloud Storage, and BigQuery. I find them extremely useful because enterprise, we have a lot of data in BigQuery in my case. Google Drive, of course, who doesn't have a huge amount of files in the Google Drive? And so all of these are there, guys. You can do that, right? Not to mention that you can load any Hugging Face dataset, of course, right? IMDB, JSON file, Jupyter Notebook, right? If you want to treat a Jupyter Notebook as a data source, you can load that too. And lo and behold, it will get the content out of it. JSON files. So enough said on that topic. Now, we are going to go to Gutenberg Loader to load this book of mine that I like. Well, I didn't read it. But my favorite, one of my favorite books, Mail on the Floors. You load the data. Now character text splitter. Think of it as your tokenizer. What in hugging face you would call tokenizer. This is it. It will get you that it will break it up into texts together, right? So maybe I should show you what does text look like, let me, let me break it up here. And let me run this from the beginning. And let me insert here one. As you can see, it is made up of little bits of content, it has been broken up into it. This content is goes from here to here. Right. Then mostly in the beginning will be copyrights and so forth. But after that, it gets interesting here document page book first boy and girl outdoor outside the dark milk mill and so forth so that's where the mill uh part is love scene etc etc so you can see the content come come out at you right um if you want to say let's say that i want to go to the third one third three and then i can say dot page content page content and you could do oops sorry document object is not scriptable Oh, sorry. Document object is not script table. What is this? Let's see. Document. And this document contains dark page content. Let us see if I can do that. I'm trying this thing on the fly. There we go. We get it. And if you do a print. Actually let me do it like this, I find it easier to do display mark down. Much better right. This this gives you the table of content, Let me take some random one. 21. Let's see what that is. Look at this. So beautifully it gets. But as you can see, when it chunks, it chunks by size. And you get these little pieces of text. What do we do with the snippets? Why are we chunking it, guys? Can you guess why are we chunking it up into pieces? Why not feed the entire text? You should know the answer. Exactly, the token limit, right? So if you remember, S-Bird, we had a 512 token limit. If you use a big bird, it had 4,000. Open the GPT-4, I believe, is a 8,000 token limit or something like that, 8,000 or 16,000 token limit. So there is a limit to the number of tokens you can feed in for indexing. So there is a limit to the number of tokens you can feed in for indexing. So, no, actually, it wouldn't be GPT-4. It would be the ADA-002. ADA-002, I believe, has an 8,000 token limit. That's what the OpenAI's embedding says, ADA-002. By the way, you can download that. You don't have to go there and do it. You could do that. Now, what are we doing? We to go there and do it you could do that now what are we doing we are getting the embeddings from that text and where are we storing the embedding we are storing it into the chroma database you get an index what you are getting is an index then and then you're going to use this index to retrieve documents retrieved text and the embeddings. So you create a retrieval QA system question answer system from chain type of course llm is them change. Game type is stuff now this thing guys now I find at this moment, the library is still evolving I have never figured out what are all the chain types, I mean every time I figured out some of them more of them get added or something else happens right so i'm having a hard time catching up if you know a better way then let me know because i i myself like you all i'm still in the learning curve i think we are all in the learning curve so so i asked a question. Now look at this question. It's not an easy question to answer. I am saying. What were Maggie's most poignant childhood memories? You know, it is a. It's a higher level question. You're not asking for a fact where she where was the mill or where is this location? or what did x say to y which would be quoting verbatim searching and getting it do you realize that a question like this can never be answered by a search engine traditional search engine right it needs a lot of processing and it said fairly accurately maggie's most poignant childhood memories were of a struggle between her inward impulses and outward facts, eager life in the triplet world of reality, books and waking dreams, and her feelings of privation, which made it hard for her to enjoy the present moment. I suppose this can be said for many of us bookworms. Then I asked her another question. But observe it. It understands the text. Do you see this? It has made sense of the text. The next question we ask is, what makes us love this earth so much, according to this author? Right? Explain it with two paragraphs and the the interesting thing was when i asked this i happen to know the book more or less large sections of it by heart memory some of its most passages and there is a passage there that goes something like that that we would not have loved this art so much if we did not have a childhood in it it is a passage there that goes something like that, that we would not have loved this earth so much if we did not have a childhood in it. It is a childhood memories that makes us, pins us down to this earth. So the hips and horse and blades of grass and things like that. And so it seems to paraphrase that it says, according to the author, we love the earth so much because of our childhoods in it. The little things of childhood, like the sound of a gate door, the shape and color of a roof, and the sunlight on deep bladed grass, all have strong associations for us. The memories of these childhood moments stay with us and transform our perceptions into love. This is literally paraphrasing what she was saying. That is why we were we are able to appreciate the beauty of the earth so deeply. We have experienced it in its most intimate and formative moments. And those memories shape our relationship to it for the rest of our lives. I hope it does resonate with you. But more importantly, do you see guys, what is the state of the art of natural language processing today. I wonder what it will be the next time I teach this course. Because it's already achieving human like capabilities actually I doubt that most school boys would be able to write so eloquently in their answers to questions if this question came in the exam. What do you say, Abdullah? Yes. Was that before now? Yeah. Yeah? Yeah. Yeah. Yeah. Actually, there is a second paragraph in here with with with two separate paragraphs with let us say with Let us say, yeah, with with P as the separator. Let's try this now. Let's give it a separator. Oh, a QA is not okay. So after instantiated, I haven't run this part. Let me I think I stopped running here. So let me run from here chroma chroma chroma is good no i like it i like it because it's an emerging database it's open source you'd like to support it but more importantly like in my case i used to not use pinecone etc because i just felt it's all getting too commercial i used to literally maintain my own fast and uh scanned scan indices and manage them myself like literally add a homegrown database to manage it viviate is also open source yeah viviate is good there is another one qdran qdran i like that also yes yes yes yeah the good thing with qdrant is that it takes it has it has solved one problem uh when you search for things and it gets searched it doesn't lose relationship between things there's something very interesting if you go to the qdran website and you look at the way they are very graph theory based and they emphasize the hnsw lip quite a bit yeah but that's the same thing that we were doing in our class remember i said that search pre-search add add some traditional search, and then use a cross-encoder at the end of it. That's all it is. That's what Bing does. Bing is trying to weave everything together. That's right. But, you know, as you can see, I've spent my whole life with Linux and Java and open source things. So every time I hear the name of a commercial software i get hives allergic hives it's just a very polarized view so anyway so where will we just retrieve this and then uh so we are asking impulse and then we are going to ask this question. Let's say this time I asked it to give a separator and see what it says. See? Did you get two paragraphs? Yes. So register for my prompt engineering course promptly. No, no, but seriously, now, the thing, in my opinion, will be creating new programming languages, which are a hybrid of prompting and structured language. The old language, Java, I mean, I have done Java since 1994, right? But I think seeing Java, the days are coming to an end. the days are coming to an end now what is going to happen is all programming languages will have to be rethought and to leverage the l lms yeah or things like that but see the very fact that llms can emit out reams of code it means that it has some internal representation which is more efficient and it's just spilling out a more inefficient representation isn't it so why not rethink the whole space of programming languages so that we make more efficient programming languages more semantically relevant programming languages it's time to do that in my view so let us hope that in five years at this moment according to the the TOB index, the top programming languages are Python, Java and C. Let us hope that in five years, the top programming languages would be languages whose names we haven't heard of. Yes, that will be interesting. No, guys, everything is up for a toss. Like for example, what does what does a code coverage mean? What does unit testing mean? Everything is now up for a toss because in a way what these large language models are showing by being able to write all those test cases and everything for us. We may be delighted. One way is to say delighted. Wow, it's able to do that. But another way of looking at it is, maybe this is not the best way we should be writing code anymore. We need a much more succinct and powerful representation. So somewhat like the effort I heard, I hear Shalini was making in the previous weekend, trying to create a language. Yes. So guys, is it fun? So run this code guys on your own and see what you get. And while you are at it, when you create open AI, give it a high temperature so you get different results. You get a variety of results coming out of it. I'll put this updated notebook there. Then let's go to another one, which you will use in your lab, in your project, guys. Guys, today I'll also speak, give an hour to talking about the project. More, give you a breakdown of the pieces. I would have liked to cover at least one paper, but if a paper doesn't get covered, now one more thing, guys, I'm planning to cover at least two papers, open it to everyone, but frankly, my target audience would be you guys. Every week, I'll announcing a two paper readings. Typically, one will be Friday lunchtime and one will be another weekday lunchtime. I don't know which weekday. So how are you guys? Is that something reasonable for you guys? Would you prefer lunchtime or would you prefer early morning? Evening, so evening, some teaching. Namaz, yeah. Mornings are better. Mornings, I'm hiking, so I'll have to do it from the woods or sitting in the mountains. 10 o'clock. 10 o'clock. Or actually I don't mind like when I go hiking, sort of an in-between stage for me is about 7.30, 8 in the morning. I would love it actually sitting under a tree on a hill right yeah yeah see it's open to public but generally what happens is that you guys because i'll be talking about papers that you guys will understand so while it's open to public maybe three four people will come but the rest of it will i expect you guys to come to those because i'll be talking about large language models a lot. Lunchtime. Coyote Hills. Yes. Lovely. So you'll see me sitting there enjoying the bay, right? Not if you have you have the Starlink in your backpack. So it's fun actually. I have no idea. But oh my goodness, once you have starlink, you feel so free. It's such utter freedom. It's okay, reasonable. No, no, barrier latency is bandwidth is here. What they've done is oversubscribed. So sometimes it becomes very slow. It's true. But trust me, if you're doing it at 730 in the morning, it's pretty good. So a lot of the time, like I would in meetings, and people will say, we hear birds in the meeting. Yeah, yeah, yeah, because I would like to continue the momentum of paper readings guys it's important to keep reading papers, the latest breakthroughs as they come. Right. And for those of you who miss i'll also record it and post it on youtube on a private channel in other words it won't be public it won't be accessible to everyone right yeah so guys whisper now we go to whisper you need to do quite a bit of install here you You need softwares like SoundFile and Librosa. But reality is, this is again, today was all very installation heavy. When you do it and you try to run this notebook, you'll notice that it may still not work because your particular machine, especially if it is Windows or Mac, God knows what else it will require. I have no idea. But this is what it is on Ubuntu. So by the way, this IP address that I'm connecting to at the top is the Ubuntu machine in my office that I'm connecting to that, that the one that Sukpal built. Is very punchy. It's really nice. Actually, I'm revisiting my thoughts on yesterday's machine. I want to make it a beefier one. Yeah, we need to put some more in here. Yeah. Okay, guys, so let's, let's look at this. See, when you do speech to text, it's always been a problem. I tried talking to Siri. Yeah. With our, at least with my very thick Indian accent, half the time it doesn't get me right. It says, if I say, let me call my friend Chanda, so it will suddenly start saying somebody else completely. It picks somebody else from the address book. It happens all the time. I think it happens to all of you. But try that with Whisper and you'll be absolutely impressed. It beats Apple, Google, everything. Especially with Indian accents, it's a relief to find something can actually translate Indian accent or my accent my accent is what half Indian half Nepali no uh speech to text yeah but it also does language translations as we'll see so you may the beautiful thing is that somebody is speaking in French and you may be you can see the text emerge in English isn't that Nice. It doesn't do for you. speech to text yeah no I mean yeah So what they do is it is there, you have to tokenize it, but then you feed it to the transform and so the paper is very beautiful actually I want to cover the whisper paper. Right either today, but today I wanted to give in the afternoon to going over the project, step by step, if I don't do it, it is possible that I may do it tomorrow afternoon. or some point very soon, but we will go through at least a dozen papers in this month guys in the month of May. i'll go through a dozen papers and keep the momentum, so that when you come to the deep learning course you're absolutely ready for it right let's go at least to say how many, by the way, how many of you are coming to that course. Deep learning, right? These are the foundational architect. Actually, the course is renamed foundational architectures, but yeah. So very natural bridges. Listen to these papers because it will get you mentally ready for that course. That course will be very much focused on the new breakthroughs and the new thinking. So anyway, we'll go through that. WSPA. So that is WSPA. We're going to load some data set. So by the way, use the Whisper large model. It works better. Obviously, don't use Whisper tiny. You guys all have reasonably good laptop. So these are some test audio files. You can take an audio file and you can even play it now, I suppose I didn't play this, but you can play this and a sampling rate now one thing I will tell you about sampling rate. whisper prefers a sampling rate as far as I can make out of 16 kilohertz. So what is sampling see sound is a continuous waveform, isn't it? Analog continuous waveform. But you have to digitize it. So the way you do that is you chop, chop, chop. You go in there and say, what is it now? What is it now? What is it now? What is it now? And you keep picking up the values. But how often you sample from a waveform is the sampling rate. sample from a waveform is the sampling rate. Yes, signal processing, so 16 kilohertz is the preferred thing that I can make out, but generally when people record on their laptops, etc, it tends to be eight kilohertz. If you get eight kilohertz, remember to upscale it or even lower, but remember to upscale it. It's easy to upscale it. Make lower but remember to upscale it it's easy to upscale it make it 16 kilohertz yeah so uh do that and then here we go we are going to so then you get the input so what does sampling etc give you ultimately you'll get features you need to generate tokens out of it predicted ids generate token ids how do you do that model.generate is what it is exactly the same as tokenizer.tokenize isn't it pretty equivalent to it you generate the token ids and then what do you do you need to decode now you need to give it to the transformer so if you remember text processing pipeline in hugging face was tokenizer model right followed by your screen ahead for classification or whatever it is that you want to do at the tail end of it. Those are exactly the same architecture, except that the tokenizer is coming out of the sound forms, the waveforms. By sampling into the waveforms, you're tokenizing it. Once you get the token, you feed it into the model. What will it do? Model will do. What have you screwed at the end? For each of the bits of waveform, it has to produce a text yet, it has to produce into the dictionary all it is is a classifier it. is going into the dictionary using a softmax and saying what word is it isn't it and word by word by word it you're getting a sense of the. you're getting basically a transcription So if you look at the transcription guys uh make sure you understand it it's nothing but classification basically you're using a softmax into a dictionary into a vocabulary right and the transformer is doing that for you with the softmax head screwed up screwed to it that's it that's it that is it it. But the thing is, obviously, it is not just a vanilla transformer. Otherwise, it wouldn't. So there is more to it. There's more depth to it. The whisper, the whole whisper paper will do in particular. So there's more happening to it. But the basic idea remains the same. The basic architecture remains the same. Albert. No, in this case, it's inbuilt. It's inbuilt. Yeah. But if you want to handle it, you can always handle it. You can pick it up and do it. It's always fun. See, with all of these things, there is a lovely website called a paper with code. Paper with code. I would strongly advise you to become friends with that website. Whenever you read a research paper, if at all possible, if time permits, well, time is the scarce commodity these days, but if time permits, go to paper with code and read the code behind the paper. See how they have done it, right? It's not that hard. Once you, maybe the first three, four papers code, like the neural architecture, it'll take time. But actually, well, let me not get the cat out of the bag because the foundational architectures, that is literally about, you'll see that I'll make you big friends with paperweight code. We will be using that site a lot to read the code behind the architectures and walk through it. That's what that course is about. So there we go. Now, this is Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Humorous statement. This is it. So, and it is not so impressive because you haven't heard the audio, but if you should, I leave that as an exercise for you to hear the audio but what is more interesting actually is the second part you can listen to french and transcribe it into english because if you think about it if it is just a classifier into a vocabulary you can train it to classify into any language you want isn't it and so you can train it to classify uh straight into english from french waveforms yeah and that's what it is doing. You absolutely got me. See what happens is that, as I said, if it was a classifier, the problem would be the words would be jumbled up because you don't say it the same way right the moment you talk french so then there is a translation layer here so uh what happens is there is actually a decoder the auto regressive part to put it in the right sequence is there attention and decoding and all of that is there right so more is going on there. And pretty much, now you know where the complexity of the whisper comes from. That's that. Of course. All of these machines come built with that. They will create audio waveforms. They'll create MP3s, they'll create whatever you want. That technology is beaten to death. Very, very old technology. I mean, we have been able to do it since 90s. See one thing, look at this. If you look at the line 10 here. Mozilla foundations corpus is there. Right. So we are loading the data set. All right. But whisper beats at all at this moment. So guys, this is it today, because all of these things are set up, it will take you a little bit to make it work on your machine. How many of you have gotten it to work on your machine completely? So please, it is working. Okay, good. Tiny one. Okay. Okay. Okay, good tiny one. Okay, all right. So so guys, you now let's talk. What i'll do is i'll give you guys 20 min to get your head around it last 2 h. I was going to discuss at least one paper, but let me keep it for the subsequent days. Instead, let's talk through the project architecture carefully, because I really want you to take the projects seriously. Do guys by doing you learn more. Now, the ball is in your court. Do. 20 minutes break and then we'll start. In the meanwhile, please make sure you run this lab notebooks completely. Those of you who are remote, would you like to ask a question or have something to add something? Dilip, is it fun so far? Hey, how's it? Yeah, all good. It's working on your machine, no? No, I haven't finished everything. Okay. I've gone for lunch. Nice nice you missed out some good biryani and anil anil is online yeah i think so yeah he used to love it he used to absolutely love it Absolutely love it. Hey, Asif. So this project, right? Alexa does similar stuff with just a simple query. So this has to be that this is handling a much more complex question, right? Yeah. In fact, we are in the next generation beyond Alexa. Dilip, if you think about it, whenlexa started out there was the concept of intent right if you look at the alexa api you associate actions to intent look at the alexa api it will say register your register your actions against well-defined intent. What are the keywords or trigger words for the intent? Like tell me the weather, Alexa, things like that. Now, and you can literally see when that API was created, the NLP, the state of the art NLP were things like spaCy, doing a very good job. But one of the pursuits in linguistics was, computational linguistics was, the extraction of intent, the parts of speech and intent extraction. And you can see that core foundational ideas, those kinds of ideas there in Alexa. But I think we have entered a new world now with the large language model. So my feeling is that all of these things will go through transformation, big transformations. And they must be already going through it. One could imagine that the research labs at Amazon, at Siri, and all of these, Google Assistant, they're all working furiously to adapt to the new realities. But the fact of the matter is things are moving so fast that actually you will be, when you do this project Dilip, in a very genuine sense, you will have a leg up on all those big guys because it takes them time to evolve. Yeah. The example that you gave about computing the median, right? I mean, Alexa can probably spit out something that it already has stored here. We actually will read something, actually do some processing on it, give a result out. I mean, that's just amazing. Let's test it, Dilip. Let's do that. If you have a cell phone, ask at Siri, which is the median of the first 20 prime numbers it can tell you? I don't know. I've never tried it. Can somebody please try it? On Siri. See how well it does it. Maybe it has a database of those prime numbers, it will quickly look it up and tell you it is possible, but. I would consider it's on a moderately hard problem for it. It will probably Google it up rather than solving it itself. It will say here is what I found and then it will say something. So Shishinde is trying it. Is going to search. Yeah, exactly. So Shushinda points out that if you ask Siri that question, it goes about searching on the internet. But think about it, Dilip, really in this lab, you already saw beyond that, isn't it? Yeah. You created a land chain that goes way beyond that. So that is it. You guys are ahead of the curve, ahead of this enterprise-grade production systems at this moment. The world is changing really that fast. Really awesome. Let me answer. Abhijit has asked here in the class, very good question. See when you want to go to production in an enterprise environment there are many considerations of reliability and engineering how how ready is langchain to go to production here's the answer people are using it for production now despite the fact that these people are saying no no no we are 0.0.161 version it proving very bug-free and fairly reliable. It's a rock-solid code. It's a good code. It's a good code. Having said that, the fundamental problem with large language model is the fact that you don't get deterministic answers. You get stochastic answers. So people have to do a lot of prompt engineering to get it right. But are they taking it to production? Very much so. There are a lot of successful startups that are launching products, which are gaining traction. Yeah. And companies, I mean, not even that, even old, like, I mean, you wouldn't think of Deloitte, for example, as one of the technology forefronts. They are the people who build solutions for others and do a good job of it, but they have invested into sort of almost like a r&d effort, a billion dollars. Right. People are spending and when you see what they're doing. They are all doing these tools. A billion dollars, a lot of company for just one company, a lot of money for one company to throw. But that's what all the other companies are doing also. So you can imagine that there is almost a trillion dollars worth of investment going into all of this. That is why things are happening overnight. I wake up every morning and I'm like, oh, I have so much to catch up. So much has happened overnight. You go to sleep watching something and literally i do that and you wake up in the morning right i come back from my hike and there's new things waiting is that fast but can we use it for production yes you can use it there's a the problem is not that the problem is the cost of inference. Cost is too high. When you put a GPU cluster of your own, and you see, if you use OpenAI, they'll ruin you. They're very expensive. Open source is catching up. But even then, the one part that people haven't solved it, even if you use open source model, you're still hostage to NVIDIA. And NVIDIA is beginning to charge you 10, 20, 30, 40,000 per chip. And that's a huge problem. That's a huge problem. AMD is trying to catch up, but still not able to. I mean, they will catch up maybe in a year, but even then it will be a duopoly between Nvidia and AMD, because if you look at AMD, they're just 25% cheaper than whatever NVIDIA chip is, equivalent is. They did. Wow. Oh, I own a lot of AMD chips. My wife will be very happy to hear that. AMD stocks. I told her that in the long term. Yeah. Yeah. So she has been saying, you told me that AMD is a long, long term. AMD will do well. And so we put in money years ago and she has been waiting for the day when my prediction would actually come true. So what you're saying is it has come true. Good, because for years it has been just flattened out. Good day, guys. Nine nine. Yeah. All right, guys, let's take a break. But after that, it's all projects. Today, I kept it lightweight because see, I actually took out some of the labs. The idea was that if I give you all the code, then project is nothing but putting it together, which is no fun. Some things you should do on your own. Oh, this one, the two, three good ones. Unfortunately, they all charge a little bit of money, but they're tiny bits of money. What is it called? This fellow, Praveen, are you there? Praveen pointed out, I like that you there? Praveen pointed out. I like that one very much. It's pretty good. 11 laps. Exactly. 11 laps. I would encourage you 11 laps. Yeah. Laps. 11 laps is pretty good. Text to speech. Yeah. The video one is just good to go with stability. And there are a few others, but go with stability. Text to speech. Yeah, and you can be very particular, you can say, say it with a strong Nepali accent or strong Tamil accent. It will do it for you. I mean, of course, you'll have to record your own speech for it to recognize it. But once you give it snippets of your speech, it will do it. Stability. Stability AI is for image generation and for video and so forth. We do the many ones. It's hard to tell. Actually, anybody has a recommendation which is the best one for video generation. Yeah, you can try those. Try the open source ones, guys. Video open source is good enough. Text to speech, open source ones haven't really done so well. At this moment, it is still the commercial ones. But they're reasonably cheap. Anyone who took my last deep learning course in which we did NLP during the pandemic? I think Avijit, you took it, right? You didn't take it. Anyway, Albert, you took it. Oh, Patrick, you and Sukpal, both of you took it, right? Yeah. Isn't this course completely different? Yeah. All right, guys, I'll stop the recording. So after that, we'll just discuss the projects after 20 minutes. All right, guys. So now in the last hour, we are going to talk about what we were leading, what I was leading you towards the entire course. The goal of it, of course, this course, which is highly practical, was to create something that is truly next gen. It doesn't mean that we have to make it production grade to take traffic volumes in the millions, but it should certainly be a leapfrog over current technologies. And the beauty of things is that you can actually do it in small groups. So the first thing will be, the first step is, oh, why is this here? I don't know. Give me a second. I seem to have brought some clutter here. OK, and my screen is visible, isn't it, guys? OK, so the first step. Most important, form your team and give it a name. I would strongly encourage you to do it, right? So whatever the name of your team is, have you guys already talked about and formed your teams so far? So let me ask, Albert, you are teaming up with? So let me ask Albert, you are teaming up with? Yeah. Patrick? So you're going, so Albert. So for example, Albert is going with Mr. Qazi? So, and Albert. Albert, Zaheer, Farhan. Qazi. Oh, I haven't seen Junaette in a while. Okay. So this is that and this is team one. What's the name you want to give your team? Ask chat, JPT, what is the name that's better than city? Okay, you have to name your team guys quickly and Patrick you have it. Patrick, Masmi and Shalini. Abdullah, you too. Okay, give me a name for your team. Give yourself a nice name. How about you, Dhwani? Dhwani you haven't found anyone at all guys those of you who are remote anyone wants to partner with dhwani you you will You will form the Dhaani, Abhijeet and Abhijeet and Karshish, would you like to work with Dhwani? Sure. Yes. Kashish, is that okay, Dhwani? And would you like to pick one more member in your team? Yeah, sure. Anybody that doesn't have a... You want to go with that? Okay. Yeah, that's perfect. Oh, you guys are likely to be the first ones to finish your project. I think it's a power team. Okay. So we have three teams so far. Let me ask Sukpal, who are you teaming up with? Anyone is fine, sir. Sukpal, you are here. Dilip, you have dropped off. Jaishankar, how about you? Sukpal, Jaishankar, would you like to pull together? How about this? I make Sukpal. You need four or five? No, five is too much. How about this? I make Sukhpal. No, five is too much. Jaishankar. And Dilip. Oh, the first team has five people. It's a bit high. Junaid, Albert, Zaheer, Farhan, Qazi. Yeah. We have 12, 13, 13 16 16 people at least yeah that's the trouble no you guys don't want to be with jared he'll start doing everything himself yeah he he likes to do so i'll remove janet from that list and janet actually the same thing is true for shashinda he's going to do the whole thing himself i know we should kick these people out into separate teams yes sir individual. So you combine them into one team, and they they're like the meeting. Yes, they're not any another. Can we all have half of Dennis? Okay, so, Albert, you'll have the lead in that. Okay, i'll put Dennis there. Now, I put Junaid in a separate team. Let's see how it works. Yeah, I'll put Dennis in your team. Okay, guys. So, we have the teams. Okay. dennis yeah i put dennis in your team okay guys so we have the teams and okay now let's move forward guys i need a name for those of you who have formed your team please name your team dwani you get to name your team you abhijit come up with the name right away rashish right away. Rishish, Sushinder, four of you, quickly come up with a name. Phoenix. Yes. Phoenix. Kazi, come up with a name quickly. Pacesetters. Setters. And Adwani abhijit. Sukpal jai Shankar Dilip. What's your name? So while you're still here, Jason is also gone quite. Yeah. Yes, sir. I'm given name. What would you like to name it? You name it, sir. Doesn't matter. you name it sir doesn't matter i name it delete is not online no i don't see he just dropped it seems okay i'll give you some time to think so quiet. Plenty. What page set as to T to be. Oh, okay. Oh, you're with Patrick. So from Phoenix, you want to rename it to T to be. Hmm. Okay. you want to rename it to T to be. Okay. All right. And money abhijit. Sushant the cash. Any good names guys. I hope all four of you are discussing. So, Paul, sir. No problem. And so only unnamed team so far is Junaid's and Abhijit's. Dhwani's team. Dhwani, Kashi? S-E-D-O-S always for whom? Jeanette, who does? Okay. And okay, so. All right, guys. So while you are still thinking of a name, let me now give the interface. The main interface guys will be just this. Imagine an interface that is as simple as this. You can make the interface. The interface. Is conversational. It is conversational, the only thing you should be able to see is a button to press for the microphone. A button to press. It should have the following abilities. Ability. Search. Wikipedia. Articles. Search. Archive. Papers. Search. Gutenberg. Search Gutenberg documents. Gutenberg books. Right? Books. And you can pick. If you want to limit it, you can limit to to only 100 books if you want. Right, but there's no reason to limit it because I'm giving you a lot of computer sources and search session that for you, it must search your repository. Then you should search. Search the web. Right, whether it must be able to do the weather a database of medical notes. This is a contribution that Sukpal will make for everyone. Yes, Sukpal, you have to contribute this. You're ready? Medical notes. Open source one. you're ready medical notes open source one first right patrick and sukpal you're responsible for contributing this right as a mysql dump or something like that so the thing is you should be able to find the answer from this something postgres dumpster postgres postgres Postgres dumpster. Postgres. Postgres. And instructions to people on how to do that. So, guys, do you notice that we are developing a lot of tooling ability should have the ability to do math. It should have the ability to do math and Right, it should be like see it should have all of these abilities. Are we together and you and a three more of your choice. So now each team gets to add three more abilities of their choice. Are we together? You have to be able to do that. And I will release some test instructions, some test prompts for which it should be able to produce an answer. So I will release only 10, but there will be 20 other prompts which I won't show you. And the whole question is whether you are able to whether your machine is able to do those 20 prompts right which you won't see yes there's what's that any hint No, no, yeah, yeah, guys do this properly because then it will also amongst other things side it will baseline you on how well you can make prompts so when you learn about prompt engineering you will have a context you'll have a context to think about it so it must have these abilities then. Then the output. Lots of abilities are there. Look into tools. Look into Hugging Face tools. The tool section. The line chain tools. Line chain tools. I think. And oh, search YouTube. One more thing I forgot. Search. YouTube. YouTube. Right. and oh search youtube one more thing i forgot search youtube right so now this is interesting if i say find me a good something a youtube discussion you should be able to find the youtube video and get its transcript and find an answer in the transcript. Do you see that this is not an easy thing, so that is why I'm saying, guys, this is a collaborative project, one person cannot do it. First. Find the. Right. You. Find the right YouTube videos. Then search their transcripts. Answers. Output. The output. The output must contain the following, a, an essay as answer, answer in the format TLDR, summary, right? d r summary right then at least four paragraphs of text with right optionally with. Optionally with section headings. Optionally with section headings. Right. At least four paragraphs of text. B. Image. Unique image. To go. With it see. Unique generated image. See. Image found in unsplash that is appropriate to this. And D. Speech. Rendering of the essay. And finally, E, optional, but easy do it, guys. Only E optional, but easy do it guys. A video of the entire response. A video generated. So guys, I'll give you a benchmark. How would you feel if I told you that if you really were once you master it, the second time you do something like this, you would actually finish the entire project in 20 hours. It's not that hard. But because you're doing it for the first time, it will take you two weeks as a team. Yeah. But see, the whole idea is that once you do it right it becomes yours now next time it becomes very easy right and when you look at this if you had not taken this course and had given you this product specification would you even believe that you could do it no but now i hope you at least feel that as a team you can do it in two weeks isn't it that is the thing guys it's really worth doing put your energy into it and remember my doors are open any day you can walk in with partial results or ask questions and come back and i'll be there to help you right i'm going to codify this into a document and post it on slack properly so any questions guys let us think through how much time it will take to do each of the piece. The UI, the final thing is UI can be done in. You can do the UI. So here is what I'll give you a UI. Done in either of this, any of these, you do the ui in a streamlet be a grad io right if you so wish you you feel like doing it in dash or something like that etc whatever you want for plotting and fourth you can do um is literally react js or angular if you so wish right d right yeah now you you know that Google has released a very simple UI making framework. What is that called? What is the Google's thing? See, even, and Mac has come up with, Apple has come up with a very simplified way of making UI. What's that called? Yeah, Flutter is one and the second thing is sir microsoft has one too right power something ah microsoft one i don't know i i i would love to hear about it i don't know but i know that flutter is one and apple has something see apple's new ui is called what what is that the ui making framework swift hi that is it so you have a choice to do all that you You can make it for mobile, right? And see guys, this would be really good if you make it into a mobile. It will be launched from here. Server will be here, right? As a microservices. But imagine the sheer beauty of it that you are seeing it, your app in the app store, Android and... Yeah, but so Swift has a much simpler version version to make you I think it's called Swift UI. So it's a framework that's even better than Swift faster than Swift. Right? What is it called? Okay, I'll remember something. Makes it very fast. You can just literally in an hour create any iOS-specific app quickly. Right? So this is it, guys. So you can do that. And, gee, those of you who are insisting on cloud-specific technology, if you do it in Firebase, that too is fine. Firebase would be GCP. Right, right, right. So now it's become the whole framework database plus UI building framework. So use any one of these guys, use any one of these. Right? Google. It's very good. You can create you like entire end to end applications with it. It is. You remember Kunal? Kunal's entire startup is done in Firebase. Yeah. Yeah. And your microservice, like if you, when you do the microservice, those of you who are not using the extremely directly just to do it, you should do your microservice using a fast API or you can use flask if that's what you're more familiar with or if you want to do some of this in Java, you can use. Quarkus. Or a spring boot. Come again. Moreland. More than. Monolith. Oh, goodness. So, guys, you have a pretty wide degree of flexibility. I'll guide you through each of these. These are things I'm more or less familiar with. The Swift UI, maybe not so much, but I'll try to. And yeah, so there you go. Right. One of these abilities that I hope one of you guys team pick is graph, creating a knowledge graph out of the things that you encounter, right? Because that's a very powerful navigational construct for knowledge. Absolutely. Absolutely. You can do that. So guys, do this and then tell me if there is anything you're not ready for after this. Does this sound like a fun project, guys? Yes. Get started. Get started. And it shouldn't be that I'm the only one who's finishing the project. There is a prize for winning. It's good. There is actually a prize for winning. And it's a good price, but you'll find it once you the winning team gets a prize. Right. So well, that is it, guys. Any questions? Any questions from anyone? I think there's still one team that has to name itself. And that team is Dhwani's team. Did you guys find it? Shashanta, Dhwani, Abhijit, Kashish. Did you find a name yeah i'm trying to reachish. Do you have any name in mind? I don't. I was hoping one of them did. Think of something. Maybe you guys can outdo Alexa with Alexandria. I'm good with that. Yeah. Okay. that yeah okay so i'll call your team alexandria good guys so i'm going to send out notes of this project right away i'll use the next hour to write up good notes and post it on the scope of the project right and let's really interact guys two weeks let's really go at it and make progress and do show and tells and post screenshots of what you're building and have fun That is it guys. That's it. What's it? I can't. You have to be louder. Are we reading a paper? Not anymore. There's no time left stuck here because the sql i have set it up so the database created everything created here like the password did you try the password yeah exactly login with that password to verify it did you do flash privileges yes so now what you do is now click on quit. Now do mysql minus u. Whatever user you're using to use root connector. I'm going to speak on the. Oh, good. You are one of the few people who is using Ubuntu. So that worked. So now go here and see what's the username password you have in your same. So root user and same password. And so, when you run this what happens it's thing that it's not able to connect local host because you have given 127 you have to replace that word I localhost I did with localhost also with localhost it was not working. Did you create the database code code? Yes. Open up, open up a client. Just go back to your shell, say use. Now just to select count star from employee. So it's there. Yeah. So the scheme of the things that we installed. So I think i'm pretty sure that a pie my sequel is not installed. We exit out of that. You do a pip install by mysql almost surely you didn't install it i believe i installed it through uh through you you did already i installed this because the lag time was missing also I installed this because the language was missing the message that it is given this must be something minor will filter. setup is always a headache. yeah let's look at. Come again. I take pages from the printer. I can't connect to my sequel server. Server on password yeah, this is a problem name or service not farm it, so there is a there's a there's a a in the syntax we have something minor going wrong let's go and see what's wrong this is easy to fix it's shopping i think create let me see if my sql username at localhost at food mark I was at local house. This is exactly the way I'd given it. Yeah, and you're using a route in this password is the right password. That's the password I use to log in. Are you sure you're still using this password? Let's do one thing. Let's not use route. Where are you? Give me the shell. Okay shell okay yeah let's do this oops All right, guys, the course is that today it's over. I'm going to give you the write up on this. So if you guys want to drop off, those of you who are remote, feel free to drop off. If you want to stay, I will be here for another hour. Yeah, it is. It. Yeah. So. Thank you. The logged in is root, how come you don't have a privilege. Okay, Let's try. The route is always a little tricky. Let's check it out. Localhost. That is not required, but might as well add it. No. I will type. Oh, it's a different error now. It's a different error. Yeah, validation. Oh, you forgot to give the llm type create but uh and toolkit sql database toolkit now this is okay database db so let's do this let's make sure that we reach this far at least db do i split it i edit split split cell okay let's run this only lanche database okay sql toolkit db is equal to db do i install something on the sql because i think i don't know if sql database toolkit what what should i install for that nothing this should have worked because lang cheng was missing validation one validation error for database to look at l l m field required okay let us do that this should not have been true but oh sorry what did i do how do i decrease the font size of this control minus minus font size of this control minus minus. How do I zoom out of it? Yeah, good. Let's first do this. I don't know why it's behaving like this with you, but let's do that. Just leave it as that Oh, that is your real problem. You didn't install the OpenAI key. Where is your OpenAI? Remember I asked you to install your OpenAI key? What it is is go to your OpenAI account, OpenAI account. This is your key. Do you remember where you saved this key? Oh, that's your problem. We can create a new one, right? Yeah. Let us just call it support vectors. See, remember that here this is for the lab. And right away we'll go and put it in. Oh, you don't have to. We get there, we're pretty close. And that was the only reason because your open API is not yet set up. Okay. Minor things. And I think before that it was a root user should not be using root user. Generally it's something or the other. See, one of the first things is on your machine, probably security is still enabled. Developer machine, this never should be security. Just disable all security. That's the first thing I do. Because see here, the way I enforce security is, I have a very strong physical hardware firewall at the fiber, so nothing can ever come in. Then inside, everything is completely unsecure. Because it's dev, it's not a production environment here. And so we go nice and so kate export open a high sequence Done. Let's go to your notebook. Where is it? This one. Yeah, that I think I removed the sequel toolkit because that's not all oh could not find version that basically don't get forward because i think probably this is not the actual tip installed i just assumed okay let me just put these two and then oh there is no such thing yeah yeah there is no such thing it's part of the land chain yeah so whenever you do something like this it is always a good idea to put great So now we go here. Now, did not find please see Okay, what you have to do is stop this and open a new shell from which you start this. That is it just because if I do this one easy way to know that this is still a problem is to say export like percentage exclamation. dollar. When. I do this, nothing should come out here. Yeah, you notice that it's empty. It means that you just have to restart and come back. OK, yeah. But make sure that before you leave, all your issues are solved. Yes, I see. How do you like the project project is going to be good definitely i think that's we're going to give a hands-on forces to improve and build our own different me um um um Gracias. Vielen Dank. Thank you. um okay Okay. I mentioned always that strategy, but you're in a good place because you started the money. Yeah, because I have a PM you're going to install on it. some google's lms lms right which was not available on any other windows machine windows was only sorry to the only windows machine that i have is this laptop for teaching everything else is linux in my house at home i don't have any I don't have a single Windows machine it's been working 1994. 2004 18 years yeah it's been 29 years I don't think I've used ever. Yeah, I'm not. I'll move to my videos. Was it just like a guy talking was like generating calls? Generate, generate as good as you can. It's your creativity. What you can generate. You need like 100 GPs or whatever. whatever make it happen okay you could have it happen I think that's fine. I think you can do one more. But you know, you don't want to be in one of the three. So I don't want to be down here. You're going to get the science in the building. And that is like. Maybe. Or the first time. And you're going to be. um But I think you're fine. So yeah, we can we can just we can just input that. So it's not like we have those for example, but if they were the one this is the most important question. Then if you have a much longer one, yeah, I mean, it's better to like on the one more than one. You can combine it at the end. And then I don't know. Why is it so cool? Yeah, it is not production. But I mean, it's a. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. not import open a Python package, that is easy, you didn't have to open it. First of all, let's do this, make sure that the key is there. It is verified that we do have the key. The environment is properly set up. Perfect. It's a winner that this is true. Now what happens here is just, in story, getting started. Okay, right here. Sorry, I'm not wearing my reading glass. I'm having to guess what I'm typing. Okay this is Sanyal. Everything is working. He's thinking. everything is well just thinking oh you haven't paid them you need to you need to go pay them oh is it you have to give them a credit card it's very small the whole day you use like 10 cents or something so go get a paid account let's do it right now we want to make sure that this works okay enter your credit card number go into the billing section of open api open ai and finish this get passable to which one get passable portable password inputs no i have seen it but i haven't used this because i think it would help when people are going to see me so don't say when somebody else is okay get pass actually why don't you put a link to this I have seen this in people use it, but I never used it. I just want to share your notebook. Yeah, yeah can't hear you. You can also just create a Google followers within the. The web. Yes, so how do I make I have set it up? The person that I've said in the password. Done. It takes a couple of minutes for it to propagate, but yeah, run the cell again let's run this again this one yeah you exceeded your current code yeah yeah it takes a few minutes so go and instantiate the open api wherever i understand yeah this is okay oh you know what once you have changed the billing you have to get a new key go generate a new key and put it there change your gate file it's one of the nuisances of that actually i it hit me for the longest time i was wondering why is it not working and then i realized i had to create a new key so yeah so what you have to do is just create new key yeah Okay. Go to your kid. The kid. Just say, what can I do? You should just say Kate and it will go slash bash rcp. And at the very end, you will see this key. Save it, source it and you will be back. And you will have to unfortunately do that whole thing. You know, you started your car. So you so. Now from this shell start the GPT-R. Now you're on business. One by one, I think you have sorted through all this. And let us hope that by the time the deep learning course starts, we don't have to pay licensing fee to this. Yeah. still um And this is the new key value that's comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new key value that comes out. And this is the new one. It's still the old one. SK something something. Why did that happen? Just do echo. Open AI underscore Open AI underscore API underscore key. What? This is ignored. Yeah, this is ignored. Okay. So let me just close the domain. Just let me just close the domain. Okay. So let me just close the domain. Okay. So let me just close the domain. Okay. So let me just close the domain. Okay. So let me just close the domain. Okay. So let me just close the domain. Okay. This is the new one. Yeah, this is the new one. Let me just close the laptop. Just leave it on. Yeah, you can now just reboot your laptop. Yeah, just remove this. get a um You should run the Jupyter. You don't have to open that. and hit that jupiter j y j y t v r and hit tab pick one of the answers here that's it does it touch you Yeah. Thank you. So one thing. You're in action. The thing is working. Yeah, exactly. 1157. Everything is. That's why you can't wait for the insertion. Okay. All right. I think. Because it's not agent execution just region. doctrine. I want to fix it. Really weird a mistake here. But you see that it's all working now. Yes, yes, yes, yes. Isn't it magical? After all these years of SQL, you see a new way of doing things. A new way of doing things, yes, exactly. Wow. How do you like so you know like where you have this search Wikipedia articles etc right. So we were thinking we you know convert voice to text and then we send it to like chat GPT. But then how do you say, okay, like search these? Langchain. Langchain. These are all tools. Each of these is a tool. There's a Wikipedia tool in there. There is an archive tool. There is a Gutenberg loader. There is a, all of these things are there as tools. And then would we use something like a gpt code for anything that that is just your uh model the llm llm so you basically like search here yeah and you find out which of these are tools and which of them you'll make llm lms tools that's okay and connect via like agent the agent that you have created like the one you're using right now. Exactly, exactly, exactly. Which is that easy. So yeah, I was able to work the whole thing. The whole sequel plus even the this entire thing. Now each of these frankly, if you know what you're doing, these are 2 min each. what happened There is a problem and locally. Thank you. Appreciate it. Question. So I'm happy you took this course. I'm very happy. I was happy, like in the sense that I, you know, I totally forgot my coding. Now this actually forces me to like get back and I think it's critical for the next like 50 years otherwise yeah it's a new world and in fact all in a way right all those old coding languages will disappear in gradually so what i'm a bit confused about is so the terminology so we say llms and then there is this thing called like foundational models. No, no, there is that. We can use them interchangeably. There's a small distinction. Like the pre-trained models, see the BERT architecture is a foundation. When you pre-train it with some data, it becomes a pre-trained model, a checkpoint. And that checkpoint you find it. So that's a sequence of thinking. That's all it is. so when you take the deep learning courses you will learn a lot of foundation models they will all be transformed so people so they use it like it depends on yeah there's such a distinction but more or less and then when we say nlm so for example uh i saw one diagram it says like like you take text video images etc comes in the modern then you can do text see think about it this way what is a transformer that's why I put your attention is on you what is that what's the input to a transformer ultimately it is an embedding vector they go in and along with position vector they get concatenated and they go in. So now what can become everything can become, a text can become, numbers can become, a video can become, audio can become, therefore everything can go in and everything likewise can come out. So when you think it like that, that's why I gave you one reason I took you through the paper, then you're not impressed by this, you know somebody making a graphic or something it's obvious it's obvious. But then, so like for GPT-4 like any model. So you can just transform it's just the inside there's nothing but a transformer which has been made bigger that is. That is all. There's nothing magical. There's nothing . And lama and everything. Yeah, yeah. So lama is the distillate. Remember I taught you the distillation first? Distillable. So think the lama was literally a distillate of GPT. Because they drained it on the GPT. So teacher, student teacher model. And the same thing, if you look at the paper laminae that I wanted to do today, creates a farm of distillates. We talked about it last week actually. Last week when you were not there, we had like a brief discussion on that. Lamini is a lovely work because what it does is it uses what is called the ensemble, small things and it uses them as a cohort as a swarm yeah and it's just lovely the idea it takes the idea of distillate even further create very simple models and swarm it yeah very much like you would do random forest or gradient boosting are you also there in the ml 100 course or you're not? No, we said that like morning meetings. It's very hard like by the time 10 o'clock finishes here. I'm like done. I'll come with this the next one. Do all this. Yeah, next time I offer come. Actually, I'm offering in May. I'm starting here this May 20th. I'm starting another sequence of ML 100. I may be starting which is time from 3 to 6. That may be more conducive to you. I'm making it East Coast friendly. You know, one thing I was thinking, we talked about for you to advertise. I think it's like thinking of few things that you have so one is you know the name itself i know you like you put in support vectors right come up with a catchy name i know it's too deep yeah something more related to ai or something i think that would catch attention that would catch attention and then the second one i was second was like having a very nicer website. Because what happens is like, let's say, for example, all of us can, I do LinkedIn post, or LinkedIn post, right? When people come, . Yeah, I'm willing to do it. I'm doing it. I'm sitting with to create a new web server machine and completely start from scratch and do it from scratch. So we'll have two sites, one purely corporate and one just for teaching. So one for blogs and so forth. So multiple scattered and a bit more catchy names. So maybe Lama is taken. maybe malala is the next name yeah yeah yeah yeah yeah yeah initially i thought i'll take aisha but then i thought that uh may not be very happy. No, no. He'll be upset. He'll be upset, yeah. But AI or website should be like nice, you know. Yes, yeah. I need to take it again. I need to do it. Like in my work, because we created this thing called Apollo, like which was basically a multi-model database. So images and you know and EHR, everything. I had like this company, it's a UK based company, they did the graphics for me, like the whole webpage and everything. Okay, how much did it charge? It's very expensive. No, it's very reasonable. How much? I can find out. Help me with one thing. Mohammed, do you remember who works in Thermo Fisher? Get me back in touch with him. He said he can get me something, corporate training and consulting in Thermo Fisher. No, do this once. See what happens is like, people will go to the website, then they get an impression. Corporate has like a very professional impression. Right. Now our website looks too academic.                                            support, but this is my likelihood. Help me get there. Then when we do like LinkedIn posts, that said, so when people come to your site, then it's like attractive. It's attractive. No, I need to do that. I'm desperate to do that. I'm willing to spend the, the, the. See my old idea was website. My old idea was... What can we do on the other side of the website? Like what we did there. So you do like weekly or bi-weekly interviews or discussions. I want to do that. So somebody wants to... Vanu is a man. He wants to post a small one question and my answer to an interview every week. There is a radio show here. Someone does radio Zindagi. question and my answer to an interview every week so they also want to start interviewing me because they are on am oh interview should be on my website yeah oh that's it I see a very different thing with hedge fund manager of double nine car, Jeffrey Gunlock. I am totally not into money. Our Prophet said, don't eat the money of interest. The only thing I invest in is land and index funds. Because I have kept it in my mind that I have refused to eat interest. No, no, that is not his. But what he does is, like he goes to the CM, he has a deal with them.                               all right nice let's say you went to this talk yeah right which is okay i need the rights so i can post it to numbers no what are they doing organizers they have been my students here then you have like a place in your area you have like all your interns oh, then people get interested. That is right. So your website. Doesn't matter. You have interviews, then you have papers that you have written. Maybe we can write papers here. My papers are actually very well received inside the company, but I have to start writing public papers. So then you have papers here, right? You have these. Then when people come, there will be an impression of solidarity. This month I'm going to focus on that. What has happened is, I just started two months ago, three months ago. So I've been running as fast as I can. It's less than 100 days since the portrait is taken. And as a one-man operator, it's pretty much about a minute. It's okay. I don't mind that because one good thing that I feel fortunate is that maybe because I exercise and walk, I am high energy. I easily do, every day, I put in 16-17 hours hours i don't know if it comes across that i'm high energy yeah so i can go on thanks kaji help me out because businessmen i am absolute zero that's a big problem i have no business sense now I have to develop that. So like, we just say, we are targeting younger students.                                                 Thanks for pointing me in. No problem, sir.