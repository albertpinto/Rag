 So this is week two of our workshop. In the first week, as a recapitulation, we got an overview of the deep learning field. It's a broad field. We can do a lot of things. We can do natural language processing, we can do image processing, and we could do, you know, deal with tabular data and so on and so forth. And we got a flavor of that, a real quick flavor of what it is. After that, I talked about the way we are going to approach this course, which will be a little bit non-traditional the traditional way is you start with the fundamentals then you move on to CNN and then maybe RNN and LSTMs and time permitting transformers and so forth the way we are going to do it is we will start from the cutting edge so that we become useful rapidly in our labs. So we'll emphasize transfer learning, in other words, benefiting from other people's work, trained models. They are very applicable. Increasingly, these models are very, very powerful. You don't need to build a neural network from scratch and train it. Very, very often you can just take those models and just apply it to your problem with great efficacy. So that is transfer learning. The other problem that we have in machine learning is we often have a lot of hyper parameters. Now to recapitulate, hyperparameters are those things that you can't train a machine to pick up, to optimize on. Machines optimize during the machine learning process. They optimize on the parameters, but not the hyperparameters. So we have to do a lot of search, grid search, randomized search. These must be techniques some of you may be familiar with. I call them the basic techniques. But now the state of the art has moved forward. You cannot do grid search or randomized search, grid search because combinatorially it's not feasible. So suppose you have 10 dimensions or 10 hyperparameters, and each of these, even if you pick 10 values in, you're looking at 10 to the power 10, possible combinations of the hyperparameter. And you can't be making 10 trillion models. It is just not feasible. So we now have more powerful mathematical techniques to search the space of hyperparameters and even architectures to find the best hyperparameters that is called hyperparameter optimization. And often when we deal with neural networks, because one of the hyperparameters sort of implicit is what possible neural architecture should we take? How many layers there be how many nodes there should be in each layer right how many short circuits we should have which activation function we should use what should be the dropout what should be the regularization now i'm using words that you have you you most of you don't know but you will learn in due course of time. But take it as a fact that there are lots of decisions to be made when we craft an architecture. It's almost like making a building. You have too many choices. How many rooms? Which room will face which direction? Which will be adjacent to which? An analogy of that is in neural networks. So there are almost infinitely many ways you can design a neural network. Given that fact, the question does arise that in this vast space of possibilities, possible architectures, how do you find the best architecture? And that topic is the neural architecture search. Neural architecture search is the state of the art these days and it has been used everywhere. I'll give you an example. When COVID started, it started around, should we say roughly speaking, November, December. When it started, and now of course we have evidence that it might have started actually in early 2019. There are all sorts of scientific evidence problem, but we'll leave that aside. Let's say that most of us woke up to the fact that there is COVID in November, December. When we did, very early on people started applying deep neural networks to decide whether it could tell, looking at a lung x-ray, if somebody has COVID. To their great surprise, they found that yes, you can do that. Some companies in Taiwan and South Korea, et cetera, they even tried to commercialize it. Some research groups in India also looked at it. And the problem was it was not able to beat the state of the art accuracy that would be there from a chemical test. Like for example, when you do RT-PCR, reverse transcriptase polymerase chain reaction, quite a mouthful. It's an elaborate process that takes about 24 hours and in US, if you go for a test, the results typically come out in three, four days. But nonetheless, it is the state of the art. We realize that it's not the best at this moment in the sense that it still misses out 20% of the cases. It gives 20% false negatives and it gives 5% false positives. Not a nice thing, but that's the best we can do. It might have improved in the subsequent months, I do not know, but I'm quoting results that maybe a few years, a few months old. But when we tried to do it with a deep neural network, people found two interesting observations. First is that they could do it. It was close to the state of the art, but it did not beat the state of the art, which means that there is scope of improvement. Now the question arose, why did it not beat the state of the art? means that there is scope of improvement now the question arose why did it not beat the state of the art the two reasons popped up the early architectures were sort of trial and this and that which was remedied with neural architecture search and we'll come to that and this the the other big reason is there is just so little data on this disease. Catching hold of x-rays in vast quantities to train a deep neural network is hard. It's a data problem, not an architectural problem. And that is it. So now there is an open source initiative. There is an architecture called COVIDNet. We will discuss it in one of these Sunday sessions. It's an open source project now, so everybody can contribute to the research of COVID-19. What it does is it looks at your lung x-ray and literally in the blink of an eye it can tell you whether you do have COVID, whether you have some other lung problem or your lungs are perfectly healthy. So that is a positive thing. The not so nice thing is that it does not beat the state-of-the-art accuracy mostly because we have not fed it enough data and data is still hard to come by. It's one of the problems. Every single researcher in COVID, as you know, is sitting there begging for data together. So, but if you look at the COVID architecture, you will be absolutely amazed, COVID-net architecture, you'll be absolutely amazed at how complicated it is. And one look at it and you know that it could not have been just done by somebody sitting on a drawing board and thinking up a neural architecture. It could only be done through a neural architecture search coupled with experts then tuning it, changing it a little bit and adding things to it and so forth. So it has to be a collaboration between neural architecture search and experts guiding it. And that is the state of the art we have on COVID-NET. So if you guys Google up COVID-NET, you'll find a research paper and you'll find a set of data. I would love to see somebody take that up as a project for this workshop. You might end up making a huge difference to humanity. See if you can improve upon that neural architecture from the things that you learn here. So that is about automated machine learning. You can do automated machine learning by hyper parameter optimization in the case of or by neural architecture search or by something called meta learning learning how to learn how does a neural network learn it studies how it learns or any algorithm studies how it learns so there are all of these areas there's a lovely textbook that i have added to our book section. It's absolutely free and available on the internet, Hutter's textbook. I highly recommend that you folks, as you get interested, glance through it. We will cover it in depth at some point in time. So that is transfer learning. Now the last thing that I will cover in considerable depth is this whole problem of is this whole problem of explainable AI. As more and more machine learning models become complicated, the accuracy goes up, but they become completely unintelligible. Why is it making these predictions? We don't know. It is hard to trust that because we do not know the biases in the data, not because we don't trust the data, not because we don't trust the mathematics, but because we don't trust that there is no bias in the data. Data always has subtle biases. I gave you the example, the story of the military and civilian versus military vehicles. That story is much talked about in this community. I don't know if it is true or not, but it certainly has a message. Biases are hard to find. The other real case was that of the facial recognition with the facial recognition service that Amazon opened up and it had deep bias if that had been used by law enforcement agents, law enforcement agency in practice, far more number of Afro-Americans would be behind bars for no reason, absolutely no reason at all, because they would be identified as rapists and murderers and so forth. So it is as terrible as that. So much as we celebrate the power of deep learning and deep neural networks, the cautionary tale here is, we have, when we master this, with these tools, we can not only do a lot of good, but we have a potential to do catastrophic damage. And so in this workshop, you will see that from a very technical perspective, I will be talking about explainable AI, which is a hot topic.able AI not only further ensures that you don't have biases or subtle biases it's also furthest understanding suppose one example that I can give you is I talked about Kepler Kepler took the data from Tachybrahe. Tachybrahe was the, Kepler was an astronomer who's famous. Almost everybody has heard of Kepler. Not many of us have heard of Tachybrahe, who was his mentor and his teacher. Now, Tachybrahe was doing astronomy gathering data before there were telescopes sitting on his roof and looking at the skies. And the skies are best looked at in winter nights. In Europe, the winter nights are not exactly pleasant and warm like India nights. They are very, very cold. So Kepler used to be there and from the way I heard the story he was he was a brilliant mind but also not exactly looking forward to being on the roof on cold winter nights so Tycho Brahe would occasionally nudge him to be there. So in any case, as Tycho Brahe passed away, all the logs, the astronomical logs of data about stars came to Kepler. So Kepler then painstakingly, and you could genuinely say in many ways that Kepler was the first data scientist in a very genuine sense, because he pulled over the data a very very long time and there's a very interesting history to it some of you if you're interested read a wonderful book called figuring it is written with sparking language just the language is a pleasure to read there is a book that came out very recently actually figuring a year or two ago the first chapter is on kepler it's also available as an audio book just listen to the first chapter and you'll get a sense of the life of kepler and it's a pretty tragic life actually the orthodoxy uh what uh kepler's mother declared his mother to be a witch. And she was practically imprisoned and spent her life there. And if I remember right, she was either burnt at the stake so he managed to save her from being burnt at the stake so she died in prison. So he had a pretty tragic and sad life, but he made tremendous contribution and very painstakingly he did that so when he did those contribution he not only could predict where the stars would be or where a planet would be which is the prediction problem looking at the data you build a prediction model in modern language you can build a black box model that will say look at this part of the sky and you'll find the planet or you'll find this planet or this, whatever it is that you're looking for. But what he did is he discovered the Kepler's laws of motion. And I'll talk about the two laws, one being that all the planets have electrical orbits and the sun exists as one of the focal points the other being that in unit time each planet sweeps out exactly the same area irrespective of where in the elliptical path it is these were the two Kepler's laws. Now, if you think about the latter and ask yourself, can an artificial intelligence discover these laws? The discovery of the laws further understanding, it takes the frontiers of knowledge forward, astronomy forward. But just having a black box prediction model, it does serve in predicting, it has practical utility, but has it really furthered human knowledge? And if you think really about it, a plain and simple answer would be perhaps not. And so when you go and ask the black box model to explain itself, the hope is that you can find interpretable analytical models that explain it. And that is one of the big areas of activity these days. We are going to do this as part of this course. And lastly, of course, we'll do all the traditional stuff, the fundamentals, the neural architectures. Now the neural architectures are a zoo. There's so many neural architectures but we'll cover the dominant themes in this workshop as we go through part one, part two, part three. Come January, come December end hopefully you'll celebrate in Christmas, not just your Christmas, which you'll celebrate having mastered a fairly wonderful discipline. So that was the summary of last week. Last week, we had a quiz, two quizzes, week zero quiz and week one quiz. I noticed that the week zero quiz participation was quite a bit. Week one participation was a bit low so i would encourage you to go finish that quiz on your own of course by now i've posted the video solutions to those quizzes lab work please do do the lab many of you have posted done the homework and posted uh really wonderful pictures on the slack and we can see uh how well these neural networks are able to identify them you see both the strength and the weakness for example this neural network is not able to recognize faces why because for privacy reasons it has not been trained on people's faces it is not able to learn about things that are completely strange to it for example you show it a iPhone I mean I watch as one of you did I think Prachi you did and you notice that it sort of comes close it says it's a watch and so forth but it cannot say specifically it's an iWatch because it has no notion of an iWatch. So that's sort of that was that. The last is there was a weekly survey. Please do fill the weekly survey. This is how we make sure that the quality of the workshop stays high. Every week I do carefully listen to the watch or watch, rather read the survey results. Based on the survey results, if I find that on certain topics, many of you are confused, I make it a point to repeat it, either in an extra session or on the next week's theory session. So, do please take these reviews seriously. If you haven't filled it in this break, please do take out time and fill up the reviews all right folks so that finishes the review of week one now i would like to go on to the topic of this week and let me share my screen for that purpose any questions guys before we start? Which screen are you folks looking at? Week 2 plan. Today we are covering Universal Approximators. Wonderful. So you are looking at the right one. Sorry for some reason it is. Yes. So let us get started this is the plan for week two did you guys see the plan for week two i posted it both on the website uh yeah got an email too yes you got an email and it is there on the slack messages so gradually guys i may stay with just slap because it's a bit of a time consuming thing to remember to post at both the places. I hope by now all of you have subscribed to Slack. If you have not, it is really look into your mailbox. You would see an email inviting you to Slack and please do join. If any one of you are not part of the ML 400 channel, the deep learning channel, do please let me know. We will fix it during the break. So our plan for this week is, the theory session is, we will understand the concepts, the core concepts behind deep neural networks. The lab will, in general, it will sort of resonate with the theory but it will uh it it will cover a slightly different set of topics what we will do is we'll build our first deep neural network from scratch uh quite literally from scratch and we'll see how we do a detail network what does it what goes into making or writing a deep neural network then we'll learn about how to create a data set a prepared data cell the way you do for example in ml 100 and 200 you would do it using panda's data frame so what is the equivalent of data frame in pytorch and how do you load data and give it to the machine because here one of the concepts is you need to load and give it data the machine because here one of the concepts is you need to load and give it data because the data may be vast and this is generally true in machine in deep neural networks the data sizes are ginormous usually huge if you just look at the amount of data that has gotten downloaded onto your machine uh you will you'll realize that a lot of data gets used in training these deep neural networks. So that will be the Python. We will also do a blog reading, and this will be the first entry into reading research papers and things like that. So the first reading will not be a research paper, but it will be a blog. It is Christopher Ola's blog. He works at Google Mind, the Google Brain, so in the Google Research Group. And he's written a wonderful blog, which I've added to the course website. If you go to the course website, you will observe a few things let me show what you will observe you'll notice that there is a new section here are you guys able to see there is a new section here There is a new section here. Let me make it even bigger. I hope you can see Neural Nets are Universal Approximators. This will be one of the topics we'll start with today. And these articles that you see are really very good. So the reading material for this week is that there is a YouTube video and there are two blog kind of things. This is your reading material for this week. The original papers are a little bit hard to read, but those of you who are interested, you should pay attention to the original research paper. But I would say that if you don't read those papers there is no harm done much of what the papers say is already there in these two articles one article will cover today in the lecture itself and there is a YouTube video if you don't want to follow the article you can just watch the YouTube video which is very interesting actually so this is the plan for today so and for this week rather now coming back to where we are i'll get started with the theory part today we'll cover three topics. One of them is universal approximators, that word sounds rather grandiose and what it is we'll discover. The second is the activation functions and the third one is something called gradient descent. Now some of you may be familiar with gradient descent, we have discussed it in every prior workshop, but there are people who are not familiar with it so i'll review it in any case okay all that being said i'll start with this big question that you see on my writing board why are neural networks so versatile how is it that a neural net can do language translations can recognize music you know you you just play a bit of music and it will recognize what that music is, what that song is, or who the player is and so forth. It can write poetry, it can do, you know, the paintings we saw last time that it could paint it can do all sorts of things that you wouldn't imagine it would be capable of today it is almost able to drive cars and cars and so forth it can fly drones can do all sorts of unthought of things right and we live in the world of AI. AI is in a very genuine sense it is the new electricity and it is eating the world for lunch everywhere you notice every single field is being permeated by that so I'll start with something and now we'll start going deep into the technical material so I'll start with this question why are neural networks so effective? Why are they so versatile? So when you think about this, the way to go about thinking is this. Suppose, and here we'll think about it mathematically. See, your input data, whatever it is, let's say that you have the size and the volume of an animal, right? So it's your x vector, which is made up of x1, x2. x1 is the size and x2 is the volume of the animal. And so this is your R square space and what you want to do is you want to predict let us say you want to predict two things based on the size and one thing let's say based on the size and the volume maybe let's not take let's take children suppose you know their size and their well weight height and weight you want to determine what is their age so age is a real number whichever way you map a point from here to here a point to this and another point let us say to another point let's say here to that maps to let's say here nonetheless you would agree that there has to be some function function of the x vector some mapping function that takes you from here to there that takes you from here to from the input space to the target space And that is what I meant when I said that regression is a mapping from Rn, where data comes as n-dimension, now to generalize, to R. So this is, in simple terms, what a regression is. Now, there are a few caveats to that and i'll come to that in a moment by the way do you notice that i'm writing r with the unnecessary bar to it that means this r stands for the real number line so when you say r squared, you're basically, so for example, EG, R squared is essentially one real number line that you may call X1, another real number line going in perpendicular to it, X2. And all these real number lines will axis as they are called real number lines or axes they will always be orthogonal to each other right so in three dimensional space of course you can imagine a third direction uh x3 going perpendicular uh x3 minus x3 minus x2 minus x1 in this direction. So you can imagine a three-dimensional space and then from there you can generalize. So if data comes roughly speaking with n columns in a very intuitive sense in a spreadsheet, n columns, and the n plus one column is the target space, then you're basically saying, how can I read the inner row of data? How can I read the, in a row of data, how can I read the values in the n columns and use that to predict the value in the n plus one-eighth column, right? That's essentially what regression is. So to do that, you always think of it as some function that you don't know. That is it. You have to find a function. Now, how do you find that function? We'll talk about that. But before we talk about that, a little bit of a caveat. See, I always say that the target space is a scalar, right? Scalar here, generally. Let me use the word generally. But it's not always true. I sort of oversimplified things and I suppose for once I should mention it. See, if you have, if your target space is, let's say that, let me just give examples of target space. Target space is wind velocity. The velocity of the wind. Now it is more complicated, right? So what you're doing is you're predicting velocity as a target space. And this you would realize is made up of two components. V1, V2, isn't it velocity along V. North, South V. Or maybe east, west more like along looking this, along east and west. And this is along north-south axis. The velocity at a given point, right? So you can ask this question that suppose I give you a lot of weather data. I tell you all sorts of conditions or parametric conditions that are there. Now, can you based on the input, find a function such that V is some function of input data. I'll be to give you the answer. of input data. So the target space sometimes can be sometimes can be a vector. So it can also be from Rn end you are going to our M so this red so M dimensional vector so this is an illustration but I won't use this example to keep it simple just think of regression as going from n dimensional space to a number because that's simple. That's how we develop our intuition. But we keep in the back of our mind that yes, something like this also could occur. Are we together? So now that's a fun question. Yes. Can we go to a higher dimensional space from a lower dimensional space? Can we go to a higher dimensional space from a lower dimensional space? Can we go to a higher dimensional space from a lower dimensional space? Yes, I'll give you an example. Suppose you're just in Fremont approximately. Let us consider Fremont a point on a map and I say you stay in Fremont but you tell me the wind velocity as a function of altitude. So you realize that at this moment, I believe there's no breeze here. It's pretty still and rather smoky. But if you climb up in the z-axis, in the height axis, what will happen? You will start seeing the wind blowing. And so that wind will be a vector and that vector is a function just of height just of one you know you are going so in other words let's say let's write this case since Can we have regression where n is smaller than m? Isn't it? This was the equation. You want to know to predict wind velocity, not wind speed, but wind velocity as a function of altitude. And you can think of all sorts of other examples, but but the fact is yes you can so we look at three and three outputs for one input yes so if you even want to look at the see the wind if you look at it typically you look at it as along the north south and along the east way so you know you can say that the wind is blowing south, southeast with a certain velocity, isn't it? I'm just trying to imagine what the function will be like. Because I can imagine a higher dimensional function going to a lower dimensional function because it has a lot of variables in it. No, but it is not hard to imagine. So think about it this way. When you are doing it, when you are doing, let's say a point altitude. Let me just write altitude as x. When you write a function, what you are doing is you are writing f1, x is the velocity along the north-south direction, v1, and v2 is another function,2 of x oh i see so there'll be multiple functions yes exactly the only thing is you'll co-train them when you do the gradient descent you'll you'll do the joint gradient descent so can this can we have a function vector in this case it is a oh yeah the yeah, the function, the ultimate function will be a vector. It's a vector function. It has to be. Think about it. A scalar, a scalar 1D suddenly went into 2D, right? 2D vector. It has to. It has to. So this function has to be a vector function isn't it i can give you many examples so for example a temperature gradient think about temperature gradient so imagine that you realize that we live next to the bay anytime we feel hot we walk over to the bay well it used to be true in the golden ages when we had fresh air but let's hope it comes back at this moment we don't even know in california we'll get fresh air or not but anyway so what happens is that at each see at any given point what do you have point, what do you have? You have something like a temperature at a given point. Are we together? A temperature. And so let me call temperature X is the X vector here. Now, at any given point, you have temperature, which itself is a, a actually let me write it in all its glory your input space is temperature at a given point right and then you can find the gradient of the temperature right what is the gradient of the temperature it says that let's say that this is the bay right and so if i go towards the bay what is the rate of increase of T with respect to the direction towards the bay, right? Let me, B is the direction towards the bay. Likewise, I can have an increase in temperature perpendicular to it, orthogonal to the bay, let me just call it O. Vaidhyanathan Ramamurthy, orthogonal to the bay. Let me just call it. Oh, do you realize that even starting with something as simple as a number by looking how it changes across this Vaidhyanathan Ramamurthy, Space, you can actually get vectors out of it. So therefore, you realize that gradient is a vector function. And as you will see gradient is one of the topics we'll talk about today. Thanks, Sas. So this hopefully answers your question. So now that we realize that this is, so these notes, of course, I'll give it to you guys. I'll post it to the class webpage. Assuming that this is true, let's simplify life. Like I said, always imagine things in one dimension. So let us say that all machine learning, we will loudly say we are doing an arbitrary many dimensions using our usual trick, but in reality, we develop our intuition first in one dimension. So suppose Y is some arbitrary function of X. So think of some arbitrary function. Does this look strange enough? And it could be going below the axis also. So let me throw that into the picture also. It may be doing this how about this just to illustrate the point that it goes in every direction and so forth so let us say that this is fx once we realize that regression is the search for the best, the ground truth effect. So we say, let the ground truth. Producing the data. I keep using the word ground truth. Do we understand what that means? You know, that real function of force that generated the data that we have from which we are studying Isn't it from which the machine is trying to learn? Y is equal to Now This is the real fact Given this fact what is our job? We want to, the whole purpose is we want to do something like we want to, our goal, we want to find, actually, let me write the ground, okay, we'll leave it as that. We want to approximate it with g, g of x. Says that g is approximately equal to fx. Are we together? Now, what does this approximate mean? It basically means that suppose I come up with a function that is here. Let me follow it up with some other line. Suppose I did something which was like this what would you say about G you would say G of X do you see what you're saying G would you call it a reasonable approximation of an FX yes right it is and so the statement is that see you'll never discover what FX is but you can make more and more high fidelity approximations to G of X and how do we make that high fidelity approximation we need some way to quantify what does it mean to say it's very close to G or it's very close to the underlying truth and that brings in the concepts of loss function so we'll talk about something or rather quantify this word more into a precise language let me write it down we will make our language more mathematically precise and mathematics is just common sense encoded. So do not be worried about it. Mathematically precise. We'll do that. What do we mean? Language of approximation. Approximation. My handwriting is atrocious. So that is that we can do that. But at this moment, let us say that we want to do G. How do we do G? And here there is a mathematical theorem that is, that is reason for hope. This mathematical theorem is just a beautiful result actually that came out many, many years ago, I believe 1989 or 91, 89 I believe. So the original reference paper is there on the website. What it said is a neural network with one hidden layer, hidden layer, can approximate any and therefore in mathematical language and therefore every function. function. So when you write y is equal to function, and by the way, I'm writing it in one dimension, but this is actually generally true. Even when the input space is multi-dimension, it's n-dimension space, right? So it says that you can always find, and your network will always approximate every function fx with some gx, right? With some gx. Such that it's a good approximation, right? So in what sense? We'll talk about loss functions and errors and so forth. But we'll leave that for now. Those of you who did ML 100 and 200 may remember some of it. So this is where we stand so let me just summarize what we just thought in a moment what we are saying is let's go back we are saying neural networks they are amazingly effective and we want to understand why they are effective and so versatile but before we do that we set up a little bit of a mathematical machinery. We thought about it and we realized that regression is nothing but, it is this, it is a mapping from n-dimensional input space to a scalar value. Well, that is not always true, sometimes it's to a vector field, but we will skip that word. Skip that word for now. Keep it simple. So now, not only that, but to understand what is really going on, we will simplify the input space also and just take one-dimensional input space. And now we are all used to drawing curves and things like that since high school. So we end up in a situation like this. Here we are. Now the question is, the theorem is, so this is a theorem. And this theorem is called, this is literally the grand, the universe approximator nation here so this theorem has gone through many refinements over the years the original version that it came out it insisted that you must have something called an activation function. So I'm jumping a little bit ahead, but forgive me for that, that it would work only in a special case. If your activation function was a sigmoid, it was a sigmoid activation function, it was a sigmoid activation function activation function and at the same time you're talking about the one hidden layer but then the next let me just therefore call it approximation of theorems right so the a version was just very specific the B version generalized it and said it is actually not a Jay Shah, Dr. Okay, so this is y is equal to the g of x here. So this g will be a very good approximation to the fx, right? And you can have a lot of hidden layers. This is a lot of nodes in the hidden layer. So there's a very interesting part to this actually. When the universal approximation theorem came about, people then asked that why do we need them neural networks with more than one hidden layers, right? More than one hidden layer because the universal approximation theorem says that one hidden layer is all that we need. So I'm going to give you a hint. It is not just being able to approximate a function well, but it is also being able to approximate it fast enough and reliably enough. And so the other considerations that sort of justify why you should go for multi-layered neural network. In fact, the word deep in neural network refers to multi-layered neural networks. So we'll come to that. But hold that thought in your mind. I'll just take the facts at this moment. And then the last thing that came about is that, so it's a property. So I, the property of the network, property of the, people call this sort of network a feed forward network and why they call it that will that too we will learn so at this moment we are introducing a lot of animals in the zoo that we haven't explained or understood but before this talk is over we will understand that so we'll go through in cycles. We'll come back and review all this once again, once we understand those things. But we can't understand those things unless we get some foundation here. And then came the third version, or the transpose version of it, I will call it. Transpose version, which basically said that instead of creating a very deep transpose version which basically said that instead of creating a very deep transpose version which basically said that instead of creating a very deep neural network neural network neural network you can create a network which which in you can create a network which which in you can create a network which which in each layer i mean so instead of creating each layer i mean so instead of creating each layer i mean so instead of creating one single hidden layer which is giant multi layers. Right? So, so you could create a feed forward network like this which is already getting pretty complicated. So there we go. And then, so you can go through a few layers and then when you go through a few layers and finally all of those things whatever number of layers they are before the last one comes to the last one this thing this is x going in and here you have y hat the predictions you usually make it where a y hat is g gx the neural network is predicting by the way let me give you a little bit of a background on the hat notation in uh this field, it is a convention that reality is written with x and y and so forth. This data is the data that you get, observables. Predictions are distinguished by making them wear a hat. All predictions will wear a hat in this field. It's true all over machine learning. So there are three versions of this universal approximation here. Vaidhyanathan Ramamurthy, We will go through all three versions. And in fact, we will just touch it from a way intuitive perspective, the proof of this theorem goes into really abstract mathematics and we won't go Vaidhyanathan Ramamurthy, At At this moment we will take it on faith that the mathematicians must have gotten it right but we will rediscover it from a very practical and intuitive purpose sort of an intuitive manner and to do that before we do that any questions because now I'm going to start motivating start with a motivating example I will take two examples, one with classification. Vaidhyanathan Ramamurthy, And then the other would be for regression, which will come a bit later. But let's start with justification. But before I start that guys are there any questions so I have a couple of questions first one is why is this called a theorem like what is a theorem what does it mean because I felt that a theorem had particular rules which need to be which if followed will result in a certain outcome but here it seems like the outcome is dependent on say a certain property of a feed forward network and obviously feed there'll be different networks for different outcomes and the second question is why is the the C part of the theorem called called transpose version what is transposed it's just a colloquial. What you did is instead of creating a very, you know, one single layer, which is very, very tall, you sort of flatten it up into multiple layers. So people who do matrices, they tend to look at it as the, you have laid it flat. And when you laid a matrix flat on its side, you say that you have transposed it. There is no reason, it's not an actual transpose. It's just sort of a colloquial way that people refer to it. But now let me come to the first part of it. Is it a theorem? See, in mathematics, when we talk of, for example, the Pythagoras theorem, a theorem is something that is true if certain preconditions are true. So assuming that you're on a Euclidean surface, on a flat surface, then the hypotenuse square will be the sum of side squares in a right triangle. squares in a right triangle isn't it we learned that in high school right now that theorem has certain preconditions you cannot do it on a sort of a way but on on basically on your blanket after you wake up in the morning it's all linked to that so that there it won't hold true if there's a deformation if you try to do it in a balloon you might be disappointed things like that so the pre-con you have to state what are the preconditions for something to be true if those preconditions are true that is why all theorems start with if then this is true if it is a right triangle implicitly on a euclidean surface flat surface then the hypotenuse square is the sum of sides square so now that is one aspect of it it will always be true the other aspect is this remarkable quality of there's a you know there's a ring of eternity to a theorem it is a truth that you have discovered that will last from now till eternity it can never be undiscovered you can never have a version two it's not like windows you know version windows 7 and then windows 10. in software we keep having different versions of the software but it is the only thing that once discovered remains in the sphere of human knowledge, it is forever. Even physicists, theories change. There's Newton's theory of gravity superseded by Einstein's theory of gravity which someday may be superseded by even better theory so theories come and go but theorems are eternal what i'm saying is about neural networks the universal approximation theorems are theorems they are not theories they're forever there that. Once you realize that they are true and therefore they have to be proved. You need a proof of this. Theorems have to be proved. You must be remembering proofs of Pythagoras' theorem that must have haunted you in high school. So likewise, this theorem has a proof. The proof is very sort of, I would say, let's not get into the proof because it's very complicated you'll need a foyer series foyer transforms and a banach spaces and the sort of things we don't talk about uh in computer science or in engineering or in real life basically mathematicians deal with them but let's stress to the mathematician that they have rigorously proved this to be true. And therefore we know that it is true always. So what are the preconditions? The preconditions are the function needs to be, there needs to be a sigmoid activation function? No, no, no. That was the initial version. So the B version proved that actually it has nothing to do with sigmoid so long as you have this architecture one single hidden layer it will irrespective of what activation function you use it will always be true i see all right and then came the transposed version which is see these are enhancements to it these are generalizations to it the generalization says that you don't need just one hidden layer you can actually have multiple hidden layers and it will still be true nice right so this is in some sense the most generalized version of the theorem i see but one one hidden there can do the job you don't really one and they can do the job and in fact there used to be a question at one time I can do the job and in fact there used to be a question at one time before the deep neural networks came over properly people used to hand construct a multi-layered multi-layered neural nets and there was a little bit of attention actually I remember the history that some people would say it's a full challenge all you need is one hidden layer. Well, obviously, theoretically, that's true. In practice, as you will realize, reality is different. It's like the Big O notation. Two algorithms may have the same Big O notation, but one may still be 10 times faster than the other. So reality is a little bit more involved. And of course, today, we live in the world of deep neural nets, which is the whole field of study for our current workshop. So we'll do that. So now I made a pretty tall statement. We are talking about a theorem, but how do we understand the theorem? We won't go through the proof, but there's some intuitive understanding. It's really worth it, guys, because it's at the foundation of deep neural networks. So I'm going to give you that intuition before we go to the break. It's just finish the classification before we go So there is one example that I keep coming up with which is a very contrived example So I think of it of educational or didactic value only I don't think it's true in real world But I'll imagine two kinds of fruits one of those are blueberries and blueberries are light and small so this axis is x1 axis is let us say weight and let's say this is the x2 axis and this we will take as volume right so all the blueberries small big whatever it is they will occupy let's say this region of space actually they will tend to have a more a bell curve distribution so i already know this isn't very accurate but we will contrive this example and then occasionally there will be the rare big blueberry and then let us bring about some other berry uh let's take cherries right let's take a color more appropriate to cherries what is the color take cherries. Let's take a color more appropriate to cherries. What is the color for cherries? Well, maybe this. Let's take this. So let's say that the cherries are bigger and heavier. So they have a distribution like this. When you have data like this, I ask you this problem, write a classifier. Write a classifier. The problem statement is create a classifier that can associate given x1, x2, that is the X vector. It will map it to, fx, to what? A set of either blueberry, berry, or cherry. It will pick one or the other. Are we together? So now you say, well, I know one of the simplest ways we can do that is by creating something called using logistic regression. Do we remember logistic regression folks? If you don't, just take it as a fact that it is a way of finding something called a decision boundary. So decision boundary certainly merits its own line and color. Would you say that if I drew a decision boundary, let me make it really thick a straight decision boundary like this boundary then you can say that things on this side of it are blueberry and things on this side of it are cherries does it seem understandable guys that all we are doing is to create a classifier is equivalent to finding a decision boundary like this because if we have found the decision boundary we have solved the problem isn't it guys would you agree yeah yes we have solved the problem now if you look at this this is a straight line and some of you may remember that this and again if you don't it's alright you can review it or if you don't know it at all it's the first time you're encountering this, that is okay. Don't worry too much about it. It just so happens that this has a function. This distance from the decision boundary, d of x, d of x happens to be some things, some weight, w naught plus w1 x1 plus w2 x2. Now, some of you may remember that I used to write beta naught, beta 1, beta 2 in the past. In the deep learning world, it is much more conventional to use weights. The word is weights. These parameters are weights. Weights. New name, or should we call it synonym for parameters. So if your distance is positive, you know that if your distance dx is positive greater than zero, cherry. If it is less than zero, blueberry. And if you're sitting, if dx is zero, you're sitting on the yellow line, you're undecided. You can go either way. So that's your logistic regression. So that's your logistic regression. Now, when we talk, when we look at this problem, just as a recap, what happens is that the likelihood that it is a cherry. So if you ask this question. In a classic like what is the probability that a given a point is and this is a review of the logistic actually that we put it next to the name was log of odds probability that it is a cherry versus the probability that it is not a cherry the log of that is equal to the distance function so you're seeing that the log of odds that it's a cherry happens to be the distance from the decision boundary right that is all that the logistic regression equation is ever trying to say and of course this is conventionally also written in a more different way people often write it as in a in a more traditional way you will remember one plus e to the minus dx right or people use z here let me just use z and if you see z here you would see it in this format and well x is obviously a function of z with a probability of x and this is the equation or this is the form in which you traditionally find this equation represented i find this a little bit more intuitive because it means something in terms of this picture so are we together guys this is just a very a quick review of how we we learn to classify data you need to find the decision boundary in the feature space right in the input space you search for a decision boundary in the feature space, right? In the input space, you search for a decision boundary. The simplest is you start with a linear decision boundary. Make sense guys? Any questions before we continue? Everybody is quiet, guys give me some feedback. No. It is quiet. Guys, give me some feedback. It is clear. This is clear to all of us. So we have all done this at some point and we can do it. If you haven't done it, then sit with me and I'll give you a longer explanation. It's not mysterious. This is all it is so the way you do that is quite interesting now i'm going to represent it in a very sort of electrical way do you guys know what a rheostat is or a variable variable resistor exactly so what is a variable resistor. So what is a variable resistor? What you have is basically a coil into which you feed in electricity and then you have a slider that can move back and forth. And this slider, the electricity continues from this slider. In, out. And so what happens when you move the slider in a rheostat or in a variable resistor back and forth? Suppose you apply a certain voltage. Suppose I have a fixed voltage, V. You know that the current current so there is a relationship in physics called v is equal to ir right the current voltage is current times resistance times resistance. Are we together guys? So in effect, you can control given the same voltage. You can control how much current flows through by controlling the resistance here. Are we good guys? So suppose I want a certain, suppose the output current is what I look for. Why is the current I input. So voltage is your x. Now what happens your y which is your which is actually the current Is a function of X what is x voltage and how is it a function of voltage it's actually a linear function of voltage it is some weight that is some resistance sorry it is a voltage divided by 1 over R, sum 1 over R times X, which is the voltage. Am I making sense guys? Y, which is the current. Current is voltage divided by the resistance and this resistance I can play with. So you can ask this question. Suppose voltage is fixed, but I want to get just the right amount of current. So how do I do that? I just slide the resistor and I get it. Does that make sense, guys? Is this intuition coming across? Yes. This is a simple intuition. So now hold that thought in your mind. Now what we will do is, here is a simple intuition. So now hold that thought in your mind. Now what we will do is here is a mapping window. Whenever we look at input data, sometimes think of it that these are actually voltages and think of the output as some form as a current. So see what happens. We are having this. Now I'll just make this real stat sort of like this, a box or let me write it not as a box. Okay, maybe as a box. Imagine so real stats are usually square looking so I'll write it as a square. Vaidhyanathan Ramamurthy. Suppose you have Vaidhyanathan Ramamurthy. X one voltage coming here and you control it. I'll call this W1, right? The inverse of resistance, which you can change. Remember, this is the slider we can slide, slider we can use to change output, isn't it? can use to change output. Isn't it? And so your Y is the current from here, from this voltage, the current. Remember that. Let me write it somewhere in big letters so that the intuition remains with us. This is why is is the current the output is the current input x are the voltages so you say well this is good but maybe i need to look at two voltages suppose i have another x2 here well what can i do i can take another little box go purchase one more rear step from radio shack oh radio shack is gone isn't it guys is it still alive or is it completely gone anybody remembers about radio shack completely gone completely gone okay so uh w2 so where do we go for a resistor these days or a variable resistor these days? I don't even know. At one time I used to go to Fries, but even Fries seems to be on life support. So now what I will do is I have two boxes. What it will do, this will produce a little bit of a current of its own, Y1. This will produce a little bit of a current of its own y1 this will produce a little bit of a current of its own y2 and suppose i have a way of adding the two currents together what will i get i will get y is equal to y1 plus y2 i'm adding these two currents together am i making sense guys together. Am I making sense guys? Are we together? Yes. And so now imagine that these things are actually all of this here. Now let's create our first black box. Well, here it's a purple box, but bear with me now, suppose, uh, no, but let me move this a little bit up and create space if this drawing looks small guys let me know if you have difficulty understanding so now let's look at the pink box the pink box we don't care uh all we care is that internally it contains multiple of these internally it contains multiple of these two of these uh resistors or rheostats variable resistors all we know is that we are getting x1 and x2 and this is your weights w1 w2 these are the knobs that you can turn and output and there is a output machinery of adding the results of these two and getting your current y that is your current these are your voltages it's a very practical intuition so now i tell you this thing guys that i have a table have a table right and what happened is that when you bought this machine it was beautifully tuned for different input voltages you could get different currents out here right but then you because you obviously you can't avoid the temptation of playing with real stats at least i can't the moment i see real stats i start sliding things back and forth as a kid i used to do that so you have screwed it up right so god knows where these resistors are pointing so you have data you used to remember that when the real stat used to work perfectly when this box let's just call this box magic box when this magic box used to work perfectly when this box let's just call this box magic box when this magic box used to work perfectly then it used to produce a certain amount of current right voltages and current right so you have a table of this uh some table uh something something so you have a table of a lot of things and now the problem that comes is you don't know this whole thing has gotten misconfigured right and you have to now the these sliders are at random position these weights have gotten randomized and your job is to fix this magic box are we understanding it guys so how will we fix it we do know that this is that and you know why is x 1 w 1 plus x 2 w 2 and maybe it also had a little generator of current it would just produce some magically a current which was w uh it was some unit there also there is a w naught and how much current you took from that depends upon it so we'll add some magic here you can ignore w naught but just think in terms of these inputs so the total current that comes out is this based on whatever the value it is and what you're trying to do is you're making this somehow you need to restore it to its good configuration and you know that there is a solution because of course when you got the magic box you could so how will you do that there are many ways you could do that for example you could hold w1 fixed and then go about sliding w2 till you get uh the the values correct somewhere so you know you could take this row whatever the value of x1 is x2 is what you can do is just freeze w1 and if you play around just with w2 you might be able to come close to the real value of y. And then after that, you might move the w1 around a little bit, slide everything a little bit till you get this one going. But the trouble is you got this one going, but the other ones won't be going. So because data always has a bit of noise to it. So there's some, okay, I should mention that there is always a bit of noise data never comes perfectly so you'll always get in real life and i don't want to introduce a noise generator also here but think of that this is producing some random noise too so is this intuition clear guys and what you're looking at is this magic box is your regression box. Right? A regression box produces a line. The relationship is a line. So if you have X1 or x2, then this equation will represent a plane or rather hyperplane, a plane. If it was only one x1, then it would be a line and in higher dimensions x1, x2. Because you're looking actually, I should not draw it like this. The y, it's a three-dimensional data. It is something, actually why don't i do it a little bit below we are talking about this this is x1 this is x2 this is your y or rather y hat because now you're trying to predict or create the machine that will pretty much be as good as new. And so what will happen is there will be some plane. Now this plane, as you know, the equation of a plane is this something like this. So regression in this case discovered a plane. A plane. Isn't it? And when you discover the right plane by building it in all sorts of ways and finally hitting upon it, you have solved the problem. You have you have a solution or you have a model right and you may not get it exactly You know your values may be close to the real values They may not be exactly the way the magic box came from the factory, but you need to just get close enough so that it works Are we together guys? now That is regression. So to summarize regression is When we do this, x1, now let's generalize it to xn input, n-dimensional input. What happens is, think of it that each of these, they have certain weights along the way. So if you think of it as a box. And then what it does is it adds up the product of these two. And so what comes does is it acts of the product of these two. And so what comes out is y and there is an additional bit of weight coming in w naught. So what happens is the output is w naught plus w1 x1 to w to w n xn, right? This is it. And the clearest intuition that I can think of it is as a box of real stats, variable resistance. So when we talk of learning in machine learning, what does it mean in terms of our magic box? What do you think it means? Physically, what are we doing? When you say that the machine is learning from data, what is it trying to do? Anyone? from data what is it trying to do anyone figuring out the weight exactly it is moving the sliders here in there so that it is able to produce the original data or come as close to the original data as possible isn't it guys so that is what the process of learning is. Data is there. Think of it as the original thing. And now you're trying to approximate it. You're trying to recover that state. Right? So we'll remember this. Now comes one more fact. For classification, you don't just do this. What you do is you take this output and so here is our magic box I'll put it as a magic box it is made up of these weights w1 w2 x1 goes here x2 goes here now suppose you do, you create a distortion function here. So what you want to do is, typically the way you think of it is, you don't want it to be triggered. Sorry, I apologize, this is a jump somewhere. This is a touch surface and it just seems to be oh what just happened I seem to have gone to a different page altogether I apologize right this is so sometimes what happens is you don't want to trigger something until till a certain threshold is reached so you want it to be if the input if the if the initial y that is coming out here out here or here is the let me call that Z actually we always reserve the word Y so Z is your W naught plus W I X I multiplication of these summed over all possible input dimensions so what Y is and so this is your Z, what you want to do is you want to pick a threshold. Let's say that the threshold is zero. And what you want to do is for small values of Z, you want to ignore it. And then suddenly you want to do this thing that is called a sigmoid. You want to trigger action. You want to go from an off state to an on state rapidly as a function of Z and then you want to saturate. When you do this, if you look at it, it is think of S and what happens if you stretch S? It becomes, this looks like this, isn't it? A stretched out S. So these, any function that has a shape like this is called sigmoid. Sigmoid function. There are many sigmoid functions, but the most popular ones I'll mention, the logistic function is the most common that people know about. Logistic function. And then there is the error function, which is essentially the integral of bell curve, definite integral of bell curve. So inthy, Minus infinity to for those of you who are interested, or this can just ignore it. The bell. Vaidhyanathan Ramamurthy, Bell of Vaidhyanathan Ramamurthy, Bell being e to the minus t squared over t, all the usual things that you have one over two pi squared. This is your bell. So there are many, many functions that have this shape. I invite you to go discover more of those functions. All of those functions are called sigmoid functions and sigmoids are pretty much at the heart of machine learning algorithms, artificial intelligence algorithms. So, but why does it come in here? Suppose we add a distortion here so that what comes out is a value between zero and one. And this value. Why would that be useful. Suppose we could do that. Now this sigmoid and logistic for logistic case. What comes out y as a function of x would be What you do is one plus each of the minus Z where Z of X Z being this thing right so it's a bit of mathematics don't have to go into it think geometrically it just distorts your input to something else input curve to something else now why is that? It turns out that this describes With a certain cut off. This is actually describing your classifier decision boundary. Of course, this must be familiar to some of you. Let me come here. And this is a review for many of you. This is it. The yellow line that you see here and this equation as you know now you see that this equation is the same why is the probability of it being a cherry so now how does this relate and I'm quickly coming to a break but I will take this before we go to the break I'll leave you with a puzzle you realize that using a straight decision boundary, straight logistic regression, which we all have studied, we are able to, using logistic regression, which I can do using this fancy box of resistors and that distortion function. Those distortion functions have a fancy name. They are called activation function. Why that strange word activation function? You say that when something achieves a value of one, it sort of is waking up, right? It's coming, it's getting active now, it's doing something. It's getting to the active state. That is why this sort of functions that you apply, these distortion functions are called activation functions. So anyway, using logistic regression, the point is we can draw linear decision boundaries. This is a summary of where we were going to boundaries. Using logistic regression and how does our logistic regression look in terms of physicality. It looks like this. Our first is this bunch of Weights w one wk w and and then this distortion activation, this activation box, right? And then finally your output. Right? And here goes your X1, X2, X3. This is traditionally represented in a more abstract manner, or what people represent it as is this node. They will say that this is an activate, this is the distortion part. They usually don't make it square, but they do it like this and they will sort of stick this resistors as though they were in the path here. They'll take it out. So you have X1, X2, X3, so forth, W1, W2, W3, and then you're sticking one more, it's called the bias term, if you remember, and then output, this is your Y hat, the X vector, right? X vector given these values of W. So when a machine is trying to look at data, suppose you have data X1, X2, X3, and Y, or for example, whether it's a blueberry or not, which is probability of this being one or the other, let's say, it is actually using this box, essentially. And the lesson is it can draw a linear decision boundaries. But now comes the interesting question. Suppose our data comes like this, and in the interest of time, I'll make a simpler diagram. Sorry. Suppose you have data. Actually, this is not wide enough at all. Suppose you have a data where the decision boundary is like this. I'll just draw a decision boundary so that this is all blue, let's say. And now, obviously, blueberries and cherries will probably not make sense unless there's some weird genetically modified variety. Something like this. not make sense unless there's some weird genetically modified variety something like this right you have two classes red and blue so let's use the word red and the word blue here you still have your input space like this it's based like this so now you say how can I draw this V shape decision boundary this is box that we have. That is a question. And assume that you can buy in the your RadioShack just has a lot of these boxes available, not RadioShack or whatever the hardware store is, electronic store is these days. Well, I suppose it would be Ne be new egg it's an online store so um well whatever it is you can buy a lot of these boxes this logistic regressor regression kind of boxes that will help you do that so now the question for you is how would you do this anybody would like to guess anybody would like to guess nice anybody you make maybe the lines of the first one yes so one thing you could do very good why don't you articulate it say it in full words sentences what would you do where traffic I was saying since we we already have a equation for the first one that is going down then if you just inverse that then you and used another another node with the inverse of the first one. No, I'll make your life a little bit harder. It would be hard to inverse. I will make this like this. So you know, then what direction you're on the in the right direction but say what would you do what can you buy to make this work so you have essentially two lines that you're creating so you need two boxes excellent so maybe with two boxes we might be able to get away with it isn't it so what you can do is suppose I take one box here, right? Let me use white here, yellow because of the decision. So imagine that I use one box here, this corresponds to this line, right? And I use another box here that corresponds to, well, this line, right? So you realize that these will draw decision boundaries like this. Right. And something tells you that. And let's say that you have the input X1, X2. And obviously both of these are going to both the boxes. both of these are going to both the boxes, right? This is the one. So you will have, let me call this box one, this box two. So you will have a first box input one, and this one is first box input two, and this one is second box input one, and this one is second box input two, the weights, the resistors. So now you have four resistors as far as I can see. And what they can do, something tells you that they can recover these two decision boundaries for you. What do you need to do now? Then you can always take their output. Can we potentially take their output and massage it, for example, right? Produce that, so something intuition. So for example, we can say that if both of them say, let's say that this is the positive side and this is the positive side, right? They both produce positive probabilities. You can put a threshold, you can say that a p1 the the prop the total probability that p1 plus a p2 the output of 1 which is let me just call it y1 y2 so you can say that the two things y1 plus y2 should be greater than equal to 1 because this is more than 50% y 0.5 plus and this direction for y1 and this direction is y2 is greater than 5 in this direction right so in this region you can be pretty sure that no matter what, this condition will be roughly true. Are we getting there guys? Is this intuition making sense? See, this is a hand waving argument that you could play with two boxes and maybe three boxes. And now this guy just needs to add y1 and y2 and then get away with it in some way. So to generalize it, we may even put some distortions here. You can put some other weights here, layer two, let me say second layer of y1 and the second layer y2. To produce a y, you may even put a distortion. You might as well, since the shop is only selling one kind of box, you might as well stick it in here and see whether it will be able to recover this. Am I making sense, guys? Is this intuition coming across or are you feeling lost? Anyone? Did we understand that guys what we are saying? Yes sir. It is hopefully easy to understand it. So what did we do? We did something very interesting actually by putting these three things together We just created our first neural network And this magic work and this magic boxes these things that we are calling magic boxes in a more formal way These are called neurons our neurons more formal way, these are called neurons. Our neurons, neurons, node, sometimes these words are the same as our magic box. Are we together? They are the same thing. And what we are looking for is a first neuron in which, now what you do is you think of this input itself as a sort of a node in its own right all it is doing is passing it forward you say that in your network now this is your what is this this is your hidden layer are we together? This is your input. And this produces the output, the output layer. Am I making sense, guys? Anyone who wants me to clarify or is not persuaded by this argument? So now we can generalize from that, guys. So suppose I see a decision boundary, which in my mind I can approximate using a triangle. Right? So outside I see blues. And inside I see reds. Now I can guess, just a guess would say that I probably need a hidden layer of, layer of how many neurons three three magic boxes three magic boxes and then i can feed it into this and get my output x1 x2 will go into each of these and my work will be probably done but actually what happens is that this distortion function, this activation function, they are interesting. Sometimes you can get away with less than what you think because they manage to deform the input quite a bit. You know, whatever the Z they get. So think about what happens. Y is basically this function this strange function it's a transcendental function of z which is a function of x z of x is linear remember we we just wrote it w naught plus w1 x1 plus w2 x2 in this example but y does this weird exponentiation and so it becomes like a example. But why does this weird exponentiation and so it becomes like a sigmoid? It's a distortion of y, right? So activation distorts the z input. As far as the activation is concerned, z is the input to it and it has managed to distort it and so this brings us some very interesting possibilities what I would like to do is this thing this theory that I developed this way let us see if this is really true if it works so what we will do is now we will do an excursion to a website or where are some data sets drawn and we will see, use our intuition and see whether we can solve the problem. So what we learned so far is that you can use these logistic units and they have a very strong physical intuition. You can think of them as a bunch of resistors, variable resistors, and an activation function. So the only things we can change or slide are actually the resistors. We cannot play with the input. We have to achieve the desired output by sliding the resistors. Isn't it? The rheostat slider, the variable resistors. And that is a physical intuition of what learning is. Machine learning is all about getting that right, essentially. Moving those weights around, the sliders around, so that the output is what you want it to be. Now with that intuition we also take the other intuition that one box, one magic box draws one straight line as a decision boundary. Another magic box can do another straight line and then you can put them together and then put it into an output magic box and now you're done you can produce what you want right there the output that you like if it is v-shape if it is triangular if you see three lines you can do so let us see if we that intuition really is correct we can verify that what we will do is we'll go to our website a course website and we will play around with the with something that I hope you have played around with which is the where are the fun resources weekly suggested fun, deep learning resources. I'll go here and in this, I will go to something called the TensorFlow playground. come so here guys we have a few data sets let me start with this uh let me uh tell me if i should make my screen a bit bigger yeah this is my screen visible guys yes- And so we will, yeah, and very helpfully, I suppose, they are made them nice square boxes. These magic boxes, they actually look like boxes here. So, which is very good. So look at this data guys, blue data, orange data, right, are very close to ours, blue and red berries. So if you were to draw a decision boundary, how would it go? Can you imagine in your mind a decision boundary going through it, guys? Yes. Yes, isn't it? And how many decision boundaries you need? Just one, right? How could someone tell me how you can imagine a decision boundary that will classify the orange points away from the blue points? Simple linear function. And how would it go? It would go along the principal diagonal here, sort of like that, right? Imagine a decision boundary like this. to draw one boundary how many boxes do you need one box that's one box so now you look at this this is a very interesting thing see you are supposed to play around with all of this and most people come here and they do hit and trial and they try to mimic or create something so they'll do something like this and do you notice that it has drawn a decision boundary like this this particular neuron and you may feel very happy that see i have a neural network with one hidden layer well two output layers here that is drawing it so well but the question to ask is did we actually need all this? Suppose each box cost you $100. You have spent a lot of money here. So we will do something better. Let's see what happens if I. If we go just with this one, do you see that one box will just draw a straight line? Let's try that. let's start the training the big button for training is here at the top and what happens does it agree with the intuition guys that one box is enough to draw one decision boundary right it goes with the intuition we could have done it with, if you have done ML100 with me, you know that this is true. Now let's play a different game. What if the data looked like this? I'll let you stare at this data and I'll let you tell me how many lines will it take for us to get this into decision boundaries we see two decision boundaries right so we can't do with one if we try to train with one it will get lost isn't it let's try that yes clearly it is lost like it's gotten all these orange points wrong what we need is another decision boundary that cuts across here and separates the two so let's add one more two boxes well now that we have two boxes uh let us actually uh have you know it won't be sufficient we need another magic box here to uh sorry we need where is that I need to increase the number of years and I don't need two of these one should be enough let's try this does this look something that will suffice because we in our mind we saw two decision boundaries is it seems to be going along well not quite it doesn't seem to. It seems to have still missed it here. And this is interesting because this is sort of an XOR-like data set. XORs are always a little bit tricky. So see what happens if I add one more here. And these are the two outputs is it still looking simple guys it's a decent approximation yeah yeah it's a good approximation and what would happen if I just increase this here and decreased it here. See what happens. It wouldn't do because you need to create this other curve. And so in the second layer, you need to add one more. The first one is just distorting. We need to do that. So this is how you develop intuition. It is important to make the simplest, you know, neural networks. And you can often look at a problem and do that. What about this guy? Look at this data now, what would you say? There's something funny going on. Yes, remember just a transformation of the input data and those of you, of course course who have been my students will remember this very clearly actually we don't need x1 x2 at all isn't it and actually it's just a simple decision boundary we don't need this we don't need this we probably uh layers let's try a look with something simple but we just feed in x1 x2 square and see what happens do you see that the problem gets solved yes so what i'm trying to say is that you know if you think about data systematically you can create elegant and simple solutions rather than just by trial and error. So what about this guy? This is more complicated. So how many decision boundaries do you see here? Similar to x squared, but it does have a component of x, y, or x. Think about it this way. See, if you start here and you put a decision boundary like this to separate these two lines, and we need another decision boundary to separate these two lines right we need at least two different decision boundaries there is a radial function here but we also have a linear effect because it's linearly radiating out so let's try a luck we need two decision boundaries I unlock, we need two decision boundaries and let's see with this. Well, not quite. Now what can we do? We add a few more layers. So what does it take for it to do this business? Do you see how it is wrapping itself around the data and look at the loss it has pretty much hit it accurately right so i put a lot of boxes here now let's try removing a few boxes and seeing what is the minimum number of boxes that we need to do this not quite if you let it run for a very long time do you notice here that the training loss is coming down rapidly it's it is still coming down and down and down and we'll probably get it in due course of time almost there guys training laws the test error So this is a measure of error. You can see it disappearing. And this solves the problem. So this is it. One thing you see that no matter what the shape of the data is, if you take, you can always think of a neural network that will solve the problem. think of a neural network that will solve the problem so what in reality happens quite often is that people are not so careful they will not think through the logical aspect of it so they'll go something like this they will they will say oh forget the x square inputs we'll just take these and let us go and add eight neurons for good measure so this this is one hidden layer. Let's go for it. So you realize that when I remove X1 and X2 square, you are actually removing some amount of information from this, some feature engineering out of the picture now this is still high error but it will ultimately gravitate to who would like to bet that this will solve it or not solve it it or not solve it anybody's guess it's hard to solve it you know without these square components yeah but this is a point see what happens is that these points when they go in i have this layering you you can in effect get the squaring behavior by adding here let's do one thing now see what happens I add a few extra layers here so what will happen is that because you took the input and you are exponentiating it you will end up at this layer already with square components. The second and see this Vaidhyanathan Ramamurthy- Actually it's learning a little bit slowly take another Sajeevan G. According to the theorem, it should it should solve it right Vaidhyanathan Ramamurthy- Yeah, it should gradually solve it. According to the theorem, it should solve it, right? Yeah, it should gradually solve it. Because the theorem says with any number of hidden layers, you can actually approximate. Yes. The only question is, how many of those do you want? Like, how many layers do you want, and how many neurons do you want in that layer? So it is still, you can see that the error is decreasing and we can sort of trust that gradually it will get there it will still have some mistakes but it will get there you notice that it is getting there now this little link has to be fixed it isn't but practically it's solid do you see the training error is very very low now it's solid. Do you see the training error is very, very low now? So you ask this question without the square component, you know, the squaring gives you the circle is X square plus Y square, right? X one square plus X two square. Where did that come from? The reason is when this went into this neurons, each of these neurons and they exponentiated, what did that, what did the activation function do? It introduced a distortion, nonlinear distortion. In other words, another way of thinking it is, it produced a lot of higher degree polynomials of each of the input variables. If you expand that function out, you'll realize that all those higher degree polynomials are sort of born along the way. They get generated along the way they get generated along the way you don't have to explicitly feature engineer and feed it into the network and this is an important lesson guys what in neural networks one of the things we realize is that traditionally we used to do a lot of feature engineering feature engineering is still the gold standard because with feature engineering and an interpretable model, you can solve the problem, nothing beats it. But if you cannot, if you must use a black box, then some of these like deep neural networks, they have an internal capacity to discover those features. It is called representation learning and this was the breakthrough of 2009 and we, I mean 2006 of Hinton. We'll talk about that as we move along, hopefully in today's lab itself. So I've given you some idea. Now you notice that there are different activation functions, linear, sigmoid, tanh, et cetera, et cetera. Generally, ReLU will be much faster. Sigmoid is the slowest. And almost, see, when they use the word sigmoid, they're abusing the language. Mathematically, tanh is also a sigmoid. What they mean here is the logistic function. And in the deep neural network community, you'll often see this abuse of terminology they'll often say a sigmoid when they really mean damage i mean sorry logistic right because sigmoid encompasses damage in the strict sense so that is that sorry one question what does this really look like the activation functions are a topic will come to that today okay what classification problems I say regression problems well which data set do you want to use we don't seem to see many data sets and it is unclear what it is trying to predict but anyway I will leave the regression alone you guys can play with it but classification this example becomes very easy to understand now I'll go back to our stuff and ask classification is all right, but what about regression? Can we argue in a similar way that we can use these neurons, these basic units, and their activation, these magic boxes, to create a regression also? And the answer to that very presently is yes, we can do that. And I'm going to show you how to do that let me take a bit of paper and start doing them and I'll go a little bit faster now on the argument regression regression how would you do regression? So think about it this way. Go back to our situation. Suppose you have a function that goes like this, like this, right? So some weird function of X, this is X regression would be able to reproduce so this is your effects you want a G X that approximates effects how would you do that so what you do is you do it you argue for it piecemeal you say you know what just as you learn to do integration we'll break it up into tiny little stripes this function and what we will do is we will find if we can create an approximator for obviously this function should cannot move back it has to move forward so um this function should cannot move back it has to move forward so um this so let's look at this one little block right and this little block suppose i did these functions i could produce a function that could produce this and something that could produce this and something that could produce this so what will happen is this would look like this, this would look like this, this would look like this. So what will happen is you will end up with a function that goes... You see that? You can approximate it. If only I could, for example, reproduce one pillar using my magic box somehow. Isn't it? If I can reproduce this pillar at, let's say I, this location, I at location, then I can create a lot of those pillars. I just need some way to produce, produce, some way to produce produce produce produce and pay attention to this argument the SI part so how does the SI part look let's look at this the SI part and so this is the location at SI we want a function that stays quiet but just around this achieves this height and goes back so let us say this height is h i h i so suppose it produces only this much but at all other times it is zero right so in other words its value is like what people call a step function like like this like this and then it suddenly achieves the value of this this function and then it suddenly achieves the value of this, this function. And then it again goes back to zero and continues as zero. So suppose I could write this function using my magic boxes, then all I need to do is I can take those mechanism and stagger a lot of those things horizontally and I'll be done. So the question is how would I do that? Well it turns out that if you look at this function something that goes like this let's look at it it is called a step. The step is if you look carefully it sort of has the feeling of a sigmoid. So you know you have a S sigmoid what happens if you take this sigmoid and sigmoid so you know you have a s sigmoid what happens if you take this sigmoid and sigmoid goes like this like this isn't it what would happen if you sort of squeeze the sigmoid tight squeeze it so that it begins to look like this. This. And how would you do that? Well, there's a little bit of machinery here, but I'll tell you the solution. Remember that we said we do it based on the inputs, the X and the weights. What we do is a weight bias term, the weight W0. Let's say that this function is W0 plus W1X. And only in this region, we do a sigmoid of it. You know, there's a weird distortion of it. So what you do is if you make this big, by controlling the slope or rather this part w1 you actually control how quickly it rises right how much it begins to look like a step function it's just a mathematical property and what what in the world does this guy do it turns out that when you decrease it the more negative you make w0 the more it moves back and forth. So in other words, this curve along the axis, if you make W0 more negative, it will move back and forth. This is controlled by W0 and the steepness is controlled by w1. It's just a mathematical property. Just take it as a fact that it is true. And we'll see an illustration of it in just a moment. So now comes an idea. Looking at this, it looks like the first part of the slope. Would you agree, guys? If I'm writing a function that looks like this, one part i can get by one of those magic boxes box one i just need to configure it properly do you agree with me guys yes right it is straightforward right i can use box two and then i can use another box to produce this other part of it, box two, right? All I need to do is, instead of x, I just put minus x, right? In your function. And then I will end up with a sigmoid like this and that I can squeeze into a function like this. So what we conclude is by again, somehow the magic of two boxes. Are you following the reasoning guys? I just made a pretty strong argument here. I'm saying by using two of these magic boxes somehow together, right? And this solenoids built in. So not sorry, this resistors built in, I can use this combination, X goes to this and this, and what I can get is in effect an output. Note Y, which will look exactly like this. This box will produce for me, this result exactly like this, right? Will produce this for us. So far so good. So you need a pair. You basically need a pair of boxes. Make one tiny, one tiny part of the curve at SI at this location. Right? So, sir, why, why a pair is needed needed I was thinking that only one box is needed. See this box so let's say this box will produce this and then right shifted this box will produce this. Oh I see okay. And so the two boxes put together will produce this step function step function is the beauty of it and so now we now can you guess how do I create this entire thing how do I recreate the entire function what do I need to do add the same thing again and again whole series of boxes. So for each of these locations, just go adding pairs of boxes. So what I can therefore do is I can do, just build them in pairs. I'll just put dotted lines here. And then another pair, and another pair. And you can keep going arbitrarily know, arbitrarily as many boxes as there are. So suppose there are K. You broke it up into K parts, right. So K, K regions. Then what happens, you just need K pairs. K pairs. K pairs. And so we keep pairs of boxes and this input. And again, do you see the beauty of this argument guys? And then you can play with this. You have it. And so what do you see? With a single layer, you can approximate any function you want. Now, we have made this argument in one dimension. It's easily generalizable to higher dimensions, but we won't do it in the interest of time because I want to move forward. Do you get this argument? This is a fairly elegantly made argument, and it is made in Michael Nielsen's blog so that is the reading assignment for today now we'll walk over to that blog and we'll try this out in real life and then I'll show it with some code will actually do that verify that this isn't all a game this is real life it actually does happen will verify it in code does that sound like a plan days yes yeah let's do that so let's go back to our educational portal where is our go ahead so there your voice is coming with a lot of distortion. How about now? Absolutely clear. Okay. So now my question is, you know, I was just going over the previous example, which you explained, you know, for the K pairs of boxes to implement those step functions, right? So does that mean we are going to have, you know, K hidden layers or? No, no. One hidden layer with 2K neurons in it. Remember, this is one hidden layer. Let me go back. Okay. See, one hidden layer. But suppose I make K regions. Suppose the number of regions here is K. K regions are there for each reason i need a pair of boxes and so with 2k boxes twice the number of regions i will be able to approximate this function in a single hidden layer okay so or can we take that hidden layers as you know the dimensions if it is 2d then it is one hidden layer if it is 3d it doesn't work it doesn't matter see that only affects um this part suppose you have 2d sorry 2d then this will come out this will also start shooting off inputs to these this is how you go with 2D, but that doesn't work. A hidden layer is, I mean, in a way unaffected by this, what happens is that your argument is essentially correct in 2D because these are surfaces, right? You need to be more careful. The number, it is not just 2K, it increases now. Yeah, yeah. you need a lot more okay do that okay the reasoning remains the same but you you just have to do that so now let me take here guys to so guys by now you must have realized i hope that there is a lot of uh information there on the on the course web page so please do try to come to it now I have created a section for today's topic which was neural neural networks now activation function I introduced to I didn't get time to do gradient descent we might not actually so we'll keep it for the next time. Vaidhyanathan Ramamurthy, So we'll go to this a visual proof that neural nets can compute any function. Let's see. Is that true Vaidhyanathan Ramamurthy, So, Vaidhyanathan Ramamurthy, You see this thing. Let me make this This is a reading material guys for this week. Please read this very well written chapter in Michael Nelson's online book. It's a short book. Each of the chapters are, once you understand the concept, you can just glance through and you know, I've explained everything to you. You'll be pleasantly surprised that now when you read this chapter, you'll find it very easy to understand. So he's arguing for what I'm talking about. Now you can read through this, but I'll go down. And at some point he shows, yes. So you see that this is a very peculiar function. Now, how do we approximate this function? Look at this. Just look at this neuron. This neuron has, this is one magic box, right? X goes into this magic box. And when it goes in, what comes out here at this particular point looks like this because it gets distorted. Now let's play with this. distorted. Now let's play with this. See as I move this B, do you notice that it is moving to the right or to the left? Okay let me start with the weight. See what happens when I increase the weight. Is it beginning to look like a step function now? Yeah. So that serves a purpose. it shows that it does begin to look like a say and now where is this located I can you see by decreasing the remember this was W naught in our notes do you see this by changing the value of B I can decide where is this position so by now you get the idea that we can play around and create a little bit you know one little region of the function we can approximate using a pair of these and we'll see that in a bit here's a little video in which it shows this is exactly the same thing that I showed to you. Then what about the other part? The step function is not made. At this moment, it's a step up. It doesn't look like a tiny region. So we need to do the second part also. And so again, that is what he explains. So now look at this now he has taken another box well if you want to go up here we are so see what happens if i decrease the weight of this does it now look like one of our regions guys one of our regions guys yes it does and so you can play around with this and then you can expand this you can contract this you can play around with it so by now you are getting the idea that using a pair of sigmoids you can emulate regions you can even even play around with different shapes and so on and so forth you're beginning to get that idea it can even go negative and so forth so that is the point that has been made and please do have fun with this blog it's a really lovely blog so now you notice that using pairs of it you you can play around with it. So what happens? You see this. So do please play with it and it will give you an idea of how, for example, this function is being approximated gradually. And so when you look at a complicated function like this, the idea is that by playing with that you'll be able to approximate it so now what I would like to do is that show you this thing in real life with code so in your code you will see and I'll upload this for this week's lab I will show you this thing are you guys looking at my notebook now yeah yes so for you to play what I have done is I've created a simple class for your universal approximator right and what your job is just imagine think of some kind of a function so this lambda expression let me explain this is a Python syntax it basically say that X gets mapped to this this is as close to math as you can be in code does it look like that X is getting mapped to this function. X goes in, out comes this thing. And you can put whatever you want. What you do is, and I won't run it, you have the approximator. I made it very simple for you. So first what do we do? Whenever you have a model, we need to train the model, isn't it guys? Remember the first step is you need to train the neural network. Then we need to train the model isn't it guys remember the first step is you need to train the neural network then we need to evaluate the neural network and when you evaluate one of the easiest ways to see how well it looking at the correlation between Y and y hat prediction and reality how correlated are they right so this is what it is doing. And I could run it. Do you guys want me to run it from start? Or we're a little bit low on time. Okay, let me just stay here. I want to cover one more topic. So what happens? Do you notice that? How does this curve look like? This is, of course, the sigmoid looking curve. Now, if you look at this curve curve let me show it to you in a little bit more magnified way look at this and look at this do you see that there are imperfections here do you see little imperfections in the curve look at this region in particular i don't know if it shows through on your screen. Yes. Not as smooth as this one, but it is still a pretty good approximation. Would you say that, guys? Agreed. Pretty good. And let's look at the correlation, the Pearson correlation between the ground truth and prediction is 99.9984% For all practical purposes, you have a very good approximation to the underlying ground truth. Let's try something else. What I did is I created a weird function. I put this, this, sin x also into it. And then I trained it. Oh, I don't think I have run this. When you run this, okay, I'll leave this to you to run it. In my case, why is the running part not showing up? Give me a second. I didn't know what just happened. Okay, for some reason it has gone into a read-only mode oh it was hiding here okay I have to run it from the beginning let's see it is running the unit is that it's approximating it gradually i run it for only one epoch which is usually good enough for this one and the accuracy is 99.95 percent the plotting i just plotted exactly the plot we want now let's try with this weird function this weird function also is trying to approximate it. Oh, I didn't plot the figure, but you can plot the figure. I'll leave that to you to plot it. 99.98% accuracy. Well, pretty good. You know, imagine being writing some very strange function like this and then having a neural network approximated, generating data from this. I took another one, a sync function. Those of you with some background in hardware would be perhaps in love with this function, it's very common. What does it look like? So I won't run it because it takes a bit of time, but not much time, but this is it. So now I made a curve that looks like this, and look at this. This thing has been able to approximate that also. So then I thought, let's go crazy. Now, this looks really confusing, isn't it guys? Would you agree that this is, how many of you would like to compute this by hand? Any takers? I call it too many signs. So all you have to do, by the way, guys play with this. And the only thing you have to do is either define the Lambda function as a Lambda or actually define it as a function. Follow this code that we have written. The rest of the four lines of code are exactly the same. That's why I've simplified it so you can quickly play with it. So the original function is like this. Do you notice that? And what the neural net does is this. And it does it in only two epochs. If I run it for more epoch, it gets better, but I won't do that now. Here it is 98.46. So you can try running it for five or six epochs. You'll notice that it begins to pick up on some of the perturbations here. But would you call this a pretty good approximation of this crazy, crazy function? Yeah, smooth. Where do we get this notebook? I don't think it's in the original. Is it a newly posted? Yeah, I will post it now. Okay, because I was like, where is that? Yes, it is week two is the week two word is the week two I haven't done it So the functions those graphs, is there some data it's working on or it's just directly doing it on the functions we are defining? Yeah, so if you want to look at the code actually what i do is from the function i generate the code uh since you asked the thing what happens is you can if you go and look at the approximator univariate approximator you will see that what i do is do you notice that if you give a function to the input I generate the data you know create the data do you see me create the data yes that is it so in the idea is that obviously you won't know the function in real life but you will have the data and the point of neural networks is irrespective of what crazy function produce the data the universal approximator theorem guarantees that you will come pretty close to it isn't that a most remarkable result how many of you are impressed with that yes Yes. Pretty impressive. And now you can sit back and say perhaps that perhaps we are beginning to understand why do neural networks work at all? And why are they so versatile? And why are they so amazingly effective? So see, we are starting on a journey of deep learning. It is one of the things we miss. We have a lot of textbooks misses. But at the heart of this subject, it is always worth knowing what drives the engine. So now you're getting some clue on what drives the engine. So we have 15 minutes left. The one thing I wanted to cover today are the activation functions, all these distortion functions. But I don't want to do it in a hurry because that as the old British saying goes, hurry spoils the curry. Let's not do that. We will do it carefully next time. And gradient descent also next time. This took a little bit longer than I thought, but I hope you did find it, gave you some idea of what the subject is all about and how it really works. Next lab is of course nothing to do with theory. We'll completely focus on actually building practical neural networks and solving practical problems on Wednesday but with that thing there guys I mean again I would like to emphasize please do give me feedback this is the feedback I received till morning because the feedback let's look at the feedback because the feedback helps me decide what to teach over again so if i know that some topic is not clear so we seem to be doing reasonably now where have we yeah so it says understood most of it though some clarification needed or four of you felt like that so what it means is i need to be more careful and i would love for you guys to speak up when I'm not clear stop me or we will do it we'll do it in the extra session on the Saturday but one way or the other I want to make sure that we clarify it and you understand it because this field is all about understanding some very simple ideas that's all it is this is very good you should probably include at the end a little field for a text comment oh yes a excellent idea why don't I do that for this week's feedback I will do that nice so so here is interesting the pace is a bit faster then Dan is helpful perhaps we need to slow a bit. Three of you felt, one of you felt we need to go a bit faster. But most of you felt that the pace is about right. So the people who are finding it a bit slow, and three of you are there, I do apologize. Part of pedagogy, part of the whole educational processes you know what is the old slogan no person left behind you always make sure that you're carrying everybody with you at the same time you know for people so but for people who are finding it fast take it as a responsibility don't don't hesitate immediately stop me if i'm going too fast i would love to slow down see remember guys i said that this is six weeks but in reality we'll take as much time as is needed to cover part one and as you know every single workshop in the past we have gone longer than was initially planned but we have learned it well and i would like to do that mr go ahead yes so ask if you could if you could give a five minute break right so after an hour maybe just give a five minute break and then continue for another hour because sometimes it goes an hour and a half oh yes so that even a five minute break will help us to kind of you know refocus so that that's one of my feedbacks otherwise it was great i agree with that yeah okay i'll remember that and if you see me get carried away and lost in the subject please just stop me at the hour interview okay just say that might be a good time to take a break i don't hesitate please sometimes i get lost in the topic so this is good so this was something a bit worrying Auto ML we did a I clearly have done a very poor job only less than like about half the people feel that we didn't do a good job with auto so I'm going to repeat it guys I'll go deeper into it and I'll repeat it of course this was just an intro I'm going to repeat it guys. I'll go deeper into it and I'll repeat it. Of course, this was just an intro. I'm going to repeat it later. But if time permits, even the introductory part, I'll try to repeat it this Saturday or at some point. similar effect though I'm hopeful that this will this is easier we'll pick it up as we move along hopefully or otherwise we'll do an extra session on that and Jupiter notebooks are you able to follow the experiments so here there was a very useful feedback it says I need to add more comp more explanation in the notebooks so I would love to do that could one of you elaborate what would help like when you look at a jupiter notebook like this um how can i oh sorry when you look at a jupiter notebook like this give me an idea how can i help you with more like this give me an idea how can I help you with more maybe in every section I need to add more text and more explanation is that what you guys are looking for or something else should I comment my code more can you add more comments to explain the code like some in the code itself. I think, Asef, from my perspective, commentary in the in your saved functions, the functions which you're calling in this main code, I think that would be helpful because the code, I feel it's understandable but some of the functions which you have created and which you're calling, some of them functions that you have created in which you're calling some of them are like difficult to follow especially if you are not very familiar with data structures oh yes yes see guys let me be clear at this moment right to go back to the code behind and understand it i ask you to go take a tour of it don't expect to understand it yet fully it is meant to be difficult but the reason i wrote that code is so that your notebooks are simple your goal is to understand the notebooks understanding even some of the code is a stretch goal guys at this moment but i will try to comment uh make sure that there is more documentation in the in the source code itself I'll remember that so alright guys so that was one feedback and where are we in the feedback part yes and overall experience seems to be more or less positive anyway guys so we will review our feedback every week it will help you guys give you what it is that will get you the best through the course so let us summarize where we are today we gave pretty much the whole day to a couple of topics the topics were and let me topics were and let me do this i seem to have written all over this blackboard um just wanted to know what are the chapter numbers that we've covered today just to go back and review in the textbook i will post it in this right away i would suggest okay so let me remind that what i would suggest is don't start with the textbook. That textbook is a high bar. Now that you have listened to the lecture, you'll understand it. But in the textbook, the universal approximator is mentioned very succinctly, if at all. What I want you to do is do this one. Where am I? Deep learning fundamentals. Okay. Do you see this section? Neural networks are universal approximators. By now, I hope I've convinced you of this fact that neural nets are universal approximators. So guys, those of you who like it visually as a video, watch this Michael Nielsen's video. Those of you who like to read it, go read the Michael Nielsen's video. Those of you who like to read it, go read the Michael Nelson's chapter, online chapter. This is your easiest start and a review of what we have done. You'll see that you do. So he does it only for regression. He doesn't explain the classification part the way I explained. That is not there. So that you can just look from my video. That may be unique to me because I don't think I've seen that sort of explanation anywhere. So for that just go back to my video. Our portals are going to be updated so they look like that. I'm sorry please say that again Kate. our is our portals that we see going to be updated so we have these links because I don't see that right now no these links are there under the it's further down see Kate I'll give you a hint you see this navigation right always use the navigation. It is either on your left or your right. Most likely you guys have it at Sajeevan G. In this way. Right. So because it is a long a page, you know, seems like an infinite page almost what I would do is just go to the table of contents and search for this. table of contents and search for this. So you will notice that somewhere here, neural networks are universal approximators. You can go click on this. That is one way to do. Another way is you know that the word approximator is there in this page. So you can just search for the word approximator. Okay. I see it. Things just get pretty buried. And then there is another blog actually from Christopher Ola. I have interacted with him a few times. He explains, and this is of interest to those of you who want to understand how activation functions distort the input manifold, the input. so what is a manifold you know you'll see this word manifolds and topology right a topology is the shape of things manifold is uh well okay think of it the cloth right uh imagine a nice silk cloth now into in in three dimensions you can think of it as a cloth now what does a silk cloth have a property of? You can't wrinkle it up. It will always be smooth and nice. Do you agree, guys? When you look at a silk cloth, imagine a silk sheet crumpled up on your bed. No matter where you look at it, it will have smooth undulations, smooth curves and bends and so forth. So things that are smooth geometrically, ultimately that's a function. Now, again, think in terms of function. In three dimension, that your silk bedsheet with all its curves and undulations happens to be a function. And in fact, it may be a regression function right if you relate it back to our work now so maybe a new way of looking at bed sheets and blankets but it has a quality the quality it has two qualities first is you don't find sharp edges there. You don't unless you iron it, which I hope you don't So it will not have points Meeting very sharply at any point the lines linked creases You won't find creases there the second good thing that you find in silk sheets is that no matter how much you undulate it If you look locally at a region imagine that no matter how much you undulate it, if you look locally at a region, imagine that you're a little ant, right? And little ants, by the way, have you guys seen ants coming into the house? Recently I've seen ants coming into my house. And so this is very real. I saw an ant on a sort of a blanket sort of thing I have, and it was roaming around with it. So think from the perspective of an ant. Will the ant which has little eyes and can only see in front in the regions around it, will it know that the sheet is crumpled? What will the region, what will the world around the ant look like what will she see anybody would like to guess hills no it will see the plane because everything looks so again lowered space right a tiny ant or think of a dust mite what does the blanket or wherever that is yeah it is it is flat the world is flat to that little insect isn't it so uh these surfaces that have these two properties that locally they look flat flat means to use a more technical jargon they are cartesian they are They are Cartesian. They are they basically look like Cartesian play Spaces are R square R cube and so forth. But let's say R square are plane surfaces and that don't have creases These things there is a fancy word for it that mathematicians use roughly. These are called manifolds obviously, you need one more property because of the undulations one ants you know map of the world may be different from another ants map of the world because ultimately the sheet is curving around and you know it has undulations so you need a way to sort of reconcile the regions that both of them are seeing if these ants are close to each other so you have to have a sensible way to translate from one ants map to another ants map so long as you can do that and so mathematicians do worry a little bit about that but roughly speaking on a sheet of silk you can do that if the ants are smart enough so that is a manifold that's what a manifold is literally and you we can see this whole thing in much more fancy mathematics but roughly speaking that's what a manifold is so you you realize that uh regression self regression is essentially searching for that line or curve or plane all of these examples of manifolds embedded in the data in the data space in the feature space likewise a decision boundary is nothing but again a manifold embedded so in many ways you can say all of supervised learning is a search for these hidden manifolds. So with that explanation there for manifolds and the structure or the shape of the manifolds are the topologies. How do they look kind of a thing. So that's a very, very hand waving argument. So if there's any mathematician, you may get a bit annoyed by my oversimplification, Be that it is, let me take you here. So he talks about this in this lovely blog of how neural nets and their activation function, they deform the space, the input space. So you see that how the layers that come afterwards, they see a very distorted view of the original input as they come along. And so I would highly recommend you to read through this blog it's very useful are we together so these are the two readings and a video or alternatively a video that I would encourage you to do guys. So going back and then we will do the lab next time. And then I will, tonight I'll give you the theory reading material from the textbook, the main textbook. There isn't much. And then we'll talk, it has a discussion of activation functions, et cetera, but I'll discuss the activation function in much greater detail next time in theory. And next time we'll be diverted just a little bit of time to activation functions. There's not much. We covered the main idea, but I have to just show you examples of it. But next time we'll deal with, next week theory will be gradient descent and backpropagation, the concept of backpropagation. But we won't wait for theory to develop, the fundamental ideas to develop. In Wednesday, of course, we'll steam ahead and start doing practical things, build a real neural network and understand PyTorch code. So, Nisar, to your point that my code, right, is a little bit hard to understand, let us hope that gradually it won't be hard to understand in two more weeks. Okay have a question Asif. During your Saturday session, can you take an example of one of your source code and probably help us how we can learn it by ourselves, like have stops and stuff like that? All you have to do is show up. Those of you who showed up on Saturday remember at the end of it I did whatever you guys asked it's a carte blanche come and ask for it but I will definitely do that if you are around yeah all right so guys I hope you are aware that all the videos are here we had seven sessions in week one two of them were necessary sessions Monday and Wednesday there were five optional sessions all of them on Saturday I hope you are aware that we have videos of all of them here look at it the first one is a workshop administrative year the rules and regulations which was on the Monday, the first half. Monday, second half, we did an overview of deep learning. Then we did the lab on Wednesday. And these are the Saturday sessions, four sessions on Saturday. We reviewed the two quizzes. Then we did a beginner's introduction to Python. And then it was a free-for-all, like whatever. It was an open-door clinic, whatever people asked for. We will repeat this pattern as we go along. But there is one thing, guys. This week, I have added an extra thing. We are going to read papers, but this, because we are still starting on. I have not talked about Christopher Ola's blog this manifolds in topology blog please read it this is a stretch goal it's an optional if you're just entering machine learning though it might be too much for you if you want to read it if you and discuss it then do read it and we'll discuss it on Sunday at noon. So it's totally up to you if you want to go that far. But if you do, I will have a guided walk through the whole blog and I'll explain things. All right, guys. So with that, I will conclude for today.