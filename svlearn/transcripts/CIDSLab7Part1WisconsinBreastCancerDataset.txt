 We can see, hear you and see the lab. It's great. It's wonderful. Thank you for confirming, Kate. All right, guys. So today is the afternoon. We are going to walk through a particular data set. It is quite celebrated, especially in machine learning. Whenever you take courses in machine learning, sooner or later, you have to encounter this data set and go through it. Sort of a rite of passage. It has an interesting history. I believe it belongs to the 90s. Now, the way I remember the history of it, and I may be slightly off so please correct me if you find mistakes in what I say later. A few scientists they got together and they asked can we apply machine learning to tell when you look at tissues, breast cancer, like whether the person has malignant breast cancer or benign breast cancer, when you have tumors, and this is one of the things women absolutely fear, is obviously any kind of a tumor or any kind of a hardening or anything in the breast tissue. And usually, it is mammogram is followed by biopsy and pretty invasive things. In those days, it used to be pretty invasive. You had to cut open and go and look at the tissue and it would leave scars, not a very pleasant thing. So, and like this, there are many other data sets to do with prostate data, kidney data, liver data, this and that. And we are going to, over a period of time, look at a lot of such medical data. Today, the simplest of them is to do with breast cancer. This is why it's a good starting place. Now, what happens is that there was a technique developed which was called fine needle aspiration instead of opening up a person you would just go in with a quick quick very tiny needle and aspirate out a little bit of the tissue and then you would look at the tissue under the microscope to see is it a benign tumor or is it a malignant tumor now these scientists, they had the idea that what if we could do feature extraction from those images. Dr. G R Narsimha Rao, Ph.D.: What if we could look like instead of just looking at it quantify what is it that the pathologist actually look for what tells them that it is benign or. malignant and let us quantify those as mathematical measures so we can automate the process. I believe they had some degree of success. What I remember is they tried to commercialize it also and so forth. So they worked pretty hard in trying to do feature extraction from the data, from the images. So the features they extracted was obviously first is ID, we can ignore. Diagnosis is, is it malignant or benign? Now, they looked at the radius of the cells. They looked at the texture, the perimeter, the area, the smoothness, compactness, many things. And they looked at the standard error of these, the worst case situations, the mean of these. So they tried really, really hard to do as much feature extraction as possible. And we will see whether it makes sense. So now just a little bit of a domain aspect of it. You have to understand that normal tissues have a growth cycle. They mature to a certain degree. A cell reaches maturity before it splits, before it has cell division. before it splits, before it has cell division. Almost by definition, the cancerous cells are cells that replicate very fast. They don't ever reach full normal maturity. They grow, split, grow, split, grow, split, and very rapidly they grow. And so the cancer cells are generally not big cells. There's a lot of tiny little And so the cancer cells are generally not big cells. There's a lot of tiny little relatively smaller cells and fast replicating. And that is the nature of cancer cells. So you would imagine that these features all make sense. If cancer cells relatively malignant cells are fast replicating, their radius would be small. Their texture will be different, not mature. Perimeter, the circumference again would be smaller and smoothness, compactness, how compact they are, they will be far more compact. Concavity, whether they show concavity or not, or do they just bulge. Concavity points, how many such points there are? Symmetry, the fractal dimension is something very interesting. It is a measure of how corrugated or sort of how many little bumps there are on the edge. The word fractal comes from the boundary of nations. For example, if you look at a map, you will realize that what is the length of a country's edge, an island's edge? Sure, the answer would be well practically infinite because you know little zigzags are there all over the place. So there is the concept of fractal dimension which is a measure of how much sort of, think of it very roughly as the bumps that you see on the surface. Think of it very roughly as the bumps that you see on the surface. Radius standard, then the rest of it is the same thing repeated as standard error and so forth. And then the worst values of it was the worst radius that you see, so on and so forth. So three types, the mean, the standard error, and the standard error, think of it as sort of like analogous to the variance and the worst point. So if you look at this data, this data comes to two unnecessary columns unnamed and id i have taken that and represented it here when you look at this data you can oh sorry data is not defined so give me a moment Data is not defined. So give me a moment. There we go. So this is, again, to remind you that you can always prettify a data frame table to look more pleasing if you wish. Well, I don't know if you would consider this more pleasing, but you can style it. And this is it in a simpler form. You're seeing a few rows. Are there any missing values in the data? We noticed that there are no missing values, so we don't need to do missing value treatment. Now, when you do classification, remember, looking at data imbalance is important. Here, when you look at this data, you see that most cases are benign. Most tumors are benign, thankfully. And a smaller proportion of cases turn out to be malignant in these situations. In fact, a two-third, approximately 63, 64% are benign. And the rest are malignant. So what do we do? We have a lot of features. Let us do, actually, they are not seven variables, this statement is incorrect, but let's go and build the box plot and the violin plot. Violin plot will show you the distributions and box plot will show you the outliers and how far they're stretching. They're very similar, but in my view, I always tend to look at both. So for example, you can see texture mean has a lot of outliers, right? Clearly spelled out outliers. Concavity mean has even more outliers. So fractal dimension has outliers, strong outliers, compactness has outliers. So you get a sense of what the data is. Any questions so far, guys? It's very simple data exploration. So what does the outlier mean here? Outlier means it's outside the normal range of values. Is that like the cancer? No, no, not necessarily. It's just that some data points have, you see it both in cancer, like for example, look at compactness here. Both for cancer and cancerous and for benign, you see that you have outliers in both situations. It's just a fact of life in the data. So then this is a thing, you know, when you look at a graph like this, one can get overwhelmed. And what you have to do is soak it in. You soak in and you look at it. And the first thing that stands out in the very first row itself, look at this radius mean. When you look at radius mean, what do you see, guys? Look at the x-axis. look at radius mean what do you see guys look at the x-axis do you see that you can differentiate the blue from the red the malignant for the uh the benign is blue malignant is red if we just separate the decision boundary around 15 or 16 it would separate them okay please go ahead It would separate them. Kate, please go ahead. They're well separated. They are well separated along the radius mean axis, right? And so it almost like begs the question, do we even need to bother about building a classifier or visually we already know? Use radius mean and you have the answer. And there are a few more predictors. Perimeter mean, which is related. Area mean again has a separation some don't have smoothness doesn't have a good separation but okay cancer oh what just happened give Give me a moment, guys. Okay. Give me a moment. I think this thing has been done. This thing has been done. Yeah. So we are looking at these. Sometimes the separation is pretty pointed. Like, for example, concave point mean. Do you notice that there's a pretty good separation, concave points mean, between the benign and the malignant ones. So there is overlap, but in the overlap region is the outliers of benign overlaps with the regular ones of the malignant. Do you see this? Here is the outliers and here is the normal values of that. So it means it's not a perfect measure, but we could use concavity points mean as a pretty reasonable way of separating the two out. So these are the things you should look out for in the data when you see this. It gives you a strong intuition. And so when you go armed with this intuition into building models, you feel you know what to expect. So I've just separated out area mean to illustrate the point that you can literally draw a line here, a vertical line where my mouse is, and that would be a pretty good classifier. Let's look at the correlation between variables. Because we don't want to see very strong correlations. There doesn't seem to be very strong correlations. But there is some degree of correlation, positive and negative correlation. So, for example, smoothness is a very negative, relatively negative correlation to radius worst. Isn't it? And you would imagine that now you can start imagining why it is so, right? So if it is, basically what it means is that if radius increases, smoothness, worst radius increases, smoothness decreases. So if you leave the worst part aside, if you look at only the mean part, then you see there is a strong one fractal dimension mean is strong negatively correlated with area mean which again makes sense right um so it is worth sitting and pondering over it seeing which is positive does it make sense or not in terms of a domain understanding and then we take the pair plots. We always draw the pair plots. What I do is there's so many predictors, 30. So I broke it up into the ones that end with mean, the ones that are standard errors and the ones that are worst so that we get three different plots. When you do this, you get this plot. By the way, this plot in your screen may look small and you may not be able to see this plot. By the way, this plot in your screen may look small and you may not be able to see this legend. But what you can do is you can save the image. Let's say I will save the image on the desktop, for example. And then what I can do is I can open it separately. And when you open it separately, you will realize that you can zoom in. And actually, it is pretty detailed. You can see area mean, perimeter mean. So this becomes a giant image that you have to... What I do is I take this sort of image, and then I move back and forth and I try to understand. So let's try to understand. What do you see? First of all, if you look along the diagonals, some variables are well separated while others back and forth and I try to understand. So let's try to understand, what do you see? First of all, if you look along the diagonals, some variables are well separated while others are not, right, with the benign versus malignant. In some of these predictor cases, features, they are well separated. In this case, for example, smoothness mean, you would agree that the separation is not that much, there is a lot of overlap. Whereas if you look at this one which is area mean the separation is fairly good i wouldn't say perfect but good if you look at maybe this one is a little bit better what is this concave concavity mean and then concave points mean seems to be even better so you can play around with it. Now let's look at this. When you see things everywhere, the two colors seems overlapping as well as slightly separated out. Now, do you notice anything else here in this diagram? You notice that most of these things are clustered around the origin, bottom left-hand corner. This is pronounced here when you look at this right and some of these are pretty pronounced let's say which ones here do you notice that the blue ones are pretty concentrated and the red the purple ones are a little bit more spread out so these are just things to notice when you look at the kernel density plot let's look at these you see that how well separated they seem the purple ones are centered here the the blue ones are centered here so the whole thing looks very promising that we might be able to build a good uh this one if you look at it again all of them seem to indicate that there are many many predictors that can help us distinguish between benign and malignant tumor in this data isn't it look at any one of these the ones where it is not is this which is symmetry mean the two are very overlapping which shows up in this picture also but in most situations they are well separated let's say concave points mean is really well separated and so forth so what can we do it's good we can do that so let's go back to this diagram yes how do i look at like morning you mentioned something about like additive causes versus like multiplicative causes? Right. How do I get ? I'll come to that. Or like in this chart or like somewhere else in the notebook? Yeah. What you would do is keep that discussion aside. For regression, it's a more intuitive thing. If you look at the target variable, and the target variable seems to have a log-normal distribution kind of thing, skewed distribution generally it means that it is a multiplicative force involved see none of these are very hard and fast rules but i often i tend to find that it is mostly true you will have multiplicative factors involved. We did that exercise last time when we saw that. So that is that. So likewise for SE, I won't repeat this whole thing. You see this distribution. Then for worst case, you see this distribution, right? So all of these. Now, the point that I'm making is, guys, when you see this distribution, don't just say, okay, yeah, it looks pretty. What I would suggest is the bigger the graph, see each little tile, give it at least a minute. Think about it. What does it mean? Why am I looking at it? You know, move around it. This is what I do on my screen. I keep, whenever I get data, I keep pouring over it like this and seeing what it could mean, what it could mean, what could you know, you get little little hints from each of these. And those little tidbits of hints, they give you a deep intuition eventually about the data. So do spend a lot of time when you get data in doing that. So I said that the spread thing is that like, they're looking for the variance? No the shape of it, the shape of of it the one which is on the right hand side with the dot spreading out oh yeah this sort of spread out it just means that one variable one value is clustered the other value is spread out now why it is spread out we need to think about it right we need to think about it uh asif why did you break the features into three spaces oh because it is it is just a optics thing there are 30 features so 30 columns in this grid would make each of these little things tiny it would be very hard to decipher it's okay manageable yeah just to make it manageable. And basically not the best idea because what if there's cross interaction between the mean of something and the worst of something else, right? Those cross interactions have lost. Okay. And so ideally I should have just done all 30 by 30 in one go and taken a zoom, know, just like i'm doing here zooming into it and then looking at it carefully, I should have done that now, but it would look in the Jupiter notebook it would look hopeless. Okay that's the only reason. or just just whatever program it is. or just just whatever program it is in your machine you'll always have some image viewer program right to zoom in and zoom out oh i see it's just an image you took and yeah that's right yeah so then i'm going to now one of the things i'll do this is just a technical when I'm going to use the yellow brick, it likes its target variables to be called one and zero, the yellow brick library. So instead of benign and M, I just found it easier to follow the yellow bricks convention. So I made M for malignant, one for malignant, means the positive case, and zero for the benign, the negative case. So it's just a data target variable change. Then first things first, do you notice that I do the dummy classifier? Why is it a good idea to start with a dummy classifier? Benchmark. Benchmark. Exactly. You get a baseline. A dummy classifier will ignore all of your predictors and it will just look at some characteristic of the response itself. Here, the most common response. So because the positive case and the negative case, negative case is more common, 63.4%, it marks everything to be benign, no tumor. Of course, that is a useless diagnostic tool because it has missed out on all cases of cancer, all malignant cases. Nonetheless, its accuracy is 63%, right? And look at it. But what is noteworthy is that the thing that really matters is the recall of the positive case. You don't want to miss the positive case. You need a good recall on the positive case. In fact, the recall on the positive case is zero and therefore the accuracy is misleading. It just represents data imbalance. This number is bad as it should be because it's a dummy classifier. This number is bad as it should be because it's a dummy classifier. So the first exercise I do is, it is what I call the one hour. So I told you that sometimes, quite often, just one predictor is enough to do the whole analysis. Right? And I do it here. I use area mean. I invite you to use concave points or worst because that seems to be the clearest one and see if your results improve. In fact, it will a little bit, I think. So this is the standard classifier. By now, this code should be very familiar. You take the data, predictor is area mean. You build a classifier. You look at its confusion matrix and what do you see in the confusion matrix you see that we have um nine cases that we missed right nine positive cases we marked as benign so we missed but still if you look at the recall do you see that the recall is 83 percent it has improved a lot compared to zero right look here it is zero and now it is 83%. It has improved a lot compared to 0. Look, here it is 0. And now it is 83%. So 83% is a vast improvement over 0. Accuracy has gone to 90%, which is quite good, actually. And you can try it out. I'll give you a hint. A few other predictors, single predictors are much better than this also I will let you find those out so now the question is is this a good model right is it something that is usable one would argue it's a fairly usable model but nonetheless it seems to have missed nine cases, right? Nine people would go away thinking they don't have cancer when they do have cancer. So let's, the same thing, information is plotted out here. You see, when something so dangerous as cancer is involved, you have to be very carefully look at the positive cases. What's the precision, the recall of that right and the f1 score is 86 it's a pretty good model but still uh in a dangerous situation like this you probably want something better there is a lesson here breast cancer data at one time historically when this was happening people were coming up with very fancy algorithms, all sorts of deep decision trees and whatnot to model this. And this person Hult came up and he said that, see, whatever your fancy algorithms you're using, just picking one predictor comes within range of that. It led to a little bit of a controversy and discussion. This point is not always true. This is true here because all the other predictors are related to, all the predictors are interrelated to each other. So you would imagine that if you have a cell, its perimeter and area and radius would be very well related. You can't have a huge area with a very small radius, right? Common sense. So there is a lot of interrelationship. It's not always true, but sometimes it is true. You should try out a one predictor model always just to see, get a baseline for multivariate models. And you notice that both in regression and classification, I tend to do that. So here is a multivariate logistic regression model classifier. Now I do this. And you notice that when you do a simple logistic regression without anything fancy, how many cases did we miss here? Look at it, guys. How many cases did we miss? Wow, only one. One, only one case. And once again, we are not using anything sophisticated. Our sophisticated algorithms will start two weeks from now. Just linear methods and already you're doing so well. Look at our recall, 98% and accuracy is 95, but the recall of the positive case, which is really what matters in a screening test has gone up dramatically. So you would say it is beginning to look like a useful diagnostic tool at this moment, isn't it? Right? It depends on your definition. If you don't want to miss any case whatsoever, then maybe not, but it is certainly a very useful diagnostic tool or getting there. So then when you work out the class probabilities and you do this, this image needs, once again, let me, where is this image gone? What if just one quick thing like, so what did you change to get from 83 to 98? I included all the variables, multivariate now. Oh, okay. So this one again, when I have this, I save these images, and then I like to zoom in. So let's zoom into this for a little bit. So first, let's look at the top left in Karna. What is it saying? What is the most important factor? Guys, concavity worst. Yeah. Seems to be very important. Symmetry, et cetera. Right. So then what is the second most important factor? Texture SE. Do you notice that? Texture underscore SE. It has a negative impact in predicting, which is good. Ultimately, what matters is the magnitude. Now let's look at the confusion matrix, and how does that look? You look at it, the principal diagonal is very strong, right? And we seem to have missed, gotten seven cases wrong. What matters is only one case is such that will have very negative real world consequences. In other words, somebody had tumor, malignant tumor, and you just said it's benign, don't worry. I suppose the six people are concerned. Ideally, it shouldn't be there. But even if it is there, it's not as harmful. You go and scare six healthy people and tell them they have malignant tumor, they will be frightened for two weeks, get more tests done, and then they will go smiling because now they'll find out they don't have it. But this is terrible, missing out on something positive. This is now the precision recall that you see. The numbers are beginning to look very good, even with simple logistic regression directly applied. How does the ROC curve look, guys? Very good. Very, very good. It's hugging the top left corner. And so this is all very encouraging. This is that. Now, what are the importance, feature importance? You notice that this one seems to say concavity worst and texture SE are the most important factors. Now let's see what, one thing is that sometimes you have to worry, how did the tool come up with it? And here I would say that in my view, I don't take yellow brick as seriously as doing it by hand or using Shapely. You'll see that the answers differ. So remember what I said for a for sorry, I apologize, I wanted to make it bigger and I made it smaller. Okay. So feature importance. One of the things I do is I print out, I told you that for linear regression models, linear models, not regression, logistic model is also a linear model. Remember, beta naught plus beta 1 x1 plus beta 2 x2 and so forth you can if you have scaled the data if you have remembered to scale the data then the coefficients of the features is literally a measure of feature importance isn't it the magnitude of the coefficients is a measure of feature importance this is a beautiful thing that happens for linear and logistic regression let us see if this is true according to this all. This is a beautiful thing that happens for linear and logistic regression. Let us see if this is true. According to this, all I do is I look at the coefficients and I scale them down and print it out. It turns out that concavity worst and texture SE are two very important ones. Radius mean is number three and so forth. Does this agree with this? Concavity worst is what we saw. Do you remember guys? Yes. Yes. So there seem to be an agreement and I won't go down the rest of the list, but it is enough to see that these guys are in agreement. Then I just plotted it out as bar chart to make it obvious. How much do they matter? So you realize that much of the area is taken by one, two, three, four, five, six, five, six predictors. So this problem is amiable to dimensionality reduction in some form. And we'll try that later on when the time comes. I also did mention that the gold standard that I that I look for is the Shapley values. So when you look at the Shapley values, you find that the answer is slightly different, actually. The answer that it comes up with is perimeter worst, area mean, area worst, perimeter mean. I'd like you to figure out why this happened. Actually, I'll give you a hint. Clue is in the notebook itself there is something i did which if you can figure out what i did you will know why the answers are different but i'll leave it to you right but any given time i would trust this guy perimeter worst and so forth but these differences are not vast they're pretty much along the same. The reason it happens is all the features are so interrelated. Partial dependency plots, which of them has the steepest? Perimeter mean matters a lot, is very steep. And I just took the mean ones. Then area mean also seems to matter. the second steepest i'll leave that one of the things is a higher dimensional model is very hard to visualize prediction so just for fun i took two random features i took area mean and concavity point first i expect you to just try out with your own words. I built this prediction model and you see that there are quite a few misses, eight misses, but I wanted to visualize and see. And of course the accuracy has gone down, the recall has gone down. So things have gotten a little bit worse, but the purpose was to just plot it. When you plot it, you get a decision boundary like this. Let me now decrease the, oh my goodness. I tend to forget which decreases, okay. Can you guys discern the decision boundary here? Yes, nice white line. Yeah, nice white line, right? Okay, let me try to make it in one screen. Yes, it is almost vertical implying that area mean matters a lot more than concavity point worst. Concave points worst. This is a pretty significant predictor if you build a model between these two features. So now I leave this as an exercise for you. Do you realize that we did not scale the data? If you don't scale the data, well, of course, then I'm telling you the answer, but OK. Can you address this analysis? Not fully. Feature importance. You cannot trust the feature importance by just looking at the measure, just looking at the coefficient because you haven't scaled the coefficients. Scale the coefficient and then see whether these values agree with what Shapley has to say. I leave that as an exercise for you. The other thing is I did not do power transform. Do a power transform and see does the power transform help you get better results. And lastly, I did not do the discriminant analysis part of it again, because I left this as an exercise for you. Follow, there is no difference between using it here and using it for classifier one, two, three. The previous analysis is just a repeat, but it should be good practice for you. So could you please do that discriminant analysis and sit with the TAs to run through your solution, see if it makes sense. We'll be all there to help you. Any questions, guys? Anybody has a question? Is one normalized and another one not? Yeah, actually, that is it. I didn't scale the data at all. So basically, these numbers that I produced just by't scale the data at all so basically these numbers that i produced just by looking at the coefficient are not meaningful and i wanted you folks to realize that that this is a mistake a lot of people make i deliberately made the mistake because i wanted to leave this as an exercise for you to fix um i had a quick question. Yes. In the first box of the data visualization section, it's like way at the top. This one? No, no, no. It's that like it's towards the beginning of the notebook actually. I'll tell you when you get there. This one's? Oh, you know what? Never mind. Never mind. I figured it out. Sorry. never mind never mind i figured it out sorry sorry i figured it out that's right so guys this is straightforward by now after your practice with classifier one two three you realize that going over a more complex data set is also straightforward you need to bring the same carefulness about the analysis to this. That is all it takes. Right? And no magic, always do the dummy classifier first, do a univariate model, then go and do more complicated models. More complicated models need more interpretation and power. So anyway, I've given you the solution. I thought I'll leave it as a puzzle to figure out why did feature importances hand computed differ from Shapely? And the answer to that is the scaling, right? You cannot look at the coefficients till you scale the data. You must, must scale the data. Are we together? So how would you scale the data. Are we together? So how would you scale the data? Let me give you a hint. You need to add what lines of code here? Let me, in cell number 28, what is it? What is the code that you must put here? Let's say standard scalar x and you will get scaled is equal to this and then what do you need to do? You need to create your x train x thing from the scaled data. x scaled. This is it. I won't run it here. But if you do this, now data is scaled. Maybe I will run it here. Let me do this. I don't know if it will run here, because on this machine, I'll have to run it from the top. Okay, let me run it from the partially I'll run just enough of the notebook, because this notebook takes a long time to run. Why does it take long because of those uh pair plots oh yeah yeah no sns pair plots is it's a the library is slow it's just that you can't do much about it so i will drop i will just ignore some of the rest of the analysis uh go straight to where we create to where we create numpy access. Okay, mean features, let me just do this. I won't plot any of these. This will keep it slow it down. And we don't need it. But what we are doing? Data. Yeah, I need to do this. Data. Okay, dummy classifier, univariate, etc. We did. Multivariate. Okay, here we go. So we are making three mistakes with multivariate and confusion matrix is this. Classifier report recall is 94% pretty good. Then now you get the coefficients and this will take a little bit to come. Okay, so now the features obviously have changed because they have become columns. You have to go and look at the columns, what they are, but I'll leave it at this for a moment. The model diagnostics, let's see what we are seeing. We are more interested in that. When you look at what we are saying. We are more interested in that. When you look at what we are saying, we are now saying radius SE is most important. Concavity point worst is the next most important. Do you see that, guys? Our answers have changed. And let us see what Shapley has to say about it. Shapley, import Shap. Oh, on this machine. Sorry, guys. I don't have Shapley, import SHAP. Oh, on this machine, sorry, guys, I don't have Shapley on this machine, on this laptop, so I won't be able to, I'm having difficulty installing. Let me try one time more, see if it installs this time. sure it says successfully installed and let's try a look now do you need to change x train or oh yeah so it came through it ran through guys. So now when you look at it, radius SE, concavity worst, texture worst. And this is what we came up with. Radius concavity worst. Well, some of the orders have changed in our case. Right. But the top two are aligned. Generally linear models your own coefficients are more reliable than shapely because shapely will do this big statistical you know it will keep jumbling things up and look at every possible permutation and combination so all things said this is where we are so it's not clear to me why the when you do the standardization the feature importance changes it's quite simple because if you define feature importance by uh by the size of the coefficient so let's say that you you're measuring elephants in grams versus tons okay if you measure it in tens its coefficient will be small if you measure it in grams the its coefficient will be small. If you measure it in grams, the weight will be, the coefficient of weight will be huge for anything. So that's a drawback of the packet. No, that's not a drawback of the, no, not the Shipley. It's a drawback of us. That was not the packet. That was me doing it by hand, computing feature importance by just looking at the size of the coefficient. You cannot just look at the size of the coefficients unless data is scaled. I see. That's the point I'm making. So a basic point. Okay. All right, guys. So with that, I will, we finished this. I'll give you guys five minutes, five, 10 minutes to relax. And then we'll change topic. We can do more and more classification examples. I'll keep posting more notebooks, change topic. We can do more and more classification examples. I'll keep posting more notebooks. But let's take a five-minute break and then we'll do something fun. We have been doing a lot of serious things. Now we'll do some artwork.