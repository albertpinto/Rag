 So to review, we talked about classifiers last time. Now, classifiers are different from regressives. The fundamental difference is in classifiers, the output variable is identifying a class within a category. output variable is identifying a class within a category. For example, we are telling whether an animal, given its characteristics as input, is a cow or a duck or a horse and so forth. That is an identification. So that brought up the concept of a category of classes, a finite set of things. And you have to pick one. There is also multi-select classifiersifiers but we won't go into that now. For all practical purposes, let's consider one. So a thing is if you give the height, the weight, the size, the presence of horns or not and so on and so forth, hooves and so forth, you have to tell, the machine has to tell whether something is a cow or a duck. To be able to do so is saying that you are doing classification. Implicit in classification is you're doing mostly correct classification. An algorithm that is able to do that is called a classifier. So as I review this material guys if you have questions do please raise your hands and speak up. Now we took the example of cows and ducks and we looked at how we took just two features weight and size of a cow or a duck and we looked into the feature space where x-axis is the size, y-axis is the weight. So this is called the feature space. The word is feature space. The input space or the feature space. So in the feature space looks like this picture on the left hand side. You know that the ducks are light and small so they occupy closer to the origin region and they all the ducks their weights or their data points they cluster around and they look like a bell in one dimension and a bell hill in multiple dimension it's just a rounded hill kind of thing. When you have this, and likewise for cows, the hill is much more broad. Cows have a much longer variance, bigger variance in weight. But nonetheless, if we were to sort of split and not look at that too carefully, we can say that they look somewhat identical bell hills. If you do that then creating a decision boundary is quite easy. You connect the two hilltops which I have done here with the green line and then you take sort of the perpendicular bisector of those and that becomes a good decision boundary. So that brings up the decision boundary. Decision boundary partitions the feature space into regions. One region for one class. So the lower region on the lower side of the decision boundary, any data point that will be found will have to be called a duck. Any data point found on the upper right-hand side of the decision boundary will be called a cow. So that makes for a classifier. This particular classifier, this way of doing it, is called linear discriminant analysis. It discriminates based on one fundamental assumption which may or may not be true with data. It makes an assumption that the classes are well separated in the feature space. That's an important point guys. Remember this algorithm will work only when data is well separated in the feature space. If it is not well separated, then it's actually begins to sort of go down and not only are they well separated, they look like bell curves. Now what happens when they overlap, we'll talk a little bit about that today. In general, one fundamental requirement is that all the data points of a class are clustered together in approximately a bell hill of some sort. Then this sort of algorithm works very well. Now, here are the assumptions I talked about. The second assumption is, they are more or less like bell hills. For linear discriminant analysis, underlying assumption was that they all the bell hills look similar similar by the shape of the variance shape I mean sorry they share the same variance or spread at least approximately so it was just bell hills located at different places in the feature space. On the hand, if the bell hills don't look alike, like for example in cows and ducks, it's not as touching if we say that the two bell hills look alike. They don't. The cow will have a much more spread out bell hill, the variance is high in weight. A cow can be 500 I suppose or 600 pounds plus minus to 300 pounds whereas a duck's weight will be pretty narrow let's say about I don't know how much ducks weigh let's say 10 pounds plus minus five pounds or something like that right five six pounds. So the variances can be different but so when that becomes an issue and you have to account for the fact that not only are the bell hills located at different places but they also have different variances but then this there's a generalization or the extension of linear discriminant analysis. It is called quadratic discriminant analysis The way quadratic discriminant analysis shows for is that the decision boundaries become They become parabolic so quadratic Sort of they are not straight lines anymore that's the only distinguishing feature now sometimes you can use that to your advantage as as we will do for example when we do the labs you'll notice that in particular in data set 3 you will be using quadratic discriminant analysis quite an advantage linear discriminant analysis won't work there so that is something to know the other point with discriminant analysis is it can not only do binary classification a situation in which you distinguish between just thousand cows and ducks you can actually take put in as many animals as you want suppose you bring in a horse now you have a triangular situation and so you connect the hilltops of the train of the each of the bell hills you just find the bisectors bisectors of the connecting lines and then you will end up with this decision boundary you'll end up segmenting or partitioning the feature space here into three regions so there's any questions so far i hope this looks like a recap of what we did the previous time if you did not understand the last time or you want me to repeat the explanation now is the time to speak up so this is that so in simple terms a classifier geometrically partitions the feature space into disjoint regions, each region belonging to one of the classifiers. So it is a property, not just of the discriminant analysis, but of all classifiers. It's a universal property. geometric perspective is they take the feature space and they create disjoint partitions or regions of the feature space and give each partition a class one class only now a review of the point is coming towards let's suppose the the cows and the Dutch their variance as the hills spreads are different then all it does is as this picture shows it makes it into a car that is that now that's a recap with that I would like to move on to finish off the discriminant analysis final consideration as if I have one question here on on the on the if the if the classes on the input feature have some overlap so we cannot apply the classification at all no we can in fact that's the topic I'm about to cover any other questions guys so let me take this example in one demand yeah so so for us so for LDA we can have like more than two classes where we can it's a straight line we can not just straight line both for linear and quadratic which has curves basically in discriminant analysis the only underlying assumptions are the only assumptions are but each class is clustered appropriately around a different point in the feature space. Okay. Essentially, bell hills. Other than that, there are no assumptions. Are we doing that? Like, for example, if... Asif? Yeah. Do you have to define a loss function here before you divide? Recreate the discriminant? The question is is how in the world do you solve for that the loss function in linear regression was subsquare data what is the loss function for classic fires that too is the topic today we'll do that time permitting we'll do that today or we'll do that tomorrow because that's a big topic in itself. These two loss functions drive or are very dominant in the machine learning world, the loss function for regression and the loss function for classification. And I will talk about that, but for that, we need to build up a bit of a mathematical architecture. The difference is that the loss function for classifiers requires us to introduce one more concept called Emily Maximum likelihood estimator Because it's a little bit of a broad topic We do it today. I will finish the other to finish this classifier the discriminant analysis and then I'll also like to finish the topic for logistic regression those are the topics next time I'll cover so now I'll deal with overlapping overlapping hills Overlapping data. Geometrically it means overlapping . So how does this situation look like? Let us say, let's take one dimension for 1D. Suppose this is, in fact I will not bring about the other dimension at all, suppose this is your x-direction and let's say that you have some data point here. Let's say we are talking about horses and cows because I suppose their weights will overlap. So let us say that you have a lot of data points. I'm raising it here but they're all points along there. Lots and lots and lots of points here. So let us imagine that the histogram or the frequency plot looks like this for a horse. And let us take cows. The cows are pretty close in weight. And you would imagine that they would have a lot of overlap. So here we go. And so the cows go. Let me make the overlap more severe just to illustrate what we are talking actually more than that let me make this green line a bit more pronounced let us say that this is the I seem to be making a mess here. This is the horses. The data, the weight of the horses are all adjusted here. Okay, in this region and the weight of the cows are now, let us say that, you notice that now the data is overlapping because there are regions in which the cows and the horses are both exist so this is this is the region in between that you see here types of data exists both cows and horses exist and this is bait let's just take a wait does this make sense things I hope this picture is intuitive. These are cows. I should write it in blue. What are these hills that I have made? These are just the histograms normalised. When you take a histogram and you divide it by the total amount, total weight of all the horses and cows, they become what is called probability distributions. A probability distribution is nothing but a histogram that has been normalized. So this is what you get something and by the way I'm being a hand waving there a little bit of toxin with that is it. So is where you are so where do you what is the weight that you find most most horses to have so you see that most horses have that this is your new horse the center of the average weight of the horse and likewise what is the average weight of the cows obviously this goes like this so the average weight of the cow is this is new cow what does mu stand for average it's the average so now think about it this way I will put a red point and tell me what is it suppose I get a data point that is here I'll call it a I'll take a data point that that is here B I'll take a data point that is here and here I'll call it C and I'll take a data point here. I'll call it D. So tell me, in this diagram, if given this distribution, this common sense, at A, what would you guess it is? Is it a horse or a cow? A horse. It is much more likely to be a horse. There is a really vanishingly small probability that it may be a cow. The reason for that is bell curves actually never go to 0 even though in this picture I seem to have made them go to 0. They always remain above the 0 value. They never never go down to 0. So there is a vanishingly small probability, let's say 1 in a million, that it may still be a cow but for all practical purposes we are making a pretty safe bet when you say that A is a horse, right? So A, you can very confidently say, and you can say it with confidence. What about D? What is D? D is more clearly a cow. More clearly a cow. It's pretty certain, right? So you would say that you can make this thing with high confidence, high probability. Probability you're able to tell. Now what about points B? B is more likely to be a cow or a horse is the point b you know it could be either but yeah it could be either but if you had to make a bet what would you say is it more probably a car or more probably a horse? More probably a horse. More probably a horse. A heavy horse or light cow. A horse. More likely to a horse. Or maybe a rather emaciated and underfed cow. So on the other hand, a point C here, and this is what gets tricky on point C. What do you think it is? Is it an overfed cow? Or more likely, is it a cow or a rather obese horse? C is more likely to be a cow. More likely to be a cow, isn't it? More likely a cow. So the question comes, you're going from very sure if you go from A to B to C to D, as you go along the X axis, you go across the spectrum of certainties. In the beginning, you're pretty sure it's a horse. Then you're less and less certain, but you're still saying horse, you reach B, you're still saying horse, by the time you reach C, you begin to say it's more likely a cow, and by the time you drift a little bit more, you become more and more certain that it is a cow. So you would imagine that there is an inflection point at which you sort of are sitting on the fence, you're not sure whether it's a cow or a horse where would you draw the inflection point would you draw it something like this yeah this line isn't it what you would do is you would take the point where they intersect and you would draw a line there right there itself at this point and you would say that this region is horse. Let me make it a little bit bigger. This region is all cars once again you have divided this line the feature space is just a line in this you have divided the feature space into two regions to the left of this white line and to the right of the white line to the left left are all horses, to the right are all cows. Now what is the technical name for such a thing? Something that divides a feature space into partitions, one for each class. What do we call it? Decision boundary. Excellent. So this is our decision boundary. higher dimensions the green line somehow disappeared. So that's what I'm talking about. It's very hard to go through this. So, here we go. And at this point, sorry, let me just... Now, before we continue, let's look at the implication of what we have just done. Do you realize that we will make mistakes? This region, this region, this in-between region is the region of mistakes. Do we agree, guys, this region? If I were to switch to a white background, look at the yellow part. This is the region where we are making mistakes or are likely to make quite a bit of mistakes actually. So this brings us to a situation where classifiers, okay, now this is wrong. Let me go back to the color. So we realize some important fact, classifiers, very much like regressors, classifiers have errors too. Isn't it? So what can happen is you can get confusing. The classifier may confuse a horse for a cow or they can have a cow as a horse so let's make a matrix we say that suppose in reality it's a cow a thing is either a cow or let's put it in full letters let's say that you know the ground truth you know the answer and you're asking a classifier to learn it so and then once the classifier has learned it you remember I'm putting hats on predictions so what can happen good thing could be a cow hundred instances of data let us say that we got the cows and they're equally split between and need not be equally split but this is an example between cows and horses. If you have a situation like this, so there are 50 cows. Let us say that 50 out of the 50 cow, 40 of them were recognized as cows, and 10 of them were mistaken to be horses by your classifier. And likewise, there are 50 horses say that about 35 of them recognized as hot and about 15 of them were confused as cops it is called the confusion matrix. This term is a technical term and I hope it doesn't need much explaining. Why is it called confusion? Because it literally quantifies how confused the classifier gets in identifying cows and horses. So how many of them did it get right out of the hundred? 75. So the correct ones are 40 plus 35 is equal to 75 and the errors are how many of them are wrong 25 10 plus 15 is equal to 25 so now if i were to divide this with the total the total being accuracy is definition. This is the definition. Basic definition. Accuracy is correct over total. How many total data points did we have? So we have 0.75 or 75 percent is the accuracy. Now what is the error rate? it is defined as by the way this symbol mathematicians used to say when you have two dots and an equal to it is supposed to be defined as so error rate is defined as errors total and so here it would be and it would be 25 over 100 that is so obviously 25 over 100 I'll just write it as 0.25 0.25 and that comes to our other other way people often speak about is 25% is the error rate so it is obvious that accuracy plus error must come to 1 does that seem obvious guys a plus errors is equal to it must always be true so either you are right or you're wrong the rate at which you are right and the rate at which you're wrong should add up to essentially one so this is these are definitions this particular region let me just say but these are definitions so we should remember these definitions this is a little now as we make progress we will talk more about we will introduce concepts like precision and recall but that will come later today I would like to talk about something called true positive and true negative these are often called in the nature type 1 type 2 errors and so on and so forth a lots of words more intuitive time so when you say true positive true negative I will illustrate it with a different example where we have the meaning of it becomes much more obvious so let us say that today we are all worried about let us say new 19 test is ever perfect so what it does is it takes the data X which is I don't know attributes in your saliva attributes your saliva not the saliva I believe they work with nasal swabs right BS right swaps I could get some chemical attributes biochemical attributes attributes in your swaps and I don't know the details. So I'll leave it as that. That is your X vector. That goes into this. What is Y? Y hat. Y hat belongs to the class of positive. Does have COVID-19, right? Or negative. Healthy. Why? I.e., does not have COVID. Does not seem to have. 19. Does not seem to have COVID-19. So this is a prediction. Any lab test, there's no lab test that is 100%. Every lab test is like a machine learning. It is a machine learning classifier of sorts. Because what you do at the end of it is you look for presence of certain reactions. These, from what I understand, not the biology so something called polymerase chain reaction and things like that now that is something I'll have to ask questions of molecular biologists but to me it just sounds like a big fancy word but in any case it can do that so now if we do our conclusion matrix for this classifier detectors, classifiers are the very nature is detectors in such situation. So let's think about it. This sort of a situation, this example, I like this point, this use use case illustrates the asymmetry of data. Most people, do they have COVID or they don't have COVID? They would not have COVID, isn't it? The vast majority, at least we are still at this stage at which the positive test cases are far fewer than negative test cases. I believe they just released the data have it will have it will be most of the data points with which you try to train your classifier they would be negative they would represent healthy people so let us write symbols for it. If I were to write symbols, this, sorry, give me a second guys, this thing has dropped off on me. If we were to use symbols, we would say, let's use a symbol for positive has COVID-19. And we will say, let's use a symbol. Let me just call it a positive case. This is a positive and then does not have now you have a machine, the classifier cases will be much fewer. Now, this seems obvious, but it has actually quite a bit of implications, basic implications that I would like to highlight. So now let's take this example. Let us say that, God forbid, I hope the Fremont's test is not inaccurate. It will have some level of inaccuracy. No test is ever perfect. So let's say that people who had COVID and you identified as COVID, there were 37. Let us say that people who did not have COVID and you identified correctly as not having COVID, let us say 900. I'm just throwing random numbers here. Then we have now left about 63 cases. Let us say that out of 63 cases, we confused 50 people and said they are actually healthy when they have COVID. Let's say that they are very early stages of it and your test couldn't find it. And let us say that you have 13 cases in which you declared a healthy person to have COVID. Now you realize that mistakes in these situations are pretty bad. It's something to keep in mind. So sometimes I'll just make a point sometimes classifier classifier mistakes can have devastating consequences. So for example another thing is suppose you are being tested for cancer. We all go through cancer screening as you get older it becomes almost mandatory to regularly go through it and even from an earlier age. So what is the worst thing that can happen? You have cancer and it is not caught in time. So if you're declared healthy when you do have cancer, it's not detected, then by the time it's detected it becomes far more expensive financially and in terms of suffering for the patient to cure the person or to bring the person back and if you are too late then it may be impossible to bring the person back at all so one of the things to realize is certain mistakes can have devastating consequences but then there is another aspect to that the kind of mistakes matter so let's think a little bit about what I mean here kind of mistakes This mistake, I will highlight this or say, this is, what is it? Is it, we have identified positive people as healthy. So this is, is this, I'll call it false negative because that is it because the person was sick and before and we did not identify the person as the word false negative makes sense to all of you yes so it is false negative and this you would agree is the opposite situation. It is the false positive. And this one is true positive. This is the happy situation in which your test got it. Your classifier was able to tell the sick people as the sick people. And what is this? This is a true negative. True negative, exactly. Thank you. True negative. So these words get it into your mind. But when you set a positive and negative, you have to ask yourself, which class should I consider the positive case situation? Sometimes the domain experts will tell you what is a positive case. But sometimes, but generally in the absence of information, one rule of thumb is whichever is the rarer situation, look into your data and look into your labels, whichever label is less frequent is your positive case. So for example, in medical literature, this becomes pretty obvious. Positive cases are sick people because fortunately most people are not sick. So you mark a class as positive, in this case COVID-19 has COVID-19, and then you have true positive means how good were you in catching the sick people as sick people that is a happy situation how good were you in identifying healthy people as healthy people they're not sick as not so that also is a happy situation you want to have more of that so this is your principal diagonal in this matrix isn't it in this matrix this is your principal diet but then everything perpendicular to that off diagonal are bad things the first is false negative a lot of sick people you marked as healthy because if you mark them as healthy as we know today by the way this is a quite a bit of contemporary relevance. We're having so many situations in which people were screened. For example, when you go for a COVID-19 test, the classifier sometimes, the first line of classifier is just a nurse or a medical expert asking you, did you just return from China? Or did you travel or were you in contact with somebody who returned from China and if you said no they would say well in that case you don't have COVID you don't need to be tested go home now was that a very accurate classifier was that a good classifier guys it was it was a health policy blunder to say like that. In hindsight we know that. It was, it would be considered imbecile to have behaved like that. And the only thing you can say is the reason people behave like that was because we simply did not have enough tests. So the tests had to be given to the most needy. Well, then that shifts the question, why did we not have enough tests? Well, that is the question. Certainly, as a classifier, it's a very poor classifier. As we all know, a lot of people had COVID. They got extremely sick and they died. So obviously, we wouldn't consider that a very good classifier. Then comes a classifier that can do tests. As you know, there was a test created by, in Germany, and advocated by World Health Organizations and a lot of people. In Europe it was used, in Singapore it was used. It is being used, which is rapid testing based on two protein tests. It looks for two proteins that are found on the body of the COVID virus. We decided it shouldn't be used. Why? We are going to come up with a better test which has three proteins. So why did we think that we need three proteins? Because we felt that it would miss some of the COVID cases. We needed a far more accurate. So now we are swinging the pendulum to the other extreme. We need a very very sensitive test that catches all people who have COVID. The idea was that if the two proteins are not present, it is still possible that you have COVID-19. You still have the virus. And so we were trying to get to a situation where we did not have false negatives. And that is still an ongoing effort. As of this moment, a much more sensitive test has not come. So people are still using the... After much... I didn't use the two protein test which has been used at this particular moment but it does highlight the point that would you in a man in a time like this and you know these are real-life decisions when you deploy a classifier in the field every classifier will have a false negative rate do you not deploy it at all or do you say, well it is better than nothing and so let's go ahead and deploy it till we come up with a better situation. And it's a policy decision which way would the country go. Different countries went different ways. The European countries for example, they went ahead with the two and much of the world went ahead with the two tests. In US US, we believe we could actually come up with a much better test, and we thought, let's go and wait for a three protein test. And I'm not a biologist, but this is how I have been told the situation worked from the New York Times. And then it turned out that the third protein test was not accurate. So, well, it became a mess. And now they're trying to create yet another more sensitive test and these are real things in practical life a classifier is never perfect you have to choose should is it worth using or not and so those are the decisions that people face now you also have the false positive at this moment a healthy person is declared to have a coveted say now which of the two is more dangerous a false negative or a false positive false negative positive false positive why is the false positive more dangerous don't want to miss any case is the most dangerous because you let one person that I know miss a sick person so the idea is that suppose we declare a healthy person to be sick the person will get depressed and start getting scared but will be quarantine and in a few days it will turn out the guy has recovered from the fever and the flu and it probably and it wasn't COVID so it causes a nuisance it sort of create stress in the patient's life but it is not fatal so a false positive is not fatal in these situations but a false negative can be fatal because if you miss a positive case like you said so far then it is very very dangerous so you try to get a test which has very low false negative rate and which is the hope I suppose which is why we went through this very interesting situation the hope was that we could create a much better test with a higher false negative rate and that is still work in progress so false negative in this case makes sense likewise for cancer what will happen if you declare a healthy person if you have a false positive you became a healthy person to potentially have cancer obviously you know you don't rely on only one test if something looks fishy in one test then you do secondary you know you do a sequence of tests well some other tests will after that more intrusive test it will come out and say this person is totally healthy so barring a small scar for biopsy, the damage is limited. On the other hand, if you tell a person with cancer that you are healthy and you don't follow up with that person with other tests, because there's no reason to, you have classified the person as healthy, then the price or the consequences can be very dramatic. So that is the concept of true positive, etc. Now, there are words like precision, recall, etc. We will cover that Matrix is a grid of numbers. And that matrix is about, let's like this matrix here, true positives, true negatives, false positive, false negative. And you attach the word positive negative and you know when by convention you apply a meaning to that if you don't then you just talk in terms of the confusion matrix and you can leave it as that so there we go that is the concept of positive and negative so for, now if we go back to our cows and horses, you realize that this region, this green region, is the region of mostly true, let's say that the horses are positive. This green region and this blue region, they are all regions of true horses and true cows being identified as cows. The in-between region here the one that is highlighted in yellow this is a region very likely to make mistakes isn't it and that's where that is the region of most error for us because these two bell curves overlap now what if they overlap even more let's take the limit two species of horses let's say that this is a hole and there is another species of course what just happened let's take another species of course I'll take you which has now guys talk about this how accurate is this classifier going to be horse type two let us say this is some horse of type new horse the mu is the the mean where this location and this location on the x-axis and let us say that the axises size of the size. And it is quite possible. So it happens when two species of horses are very near each other in sizes. So what will happen? It agrees with common intuition that you will have a pretty high error rate. Do you see that the overlap region is pretty substantial? Should I say this entire region let me mark it this way let's make a decision boundary here is your once again you take the hilltops and you bisect it so this region is horse type 1. This region is horse type 2. You realize that there will be a lot of horses, blue horses here, and there will be a lot of green horses here. So you will have high error rates or low error rates in this situation hi hi in discriminant analysis the error rates are proportional or geometrically they show up as the degree of overlap between the two Bell hills of bell curves Does that look pretty obvious right Yes, I hope it looks straightforward yes, it's very hard in the in the asymptotic limit Suppose we have asymptotic limit You have a situation you have Do you think this classifier is even worth using? Not much. It basically means that whatever feature is here, that you're using along which these two things overlap so widely, is probably not a good feature. That is the only feature you're using. Input data does not give you enough differentiation between the two types. And the same thing can now be generalized to higher dimensions. In two dimensions for example if the bell hills have a significant overlap the error rates will be higher. So this is all I have. Let us go and recap what we learned. I'll just let us go and recap what we learned so we learned that geometrically we can have overlapping data when there is no overlapping data example for ducks and cows there is no miniscule cow that you will confuse with a duck well hills are very well separated so a classifier works great and it tells common sense you know a duck you can carry in your hands most of us can't carry a cow in our hands maybe athletic people can carry a newborn calf so the weights are quite quite different easy to classify just based on weight then in real life situations it gets a little from that very clean situation it gets a little bit less a horse when a cow now if you only look at the weight it might not be so by the way any biologist any zoologist here am i right about horses and cows that they can have overlapping isn't that cows are very very heavier than horses I don't know let us assume for the sake of our learning that cows and horses have overlapping rates. In the in-between region of rather big horses and rather small cows you don't know if it's a cow or a horse. So you have error rates, quite pronounced error rates, and error rates when you do they come because a cow can be confused for a horse or a horse can be confused for a cow. This representation of what happens, how well you classify a word, this is how you measure errors in classifier. This is by the way one step towards the loss function. There's a whole session we'll do next time on loss function. Keeping it for that, but I'm laying the groundwork here. This is there. Now the definition of accuracy is the number of correct predictions out of the total. And the error rate, which is the converse of it, is the amount of errors out of the total. So, obviously, in this situation, this contrived example, we have 75% accuracy and 25% error. Now, let's take a situation in which data is skewed. They're highly asymmetric. Very sick are few and healthy are many, for example, is a medical situation. We took the example of COVID-19 here. So what happens here? We can have a lot of people, and this I think is somewhat, I mean, I just cooked up this data because I came to know that there were close to 100,000 cases tested in Fremont. And obviously I'm hoping that the error rates are not so bad, they're very low. I don't know what the real error rates are. These are contrived examples. Do not treat it as real life reflection of what's happening in Fremont. This is illustrative of that concept. And 37, by the way, were the actual number of people who were found to be positive. So 37 that. And the rest of the example numbers are contrived. Let's say that 900 didn't truly have it, God forbid, but we had 50 false negatives, people who did have it, but perhaps in such early stage it wasn't called for, and healthy people who were scared into the belief that they do have COVID. So then brings up the concept of false negative and false positive. False negative is when you take a sick person and you declare to be healthy. You take a healthy person and you declare to be sick that is a false positive. Now we do know at least two methods that have been applied recently. One was just a questionnaire. Did you go to China or interact with somebody from China or travel abroad or something like that? If so, if not, then you're just declared to be healthy. You're sent home. We didn't have enough tests. So we had to ration it. That as a classifier, is it a good classifier or a bad classifier? Too simplistic. too simplistic it's too simplistic it's likely to have a high what false positive or false negative false negative false negative and in medical situations, generally high rates are. Heart rate and which is why you need biochemical test, which has come now. Let's hope that the accuracy of the test is high and the error rate is low and certainly what matters is not just ever but type of error one type of error can be far more devastating than other type of error false negative has so all errors are not alike in other words some have deeper impact than others that is something to remember now that is the summary of it in the case of discriminant analysis geometrically the errors come from the overlap region between the two bell curves largely there's always some overlap but but how much overlap there is at any given place determines the amount of errors that you will have. And the more the overlap, the worse the classifiable function, if you are going to use that particular feature to classify. In this case, the size of a horse. So there are two species of horse which are very close to each other. Probably you don't want to use the size of the weight as a metric. You probably want some other test, perhaps a genetic test to tell what it is or maybe a color test. Maybe the two species of horses have different color coloration one is light brown and another is dark brown and so forth but size would not be a good predictor now one last thing I would like to mention is see whenever you measure a model the metrics of a model how good is a model remember that in linear regression we said that it's not enough to just look at R squared you have to look at many things and make sure that they are right you recall that guys your the residuals should be I should show more skilled skidity, uniform in simple terms. You shouldn't see a pattern in your residuals, that is important. You also look for good P statistics and so forth in your P values and whatnot. No one test should be taken as in and of itself a gold standard. It's not a litmus test. A lot of errors were done in many many subjects because people over fixated on p-values. If the p-value was sufficiently low, below 5%, they thought they have a result. They have a result that's statistically significant. So a lot of research for many years had to be so now we don't trust them anymore because of this fixation on p-values likewise the same is true for R squared I believe in we did the lab we saw that in the case of data set to the R squared turn out to be pretty good with a linear model but then on further test we realized that the residuals look pretty poor, they show a pattern and that was bad and so you have to have multiple things to tell whether a regressor is good or bad. You have to be very cautious. The first quality of a good data scientist is they are very cautious even when they have a good, they think they have a result, they're only cautiously optimistic. They're very free to admit a negative result, you know, that we didn't succeed, but they are very cautious about saying that we may have something, a good result I remember that as a basic habit too optimistic there may still be things that you may get wrong and this field is quite interesting you if you are optimistic you're not careful in the early part of your career sooner or later someday you'll make a grand ass of yourself everybody has done that because you would confidently say I can see this and then the very next day you'll find something some data that completely destroys your model and then in hindsight you look back and say I know you know this why this model work why it got food I wish I didn't I didn't express so much confidence to the business people that we have a good model. So remember that. So now coming to classifiers, what do we do? One of the measures that people get fixated on is accuracy. And many, many people say, you know, I have a classifier or a test and it is very accurate. So I wanted to speak a little bit about accuracy. Is this all we need? Because most people keep reporting on accuracy of the tests. And a test is always, in a sense, a classifier. So let me ask you this question. example of COVID the same example suppose I have a magic box and you come to my testing center and I say that my I have such a wonderful test that I can just look at you and tell whether you have covered or not believe it well what is your accuracy I say to you that my my accuracy is actually a pretty high 93% I mean 91.3 percent you would be pretty impressed a test that is 91.3 percent accurate you would say well i'm going to buy that test so i'll pose this as a question if i tell you that my test is 91.3 percent accurate and it is indeed 91.3% accurate. And it is indeed 91.3% accurate. No cheating there. A lying out there is, would you buy the test? I want some people to think openly. Would you buy the test? You want it better. Well, 91.3 is pretty good let us say in the absence of anything else let's say that the new medical test is still in scarcity a few weeks ago and I open shop and say hey I have a way all you need to do is come and show your face and I can give you the result in one second three four days but my result is in one second results guaranteed with ninety one point three percent accuracy I do have some error rates I am ninety one point three percent and you say well wow that looks pretty impressive isn't it anybody would find a way obvious law in this yeah it is to I mean it is still not on the test data right it is only across validate trying to find a needle in a haystack so see assume that I give you all the data to validate that my test my results are actually I have a model and you can try it out on your test data you have a private list of people who are sick and not sick and they then you send it to me and then I make predictions and lo and behold it always turns out to be ninety one point three percent accurate 90% does not have any illness as such in the raw data anybody else would like to say I say I would like to understand is it ninety one point three percent true positive or true negative no I am saying that my my results accuracy it will have what is the accuracy the number of times that I will give you the right answer you can test it out you have a private list of known second healthy people you send them to me I'll make my prediction now you check how often was I right I'm ninety one point three percent right it could be the null hypothesis also could be like ninety one ninety two percent so how to your it's in balance see all of you guys are getting to the right answer you're all saying that I think what I want to hear it much more articulated everyone so vocalize think why accuracy is just it's dangerous to just look at accuracy and I'm not cheating you can try out my method in fact that today I'm willing to open a shop right now given this data let's say that this data written in green is the data for Fremont I can claim that I will have ninety one point three percent accuracy based on this thing you can send your patient trying to find such a small number somebody said something who is that right if I have no real test I look at everybody and then I give them a private slip and say you can go home and look at whether you have it or not for reasons of privacy I can't tell you what I think is so I think can it be balanced and unbalanced because the classes are positive and negative is like it is not I'll give you the answer now. See guys express it in a way that. For the entire 97% of it is. Actually infected, then, you know. Your test has to be, you know this has to be you know more accurate you need to be more accurate than 97.3% test to be relevant all of you are coming to it's the recall recall I know from experience or by out of 1000. So I know that 91.3 people are healthy. All I do is I just declare, I just look at a person, call them privately and say now I'm going to disclose your result say you are totally healthy and what will happen I will miss those 87 people I will be wrong about those 87 people I would have declared I would have declared my 913 people who are healthy as health error rate will actually be low my accuracy will be very high but you realize that this is this classifier is no use there is a reason why the US government is not lining outside my to buy my classifier it is absolutely useless why is it useless it is useless because it fails one the mental tech does not identify the true positives at all but then you can do the opposite suppose I say that all right whosoever comes to me I'll just look at him and say that guy is sick then what happens goes up but I never miss a good I never miss because to me everybody is positive to is a fairly useless situation now these things things happen in real life. For example, if you look at the stock market, and I'm sure many of you are in the equities market and you keep reading the analysts and the commentators and all these pundits who make a projection into the future. Amongst all of these, there'll always be one or two people who that they predicted the dot-com bust anybody else could they predicted the 2008 bus before anybody else could and they have quite a reputation because of being you know the office doom who could correctly predict predict the doom but everybody else was optimistic why were they right because I predicted it every time and for once it got like true so if you do this every time you keep predicting when the doom comes in the markets crash you will look like a profit that is what's wrong with these things you know the saying is that even a broken watch or a broken clock it's right twice a day you please write twice a day whereas your watch may actually never be absolutely right it may be a couple of seconds ahead of behind the standard definition of time by the atomic block of the US government but a broken watch will outdo that I'll do your watch it will be absolutely right twice a day you have to watch out to identify a good classifier you need to look at many things you need to look at accuracy but first thing you do is look at the class imbalance you realize that out of a thousand or out of a hundred ninety one point three percent people are healthy so if you if you actually see is nothing more than ninety one point three persons not really doing a good job it needs to be better than that better than that is called the left how much left you have essentially this classifier by the way my classifier is it absolutely useless no it is a perfectly good classifier legitimate classifier in the sense that it is making fairly accurate predictions you call it that there's a name for it in machine learning it is called the zero or the zero r classifier or the basement classifier in any problem you need to first identify the baseline classifier over which we are trying to improve so somewhat like in linear regression you have the null hypothesis in classification you have the baseline classifier just find the majority class and always predict that you you're ignoring all the features that's where the world zero are comes from you know none of the features you even bother to look at the temperature of the patient you didn't take there you know whether they are coughing or whatnot all you cared for is you declared the majority of people ahead we are declaring everybody is your baseline classifier with accuracy of 91 points you do must improve upon that are we together the other thing is you have to look at the types of errors true positive and true negative you have to ask which which is more adverse if you have to focus on improving one which one would you improve now generally what happens is that after a certain limit it becomes a trade-off between true positive and true negative you're not going to get any further accuracy you can have one guy we can choose but you have more true positives or more true negatives and that is something we can we would think about let's say that I will illustrate that with an example suppose this situation where are we go we go here let us say that horses are ten times more expensive which perhaps is true in this country but let's say that horses are ten times or hundred times more expensive and somebody is trying to sell you an animal and say it is a horse you realize that which where would you rather make a mistake false positive or false negative false positive you don't want to have a test that will us that will confidently tell a cow to be a horse. You would rather make mistakes in which you missed a horse rather than be duped into buying a cow. If horses are 100 times more expensive. So one way to argue with that is you have to look at what your positive test case is. It's horse and the kind of errors you are trying to make is you don't want to have just as in the case of illness you don't want to have false negatives so do not have false positive what will you do where will your decision boundary be you realize that you won't put the decision boundary where it is you will instead perhaps put your decision boundary if you want to avoid the cows being considered horses you would perhaps go as far as this you see my dotted red line and you would say that anything more than the dotted red line maybe there's a reasonable probability that it may be a cow you would rather not buy that make sense good yes by sliding your decision boundary backward and forward you can control you can minimize either the true positive false positives or the false negatives and this situation occurs with many classifiers. Moving one needs to lose the other, lose the pattern of the other. It's a trade-off thing sometimes, beyond a certain point. So that is something to remember about classifiers. So that is all about measuring the classifiers. So the answer to that is no look at class imbalance look at the adversity of the errors look at imbalance compare results with the baseline classifier So, remember, decide which type of error is worse. Decide. Catastrophe. These are the things and then not only that, but also adjust your decision boundaries. to minimize adverse type of errors, whichever error is adverse, right? Even at the cost of the other type of error. So this summarizes it. This is important. Now we'll give some names and talk about precision and recall and we'll talk about different things in the later lecture. Today I want to take a break. It's one and a half hours now almost. Let's take a break before we go into the next topic which will be another kind of classifier called logistic regression. Let me draw a big line here this is the end for this part uh maybe even a and then we talk about a new classifier a logistic classifier logistic and regression the word regression is unfortunate in this because it confuses people but you'll see why the word regression is unfortunate in this because it confuses people. But you'll see why the word regression comes into that. We'll learn about a new type of classifier called the logical regression classifier. Let's do that after a 20-minute break. Let's regroup at 9 o'clock. I will pause the recording for a bit. So this is called logistic regression. The word regression is often confusing. It seems that we are doing regression, but actually no, it is a classifier. So confusing name. That's why I tend not to use the word regression. I just say logistic classifier. tend not to use the word regression I just say logistic classifier so what is a logistic classifier the logistic classifier takes a different worldview on the data remember discriminant analysis said in the feature space each of the classes are separated from each other it may or may not be true the ground truth may or may not agree with that underlying hypothesis that they are well separated. What if it is different? So, I will contrive yet another example. I don't know how realistic it is. In fact, perhaps it's terribly unrealistic, but for the sake of learning, we will contrive that example. So, suppose you have, let's take two kinds of fruits that look pretty similar to each other. We'll take blueberries. Let's take blueberries and the axes are still the same. Let us say it is the weight, size and the weight. Right? I'll call this the future x1 and the future x2 so our size is one feature or weight is another or you can pick your and so let us say that the blueberries are small these are data for you to call them berries and something like that. I'll just mark it. And again, remember that we are not trying to be biologically rational. It is just a pedagogy for the presentation. Imagine the criticalness. And let's take somebody who's very good, somewhat within the vicinity of a blueberry. What would that be? Raspberry? Somebody knows that. Kate, what would be a berry whose weight is somewhat close to but more than blueberry? Are you there, Kate? I think we lost Kate. Anybody could give a glance. Would you have a name for a berry that's perhaps a little heavier than blueberry? I can't think of anything. What about raspberries? Are they heavier than blueberries? Yeah, about approximately. A little bit heavier. Okay, so we'll just assume, okay, since we can't think of a better berry, I'll just, I'll call it red berries. So they're blueberries and they are red berries and God knows what those red berries are, but their characteristic is you've got their sizes and they look like this Something like this. This is a very contrived example. And then there are certain red berries, which are small, and then you could have regions of overlap. Likewise, there are certain blueberries, which can be large and let us add some so guys if I were to ask you that yeah are the classes well separated does it meet the fundamental assumptions of the discriminant analysis the hypothesis of the discriminant analysis makes about the underlying ground truth Is it met are the two classes? What are the two classes the blue? The redberry These are the two classes. If you look at this picture in terms of size and weight, do you feel that they are well separated? They don't seem to be, isn't it? There is a level of overlap. The second thing is, do they seem to form bell curve distribution? Like, are they looking like bell curves or are they centered around our places like a bell hill these berries who would like to answer this question all the Blues clustered around someplace and are all the reds clustered around some external size right you see they occupy different regions of the feature space all right but do they say if I make a histogram it's not a balanced bell curve but skewed it is not a balanced bell curve exactly it is cute so it seems to violate some of the assumptions of the discriminant analysis. And so this is something, the reason I mention it to you is that the ground truth may or may not agree with the fundamental assumptions of a given algorithm. So this logistic regression is an algorithm that shines in situations like this where you see this. See if I were to ask you this question, let me ask this question by putting a point somewhere. Let me put this point B what can you say about ABC and D is what would you call it a blueberry yes you would classify it as a blueberry just visually looking at it and B would be what would be a red berry and you're pretty confident quite likely very likely let us just say very likely and what about B are you quite sure that it's a blueberry are you less sure about it right it's probably a blueberry but as you notice next to B is also a red dot. So you're not quite see it is probably a what it's probably a red berry so as you progress from a to B to D I will make this arrow in this direction you realize that progressively more confident that it is red more probable more likely that I'll be together as you go from origin from this point as you go along this line this is your line of increasing likelihood that it is a red berry would you agree guys with this statement I hope you see this it is quite obvious right and so interesting thing is what would be a good place to put a decision boundary it will certainly be just along this line find a point where the likelihood is a half and half which in B and C somewhere and draw a decision boundary like this will draw a decision boundary I hope I get this right no no no a decision boundary i hope i get this right there's the other no not this this will draw a decision boundary does that make sense guys this would be our best decision boundary going through this and let us mark it this side has This site has red berries. And this site has red berries. This site has red bed. So, the feature space, I'm getting a bit of a gap, you can use it yourself if you're not speaking. Generally, if you do not have a question, make sure that you have only one speaker attached to your laptop, your headset. You mute your cell phone and use your headset, or remove your headset and then use the laptop. You won't get it. All right, here we are. We have partitioned the space, the feature space, once again into two halves. One region belongs to blueberries. Another region belongs to the red berries. Isn't it, guys? And what is this decision boundary looking like? The decision boundary, let us look at its characteristic. The decision boundary, and I'll mention this. In two dimensions, suppose there were more features, it would become a plane in a three dimension. It is like it's a linear decision boundary. I.e. the decision boundary is straight or linear. straight or linear straight or linear that is its defining quality that we have done in this model logistic regression a way of looking at the world view the world and it is a hyperplane in four plus dimension. Anything more than three dimensions it will be a hyperplane. A hyperplane is a generalization of a plane. It just is a plane in higher dimensions. Mathematicians can, this generalization comes very easily though for a mind to visualize a hyperplane is a little bit hard. Just think of a plane and then imagine that it is mysteriously they have more axis to it than just two axis to it. So that's a hyperplane. Mathematically it works out. Human beings find it a little bit hard to sort of understand. So are we together so far guys? What I will do is I will take this region, this picture and I'll reproduce it below because I want to give you a sense of how these things work. So I'm going to make a much bigger drawing of this and I'll put fewer points of the blueberry and so that we have less clutter. Just assume that it is the same picture. But. You have. This region is that. Of course, there are letters. This is your description. Now if I take an arbitrary point. Let me take an arbitrary point. At that point would be. Let me take this point now I'll introduce some vector notation so this one is a x1 direction this is a x2 direction so you agree that associated with point P I can write some x1 x2 of that point P point P has some xy core x1 x2 coordinates does that look simple guys it should be wherever it touches the x and y axis at the x1, x2 axis. Y here is for x2. Do we agree, right? A point in a plane has a coordinate, has certain coordinates. If you have forgotten your coordinate geometry, you can think of it as longitude and latitude. Every point in this has a longitude latitude, roughly speaking. Now the question is, how confident you are that it is a red berry, probability of a red berry. How likely is it that it is a red berry? You realize that one thing that matters is this thing. one thing that matters is this thing this I will call the distance B affects this point or D of point P let me just call it D of point E point P D of point P is will define it as distance and by distance it is always shortest distance because implicit shortest distance so when people in this field talk about distance implicit it is that most of the time unless stated otherwise they are looking for the shortest distance shortest distance from the decision boundary. Now why is this distance d important? You would agree that if d is zero then you're sitting on the decision boundary. So which is more likely? Is it more likely that it's a blueberry or it's a red berry? What would you say guys? Red berries. No, you can't say anything. It is the inflection point between red blueberries and red berries. Literally sitting at halfway point between. Oh, if it is D is zero, then I see. Okay. Let me put, mark it with a point here. Let me take a point. Let me call this point. What should we call it? So, he is on the. Boundary. So, what what is the probability that the data point? Is a blueberry or a red day you would say that, you know, you would say that the probability of E, by definition is half that it's a red. It is equally likely to be a blueberry that is the literary definition of decision boundary because by definition on this side it's blue on this side it is red do you see that guys and so there is a point at which it you're not sure whether it is blue or red. It's literally sitting on the decision. So the intuition here is that D is equal to zero means on the boundary on the boundary. So equally likely. Equally likely to be either to be either on the other hand d greater than zero what does it mean if b is greater than zero if you are somewhere here like for example for the point e or p should i give you a new color maybe let us say point P what can you say about point P is it red berry or is it more likely to be red berry or blueberry we would you would agree that D is greater than zero than zero and D is will take the convention that if you are on the lower side of the decision boundary or if for example for a point let me take a point this. This point is, let me call it Q. Q is at a negative distance, negative d prime. So let me call this distance d prime or dQ. dQ is negative by convention because you take one direction to be positive and the other direction to be negative right so this is you say that dq is less than zero so in the case of dq less than zero what can you say the point is what is it a blueberry or a what can you say the point is what is it a blueberry or a a red berry let me know if I need to repeat this I hope this is a fairly obvious if I take this point this is clearly a blueberry it's where blueberries are surrounded by blueberries those because light it is small and therefore it's a blueberry more likely to be so this is it so in other words we have come up with a way to classify use this distance in other words this is important operation in other words geometry we can use the, and now I'll give a name to this, a well something is, whether it is more likely to be red-berry this distance function. And this distance function has a definition, distance function of any arbitrary point x. Now I will use x could be any arbitrary point. The word arbitrary is often used in mathematics. It means that you just pick a point with nothing in particular about it, nothing special about any random point. I'm writing it is in this notation and from school you may be used to this one x1 i x2 j remember vector notation you may be familiar it is all the same it is just conventions of writing it so a point given a point then you can find the distance from the decision boundary B X Now here comes something and now comes a intuition that we have to develop and this is the crucial intuition As D increases You know that it becomes probable that it is a let's think in terms of probability probability we will now think of probability specifically we choose one red berry this is the probability of a red berry. And this probability of a red berry we will write as p. p, the p of x is the probability that a data point x belongs to a red berry. That is what we have. Now, a basic primer on probability. Now, a basic primer on probability. Probabilities go from 0 to 1 a red berry. Probability one is that it is a red berry. And then in between values are degrees of likeliness that it is a red berry. So that is the definition of probability. P always belongs to Px. It belongs to the interval. This is this epsilon stands for belong to. It's not the error symbol. People often use this symbol. Let me use it as a bigger thing they often use like this. So why is sorry guys my hand is coming in. Give me one second. I think you know this writing pad is touch sensitive and I need to disable the text sensitivity because my hand is coming in the way. So give me a moment. I'm going to take a screen and try to show you. function I am not able to find the right knob to turn off the options. Okay, here we go. This is an old habit in swimming, it's like this. We can have... Okay, so we won't waste time here. I'll figure it out later, but somehow my hand touch is affecting this. So this is a thing. The probabilities go from 0 to 1. Now let's try to relate px to b of x. You realize that there is some relationship as the distance increases and let's look back at this figure. You realize that as the distance increases and let's look back at this figure you realize that as the distance becomes more and more positive the probability that it is a red berry does it increase or decrease increase increase right in fact when D 0, you want the probability to be half. Beyond 0, you want the probability to continue to increase from half all the way to 1. On the other hand, when you go in the negative direction, when you go from d is equal to 0, which is at half, to d in this negative direction, how far you can get? Well, theoretically, you can go to infinite d is equal to minus infinity except that in real life there are no negative weight and negative size berries but let's take it this way I take it like that as a theoretical exercise heart exercise that when B becomes more and more negative the probability gets closer and closer to what value the probability of it being a red berry so blue bits so there is an interesting parallel here we do know that we have latched upon the right thing this is the dx tends to infinity, px tends to 1. As dx tends to minus infinity, negative direction, this tends to 0. And also we have a px is equal to half when dx is equal to zero. In other words, when you're sitting on the decision boundary, the probability is equally on both sides. It could be blueberry or red berry. So now what we do, and we are going to think like people who are creating, building up And we are going to think like people who are creating, building up a classifier from scratch. How would you do that? You realize there's a problem. D belongs to the domain. D belongs to the domain. Minus infinity to plus infinity. P belongs to the domain. Zero to one. But we do know that as one increases, the other also increases. We just need to figure out a formula of P in terms of D. In other words, we need to say P is some function, some function of B of X. We do know that because as D increases, P increases. But what function it is? So let's try to worry about this central problem. D goes from minus infinity to plus infinity. P only goes from 0 to 1. Let's see if we can do better. It turns out that people who gamble a lot in horse racing and so forth, and people in common language when they say what is the likelihood of rain, what's the likelihood that somebody would show up and so forth, they use not the word probability, they use the word likelihood. Likelihood or odd, actually not even odds. Let me use the log odds. Odds. I won't use the word likelihood. Have you heard people say talk about the odds? The odds that for example this horse will win is 10 to 1. Some horse that is favorite and everybody has confidence. People will say odds are 10. people will say odds are 10, 10 to 1 or the odds are very low they're close to 0 and so forth. So odds tend to go from 0 to infinity. Like somebody says that the odds of my horse winning is a million to 1. Saying they're very confident that the horse is going to win. Or for example if you ask this question what are the odds that we can have perfect global warming. So depends upon who you are. Some people will say the odds of a catastrophic global warming are million to one. They're pretty sure it's going to happen. Other people would say no I'm not really sure. I would put the odds pretty low. They will be global warming, you know, catastrophe or something like that. So people differ on their perception. Talk in terms of odds. Usually you don't find common people talk in terms of probability sector where probability goes from zero to one. So what is the definition of odds? Odds is it turns out odds is defined as the probability of something over the probability of its not happening. P over Q. Q is 1 minus P. Not happening. The probability of not happening. So for example in the case of a horse is a p is the probability that the horse will win. Q is the probability that the horse will lose. So that is called the odds and because q is one minus p odds are a p one minus p. So in case of a blueberry red berry situation it is p is a function of x somehow. So you'd say that odds are this. Now let's study the odds. What does the function the odds thing. Let me use a variable or something for odds. Let me call it a symbol. Let me use a symbol, O , which is by definition the probability of winning over probability. Probability of it being a red berry versus probability of it being a probability. Now let's study odds. We know that P goes from, Px goes from, belongs to 0 to 1. Dx belongs to, I'm writing this in here, Dx belongs to minus infinity to plus infinity what about odds of X what's effects see what let's think about it when probability is 0 0 over 1 minus 0 is equal to what is it equal to guys 0 over 1 is equal to 0. So it goes from the interval 0. And when probability tends to 1, like let's say that probability of something happening is 0.99999. So this is close to 1. And the denominator, 1 minus something, almost 1, is equal to what? A very small number number 0.0001 so now when you divide 1 by a very small number what do you get a very large number you get something that's closer to infinity so the domain of the odds is from 0 to infinity well that seems to be an improvement we have somehow constructed from Px something if you look at this it is a little bit more like dx. The odds are a little bit like dx. Now you say that well we are almost there in creating a relationship between probability and distance. We do know, we are trying to infer what this function could be. Now comes this thing that there is still the problem that this goes from minus infinity to infinity and this goes from 0 to infinity. Once you face this problem, now you have to use a bit of a trick. This trick turns out that people who are savvy with mathematics they know it. If you want to convert something that only stays positive you notice that this only stays positive. There is actually a very easy way to do that. You do this. So I'll give you a basic mathematical trick. You take any number. Let's say that X goes from any number. Think of e to the X. What happens when X is positive? x is positive when x is positive e will be e to the x will be what will it be positive it will be positive right yes positive and generally it will be greater than uh it will be something right when x is let's say negative 10 what about e to the minus 10 is it positive or negative it's positive it is still positive it will be very small but it will be positive, isn't it? So this looks like a good trick. If we could take the distance and we do e to the dx, now what happens? e to the dx will go from e to the minus infinity is what? What is e to the minus infinity? That is 1 over e to the infinity and that is equal to 1 over a very very very large number is equal to 1 over a very very very large number is equal to 0. It goes from 0 to of course e to the power infinity of course is infinity. It goes to infinity. Now you see we have a lovely thing. We realize that this guy and this guy, they behave exactly the same. Do you see these guys? The odds behaves like e to the exponentiation of dx. And once you see that, this is when a mathematician says a moment of epiphany or a moment of discovery you really get excited because you have found a very simple way of relating relating the probability to this so you therefore make a theory let's invent a theory we say I suppose this requires it requires a new color perhaps we will say that maybe maybe odds of X is equal to up to a proportionality constant why bother about proportionality constants e to the D of X suppose Suppose we do this. This agrees with our intuition. If you look at it, the intuition that as D increases, odds increase. Isn't it, guys? If you go and look at this as D increases, as you go more and more towards positive direction, let me mark the direction like this, as D be increasing, odds increase, P increases. P increases and the D increases. So we write this theory. This is so lovely actually to find a relationship that is so simple. And if you do this, what you have just discovered is a very, very powerful equation in mathematics that is used all over the place. It's used in a population studies. I mean, one of the most fundamental equations in mathematics applied mathematics is this equation it is called the logistic equation and its utilization and i'll tell you all the use cases that it comes to but let us write it down what was odd o of x it was a p of x divided by 1 minus p of x isn't it guys is equal to e to the d of d of x this is our foundational equation writing it back in terms of of p and this and there are many forms you can derive from that. For example you can say log of P X 1 minus P X is equal to B X. In other words distance is the log odds. This is an intuitive way to remember. As D increases the log odds of it being a red berry increases. And now this can also be written. You have this equation also reformulating. Reformulating it as is that so you have if you solve this equation px 1 minus PX is equal to e to the x e to the DX oh no sorry yeah e to the DX if you write this and then what do you do suppose you add PX to the numerator to the denominator in both the situations you will realize that this equation becomes what does it become sorry let me write it down here e to the e to the d f suppose you add numerator to the denominator which is perfectly legitimate so long as you do it to both sides you will realize that px is equal to e to the dx 1 minus 1 plus rather e to the dx do you see this guys from this you can solve your way to this simply by adding the numerator to the denominator and this is the same if you divide both the numerator and the denominator by e to the DX it will become 1 1 plus, e to the minus dx. Are we together? We can write it in this. And this is the form that is much more commonly found. Now, I use the word d for distance. generally in books you find D of X called Z of X or just Z. What I call D because to me it is very intuitively the distance function it is in fact not just to me it is acknowledged as known in the field to be the distance function but by convention people often write it as zx or just z and so the common form that you find in books is a p of x is equal to 1 plus e to the minus Z and I'll just write it as Z here of Z of X is implicit you let me just write it in the form that you often find it in books where it's understood this is the way the typical form the typical form of the logistic equation. Now I'm going to spend the next half hour probing into this very very interesting equation and making it down to it, making it very real for you guys. But do you see what happens guys is that when you open a textbook in machine learning they will they will start right away with this equation like for example your textbook is now it starts with this equation it is really worth asking where in the world did somebody uh where did where did this equation come from how did somebody think of it from first principles and why should i believe this equation come from? How did somebody think of it from first principles? And why should I believe this equation? And I hope I've given you the foundational understanding of where this equation comes from by looking at this example. Are we together, guys? I hope this becomes clear. Now, there is one little thing that I haven't mentioned. I'll keep it perhaps for next time today. We may not get time. That D of X is the equation of a straight line decision boundary. Let me write it down. D of X, i.e., the equation for the decision boundary. For the decision boundary, it is actually can be written, it is a straight line or hyperplane. So equation of a straight line is beta naught plus beta 1 x1 plus beta 2 x2 and how what where this comes from and then you can generalize it to higher dimensions to that this is it now derivation of this will be in the extra session because it sort of gets a little matzy and you may or may not be interested with it if you're a person who's only caring about focused on the practical application let's say you don't need to know this so those people who are excited about understanding how did this whole thing happen we will cover it in the extra session for the rest of it just take it on trust that it is actually so as a fun question yes that's two-parter so why exactly why did he use ex why not just any other number why not why it is true a very good it's a very good question see what happens is At least, why did he use e x? Why not just any other number? Why not pi raised to x? Very good. It's a very good question. See, what happens is you look for the simplest thing available to you. Now, if you are savvy with exponentials and your algebra and so forth, the most natural thing that comes when you want to convert something that goes from minus infinity to infinity down to only positive part of the real of the number line one easiest way is to just exponentiate it if you try to think you may be able to think of other functions too but by far e to the x would be the simplest that will come to your mind and can you use other functions by all means this we are just making the simplest theory there are other theories and so they make for other classifiers and the second question is why did he choose equal to I mean it should be proportional to proportionality you could do that but you know odds the trouble with arts is is just a number so suppose you you put a proportionality constant you can just redefine your odds absorb that proportionality constant because the point is odds vary in proportion to P the like the distance like log of all you say the channel is proportional what happens if I set the proportionality constant to 1? I'll just end up redefining my notion of odds a little bit or my notion of distance a little bit. So you just stop it. Won't that affect the classification then? No, it doesn't affect the classification. So since you asked that question, it's a mathematical trick and those of you who are not very into it. So let's say that we said log odds, right, is proportional to d. Odds is proportional to the e to the power d. d and suppose I did this odds is equal to therefore let me just write it as odds 1 odds X is proportion to D of X and so therefore odd effects to your point is very simple to see this is equal to some proportionality constant E to the d of X isn't it and now lambda I can write as exponentiation of some other constant e to the not lambda but let me just call it some value let me call it some constant C I can write lambda as e to the C some proportionality constant and so it will become e to the DX and so what we are saying is odds of X is equal to e to the B X plus C now what does the express C do it just shifts like it just adds a constant to that which is not terribly useful it just moves the line a little bit that is why you don't care for the proportionality constant and that the simplest way is just set lambda is equal to 1 or C is equal to 0 and you end up with a simple three to summarize. We have this lovely equation, which says that the probability that it is a blueberry that this point is a little bit of probability. That X. In feature space. Redberry rather let me not confuse it red berry is equal to of X which is the same as now when I expand the value of D e to the minus beta naught minus beta 1 X 1 minus beta 2 X 2 so this is it or rather if I just e to the minus z. It is the famous logistic equation. Now, this discovery of a logistic equation, I've literally taken you, I hope, through a process of discovery from first principles. What does this function look like? If you plot it on a line, on a graph, what does the logistic equation look like if you plot it on a line on a graph what does the logistic equation look like it turns out that it is it showed up here but it shows up at countless other places and it has a very interesting look to it so this is how it looks this is zero so what happens is you realize that when X is minus infinity this will be zero. The logistic change will be is okay I'll just use the yellow line it is here very small when X is infinity this is probability in a p of X p of x. The maximum value it can achieve is 1. So the minimum value it can achieve is 0. We realize that the maximum value that it can achieve is 1. And in between, it will rise up slowly like this. Now this is what the logistic function looks like. This function has some very interesting qualities to it. First of all, needless to say it is a continuous function. Let's look at its quality. The mathematicians like to describe it by qualities continuous. It is smooth. Would you agree that there is no reason why it should be just smooth? Any doubts? It is smooth. The smooth word in mathematically means it's differentiable means you can find the derivative everywhere of this function, but forget about that if you are not interested in that The calculus aspect of it, but just notice that it is smooth. The other thing it has is monotonically increasing monotonically Increasing You see that guys that as X increases it keeps increasing. What would be a monotonic means? It only moves in one direction, does not move in the other direction. So for example, as x increases at no point does it start decreasing. It always keeps increasing. If it increases it always increases. If it decreases it always decreases. That's the nature of monotonic function. Here it is monotonically increasing. It's a quality isn't it? And lastly has negative saturation point saturation point at zero. This is also called net lower this is your lower asymptote. Mathematicians use a lovely word asymptote. So you see this right that as X goes to minus infinity this a probability of X doesn't budge much. It sort of saturates at zero. You see this guys in this region it saturates at zero. So this is a lower asymptote. And what about this point at this point when X tends to infinity. Does it again saturate it again has a saturation point that is has upper as positive saturation point positive X saturation negative X saturation saturation point saturation point saturation point at P is equal to 1 this is your upper same and people who are used to the mathematical language they will say that the logistic function are asymptotes on the lower side to zero and on the upper side to one it has lower and upper asymptotes now it turns out and you know something peculiar I'll tell you or a way to remember think of this as s notice notice that it looks like a S stretched out. If you pull this and this in the other directions does it look like this right a stretched out s do you see that guys or I would like some confirmation that this is very obvious. You take an S and you sort of stretch it out horizontally, pull in opposite directions at the tips and it will begin to look like this. You see that guys is it obvious it is obvious right? So it turns out that all such functions. That. Look like. Stretched out. Yes. And have. S and have the properties of being continuous, smooth, monotonic and with upper and lower asymptotes sigmoid functions are called sigmoid functions. Are we together? example of the sigmoid family of functions. Are we together? Now this by the way is a big statement because it will haunt you of functions. Are we together? Now this by the way is a big statement because it will haunt you for the rest of your career in machine learning. It's used everywhere. The sigmoid functions are everywhere. Logistic is only one of them. If you try to plot tanh, you will realize that that also looks like that. There are quite a few functions that look like that. If you take the integral of the bell curve to your surprise the integral of the bell curve will also look like that there are many many such functions so let me illustrate that see a bell curve looks like this now look at the error function, the integral of the bell curve, 0 to x of e to the minus bell curve function is 2 squared over 2. This is the bell curve with approximate, you know, some proportionality constant. So just take this fact, this as a thing and you will realize that what happens is you're looking at the area under the curve up to some value x. So when x is minus infinity, what is the area under the curve? It's zero, isn't it? what is the area under the curve it's zero isn't it there is no area under the curve yeah it is zero and when x is equal to plus infinity you know the total area whatever it is it will saturate to that because you realize that after a certain limit the area that is behind it does not increase, it saturates. So this function also shows a behavior that is like this sigmoid kind of a behavior. Let me make it look more sigmoidal. So logistic is not the only sigmoid function. There are many sigmoid functions. They are all around you, the sigmoid functions, and they are very, very useful. The whole theory of logistic regression is one of the most powerful classifiers in the sense that it's interpretable, it's simple, and it is ubiquitously used and when it works, we love it. Many times it doesn't work. It's a simpler model, but the more complex models are actually built out of it. In fact, today the state of the art is something called deep learning, deep neural nets. One of the interesting things is deep neural nets are built, at least one family of deep neural nets, are built out of sigmoid functions or logistic functions. So today you've got introduced to one of the big pillars of machine learning. I took you through this intellectual journey and I took you through this derivation. By the way, I've never seen this derivation explained in textbooks. I will explain it from first principles because it is such an important part of the whole field of machine learning. If you didn't quite like it, you know, if you are very practical minded then please forgive this mathematical digression. And if you do like mathematics it's really fun to know, you know, what is it that drives all these neural networks and a lot of machine learning, what function is it? Where did it come from? So, really worth knowing about this. So, this is a logistic. Many things. For example, in your nerves, the activation of the nerve-to-nerve communication happens through a sigmoid function. The signal transduction within a nerve itself is an activation function so logistic is all logistic or sigmoids are also called logistic is also an example it's a call activation function there are many activation functions sigmoid the logistic is one of the activation function what it means is and the many uses of example if you think of a transistor those of you remember your transistor theory imagine that you have a positive charge I don't know how many if you remember and this is the ground this is the bias what happens when the bias voltage is low no current flows through low bias a negative bias no current after a certain value some bias current begins to flow through current begins to flow through high bias this entire this is called a transistor a transistor goes from when bias is low no current flows through things that don't allow quillens to flow through are called what are they called non conductors non conductor of electricity and high bias current flows through slowly flows through so it has become a conductor and therefore the word semiconductor it is something that is both a conductor and a non-conductor it's sort of half based upon the bias right that is where the words come from and transistor as you know is the fundamental building block is the atom of electronics of computers at the fundamental level is the transistor that drives all logic and there it is you have the logistic function. If you look at the bias voltage and you look at the current going through it will again show you a sigmoid function or a sigmoid shape and those of you who come from how many of you have electronics background if you remember this is how a transistor works. Your nerve currents work like that. They also have activation. Populations of species work like that. So for example, you can talk about how much risk, like what happens to a population. Let's say that this is time. Or this is a time a population will start very low of a species. If you throw them at an island, it will grow, grow, grow, grow, grow. And it will saturate why why will it saturate? Well, the theory is that after a little while, any ecosystem can only support so many rabbits. Let's say. So, it will go or so many people, so if the population will saturate. So this is the logistic population model. So, as you can see this logistic function, it has many, many years. In fact, if I remember the history of it is like, it was called logistic because it also describes the literal logistics of armies during war. Logistics of things and so it. It is applicable there also. So many, many places it is applicable. So now, what does it have to do with the classifier? What it means is, suppose you can find the probability that it is a red berry. What you can do is you can make a decision. Probability of red berry greater than 0.5 means, means classify the point the point as red berry less than 0.5 greater than equal equal to blueberry. In other words, the decision boundaries there. And this number is called the cutoff. That helps you decide. Now, cutoffs are important. There's one more point I would like to make cutoff in the last few minutes. See what happens is that cutoff is your choice. For example, if you're looking at somebody having a cancer or not, and you have a test, you have a classifier, a person who has a 50% chance of having cancer, would you call him as a positive or a negative case for cancer? What would you do? If a doctor told you, you have 50% chance that you have cancer. Would you act upon it or would you just sit there? Act upon it because the consequences of not acting upon it are very drastic. So the cutoff that you choose depends on the context. So for example, for cancer detection or something like that, or cancer, very serious issues or other serious issues. So for example, if you have a certain probability model that a certain public transit system is going to be attacked, you won't wait for a probability of half, 50% chance that yes, it will be attacked before you take action, preventative action. What will you do? You will go on hyperdrive and security measures at fairly low probabilities, the cutoff in such situations can be as little as 10% even if there's a 10% probability or even a 1% probability you want to say that it's a positive case it needs further study and that is what happens in many cases anyone test if it comes out even a little bit positive you do indicate it as positive probability there are certain cut-offs and then you send it for further study you send the patients to further testing in security modeling again the thresholds are very low so where you put the threshold completely depends on you I'll make it real for you with another financial exam so let us say that you all have children and i'm sure that you all have been saying just send your children to college one fine day a friend of yours comes and says hey you know i've lost my job i'm going through hard times and could you lend me some money well you are a good friend you You say, well, sure. And you're thinking of something like a few hundred dollars or a thousand dollars. A quarter million dollars or half a million dollars or something like that. Pretty large number. Now you're a bit shocked. Because that is the total pile of money, let us say you have saved for your children's education. And perhaps it's also all that you have retirement and so forth it's a lot of money now the question comes well he's your friend you would like to help him what probability will you give him the money you know if you are 100% sure he'll return it you you would give him the money I suppose you would be a good friend but then we all have different tolerances for risk you would you would agree that if there is a 50-50 chance that he'll return it you would be very hesitant to give it you wouldn't give it to him on the other hand I do would probably want to assurance that is in the high 90s that your money is coming back because it is the only nest egg you have that you have of the savings you have for your children and for your time and then so forth so where you put the cutoff in a classifier give him the money or not probability that he will return at what point you classify that yes he will return versus in default he won't be able to return he won't succeed so depends upon for medical situations of cancer you would put the cutoff very low maybe at one person to two persons or five person even if there's a slightest chance you may have a debilitating disease or terminal disease, you want to indicate it right away. On the other hand, for certain situations, you need absolute surety before you say it's a positive case. You would want to loan money to somebody only if that's the only money you have. You would want to loan it to the other person only if the probability that you'll get it back is in the high 90s and that illustrates the fact that that off and where you put it is rather problem dependent the problem that you are trying to solve it depends on that problem there's something to know about probabilities that when you use probabilities and check continuous numbers which is 0 and 1 and you make a classifier out of it, you have to choose a cutoff. In the absence of all information you can take for example blueberry, redberry or a dozen apple, half is a good number. But in all other situations you have to be context aware. What is the context here? Where should you put the cut-off? Are we together guys? And with that, I will end this. Now one more thing about cut-off is, this cut-off right, sometimes you can keep it at half, but you just have to move your decision boundaries up and down such that it serves your purpose. So there are many ways, many knobs to play with it. You'll see it practically. You can insist on probability half always being there. But then how you move your decision boundary up and down so that you always get good results is interesting any questions anything as we started this with taking two input feature classes right all all the things that we did would still apply works for buying for buying you can it only works for cows and ducks you can bring in a horse You have to play a game. One versus versus. So what you do is you can do is you. It is that it is a. Probability that it's a. And probability of ability. Duck versus versus more. And then you find out you find out what it is is the highest the highest. If it turns out that the answer to the duck can it be. So I'll repeat it for multi-class one versus rest whenever you get a binary classifier you can do this so for example you can say probability of cow versus not cow then you can say probability of a horse versus versus not probability of a versus not not fill me example in the case of death either a duck or it is horse or cow then you would compare these three probabilities pick the highest isp and find out which animal is it associated with so that is why the logistic regression when you apply to multi-class you have to build innocence three models models or number of classes. Minus one typically. So as if I have a question. So the choice of decision boundary, I want to clarify this, that is based on the cutoff probability of given. I can't hear you. You have to be a little bit louder. So I just want to clarify the choice of the decision boundary. How do we choose the decision boundary that is based on the cutoff probability? Is that correct? In other words, how do you find the decision boundary is your question, right? Yes. I do agree that we need to, once we find the decision boundary, this is the theory. Problem remains, how in the world do you discover that decision boundary itself? And that deals with our next topic, that is the loss function. How do you, you know that in the case of regression you find the best fit line by using sum squared error loss function. So the next topic will be exactly that. How do you discover the decision boundary? How do you discover the decision boundary? And what is the loss function? It becomes the broader question, what is the loss function for classifiers? That itself is a bit of a mathematical digression, but today we have had enough. So I'll stop here, and we'll talk about that next time. Because we are running out of time. It's 1027. We have three minutes left. I would rather take questions. Because after that, I have my meeting with the India team. Any questions, guys? By the way, was it clear? I know that we did a long intellectual journey today. But was it reasonably clear? clear you feel you understood it anyone yes yes good so i'm going yes yeah i'm going to share this now share this clear sir stopping the recording now oh something strange happened. Maybe the recording of the second half didn't come through. Or it did. I don't know what happened. It says record. So guys, the second half of the lecture may not have come through, in which case I will sort of repeat it at some point for you guys. And re-recording it which is unfortunate i'm just looking at it and it seems that i might not have gotten it let's hope that i got most of it i don't know where i made a mistake and stop it but i'll post these notes and we'll take it from and we'll take it from you. We have two minutes if anybody has a question, please do ask. Sir, I cannot play YouTube videos still. I don't know. This is private. Who am I talking to? Sukhpal. Sukhpal, did you log in with your YouTube ID? With the same Gmail ID. You have to log into YouTube, otherwise can't I'm always logged in because I have YouTube premium so that only works when you know my email is and or to Prachi Prachi and Lenny's and could you guys please help him him i don't think thank you sir and good night and do reach out to me otherwise if you can't reach prachi and these people i think prachi is not here dennis was here these people will help you i'll help you any other questions guys good night good night I have a question the one with the transistors the one where it either passes zero or it passes a signal is that a sigmoid function or is that is that a different function it is a sigmoid sigmoid it's sigmoid i thought it was like a the red loser yeah it's not yeah yeah it is a yeah it is a see here's the thing here's the thing it is rectified rectified and go negative negative now right from I get it. I get it. Now, from my electronics study, but I remember that it might function. Maybe wrong. It is possible I'm wrong. So that's a good point to cross-validate. Go check it out in the text box. The current through a transistor. In fact, you can check it right now. Transistor function of bias. I don't see a function here. Okay, I'll look at that. Maybe if I'm wrong then it's right. So from 30 years ago, if I remember right, it was the graph represents the current and voltage of a transistor. And yes, it is like a sigmoid function except that it doesn't have the current through it. Okay I'll look it up. Maybe it is not exactly a sigmoid function. I used to always believe it is. Any electronics engineer here working with semiconductor physics? I'm used to . So is it a sigmoid or is it not? I.V. characteristic? Yes. It's actually. Yeah, we don't. So after the threshold voltage actually sure it does not usually where we operate. The operation region, but beyond threshold, we just look at the right side of the. That is right. Yeah, you're right. It's a big one. Yeah. Good. Yeah. Good. All right guys. Good night. Good night. Thank you. Right. Good night. Thank you. Okay, let's get together sometime tomorrow afternoon for that, you know, the government registration stuff.