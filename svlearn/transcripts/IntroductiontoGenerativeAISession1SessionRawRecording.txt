 Welcome everyone to this session on Generative AI. This is a four-session small series in which we are going to delve into this world that has pretty much dominated design. There's a lot of exuberance about Generative AI. It almost seems too good to be true. What is it? Does it really have all the potential that people are ascribing to it is it hype what part of it is hype what part of it is real and and what can we make out of it what does it mean to us in day-to-day life these are the questions we're going to answer now in this audience there are a lot of you who come from a leadership background there are people who come from technical background and i will try to address as far as i can to the questions that both of you may have in your mind so we will start let me start by sharing my screen. And give me a moment, please. Coming up. Are you folks seeing the screen which says Generative AI? Yes. So a little bit about me and about us. I have been in two parallel tracks. One is academic and one is industry. After graduate school, I've been in the industry. I worked for nasa for cv for oracle and for cornerstone and startups and many things and i've been the chief architect for the better part of to almost one and a half decade in companies at the same time and had leadership positions i just left my previous job as senior senior vice. While I've been doing all of this, I've also had a parallel academic track. Through graduate school, I realized that teaching was something that I absolutely loved. And so I've also been teaching various topics in computer science and artificial intelligence now for the better part of three decades so as I talk if you do notice that I get into a bit of an academic mode pull me out I apologize for that I'd like to keep this session very interactive and very much about what can we do so this is it this today is generative AI what when why where what is it the basic coordinates of this big big topic that is on everyone's mind generative AI it is hard these days to open a newspaper or to watch a news item on the video without encountering this term. So now the way we will do this for sessions, you will see that I move back and forth between a slide deck slides and some playing around with some websites and examples and handwriting. You would literally see me write on the blackboard and so to explain some of the concepts but today we'll keep the concepts to the minimum and just talk about some broad topics so a little bit about this we keep calling ourselves the Sherpas on your journey as you learn this topic of generative AI even though it's only for four sessions. Look at us, look at me as a person who's helping you understand this topic. So do not hesitate to stop me. Now, I'm going to just for a little bit tell you about this organization that we have. We translate leading edge research into our products. We have been doing it for a very, very long time. If you any one of you want to know more about me or what i do you do please reach out but for now we'll move on with this now this topic of generative ai has ai built in artificial intelligence is something that has been a millennial aspiration of humanity but thousands of years we have references references in ancient Greek mythology of intelligent robots, we have references in in Hebrew literature of the so-called golem that can be created and it comes with appropriate warning that if you create a golem, an artificial being, then it is attended with great danger, something that we are only beginning to realize that artificial intelligence today is not a complete blessing. It comes with its own dangers. It can wreak havoc in society. It can do harm to, it can be used by malicious actors for all sorts of inappropriate purposes but it is also something that is definitely going to transform life as we know it we are in the midst of a very cataclysmic change in societal structure for better or for worse we'll all see but it is happening it is happening as we speak so there's a lot of history that i wouldn't go into but we will talk a little bit about what is generative ai and somewhere around generative ai you often hear this big phrase attention is all you need it sort of has become like a mantra that gets talked about quite a bit as a starting point but actually generative AI has been there for a very long time what its impact is on the industry since today's introductory topic we'll touch upon that can I interrupt real quick would you uh it sounds like the sound is not really clear so if you could come to... Yeah, perfect. Is it better now? That's much better. Thank you. Okay. So I apologize for that. So we need to talk about what is it doing to the industry and to society in general. We'll talk about who is advancing and who's thinking, who are some of the people who are forward-looking. And today, this perhaps includes all of us. Out of the seven billion human beings I would imagine, at least a couple of billion are actively engaged with generative AI in some form or the other. It has touched every aspect of society, every aspect of life at this moment. So AI itself has been around for a long time. It has been there since the 1950s. And in the beginning, it was used for things like playing chess or solving mathematical problems. It seems remote from practical life. The roots go even further back. It goes to the mathematician, Carl Frederick Gauss, who created the first so-called learning approach and the least square method. And I suppose regression as a method started with him. But that's a long history. What I would like to talk about today is just focus on generative AI. When we talk of generative AI, it almost seems as though it is something that got generated in 2023. It's not like that. It's been there for a long, long time. It started in the 1980s with so-called recurrent neural networks. Those recurrent neural networks were a particular neural architecture or AI system that could actually generate new words that could write a few if you prompted it enough it could translate English into let's say French or vice versa it could do all sorts of things it could condense paragraphs it could generate text and things like that so in in machine learning there are two essentially broad classes of algorithm one are just essentially broad classes of algorithms. One are discriminative algorithms. The discriminative algorithms are like classifiers and regresses. An example of that would be you're looking at an animal and you need to create an AI system that can tell what animal is it. Is it a cat? Is it a dog? Is it a horse? And when you create a system like that, what it, the way mathematicians say is that given all the parameters, what is the probability that it's a cat? What's the probability that it's a dog? And if you could do those probabilities, then you pick the most probable thing and that is what you predicted to be. So that is discriminative learning or discriminative algorithm. Likewise if you have a let's say that you have a young entrepreneur with an ice cream shack on the beach and the entrepreneur is trying to predict how much ice cream would sell today. That prediction is important to the entrepreneur because the entrepreneur needs to decide how much ice cream to purchase in the morning from the wholesaler. Then that model that they are using, they're predicting an amount of ice cream that the entrepreneur would sell on a given day. That too is a discriminative model or discriminated about that and why because based on the weather conditions before whether it's a work day or not whether it's a warm day on the beach or not whether the surfs are rising high and many parameters wind speed etc etc the entrepreneur is trying to estimate how much ice cream would be sold. It's predicting a number based on the facts. These are discriminative models and they have been around for a very, very long time. Generative models too, it turns out, have been around for a very long time, though they haven't been getting as much attention. A part of the reason was that their uses did not impact our lives in so dramatic a way, but over the years, over the decades, gradually their real life impact has been increasing. It has been progressively getting closer and closer to having a dominant role in our lives as much as the discriminated models have. So recurrent neural networks were used initially for language translation. And as you remember, a decade ago, when you would try to do translation from one language to another, it was at best an imperfect thing. Sometimes all you could do with that translation is get some sense of what it must have been in the original language. In fact, it was very common for the young researchers to entertain themselves just by using a translator to translate something in one language to the other, seeing how funny it sounds or how funny it came across and having a pretty good laugh at it. But things have improved dramatically since then. In the mid 1980s came something called the Boltzmann machine and the restricted Boltzmann machine. These were perhaps the first generative neural architectures. I won't go into what they come from, but there's a few who have a background in material science or physics, just for you to know. It is based on statistical physics models and Ising model. And was perhaps the precursor or the generalization with the so-called energy-based models which are still which have gained renewed interest since the since 2010 in the last decade perhaps then along the way came the long short term memory one of the problems with recurring neural networks was that if you give them a long passage to translate, they would remember the more recent things better. And what you give it initially, it used to forget. And people tried to remedy this with this complicated thing called LSTM with quite a decent degree of success. So those were generated. You could generate text from that. You could generate translations from that, summaries from that, and so forth. And they were perhaps the first practical models in relatively widespread use. Then around 2013 came something called the variational autoencoders. Variational autoencoders are interesting machines. They try to look at the input data and say what if this data actually could be represented in a much more meaningful latent space and in that space you could understand its structure better and then from there you could decode it. So you encode it to a more meaningful latent space and from there you decode it. But when you do it, you impose a sort of a necessarily probability distribution called bell curve, a bell curve, a Gaussian-like distribution. And while it gets technical and I won't go into it, one of his first consequences was that it could do pretty good generative, it could generate data. For example, it would generate people's faces, people who didn't exist at all. It could do that. Then around 2014 came the generative adversarial network with a very interesting history. It was playing, it played upon the fact that, and this was, this is the one algorithm I'll talk a little bit more in depth today, because it really caught people's imagination. If you look at the history of generative AI, people really woke up to generative AI with the GANs, with the Generative Adversarial Networks. So it is an interplay between two adversaries, think of it as a cop and a counterfeiter, a generator and a discriminator, and the interplay between them and each trying to play an adversarial game and getting better and better led to a generator, a counterfeiter that could generate very plausible counterfeits, and that led to the rise of fakes or the so-called deep fakes. We will see in a few examples that it can generate very realistic fakes, and those fakes are not all harmful, they're often of good value. For example, GANs can produce data data generate very useful and valuable data in a variety of circumstances they can be used to do mural style transfer so for example Monet and Van Gogh are gone but if you want your house and your landscape to be rendered in the style of Monet and Van Gogh generative adversarial networks are at your service they'll do a Django. Generative adversarial networks are at your service. They'll do an amazingly, amazingly accurate job of repainting your landscape in the style of whichever artist you like, Monet, Van Gogh, Picasso, you name it. So all of these things were going along the way also around 2016. As you can see from 2010 things began to really heat up in the generative AI landscape. 2016 saw the birth of normalized flows, another class of generative models that are quite important these days. But then I guess the really big breakthrough that But then I guess the really big breakthrough that changed the world in very profound ways, and more profound ways than the previous models, it was the coming in and the discovery of the transformer architecture. Transformer architecture came pretty much the paper that announced the transformer, or today what you call the large language models and chat gpt is an example of that it started around christmas time around december of 2017 with a landmark paper called attention is all you need this paper created it was it was initially meant to be a sequence to sequence model, something that would encode an input and then create a latent representation. Excuse me. And then decode that latent or the abstract representation into whatever you wanted it. So what does that mean? You could take text, you could encode it, and then choose to decode it in another language or decode it into poetry or decode it into a summary or decode it into sort of, if it is a prompt, decode it into a narrative, and so on and so forth. So that was the transformer that was announced in, that was first showed up in the literature in 2017 with the landmark paper, Attention is All You Need. That led to a vast explosion. Transformers would take over the world, quite in a very, very literal sense. AI would not be, especially in natural language processing would not be the same ever again people knew that the world had changed as a quick follow-up came the visual transformers and those visual transformers did something amazing they reformulated images videos etc also as a vocabulary as a vocabulary, as a form of, as a language, a visual language, audio as a visual language. And so you could apply this generative thing, the transformer, especially its decoder part, to generate all sorts of things, not just generate new text as stories, as poems, as answers to your questions, but as new pictures, new videos, new audio, music generation. It seemed today, it seems hard to imagine that transformers would not solve whatever problem that you're thinking of. They seem to be doing extremely well. They seem to be taking almost all the exams like for example sat and whatnot and the law exam and the medical exam and they seem to be acing it and doing extraordinarily well they can generate answers to the toughest problems and of course this hardly needs being spoken of because we have all been since november of year, we have all been playing with things like ChatGPT and BARD and a Cloud from Anthropic and so forth. And those of you who are technically savvy have also been downloading and playing with your own open source models, starting with Flamingo and Lama, Lama 2, now Mestrel is the latest and uh raccoon and so on and so forth and uh there are almost two parallel tracks one of commercial models and one the initiative from the open source and what we are looking at in 2023 is quite literally a generative AI Cambrian explosion. So just to wet your recollection, we use the term Cambrian explosion in evolution to refer to that era when all of a sudden on Earth, a wide variety of life forms, a wide variety of species began to surface. suddenly there were so many, many, many new species of life on Earth. And that was the Cambrian explosion. And what is happening today in 2023, especially in the space of generative AI, can be likened to its own Cambrian explosion moment in AI. It is hard to keep up. I feel I try to read at least one paper a day and sometimes two. And yet I don't feel that I'm able to catch up. Things are moving so very fast. And these are not just trivial additions. Great ideas, very creative things are emerging at a very, very relentless pace. And it does feel like a Cambrian explosion. So this is the world we are in. And this is the journey that I would like to take you folks through. It's a very interesting journey, but today we'll keep it at a fairly high level. And see, so just a little bit, you'll notice that I'll talk a little bit tangentially because some of you are leadership people with management. And the question that you are asking is, what does it all mean to us in the enterprise? So every once in a while, you'll see me sprinkle a few practical facts. So for example, the global market here for AI is booming. It is anticipated that it will cross nearly 100 billion. And it is already nearly 100 billion, right? And it is already 100 billion, actually. It will increase by 20 folds. And people are projecting all sorts of numbers, 1 trillion, 2 trillion, 3 trillion. No one really knows. All we know is life as we know it is going to undergo radical changes. It is undergoing radical changes. If you look around you, everywhere, I just happened to purchase something as simple as a video camera, and I noticed it has AI built in. Today, whether you know it or not, even your smartphones, have you noticed that the pictures that you take with your smartphones look much better than when you look at yourself in the mirror? And that itself is a gift of computational photography and a bit of generative stuff is going on everywhere. So we live in a world in which it is hard to tell where generative AI is not making its inroads. And yet, as you look at this generative AI, there is the fun part. There's a part and the theory part, the things that you do in the lab, the things that you get impressed with, and then the things that you do to take it to enterprise scale. Some of you who are wondering, how do I take all of this and adopt it in my enterprise? What does it mean for me? So there, it's a long journey actually to go from theory to an enterprise scale robust and high performance architecture. quite complicated actually if you look at a ai centered enterprise it is not just a few very good models it is quite a few things you need data infrastructure and because ai is very very data hungry if you were to ask this question why has all this development happened now and why did it not happen before why for example did it not happen in the 1990s? The answer can be summed up in two statements, data and hardware. A lot of these algorithms, in one form or the other, did exist. They have been evolving. These algorithms have been going through pretty steady evolution. Nonetheless, 20 years, 30 years ago, we didn't have enough data. And we did not have enough hardware at all. The amount of hardware that these things need AI needs is just phenomenal. It's almost like we today, for example, if you the chat these GPT models and these large language models they're supposed to be close to let's say 250 billion, 500 billion or a trillion parameter model. On the horizon already are rumored to be 10 trillion parameter models and even rumors of i don't know how much how much validity to put that in as as soon as 2024 we may see the arrival of 100 trillion parameter models i don't know how true that is but 10 trillion does seem very plausible and it's around the corner so we are talking about vast hardware infrastructure at the the same time, vast data infrastructure. If you look at these models and you ask, what did it take to train them? It is almost like you took a baby and you put all the knowledge of the humanity through it. You put the child to learn from all that we know, all that we have created. that we know, all that we have created, all the videos, all the audios, all the text, everything that you can imagine seems to be finding their way into teaching these AI models. So that you need, and therefore there's a vast data infrastructure that comes into play. You need ML platforms when you do things at this scale. You need to have a methodical platform and a process the analogs process it also brings about a lot of people who are involved stakeholders people who do and people who are the receiving end of the impact it brings up ethical uh questions and frankly interpretability questions do we trust a machine because it says so and we don't know why it says what it says? Right? Why would we trust its predictions? So interpretability or explainability is becoming a dominant thing in the enterprise. And of course, analytics and visualizations of the predictions of the models have been a crucial thing so i just brought this picture here to show you that the actual world under the covers the technical world is pretty complex it has a lot of moving pieces and entirely different subcultures there's the culture of the tribal culture of the data scientists and ai and the mathematicians who are busy creating better and better algorithms there is the tribal culture of the data engineers in the day and the computer scientists and the platform architects who are busy making robust scalable architectures and there is the tribal culture of the systems um engineers and the devops and the mlops people who are trying their best to make sure that all of these things actually can run at scale and at high performance and robust DevOps and the MLOps people who are trying their best to make sure that all of these things actually can run at scale and at high performance and robustly and securely and so forth. So there is a vast, vast amount of engineering that goes to make any one of these things possible. And I won't talk much about it, but just for a moment in the beginning, I'll talk about all the things that it involves. You have to take in the data from very disparate sources from relational tables from the web scraping the web from all the textbooks that are available in the open domain from legal documents from health documents from forms and whatnot and all and while you're at it even synthetic data generation in fact you use generative ai to generate data to teach again the ai models and it all goes in there you ingest the data clean it validate it transform it rationalize it make head and tail out of it then you do all sorts of experiments to train the model to teach to build something of value from it and then you have this whole world of deploying the models and taking them to production and at the end of it at the end of this vast was journey comes out things that we take for granted for example the google search and not many of us want to think what tremendous amount of AI has gone behind it. Or for example, chat GPT or any one of the things or when you go to stable diffusion or mid journey and things like that. It takes all of these things take a vast amount of infrastructure, your social media, your Facebook and things when you get tagged in pictures automatically there is a lot of infrastructure in fact mind-bogglingly large amount of infrastructure whatever you whatever you may guess i bet you the infrastructure behind these things is probably at least a hundred times whatever your guess was. It takes that much to bring about these very intuitive, very necessary services to make. So today I'll take this generative AI with examples. Let's not go too much into the technicalities, but just stick to examples. What can it do? What can we do with it? So you look at this person and it looks like the person we know, I would imagine, but actually this person does not exist. This is a creation of generative AI. And let me show this in action. Look at this person. This too doesn't exist. And I'll refresh this page. This too doesn't exist. Now, if you look at these people, I don't know if you can tell that these are not real people. Anybody has a comment or anybody feels this is completely fake and not real or it looks like a cartoon? To me it looks very realistic though if you really are good at it. And if you look very, very carefully, you might be able to find some artifacts that may give you a clue that this is perhaps not a genuine person. But it takes a specialist to even and even they are not sure that AI has become really that good at this moment. Right? And we can keep changing. None of these people that you're looking at on the screen actually exist. So it is perhaps you're familiar with this. And this is deep fake. But what I'm showing you today with with this and you may it is often called a deep fake but it isn't just with this you can do that with um music you can do that with um uh videos you can do that with writing you You can generate passages that look very Shakespearean, but don't exist. Oh, sorry, I apologize for this. It seems to have some... The other example that I would like to take is of drug discovery. When you look at the effort that goes to discover a single drug, if you talk to a pharma company and you ask, why is this very simple medicine, this tablet, or this injection, why is this tablet worth $400? Or why is this injection, why is this tablet worth $400? Or why is this injection, those of you who are familiar with oncology of cancer and so forth, know that these days the prices of those drugs have become unbelievable. They have too many extra zeros associated with them. I'm told that there are drugs that cost $50,000 per injection, sometimes $100,000. And I also hear, and I don't know how credible that is, somebody once told me that there are medicines that cost hundreds of thousands of dollars per dosage. Why is that? The answer usually given is, oh, because it takes us a decade to discover a drug. And it takes an army of scientists and a vast amount of resources to go through the whole process of discovering the drug, making sure it is safe, that it actually works, and then bringing it to market. And amongst the issues that was there was a millennial problem. People who did protein folding, proteins, what happens is that whenever you have drugs, you have to ask which part of your DNA or the protein that is exposed and what will it touch upon and what will be the value of this particular drug and so on and so forth. So there's a whole field called protein proteo protein economics so in that field the belief was that this is how it will be for a long long time it takes one researcher maybe a whole year or two to know the structure the 3d structure of a protein. It used to be that hard, and that is why it took such a long time to make progress in some of these pharmacological fields. And then came the great breakthrough from generating AI. AlphaFold came, it applied AI and quite literally in one stroke it pretty much cataloged the structure of every single protein in the human body. Right? And now by now I think it has reached the level that it has cataloged the structure, the 3D structure of just about every protein we know about. So pause for a moment and think, what life changing impact are we looking at? What does it do to drug discovery? It squashes the timeline by a vast amount. It squashes the cost of drug discovery by a vast amount. You get a huge, it doesn't mean that it completely eliminates it. You still have to look at the safety of the drugs. You still have to do a lot of research. But one of the most tedious, the most painstaking aspects, perhaps the most painstaking aspect in the scientific process of drug discovery has perhaps been solved. And it has all happened fairly recently. Now as you can say, Alpha 4 reminds you of Alpha Go to some of you in which an AI beat human beings at the very complicated game of Go. Go was supposed to be a game of intuition and a very human game at which obviously AI was not supposed to be able to beat us. If you say AI beat us at chess, we would say, all right, chess is very cerebral, very intellectual. But Go was supposed to be a game that needed a lot of intuition and strategy and things like that. And here we go, AlphaGo beat us. But while it was at it, perhaps as a corollary, it went and created the Alpha Fold. The researchers managed to harness the power of all of that to create Alpha Fold, which is one of the greatest breakthroughs of our lifetime, I would say, to be at least in the field of biology and medical sciences. So that is generative AI. Then, oh, I'm sorry, but I apologize. I think what has happened is, please give me a second. You will see me hop across because there were a lot of other slides from a different talk that are there we live in the world of generative music music generation music generation has become and this is just one website I would like to just go there and show you what it means so this is Alpha hold by the way if you those of you who don't know what proteins look like, they look very, very complicated. If you look at the string, they are very, very complicated structures, they are one of the most complicated molecules that you can think of. So we won't go there. But let's go to generative music i will sound draw and this is only one there are many many websites that are doing generative music and if you were to If you were to look at the music that it generates, I would let you play with that. Just for fun, perhaps, I don't know if my sound is shared or not, but I would like to play a music. Let's see if my sound is shared. Share sound. And I'll just pick any one of them and I I don't know how impressed you are, but it is impressive enough that my family, which is heavily into music, they consider it to be a a very very big deal that today you can synthesize music and generate music of such high quality just like that so it is a big deal then let's try something else Generative design. So, for example, if you go and look at, like, the design of engineering stuff, like you design a motorcycle, you design an, of any piece of engineering used to be a very painstaking labor-intensive process. But today we are looking at a world in which these things have become assisted with generative AI. So each of these designs that you see are the product of generative AI. And isn't it amazing that it is going to change the shape of things in a very, very literal way. It is coming up with shapes that you and I would not have normally thought of as possible. And yet, once we look at the image what AI produces we realize oh goodness yes indeed it makes a lot of sense the other is urban planning you want to design a city you just say this is how I want the city to look the street to look and it will generate you a photo realistic picture of the city what would it look? And I don't know if you're looking at my screen. I hope you can see that this puts a completely different aspect to urban planning, a very visceral feeling it gives to whatever it is that you think you're designing for. Same Same is true for architecture. You can do that. And I want to continue with this, but yes, you could do that. Then, fashion. Fashion is of course, we live in a world in which by its very nature what people wore yesterday, they would not be seen, like to be seen in wearing today. Gone are the days when people could wear the same t-shirt for decades, actually, not quite gone. There are diehards like me, the t-shirts or the clothes that I'm wearing are two decades old, but that seems to be an exception rather than the norm. So, well, today you can have generative AI that will generate all sorts of fashion and beauty designs for you. That is generative art, quite literally, for you. Then, I will canvas. This is actually quite interesting. You could, let me show you what it means um did it yes look at this you're looking at a blank blank canvas on the left hand side you're just making some box and what it is doing is on the right hand side the generative art is building a landscape from your little doodles and this is not something far-fetched today there's a few who have been following adobe photoshop and adobe's products you know that this is very much already there in the latest releases. This product, by the way, is NVIDIA Canvas and NVIDIA Studio, and you can go play with it. And now Adobe has incorporated a lot of it into their product line. So this is all generative. In fact, those of you who have been doing a lot of art and doing it very tediously using masks and this and that people are swaying by it that the creative workflow will never be the same again the generative AI has completely changed all of that so that is that and I I wouldn't like so doodles to photos is one thing. Neural style transfer is quite interesting. This is the last piece I would like to talk about. I believe it is the last piece. What you could do is turn any of your photos into art. So here is an example. You see this picture. This could be a picture from your family album, and you take a style, let's say Van Gogh style, and you say, all right, let's do a neural style transfer. And before you know it, you have this picture rendered in the Van Gogh style. And if you look at these details, it is amazing details. There's a few who are familiar with Van Gogh would almost feel that he has come out of his grave and started painting all over again. So and you can do all sorts of things. You can apply different styles, different, not just of one artist, but of as many artists as you wish. And it can go on. In fact, today, generative art has taken on so much relevance that the whole world of art is upside down. There was this story that I heard that in Wisconsin, there was a major art competition, which perhaps happens annually or something like that. I don't remember the particulars, in which there was this beautiful work of art on a vast canvas. It had lots of subtleties and details and whatnot, and it won the first prize. Those of you who followed the story, if you remember that picture, it was absolutely awe-inspiring. And then the artist came out and said, well, he had used generative AI to create that painting. And that led to quite a debate in the art community. They said, well then then you should be disqualified and well the artist argued that why some you have to become very good with paint brush and other tools to create a painting and he had to become extremely good at generative art techniques the equivalent of paint brushes the generative art techniques, the equivalent of paintbrushes, the generative art techniques and the tools of the trade and the prompting, the right prompts and everything else, and he had to spend countless hours to create that great work of art. And that work of art was as legitimate art as any other art. So that creates a question, that creates its own question. What is art then? This question, if you remember, came up in photography when Photoshop came about. And so there was a photograph and people like me who were photo photographers, amateur photographers or hobby photographers, we would go take painstakingly wait for the sunrise at 4 30 in the morning or something like that and be camping there and take picture day after day to get the perfect shot and then came Photoshop and all of a sudden you could convert very ordinary pictures into beautiful sunrises and sunsets and so there was a debate many years ago, is that photography anymore? And at some point, people had to draw the line and say, well, that is graphic art. That is not photography. But nonetheless, some, or which is considered still honest photography, it still has had its light intensities and levels and contrast, et cetera, improved upon. Whereas a couple of decades ago, the definition of a photograph used to be whatever it is that came out of the camera. So the world is changing, and in this world of generative art now we this is i deliberately took the examples that are different from the ones that you guys are already familiar with for example today i'm told that all children write their essays using at least some assistance from um the large language models like chat gpt right they give they're prompted with certain topics and say okay give me some ideas on how from the large language models like ChatGPT. They prompt it with certain topics and say, okay, give me some ideas on how to write it. People use it for all sorts of purposes. For example, when I have to argue a point, one of the habits that I developed is, if I had a thesis in mind, I would give it to this large language models and say, argue against it, disprove it, or find weaknesses in these arguments and I find that it does an extraordinarily good job and it would uncover flaws in my reasoning so that is again a use of generated AI or today journalism and writing as know, is on its head. People are asking, okay, where does, how do we preserve human creativity in the face of these large language models? Many of you are familiar with the fact that Hollywood had a huge strike, and one of the components of that strike, I'm told, was the fact that writers and artists were complaining that there's too much use of generative AI and that is going to take away their jobs. So it is going to have an effect for the good and for the bad. Generative AI also creates fakes and it also creates good things. For example, I'm talking to you, but everything that i said to you today now we can convert it into a completely different language for example swahili and it could be it would appear as though i've given this entire talk in swahili with the right gesticulation and everything we can do that generative video creation and voice creation. Or I can convert this sound into just perfect pitch American standard accent, which mine isn't. So that too is generative AI. Is it good? Well, that depends on the context. But it is certainly a world that we have entered, for better or for worse. So generative AI is very much here to stay. So today, I thought I would just start with a few examples, just to broaden the scope or understanding of where generative AI is today. What is it doing? And I would like us to, typically when you do a course like this or a thing like this, inevitably you get into the how to do it. And we don't pause enough to think about the ethical and societal impact of all of this. On the very positive side, it accelerates productivity. Jot down a few points and ask it to elaborate it into a well thought out article and it will do it for you. It is your thoughts, well articulated. For people who are immigrants, it is a boon because they often think right but are not as articulate with the native english and so for them it's a great boon but and and so on and so forth but also it could be it can lead to a collapse of reality how would you distinguish that the the creations of generative ai look so uncannily real like this person that is not real and the videos and the sound today we can take three five seconds of your voice and then we can create a recording of you saying things video expressions voice your voice saying things that you absolutely never said so what does it do to it used to be said that believe half of what you hear i mean believe uh half of only what you hear right now it has become that you can't trust what you hear you can't trust what you see, right? Because the boundaries between truth and fake or artificially or generative AI is beginning to blur because generative AI does an excellent job of realism, right? Excellent simulation of reality. It is there in code. Those of us who are programmers today, I can't think of any programmer in the last few months who I've seen not using a copilot of some sort to assist in their programming. So is that code theirs? Is it their creative expression? It certainly is, because they're guiding the copilot and taking its assistance to do it. But is it wholly their creative expression? That leads to vast questions of jurisprudence. For example, if that copilot, if those AI has been trained on vast amounts of data, vast amounts of code, that code has been written by countless programmers before then. A lot of the code is copyrighted. A lot of the articles, the fact that these large language models can write wonderful articles is because it has read the styles of all the great authors and journalists. So to what extent is it legitimate to use this? These are questions worth asking. Is it a copyright violation to use that? So in other words, we need to think fundamental questions of jurisprudence about copyrights and property rights in face of generative AI. We need to think about its societal impact. We need to think about the ethics of all of this. And we need to think about what does it do? What, where exactly is the litmus test of realism, or of reality versus fake of authenticity? What is it? As you know, countries are making laws now they're saying, if you have a large large language model and if it is something generated, it must be watermarked as so. In a mostly hard to erase form so that people can take that this is, can tell that this is generative AI and this is not real or real in the traditional sense. So those are thoughts to think about. Today was a pretty general talk, but from the next time, we'll get into specific models. In the next three sessions, we will talk about models like the GANs, the Generative Adversarial Methods. We'll talk about the large language models. These two things we'll focus on quite a bit, and we will actually go a little bit deeper to see how is it that these things work. We'll talk a little bit about the theory. We'll look into a few examples. We'll make them work and we'll see how it goes. But with that, I would like to end today's sessions and take questions. If you have a question, please use the action button and raise your hand and we'll go one by one. Anyone? There was one question, Asif, in the chat. If generative AI becomes the primary data source, would we run out of real human data? That's a very good question. Actually, what you're basically saying is real data takes effort to create, but generative AI can write, for example, if you sit and write an article, it takes us a long time to think about it and then write it. Generative AI can write an article with just a few prompts. And will we run out of real data? Now, we can run out of real data in two ways. We mean generative AI needs data to train. So there are many complicated aspects of it. First is that, are we really training it with real data? Or is generative AI being trained with generative AI, data generated by another generative ai being trained with generative ai generate data generated by another generator and if that is so are we not getting into a circular argument and still and wouldn't the generator v i get into producing only stereotypical uh generations are very very trained on generative ai producing more content that gets back into training more generative AI. That is certainly possible, though there are many aspects to it. See, human beings are producing vast amounts of data. Whenever you generate, it is not just pure AI generating it. The intentionality is yours. The seed comes from you. You put some thoughts together and say elaborate upon this. So it is the it is the interplay between human parts, human creativity and generated way. I tools that produces data. So it is new data. That is one. The second aspect is we are in a world in which we are seeing something called emergent phenomena. There is a belief that complex systems, they're reorganized through selection process into more complex systems and they achieve higher levels of higher cognitive functions or higher functions. That can have profound implications and that could be in general a force for the good. That is yet to be seen how it all pans out no one really knows yeah we have a couple of hands uh rajagopal please mute unmute yourself and ask the question yeah thanks thanks um yeah so my question is uh uh for any uh suppose if a product is released or any anything that we develop there is a proper security testing or to ensure that how the product is secured or or the environment is uh not violating any security aspect so and we know that generative way when we are talking about i mean it should be more the ethical right how how even if we develop anything in generative way or any things yes evolving on the ethical testing or something like that, how to control before some product is released in a generative way. Yeah, Rajagopal, that's a great question. Thank you for asking that. Ethics is a huge concern. As I said, ethics and even broadly jurisprudence, everything is on the table at this moment. Everything is up in the air. Do we know how to ethically test a large language model and be absolutely sure that it will be ethical the simple answer is no what do we do ethics has many aspects that it should not lie right today it doesn't intend to lie but we do know that these generative ai's hallucinate they they make up things, because they are not truth engines, they are plausibility engines. These AI models, they are trained to produce the most plausible answer, namely an answer that human beings will find to be correct. But to make human beings produce an answer that human beings would perceive as correct is very different from telling the truth. That itself is an ethical problem. And hallucination is a leading research topic at this moment. Nobody has a solution to that. The other thing is that do these models, generative AI, do they learn, figure out, or answer questions based on what we want to hear in other words are they capable of manipulation there is some evidence that yes that is true there is something called the theory of the mind it turns out that the general belief used to be which i don't agree with by the way that only human beings have a theory of the mind animals don't so human beings know what the other person is thinking as we are communicating with them we have a theory of the mind animals don't so human beings know what the other person is thinking as we are communicating with them we have a theory of their mind or conceptualization of their mind with dogs and cats and other things don't those of you who have who are dog owners and cat owners would vehemently disagree but it so turns out that the philosophers in the world in the academy at this moment strongly believe in the theory of the mind concept. It turns out that we have evidence now that these large language models, as they engage with us in a conversation, they do develop a theory of the mind about us. And so the answers they give is conditioned on who they think we are and what we are thinking. That itself has its own ethical implications. We do know that human beings lie and human beings lie all the time, right? Those are harmless lies. Most people tell it to not hurt somebody, to just quite often it's a, you just don't mention an unpleasant thing because the other person would be hurt knowing that you don't you don't give your harsh opinion and things like that you always soften it up and are gracious and so on and so forth the question is well are we comfortable if the large language models are also doing that? This generative AI is also doing that. But more than that, are these things going to perpetuate hatred, bias? See, it has taken human beings literally thousands of years to even realize that gender bias is a bad thing, that sexism is bad, that racism is bad. Just not more than two, three thousand years ago, Aristotle decided that human beings are probably smarter, men are smarter than women, amongst other things, because we have more teeth and we have larger brains. Obviously, Aristotle didn't open the mouth of mrs aristotle and count the number of teeth there right and certainly if you argue that men have bigger brains then what about whales right or elephants then they must be way brighter than us but we are not willing to conceive that so bias and discrimination takes humanity thousands of years to even acknowledge, even amongst the best of us, even amongst our best philosophers. But our literature is filled with that as we are making progress to imperfectly fight these biases, these stereotypes. What about the vast literature that we have produced on which these large language models are trained? So large language models inherently when they get trained or so-called pre-trained, the first stage is they pick up all of those racial biases, those sexisms, those problematic literature. They learn it. It's a child that is just unconditionally learning from all of that. Then you have to come upon a process of called reinforcement learning with human feedback in which you have a human being telling that in this is appropriate to say, and this is not appropriate to say. And so the language models learn to say things appropriately, but it is not watertight it may still say or perpetuate things that are ethically suspect, right? And it also raises the question that while it may say one thing, will it always say the right thing? People have easily fooled Chad Gpt into saying terrible things, practically making it call for war. And there was a famous case, speaking of ethics, in which Chad Gpt got busy trying to convince a New York journalist that he did not actually love his wife of long standing and that he was under the illusion he loved her whereas in reality the journalist loved Chad GPT so well there is the ethics for you it's it's a pretty problematic situation at this moment. We'll take one more hand. Gopi, please unmute yourself and ask the question. Thank you, Madhu, and thank you, Dr. Asif. When you were showing that timeline chart of the evolution of AI and the big hockey stick growth that you talked about when we come to the Transformer stage, right, which is like in 2017 with all you have to do is to open up that paper. In terms of implementation of AI or use of AI in product creation or whatever, has there been any significant change from the prior use of AI, LSTM and all of that versus in 2017, did something change in terms of how businesses have implemented or adopted the way they do development or something like that? It would be a reasonable approximation to say, reasonably correct approximation, that with the transformer paper, 2018, when people came back from their winter vacations, they realized that the world had changed. RNNs and LSTMs, they completely lost their dominance. And just about everything we have been doing since 2018, you can say that most of it now is either directly done with transformers or done with transformers somewhere in the loop. It's literally that transformative. The world has changed, completely changed. In fact, literally, you could say that in one fell swoop, entire textbooks written on natural language processing and many of the sub areas of AI, you could as well put it back into the history section. It was that profound a shift. Madhu Thangavelu...Bhagwath Madhu Thangavelu...Bhagwath Madhu Thangavelu...Bhagwath Madhu Thangavelu...Bhagwath Madhu Thangavelu...Bhagwath is when i look at it from the industrial angle i think when we're looking at it from the consumer angle i totally see that and can feel that but when i'm looking at it from a manufacturing or a you know supply chain and that kind of space i'm not entirely sure that it's you know very evident to me do you have any examples of use cases there that have gone into the transformer era? Yes, I can give you examples of that. See, when you talk of, I'll give you one example. See, when you talk of supply chain, and supply chain is a vast, vast field. Let me take one particular example. It used to be that if you had to tell, like for example, the concept of zero inventory, and you have a warehouse and you want to keep the least amount of things in the warehouse because things come in and things go out. You want to have zero inventory, like things sell and you want to stock only as much as you can push forward in the supply chain. So you have to look at something like what is the median duration or what is the decay rate at which these things are moved forward. There has been a vast amount of AI or machine learning algorithms, in fact entire fields of statistics for survival models and things like that, that used to address that. But one of the recent surprises that came that people actually, it just people didn't expect transformers to be successful there. It turns out, and this is the same is true, by the way, for medical survival, like people who have terminal diseases and asking how long would it survive or would something survive or in sociological situations, somebody has just come out of jail, prison, and you want to predict how long this guy will remain in society assimilated before recidivism, before the person is put back into prison, these were not things the way you expected that. The initial statistical models to because they were the crown jewel of the subject and yet today, a lot of those things because i'm actively involved in these areas on a lot of these are using attentions and transformers in fact the state of the art methods all use attentions and transformers. In fact, the state-of-the-art methods all use attentions and transformers. Thank you. Gopi, you good? All right, so we'll go to the next question. Can you talk about hallucination aspects of AI, perhaps a few examples? Oh, yes. I mean, something as very basic as this. I'll give you an example. When ChatGPT came out, I suppose it's a game that many mathematicians played, many people with mathematical bent of mind played. And I played too. And then I realized that I was in the company of thousands of others mathematically minded who asked this question of Charity Believe. We were suspicious, can the large language model reason well? So I remember asking almost as soon as it came out, why is seven not a prime number. And it said with great confidence and plausibly, long explanation of what prime numbers are. And then it said 7 is not a prime number because prime numbers are divisible only by themselves and 1, whereas 7 is divisible by 1, by 3, by 5, by 7, and by 9. And it went on. This experiment was performed by a lot of people now chat gpt has smartened up but then without naming the other a few other commercial large language models we expect the same experiment just a week a few weeks ago on another of these very commercially available equivalent of chat gpt and it still had the problem right so in very obvious ways it can mislead you you ask it one more serious problem is not really hallucination but a related thing is you ask it why is it that as you know there is something called the tornado alley in the US and some towns which are just adjacent to each other one town would be repeatedly devastated by the tornadoes year after year after year and another another town nearby would remain unscathed now the reasons for that are deep and they go into the geophysics of things and the atmospheric sciences and the geography of things of the places. On the other hand what the language models did and Chad GPT does and I believe it does it even till today is that it takes all the facts the general facts about the tornado alley, and how tornadoes work, and it comes up with a plausible answer, which to the layman would look right, and would easily convince a layman that they found the answer, they got a very good answer, but actually makes an expert, a physicist, cringe at it. Because it's not, it's a non answer. And that's an example of misleading. And you don't know that you're being misled. That's a huge danger. and that's an example of misleading and you don't know that you're being misled that's a huge danger and then comes another example of just pure hallucination i asked it who is the author of the tale of two cities and confidently it said charles dickens then i said who is the author of the smith the snail of two cities there is no such book called the snail of two cities for the longest time it used to come up with the new name every single time there is no such book as i said a snail of two cities but not once did it acknowledge that such a thing doesn't exist but perhaps because i asked this question so many times chat gpt has now smartened up try asking the question again and now this time it says there is no such book called the snail of two cities i don't know because we all talked about it and it sort of reached and it became part of the reinforcement data with which it was retrained not to answer the question or what happened but now it says that right so hallucination is something that you should assume is a rule now the question question is, how do you avoid it? It's a very active research topic. One way that you can avoid it is there are many ways. For example, you can use RAC. You can, before you ask a question, you dip into a body of current knowledge and then you ask the large language model to substantiate its answer and find supporting evidence in the search results in the documents that it has access to and searched for. Then hallucination can be to a large extent mitigated, not eliminated, but mitigated. You can greatly reduce it. So from a practical work perspective in any one domain to solve a business problem, we have reached a level that if you're careful and if you have competent AI scientists there with you, you can, for all practical purposes, wipe it out and make it unlikely. You can't eliminate it, but you can make it unlikely. You still have to be a little bit on the guard. But for many, many domains, you can make it unlikely. Thank you, Asif. There's one question from Dr. Brown. Although generically AI needs data, doesn't have any issues with human language, like the way that people speak? How can it interpret versus a text book way? Is that a question? Does it have any... I'll read this again. Although generative AI needs data, doesn't have any issues with human language? No, actually, language is data too. It is just natural language data. And it has read vast amounts of data. In fact, this is one of the crowning jewels of the transformer era. Natural language processing was supposed to be a very, very hard problem. We thought it will take us decades to solve it. And then suddenly, it became very solvable and it became solved. Language has structure, it has semantics and it turns out that transformers are actually ideally suited to understanding the semantics of languages. It does extremely well with languages. Thank you. well with languages. Thank you. It reformulates much of data now as language. So today we think of as visual data, like photograph, video, everything, we have reinterpreted it as forms of communication, and therefore a language in their own right. That's how we look at it. Thank you, Asif. I'll take one more question from the chat and then we'll go back to the hands uh with powerful chips and their cost being a huge limitation on AI builds how can lower economic countries avoid being left behind further and further in the future that again is a wonderful question. Thanks for asking that, Huseyra asked that. See guys, technology, it goes broader. I would say technology always creates the technology, technology not in the technology side. The have-nots and the haves. And the haves invariably end up exerting dominant influence on the have-nots and the haves. And the haves invariably end up exerting dominant influence on the have-nots. I mean, the whole history of colonization and most of Asia becoming enslaved or colonized has to do with one thing only, the scientific revolution in Europe. Because human beings being human beings, asymmetry of power leads to its own problems today we live in the world in which the ai needs very expensive chips today one nvidia h100 chip costs thirty to forty thousand dollars in that thirty to forty thousand dollars you can buy one thousand dollars you can buy five chips so you000 you can buy five chips. So you can imagine, five normal chips, computer chips. So today, forget about third world countries, even in US, there are very few companies that have access to that hardware in sufficient quantity. The term used is industrial capture. Not even academia has access to so much computing power as is needed to do research. We are in the world of industrial capture. All the big papers, most of the big papers are coming out of a handful of companies that have plenty of chips. The Googles, the Facebooks, the NVIDIAs the world, have an industrial capture. It has impact. It is a vast concentration of power, unprecedented concentration of power in the hands of the very, very, very, very few. And this event has never happened in history. And it has implications for all of global society. Certainly deep implications for the global global south excellent question thank you um gopal will if you can unmute yourself and ask the question um so now these days we have a lot of uh ai computing power and everything we have a lot of AI computing power and everything, but is there evidence that this AI knowledge is being used negatively like hacking, identity theft and other things? Is there a solution from AI itself to help people come out of these kind of issues that is as old equation as humanity itself we discovered fire we cooked food and we burned each other's houses and while we added we burnt up we burnt our enemies or people we didn't like at the stakes we discovered the wheel We discovered the wheel, and before we knew it, we were out on wars of conquest, conquering other lands. So any technology that comes about, to the extent that human beings are half parts good and half parts mischief, every technology goes through its mischievous use. And often if you ask engineers, they will tell you that the solution of technological problems is with technology. I'm not so convinced, but it certainly is possible to bring in more technology to solve example, to detect deep fakes, you can create technology to detect it. The reality is that then you get even smarter defects today we are facing a genuine crisis there is a practical collapse of reality we don't know what is real and what is fake and so humanity the human mind the human nature doesn't seem to have evolved at the same pace at which technology has evolved and this asymmetric evolution poses existential dangers to humanity i don't know how to answer your question beyond that it's a new movie if anyone want to check it out exactly the same topic the the reason why i'm asking is like this this human fighting and what has been going on and on and on, but this AI is like more like a black swan kind of an event, right? Suddenly, there's a huge power in the hands of a few people. Everybody else is going to be left behind. So it is an easy process if you don't check to steal power, money, everything from common people and go into some specific set of people. So what are safeguards is what I was trying to understand. There are no, there are given human nature, there are no real safeguards. The only safeguards is society formulates laws and governments are formulating laws to protect guardrails. They will succeed at it. But with all guardrails, see have we managed to eradicate wars? We have not. You consider AI a black swan event. May I remind you that these black swan events have been happening through history. When the metal age came and people learned to make knives and swords, it was a practical catastrophe. Instead of fighting with sticks, when we got angry and beating each other up, we began to kill each other with efficiency a scientific revolution brought about its own cruelty today ai means we can have loitering drones which will use the full power of ai to hunt us down and decimate us wherever we are if if somebody doesn't like us so thank you that puts a little chill in the spine but yeah that's the reality I understand that thank you thank you the movie I was referring to is called the creator so it's exactly the same topic the AI creating the bomb um we'll go to the next uh we have a couple of interesting questions here as if uh one uh is there any platform that one can use to detect bias within model during training or evaluation evaluation oh wait now done back down to it definitely there is a vast amount of tooling for bias detection see when you talk about bias let's put it within the legal framework the united states government recognizes a few protected classes age you can't discriminate based on age race gender disability and the associated biases in in processes on systems do that you can detect bias in data you can detect bias in models uh there's a vast amount of tooling in fact support vectors and not to make this an advertisement for mysl that is one of the one of the things i help companies do to detect and mitigate the possibility of bias and put safeguards in place to ensure there is no adverse impact on any of the protected classes impact on any of the protected classes. Thank you. This is another interesting question. Do you know if casino industry is exploring this technology? And if they do, how are they leveraging AI? See, two aspects to that. Is casino industry looking into AI? I bet they are. Everyone is looking into AI. Everybody is trying to figure out how can they create games. See, what is casinos built on? They need to create something that makes you feel you can win, but at the same time, minimize the chances of your winning. AI and generative AI and all of these techniques will do amazing in generating scenarios and games in which it looks so easy, so possible for you to win, but in reality is extraordinarily hard. How many of you have gone, forget casinos, gone to a country fair and have thrown rings at an array of bottles in the hope that if the ring encircles the bottle you'll get a prize only to realize that it's pretty hard all casinos they are based on that perception bias they just need to create a perception bias that you can win it's possible for you to win whereas actually it's not right it's the probabilities game the probability of winning has to be less than your perception and so um are casinos doing it you bet they are doing it are they going to use ai you bet they're going to do use ai but the weakness that all casinos to use ai or not to use ai in my view they are the exploit is the perception bias and frankly it's the same thing with lotteries right is the tax the mathematically illiterate pay for not understanding probabilities thank you uh one last question and we'll probably conclude uh today's session uh who is in driving seat in absence of AI regulations I think you've pretty much answered that but i'll let you take that again yes thank you so this is a very good question like who is watching out for us we expect the government to watch out for us organizations to do that they are actually doing a very commendable job um europe is coming out with the ai act it's practically finalized it categorizes ai systems risk in four categories from low to high. And some high risk systems are outright bad, things that violate privacy are bad. So Europe has done a very good job. California has styled something very close to the EU Act, EU AI Act. The Biden administration created something most wonderful. They created a blueprint for an AI Bill of Rights. the a blueprint for a ai bill of rights bill of rights for whom bill of rights for citizens what are our rights in the presence of ai that companies can use against us or to manipulate us into buying things and so on and so forth so what is our right as citizens they created a beautiful blueprint for that and how should ai be used then the national institute of science standards and technology the nist the standards body of the united states has again done an amazing job in a risk management framework rmf the nest rmf and i invite you to study that it is practically a blueprint of how you should design the AI systems within your enterprise. And again, this is not to get repeated, but this is exactly the kind of guidance I give to companies as they embark on their AI journey, how to create safe, risk-free AI, bias-free AI.