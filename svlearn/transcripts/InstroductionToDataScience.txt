 So this is our first session for the data science workshop and in particular this workshop will focus on machine learning or artificial intelligence as it is variously called. Now what is the distinction between these words data science, machine learning and artificial intelligence? People often use them interchangeably and if you ask the experts, different experts will give you different answers. It's quite amorphous at this moment what we mean by data science but more and more people are gravitating to the to the belief that data science is using is the is the is the study of data in some sense analysis of data for example simple analysis like the sequel queries is also data science data visualizations making plots and graphs is data science as well as machine learning the topic that we will focus on is the core part of data science there is also the term artificial intelligence and one often has this question what is the relationship with machine learning and artificial intelligence? So I'll start with that first. Artificial intelligence is the broad topic which has within it the theoretical aspects, the core of it, which is machine learning. Then it has robotics, for example, self-driven cars and so forth, the drones and so forth. These are robotics, your vacuum cleaner, if you're using a robotic vacuum cleaner, and all those things, that's robotics. And there were other areas like aspect system, export systems and so forth which are there but we will focus primarily on machine learning now while that is a theoretical or academic way of looking at this quite often people use the word machine learning and AI interchangeably and that is considered alright in recent, you might also see people sort of abuse the notation in a colloquial way and say that artificial intelligence is one specific area of machine learning that deals with neural networks, deep neural networks. Actually, that is not the way academics would like to hear it because academics and generally broadly, we consider artificial intelligence to be the big subject of which machine learning is a part. So today I'll start with this question. These words that are there, we talk about artificial intelligence, we talk about machine learning. Artificial is a word that we understand, you know, what artificial means, something man-made. Artificial means artifact, the creation of mankind. Then when we come to machine learning, the machine part we understand, we all know what machines are. Machines are usually, for example, things that do repetitive tasks or machines are again artifacts, they're creations. We create machines. But then there are two words that we should understand. What is intelligence and what is learning when we speak of artificial intelligence and today people have all these movies and books that came that machines will become artificially intelligent they will achieve human intelligence or surpass human intelligence some people even believe that they have surpassed human intelligence. So what do they mean by that? What is intelligence? And then people say that machines can learn far better than us. So what is learning? And let's spend a couple of minutes trying to understand intelligence hand intelligence excuse me and learning so if I were to ask you guys this is an open forum question what is intelligence could somebody give me a definition of Is for example a stone on the road intelligent? As for me intelligence is the ability to understand things and analyze things. How do you know that that stone on the road is not understanding and analyzing quietly? The stone on the road has... It is... Yeah, it is like we have to understand because it has no life, it has no brain. So it cannot analyze that a car is coming on me or somebody will step on me. But we can look at it and we can understand and analyze that whether i will step on it or not that's what i believe that is a good answer would somebody else like to give a different answer applying knowledge and skills sir uh manisa go ahead a little bit louder please uh yes sir apply knowledge and skills apply knowledge and skills see a program that you write when it runs it takes your knowledge you know it is applying the your knowledge that you have encoded into it and doing pretty smart things it can tell you uh what the product of two large numbers is a calculator can do that so would you call a calculator intelligent or would you call Wikipedia intelligent Wikipedia is perhaps the largest repository of human knowledge no it is a source of information or like yeah it is not intelligence intelligence is with all my sources all my source all my informations I use my information at the right time at the right place yes you Yes, you're getting to that. So people have in philosophy and in science have asked, what is intelligence? And it starts with common sense often. In school we compare children, which is a terrible thing to do. We should never compare children. But you often say that this child is intelligent and that child is dull. When we say that, what is it that we mean by that? school when do you call a child not intelligent any guesses there when a child performance it's not up to the mark of the school then we often refer the child as a dull person and compare it with other children so the way you do it is you teach the child some things then you try to see whether the child has learned it or not and if the child has learned it poorly you say that the child is done there is a something to be careful of suppose a child memorizes everything that you have taught and is able to reproduce it is that intelligence no sir it is just a mugging i believe no sir it is memorization isn't it so we keep example has a repository of knowledge today we have created in systems that has that have read just about every book mankind ever produced so when you ask it a question it's able to retrieve dip into that and produce something that looks like the answer to your question. Sidd Chandra Mounazadeh, PhD.: But you don't call that intelligence. So I would say it this way, intelligence and people have asked this question for a long time. What is intelligence? Intelligence seems to be Sidd Chandra Mounazadeh, PhD.: first of all, people in the Western world at least thought that intelligence is unique to human beings that animals are not intelligent but it was even more extreme actually people in the western world believed that all all things except for human beings are machines the the animals the cows etc they just respond to instinct and mechanical behavior, programmed behavior. And only human beings are in a true sense living things. Though they appear to be living but they are not living, but human beings are living. Fortunately in the East we never had such beliefs. We pretty much grew up with the common sense understanding that all things around us all creatures are living organisms are truly living then the question comes are they intelligent now those of you who have ever owned pets know that animals also exhibit a very high degree of intelligence they have emotions they have intelligence and so forth then you ask this question so then how do you quantify intelligence science is science studies things by first quantifying it making some things measurable unless you can measure something it is not yet science so when people in engineering try to create artificial intelligence the very first question that comes is we should be able to quantify intelligence we should be able to quantify learning people initially believed that intelligence is the ability to think, to reason. The trouble is nobody knows what thinking truly is. If you just pause for a moment and ask what is thinking, what is a thought in your mind, can you quantify it, can you touch it, can you measure it? You'll realize that actually we don't have a clue how thoughts arise in our mind. In fact, the entire pursuit of Indian philosophy has been to look at the roots of human thinking and its causations and so forth. But certainly it's not a measurable quantity with instruments. So thinking wouldn't do. The old notions of artificial intelligence was let's create thinking machines Here in Silicon Valley. There was actually a very famous company that tried to create thinking machines. It was Founded by some of the greatest minds in artificial intelligence many many decades ago perhaps before some of you were born many look Nobel laureates came and worked there and there was a high hope that they would create thinking machines, but those efforts all failed. And then people began to doubt that we can create thinking machines ever. So then they took to a less ambitious approach they said all right can we create machines that can learn and that brought up the question what is learning so I would like to illustrate that with an example suppose you take some children that you have in your neighborhood in your family you take them to the countryside or a meadow or some place let us say that in that countryside in that area in the middle there are only two kinds of animals cows and ducks so you point to a child and to a cow and you say well you know my child that is a cow do you see the horns on the head do you see how big it is and do you see the swishy tail and four legs and so forth so it's a cow then you go after a little while you encounter another cow and now you tell to that child that this too is a cow because it has horns and it has a certain shape a certain size and legs and tail and then you encounter a duck the fact it has feathers and beak and webbed feet and so forth and you explain that to a child that these are ducks after a little while suppose you ask the child, how would you know, like how would you test the child, whether the child has learned the concept of a cow or a duck? Can it recognize a cow or a duck? And the child may be able to identify. Let's say that you showed the child three cows and four ducks. And you go back and ask the child, look at this. What is this? Is it a cow or a duck? One of two things can happen. Either the child can make mistakes in giving you the answer or the child may correctly identify the cow or the duck. Now, suppose the child correctly identifies, would it make you feel that the child has learned what a cow is and what a duck is you know the essence or the the if i may use the word the concept of a cow or the cowness of a cow if you grasp then you can recognize cows anywhere likewise for ducks so if your child is making mistakes not able to correctly identify the cow in the duck you can be pretty sure the child hasn't learned yet isn't it on the other hand if your child does answer those questions what can you conclude now do you conclude that your child now has learned about cows or ducks would you like to make a guess? Anyone? Yes, at least my child can recognize by seeing that this is cow and this is duck. Yes, you would think so. There's a flaw in that reasoning, one subtle flaw. If you go back to the same cows and ducks that you showed the child and you say, what is it? Some children have photographic memories and they can just do a recall. They have a perfect recall. They will just recall that cow or that duck. They'll recognize it and they will remember that you told them that it is a cow or it's a duck so they may give you the perfect answers without actually understanding what a cow or a duck is they're just recalling it from memory do you see that so how would you truly test whether a child has learned about thousand ducks you truly test whether a child has learned about cows and ducks show them more like cows will have different color right so that's right you show it instances of cows and ducks that the child has not seen now each cow is slightly different from other cows so when the child is able to recognize cows that she has never seen correctly, now you say that the child has grasped the concept of a cow. And so the crucial word that you use is the child is able to generalize from the examples that you showed to other instances that the child has not seen. The ability to generalize comes when you can get a sense or a concept of the thing, the cow, the duck, isn't it? Because if you don't get that, you won't be able to generalize from that do you see the relationship between generalization and learning yes yeah so learning is the able ability Abhi Jain, MA, RDN, FANDUEL GARDNER, Ability to generalize from instances and Abhi Jain, MA, RDN, FANDUEL GARDNER, Not learning is not generalizing from instances. And if you go back into your own life, you know, when you went through schools and colleges, you all must have gone through some subjects that you didn't like Abhi Jain, MA, RDN, FANDUEL GARDNER, What did you do when you didn't want to learn about a subject you would pick up in India if I remember right there used to be a tradition of getting the so-called question bank or important questions instead of studying the book you would just memorize the answers to important questions because professors certain the teachers they tend to repeat the same question year after. And so you go to the exam and you successfully pass because at least some of the questions in the exam were the ones that are from what you memorized And so you pass that subject and you forget all about it. That is a classic example of not learning of not learning because you went there of course not to learn but to beat the system you didn't want to learn that subject and you move past it i hope you all can identify with an experience like that at some place so that is the distinction memorization is not learning learning is the ability to generalize, to form concepts in your mind. So that raises a question. That is all right, but how do you quantify learning? And if you go back to the example of a child to whom we are showing cows and ducks, what happens is in the beginning, as you show new instances of cows and ducks, let us say that the child has not understood anything. show it a cow or a duck it will the child will she will just guess what it is now guesses could be they have a certain error rate isn't it you shoot an animal and it could get it wrong it will get it let's say half the time it will get the cows it will it she will confuse a cow to be a duck and you know by looking at the number of mistakes the child is making as a parent as a teacher you would know that the child hasn't learnt but progressively as you keep explaining to the child about cows and ducks, gradually that recognition forms, that concept of a cow and duck forms, and the child now is able to or begins to generalize from the instances to new instances. So then what will you observe when the child begins to understand what a cow is or what a duck is you show the child an instance of a new cow it is likely that the child will make less mistakes isn't it the child may not be perfect yet she may still make some mistakes maybe if you show a cow at a great distance it will look very small and the child will say well you know it's small so it's a duck there may still be mistakes but if if the number of mistakes the child is making significantly drops it would be evidence of learning isn't it in a very quantity in a very quantitative in a very measurable way you would say that the child has learned something would you agree yes sir that is it and that is the technical definition of learning learning is reducing the errors that you make at a given task for the child the task was recognizing cows and ducks in the beginning the child had a certain error rate child was just guessing and getting a lot of mistakes in there but at the same task after some time as the child learns the error rate goes down and therefore you can tell turn the argument around and say wherever you see a reduction in error a gradual decrease of error you are seeing evidence of learning that brings us an interesting question can machines learn we we spoke about a child it's a living organism you ascribe intelligence to human children but what about machines do machines learn do animals learn you can those of you who have pets know that animals learn. You teach a dog to fetch the ball for you to do things. People have taught the dogs to do incredible things these days. Their dogs, their cats, their horses and so on and so world. Now what about machines? Can machines learn? If you stick to the definition that learning is reduction in error at a given task, it turns out that machines can learn and that's the subject of machine learning. It is when you don't program the machine, don't write code and you say, do this, do that, because that is not learning, that is machine following your imperative commands, your commands, your instructions. But on the other hand, when you don't tell the machine, do this, do that, but you give it a framework to learn from data, and it learns in a specific way, you see a reduction in errors at a given task. Then you say that the machine is learning or the machine has learned, and therefore the field of machine learning. Now we associate intelligence today in a very practical term as learning. Artificial intelligence is exhibited when machines learn they improve at a task on their own gradually as you give give it more experience more data it improves upon the task and today these machines have learned incredible amounts of things that beat us as chess that beat us at just about every game long long ago they started beating us at calculation but calculation you don't need learning. You don't need Jay Shah Rukhbamgali- Intelligence. It's a mechanical process but cognition or ability to reason to think these machines are doing with incredible ability recognize handwriting far better than human beings can. They can recognize voice, they can recognize songs. You just play a little bit of the song and it will immediately recognize what song it is, what the lyrics are and so forth. It is able to translate from one language to many languages in practically real time. So as I am speaking to you at this moment, I could train a machine and your network to immediately be giving live broadcast of this speech in Hindi, in Tamil, in Kannada and so forth. This is not a pipe dream. This is actually happening today. Unfortunately, it's not very practical yet to do it in real time. The amount of computing resources you need are far more than what you find on your cell phones, on your smartphones. But the day is near when the smartphones will become powerful enough computationally that you can run those algorithms on these little devices also but they can certainly be run on big machines with great success today if we use machines to do things that human beings can't they help find terrorists they find signals that are really deep hidden and we can't human beings have a great difficulty finding it today for example we can look at an image of the human eye the octodon when you go to a specialist they often take pictures of your eyes I don't know if in India they do that or not, but in the US they tend to take these circular pictures, the octodons. And it turns out that for the longest time people just looked into it and they thought this is just telling us whether a person has eye problems or not. Is there any damage to the little parts in the eye for example the circulatory blood vessels and so forth the retina and so forth is there any damage to it and that's what they were being used for recently not so far long ago people asked the neural network what can you find in these octodomes to the the great surprise, to everybody's great surprise, actually, the artificial intelligence was able to detect diabetes, heart disease, and a whole variety of disease that people may have just by looking at the optodome. Now, it is not something anybody programmed into the machine to learn. It just came out and found it that is learning that is the power of artificial intelligence today and you see that everywhere they seem to be able to drive cars almost it turns out that human driving is one of the most complicated activities human beings do and it's a grand challenge to make the cars be self-driven especially in the chaotic streets that human beings have they seem to be driving fairly well 99 plus percent of the time when you are on the highway and in u.s as many of you know you'll on YouTube you'll find videos of people here driving on the highway and they are sleeping in the car while the car is driving them to work and when passing when another car passes it by it happens that the driver is completely asleep. They have caught that on tape or they caught that on the cameras and they have posted it on YouTube. It's still a dangerous thing because the machine is not perfect. And when it makes on the rare occasions where it makes mistakes, it is a fairly catastrophic mistake. People die. So it's not a perfect technology. It shouldn't be done, but still it is quite impressive that the machines have come this close to it. So we are going to learn about the subject of machine learning. This was an introduction. This broad field of machine learning has three areas that we talk about. One is predictive modeling. The word people traditionally used is supervised learning. In supervised learning, you give it a few examples and you say learn from it. For example, this cows and ducks problem, when a machine learns to recognize cows and ducks, then when you give it an instance, in the jargon of machine learning, you say that the machine is predicting whether this animal is a cow or duck in a more practical sense. It's trying to recognize whether it's a cow or duck. That is an example of supervised learning because that could be possible only because you gave it instances of data, instances which were labeled where you told that this thing that you're looking at is a cow, this thing that you're looking at is a cow this thing that you're looking at is a duck right and so having looked at enough number of examples it continuously learns and then it learns to recognize so that is called predictive modeling or supervised learning now another example of supervised learning would be let us say that you are an entrepreneur and you want to open an ice cream shop. When you try to open an ice cream shop, let's say that you do it next to the beach or next to a river, whatever you want to think, someplace where children come and play. Now, you want to determine how much ice cream will sell in a given day because ice creams are perishable goods. You can't hold onto ice cream for too long. Ideally, you would want to go to the wholesaler and buy just enough ice cream in bulk quantity as you can sell in a given day in your shop on the beach, let us say. Now the thing is, if you buy too much ice cream, it will go to waste. If you buy too little ice cream, you may lose business because children will come, ask you for ice cream, and you won't have it with you because you are children will come ask you for ice cream and you won't have it with you because you are out of it so you want to predict or guess or estimate the amount of ice cream you'll sell on a given day fairly accurately but the amount of ice cream that you sell and on a given day it depends on multiple factors it may depend on the temperature if it is too hot or too cold children won't come to play parents won't bring them there if it is a working day less children come to play because parents are busy working if it is a weekend or holiday more children come in play right so there are multiple factors that determines how much ice cream you you will you will be able to sell on a given day it depends on whether your competitor is also there selling ice creams or not right and things like that so there are many many factors that are involved but at the end of it what you're predicting is how much a quantity an amount when you're trying to predict an amount based on certain factors let's say the temperature the day of the week and so forth this process too is predictive modeling is supervised learning the only way you can do that is if you give the machine enough examples that on this day the temperature was this much it was a tuesday and we sold this much ice cream right somebody has to give a lot of examples to the machine and then the machine internally finds some pattern in the data some some way some function if you can if you imagine a multivariate function such that if you give it the inputs it will produce an output which is a pretty good estimate of the amount of ice cream it says. That estimate doesn't have to be perfect, it just has to be a good estimate of the amount of ice cream and that would be solved. So it is therefore supervised learning now this kind of supervised learning is for a whole set of historic reasons called regression the word regression is actually unfortunate regress is the opposite of progress so the word has negative connotation. In software engineering, when people see regression happening in their software, it usually means that the software has gone from a good state to a much worse state. More bugs have been introduced and so forth. But in machine learning, for historic reasons, actually predictive modeling, when you're predicting a number it is regression when you're predicting a type it's a cow or duck it is classification the words are classification so i'll write it down in a little bit on the blackboard and it will become then you can remember it these are simple terms and sometimes you don't want to do any of these what you want to do for example is notice clusters so what would be an example of clustering suppose if you think of example of clustering see if you go over a balloon I don't know if you have or maybe just over through an airplane if you fly over a city have you noticed that you see an interesting pattern most of the big malls and shopping areas they are in the commercial district. And most of the residential areas, they're far out. They form their own clusters, right? They're grouped together. So when machine recognizes such clusters, it notices that in the data, it is not just random, but there is a pattern to it, right? Certain things go together that is that too is learning because it is quite useful finding patterns and data is a form of learning and that form of learning is unsupervised usually you don't have to say this is a house this is a shopping mall or things like that you just let the you leave the data there and you ask the computer do you see any pattern in this data so that's unsupervised learning it is also called pattern recognition you recognize patterns in the data so that's another form of machine learning there is a third form of machine learning called reinforcement learning reinforcement learning is through carrot and stick so what you do is you don't tell the machine anything you ask it to solve a problem do a task for example you ask the machine to play let's say checkers or chess with you every time the machine loses you penalize the machine there is a penalty so it's a carrot and stick sort of a appraise there's a penalty associated with losing and there is a reward. So it's a carrot and stick sort of appraise. There's a penalty associated with losing and there is a reward associated with winning. And that's all it is. And the machine gradually figures out what moves or what steps cause it to lose and what steps cause it to win. And it becomes extraordinarily smart about it so to give you a sense of what machine learning can do when it comes to reinforcement I would like to give you an example I'll show you a little video it's a three four minute video I want you guys to watch. The reason I mention this reinforcement learning video is because in this particular workshop, we won't get time for reinforcement learning. It's a very compacted timeframe. If you're going to do about eight sessions, we won't be able to reach reinforcement learning. Yet it is fascinating enough that I thought I'll give you guys a taste in the first lecture and leave it at that so wait a minute for me to pull up that video and show it to you this video is this is part of actually a curriculum. It's not a video that I created. It's created by some people who were some researchers and the English is not an Indian English. It's not even American English. It's by a researcher who is not a native speaker of English, just as we are not native speakers of English. A two-minute paper let me let me just find this and for that I'm going to share my screen for a moment So, and let me see if I have shared the sound. Okay, I've shared the sound now. So this is a six minute paper. We need not watch all of it, but watch a part of it. Some interesting emergent behaviors. This is two minute papers with Carol. Are you guys able to hear the sound? Yes. Yes. Yes. Very recent paper. This is two minute Papers with Károly Zsolnai-Fehér. In this project, OpenAI built a hide-and-seek game for their AI agents to play. While we look at the exact rules here, I will note that the goal of the project was to pit two AI teams against each other and hopefully see some interesting emergent behaviors. And boy, did they do some crazy stuff. The coolest part is that the two teams compete against each other, and whenever one team discovers a new strategy, the other one has to adapt. Kind of like an arms race situation, and it also resembles generative adversarial networks a little. And the results are magnificent, amusing, weird. You'll see in a moment. These agents learn from previous experiences, and to the surprise of no one, for the first few million rounds, we start out with pandemonium. Everyone just running around aimlessly. Without proper strategy and semi-random movements, the seekers are favored and hence win the majority of the games. Nothing to see here. Then, over time, the hiders learned to lock out the seekers by blocking the doors off with these boxes, and started winning consistently. I think the coolest part about this is that the map was deliberately designed by the OpenAI scientists in a way that the hiders can only succeed through collaboration. They cannot win alone, and hence, they are forced to learn to work together. Which they did quite well. But then, something happened. Did you notice this pointy, doorstop shaped object? Are you thinking what I'm thinking? Well, probably, and not only that, but about 10 million rounds later, the AI also discovered that it can be pushed near a wall and be used as a ramp, and, ta-da, got em! The seeker started winning more again. So, the ball is now back on the court of the hiders. Can you defend this? If so, how? Well, these resourceful little critters learned that since there is a little time at the start of the game when the seekers are frozen, apparently during this time they cannot see them, so why not just sneak out, steal the ramp, and lock it away from them? Absolutely incredible. Look at those happy eyes as they are carrying that ramp. And you think it all ends here? No, no, no. Not even close. It gets weirder. Much weirder. When playing a different map, a seeker has noticed that it can use a ramp to climb on the top of a box, and this happens. Do you think couchsurfing is cool? Give me a break. This is boxsurfing. And the scientists were quite surprised by this move, as this was one of the first cases where the seeker AI seems to have broken the game. What happens here is that the physics system is coded in a way that they are able to move around by exerting force on themselves, but there is no additional check whether they are on the floor or not, because who in their right mind would think about that? As a result, something that shouldn't ever happen, does happen here. And we are still not done yet, this paper just keeps on giving. A few hundred million rounds later, the hiders learned to separate all the ramps from the boxes. Dear Fellow Scholars, this is proper box surfing defense. Then lock down the remaining tools, and build a shelter. Note how well rehearsed and executed this strategy is. There is not a second of time left until the seekers take off. I also love this cheeky move where they set up the shelter right next to the seekers, and I almost feel like they are saying, yeah, see this here? There is not a single thing you can do about it. In a few isolated cases, other interesting behaviors also emerged, for instance, the hiders learned to exploit the physics system and just chucked the ramp away. After that, the seekers go, what? What just happened? But don't despair, and at this point, I would also recommend that you hold on to your papers, because there was also a crazy case where a seeker also learned to abuse a similar physics issue and launch itself exactly onto the top of the hiders. Man, what a paper. This system can be extended and modded for many other tasks too, so expect to see more of these fun experiments in the future. We get to do this for a living, and we are even being paid for this. I can't believe it. In this series, my mission is to Alright guys, I hope you had fun watching that, and that should give you some sense of what artificial intelligence today can do it is it is exceeding everyone's expectation no one expected that artificial intelligence would be so successful to such an extent today people are saying that that that we are going through perhaps the biggest revolution in our lifetime. Most of you are old enough to have seen the internet come about. That was about 25 years ago when it began to get mainstream around the world. And websites began to emerge and we felt that it would change the world much of the world came online gradually there were social discussions a lot of data was generated then we went through the world of big data because there was so much of data being produced by all these systems and the big data movement was fairly transformative. For example, Google can search vast quantities of data. There are all of these things we can do. We were finding cures for diseases by navigating through massive amounts of data that we couldn't think possible. And then along the way came artificial intelligence. Artificial intelligence is actually an older subject. Machine learning is old. If you go back and look at the mythologies in every culture, at some point or the other, you will find that people, man has tried to to become god we notice that people assume that we are the creations of god and there is a bit of a god complex or god envy that that is there in all humanity so we want to create beings of our own and imbue it with intelligence. The Greek mythologies you find reference to that. For example, the Hebrew mythology of the Jews for example had a concept of Golem. You could make a doll and a human figure and you could blow life into it and it could do your bidding. If you think of the story of Aladdin and his magic lamp and a jinn comes out and does whatever you want, that magic lamp or the creation of something like that is reminiscent of that, you know? It's human desire to create, to build powerful entities that exhibit intelligence. So in every culture you see this desire to create intelligence. Though arguably the first machine ever created or dreamt about but not successfully implemented was a person named Charles Babbage. Charles Babbage tried to create a machine in the world where before there were semiconductors or vacuum tubes. So he was thinking in terms of gears of all things. He managed to create a machine, but his dream was not to make a computer. His dream was to build artificial intelligence. And the first programming was actually done by a lady, a child of Lord Byron the poet, the British poet, Lovelace, Ada Lovelace, arguably the first programmer in the world, or certainly the first lady programmer in the world, they all were dreaming of artificial intelligence. When Alan Turing created the first actual computer that did computations in the process of breaking the Enigma code. Some of you may have seen this movie, The Imitation Games, and the whole history of the World War II and how this encryption machines are broken. Alan Turing's main dream was to create artificial intelligence. but for the longest time artificial intelligence had a checkered history. It was coming and going. People thought there would be great progress and there would come a winter in which people would give up and lose hope in artificial intelligence or machine learning. And then a few years later, another breakthrough would come and the subject would move forward. And again, it would get stuck. but people always thought that it has very limited use cases it's a very academic field that it will never become practical and then suddenly in the 21st century almost like magic all the pieces came together it turns out that artificial intelligence was waiting for two things to happen first is the computers were not strong enough or not powerful enough and it is only in the 21st century that we have the kind of computing resources needed to have deep machine learning algorithms succeed complicated machine learning algorithms succeed, complicated machine learning algorithms succeed. The other thing is this complicated, this very powerful machine learning algorithms need a tremendous amount of data. And there simply wasn't enough data. If you go back and look at your old statistics books, the kinds of data you encounter, 100 lines of data, 100 rows of data, 1,000 rows of data, and so forth. And people were trying to do something out of it. Today, we live in a world in which if you ask for a billion rows of data, you absolutely don't even think about it. It is there in many situations. So you can make these machines learn from vast quantities of data. And if you guys want a reference, this could be a good homework for this time. Read about something called GPT-2. Actually, let me share my screen. Are you guys seeing something on my screen? You are seeing something on my screen right so I will start writing down a few things that we are talking as we talk and we talked about regression regression is a box into which you feed in data so let's say that you feed in some data it is a way that finds some relationship of this input you call this the input imagine that this is a box or algorithm somehow it produces a number a real number real number is like anything from minus infinity to plus infinity. Something like 1.32 is a number, is a decimal number. Think of it as a decimal number. That is it. Given an input, it ascribes or it finds an output for it which is a number the other thing is classification you give it some input features let's say that you give it x x here could be a size of an animal the the size of whether it has a tail or not the the size of whether it has a tail or not beak or not right and so forth etc etc this is your x and it is able to tell cow or duck so it is able to identify based on input what is it that it is able to identify based on input, what is it that it is seeing. And when you can do that, that also is some sort of a function, but it classifies. Its job is to classify the input as belonging to, say, cow or duck now with these two examples let's make it more practical in reality you don't worry too much about cows and ducks but it is more like given this data is this person diabetic or not? Or more specifically, is this person healthy? I have a doubt in this. Yes, please go ahead. Go ahead. I can't hear you anymore. You said you had doubt. I can't hear you anymore you said you had doubt I'm having difficulty hearing are you guys able to hear the question also no actually she's offline oh hello sir can you hear me now yes I can hear you now sorry sir so actually my is, has you told the input can be anything, right? So like for example, it can be even the tail of an animal or whatever it is. The output will be the only in that case of numbers. No, no, no, no. I did not say that. I said there are two different things. In the case of regression, one form of machine learning is called regression. When it is regression, the output is always a number. When it is classification, then the output is a type, is an identification. You say it's a cow or a duck. So this machine, you give it some information, it will tell, it will answer. It will either say cow or it will say duck. Are we together? It is not producing a number. It is telling you a type, the type of animal that you're looking at. Is that clear? Yes, sir. I got it now. Thank you. That is it. So classification is entirely different from regression. And so let's make this much more real. usually it's cows and decks is not what you do in practical life quite often the question would be like this given these medical parameters about a person is this person likely to get diabetes in the next five years or not? Or does this person have diabetes or not? Does this person have lung cancer or not based on this X-ray? And the surprising thing is today we are able to discern problems, Dr. Jay Shah Ramanathanamraba, he or she is able to discern problems, medical problems by looking at x-ray much better than Dr. Jay Shah Ramanathanamraba, the average radiologist. Dr. Jay Shah Ramanathanamraba, The doctors who study x-rays and images heart, it's very hard to see subtle problems, you know, clogging and so forth. But it turns out that artificial intelligence can give you an answer. Yes, no. Is there clogging? Yes, no. Things like that. Is there a medical problem with this? Is there heart disease? Yes, no. So it distinguishes this patient has heart disease. This patient does not have heart disease. So that is the power of artificial intelligence. The third form that we talked about was clustering. So for example, if you have data like this and the data is broken up into situations like this. broken up into situations like this just say the data in some a plane x y plane is given to you like this what a machine will do is immediately look at this data and without being told it will go and it will say hey these are the clusters and what you just did is clusters this guy and this guy are two independent clusters it's a it's pattern recognition so this clustering is a form of pattern recognition now just to summarize what we learned, I said that machine learning is like this. First machine learning, when we talk about machine learning, we say this, learning is by this given a task let's say T right and a measure a measure of errors e you say a machine has learned a machine or human a person has learned has learned if and task p with better performance i.e error decreases it decreases isn't it the total error decreases so this is a very simple and scientific definition anything anywhere you look, if you notice that at a given task, gradually the errors decrease. When it is being done, you see an exhibition of intelligence. So a calculator, however clever it is at doing come multiplications never get smarter if it makes mistakes in a certain kind of arithmetic because it can't handle such forms of calculations that will remain a flaw of the calculator isn't it but human beings learn and machine learning algorithms learn. So what you do, how does it differ from programming? In programming, so this is a concept that is important, programming versus learning. See, when you write a lot of code, lots of code is needed as instructions for machines to follow. That is programming. And as as you know much of computer science has been about programming these very dumb machines and when you program a machine the machine never learns it just follows the instruction isn't it on the other hand if you on the other hand, if you tell the machine how to learn from data, but you give it no instruction, no imperative thing, do this, do this, do this. The only thing is a very high level statement, go learn from this data. And this is how you can learn from the data. You show it how to learn from the data, then the subject is machine learning. So when you have machine learning as a subject, people often ask, don't I need a computer science degree or an engineering degree to enter data science or machine learning? The answer, surprisingly, is you don't. If you do computer science, you'll learn programming. You'll become very good at programming and you'll learn all about machines. But that, it turns out, it helps you a little bit with machine learning or data science, but it doesn't help you a lot. Machine learning is a new subject. Data science is a completely new subject and traditionally very little of this was taught in the computer science departments. Now the situation is changing at least in the US they're teaching computer science departments are focusing a lot on machine learning but traditionally it wasn't. Computer science department focused on various aspects of computer science and software engineering and programming but machine learning was actually almost a different subject sitting on the side right but today we are doing machine learning now those of you who have computer science background or have a lot of programming background it might be it isn't that it's a completely lost cause and you're starting a new subject there are still advantages because we will do some basic programming in data science you don't need uh the the sort of traditional programming that people do which requires a lot of code you instead do very simple programming but you do a lot of code. You instead do very simple programming, but you do a lot of thinking with data. The subject is more about reasoning and thinking with data than it is about programming. The programming here is very short, but still your programming background will help you get started. Now, for those of you who don't have background in machine in data science. This is actually good news. So long as you remember your high school stuff. Vaidhyanathan Ramamurthy, The subject is very easy to learn. And in fact, I'm hoping that as in the next eight weeks I'm able to teach you enough that you feel confident and you're able to make progress on it on your own so the way we'll run this workshop is we will have one week given to understanding concepts another week to doing labs in it and those labs are simple labs but quickly you'll develop competence or ability to do lots of practical problems right and it turns out that in the industry when you go and do a job that is all you need if you're going to do research then you need more knowledge like for example the subject of artificial intelligence is deep and machine learning is deep it can take you a long time to master it I have been doing this now for decades I still feel that I'm just learning there is so much more to learn and so much research happens almost every single day it's tough to tough to actually stay completely on top of it. Every day I'm surprised with some student of mine bringing to my attention some very exciting work that has been done, really important work that has gotten done and that I entirely missed or I wasn't aware of. And I get to learn a lot from my students because of that. So it's a very exciting field, it's rapidly growing, you guys are at a very good stage to enter the field because it's a young field at this moment and it is always good to enter a young field and grow with the field as the field increases and takes over the world. How important is this field? How important is this field? People who know this field well agree that this is perhaps the most profound revolution that we are going through. People say the industrial revolution or the mechanical engineering revolution, then came electrical engineering, and then came electronics and all of that, computers and so forth. All of these are phases of the industrial revolutions in some sense. But with the coming in of artificial intelligence, it makes all those things look small. It is a transformative change way bigger than anything that you will have encountered in your lifetime. People who study revolutions in human culture deeply, human civilizations, are saying that this is even more profound than the agricultural revolution that led to the formation of civilizations. There are people who say that its importance may be comparable to the discovery of fire or the invention of the wheel in human history it is that profound it's going to transform life as we know it completely your children will not even be able to imagine what your life is like by the time they come. So this revolution is happening very, very fast. And knowledge is expanding very fast. To give you a metric, more breakthroughs are happening in artificial intelligence in the last two years than in the entire history of human knowledge. Just think about it for a moment, that more research in AI has been done in the last two years than ever since people have been dreaming of creating artificial intelligence for thousands of years. And it is continuing every time you think, wow, this is so fast and so fascinating. The next year is even more and even faster pace of development. So it is, it's very, very exciting times to get into. Now, today's session was a very general session in in future we won't have sessions sessions this general or this broad we will have more specific topics we will do code we will talk about it but i thought i'll leave you today with the with the understanding that machine learning and ai at the end of it it comes down to one simple thing you need a task to form the context you need some way to measure the error and then you need to teach the machine some way to make make less mistakes and then when it does make less mistakes it builds a model it creates a concept in its mind and you say that the machine has learned I will end with one question how do you know that the machine has learned correctly that it has fine found the right model it's a question that you often ask when you're doing a math example you need to have a correct solution. So when a machine makes a prediction about something, how do you know that the machine is making good predictions, correct predictions? Would somebody like to take a guess at that? When the code is correct, sir? Trial and error method? Trial and error, possibly. But, you know, the space of trial and error is so vast that the universe might die before you exhaust all the cases. So, when the coding is correct? Coding, no, because you don't program the machine at all. You just ask the machine to learn from data. That's the whole point that this is not programming this is learning this that depends on the results sir it depends on the results yes so what happens is when it makes prediction it will it will never make perfect predictions and the reason it won't make perfect predictions is there there will always be noise in the data so imagine that you are measuring temperature five different thermometers will measure five close to each other but different values for the same for the temperature on a given day even if you measure it exactly the same place and the same time, five instruments will have five different readings. So now if you say that, which one is correct? You don't know, there's no answer to that. You said that there are five versions of the truth, right? So there are errors in all measurement. Not only that, when you build a model based on certain factors, you don't have all information. Machine learning is the ability to build models to conceptualize in the absence of complete information so for example if you ask this question that suppose you throw a stone in the air and then where will it fall now you need to know the velocity you need to know the angle at which it was thrown and so on and so forth so many things you know but there are things that you don't know for example at that moment how strong is the breeze so when the data was gathered how strong was the breeze because the breeze is going to drift the stone a little bit from its trajectory so it will fall it it would have fallen at some place without the breeze and with the breeze it has now shifted its position and so you don't know that and because you don't even measure that all you measured is the angle at which it was thrown and the speed at which it was thrown and you use only two factors to build your model it will never make perfect predictions because there are things your model doesn't know but that affects the results and that will always be true so you build the best model that you can and so in this field there is a famous statement that goes to a great scientist named Box. His name was quite literally Box. He said, the landmark statement, he said that all models are wrong, but some are useful. What it means is you'll never get a correct model. There is no definition of correct in science. But there is a definition of usefulness in science. And this is broader. It's not just machine learning. See, when you learn science in schools or college, it seems as though we know everything. We are told that Newton's law of gravitation is true right and you do little experiments in which you drop stones or you swing a pendulum and things like that and then they all seem to agree with Newton's laws of gravitation right and so so on and so forth and so you take it as the correct law but actually as you go and do research you realize that there is no such thing as a correct law Newton's law actually happens to be wrong it is superseded by Einstein's law of gravitation the general theory of relativity because space-time contractions and space-time deformations affect affect the attraction that one object has for another which is gravity gravity and so now you say well okay now we know that Newton is wrong but Einstein's equation at the correct equation that is how most people talk but actually that's not how a serious scientist would say a serious scientist would say Einstein's a theory of relativity gives you much better predictions than Newton's theory of gravity gives for a large number of situations, it new to Einstein's theory of relativity makes predictions that so far have never been contradicted never been shown to be wrong, but it doesn't mean that it is correct. Therefore, it just means that it is a good effective theory works. It is effective. Those of you who are, if there's anybody here who's a physicist, would probably know that we know for sure actually that the Einstein's theory of relativity cannot be correct. It completely disagrees with quantum physics. And quantum physics itself cannot be correct because it disagrees with Einstein's theory of relativity. We know that both these theories, they're correct in their own way, but both of them cannot be correct. And so quite likely both of them are wrong, but we haven't figured out what the right theory of nature is. So a flavor of that applies to machine learning and things like that. Machine learning, data science is science. It's like any other science and in science you don't ask for the correct answer you ask for effective answers answers that are effective in making good predictions theories that make good predictions so the models are theories sometimes these are models about how things work and you know that the model is effective by observing that it makes pretty good predictions and that is something to bear in mind that there is no end to making better and better models but the question is where do you stop where you stop making better models depends upon practical realities. You're able to tell that a patient is likely to have a heart disease or not by looking at the optoderm or the image of the eye of a patient and yes your error rate is one in a million person. One in a million person you in a million person you get wrong would you consider your model wrong it is wrong but is it a useful model it is a tremendously useful model because it far exceeds what human beings could do or it far exceeds what previous models could do and so it is a great practical use and of efficacy. You can use it for real things. And that is something to bear in mind whenever we do machine learning. We are not in the pursuit of the right answer or the truth. In fact, in science, you don't use the word truth with a capital T because a thing can be disproved but theories can never be proved it's very interesting in mathematics a theorem can be proved which is derived from certain axioms in nature you can build an effective model a theory now one single experiment can disprove a theory. Now one single experiment can disprove a theory, but a million experiments producing results that agrees with the theory does not prove a theory. Nothing is proven ever in science to be correct. Things are only disproved in science and that is an important thing to bear in mind as we keep doing our machine learning and all of these things in fact the only place that I hear people talk about truth is when people get tend to get religious you know in religions and philosophy they have truth with a capital T but outside those domains which are in my view very non-scientific domains you never speak of correct answers or truth with a capital t but you ask for what is practical what is effective and you know what moves the needle of knowledge forward. So that's that. So all right, guys, today I will stop here. I did not introduce the machinery of machine learning. I wanted to stop right here. But I would like to recommend you a textbook for a moment. This textbook is a little bit academic. It's a little heavy reading. Don't get that textbook. It's freely available. Those of you who like to buy paper books, you can order a paper copy of the book, but it is actually legally and freely available on the internet, which is why I'll recommend this also. It is an excellent textbook. So I'm going to end today with that textbook today so are you guys looking at my screen yes yes so there is a textbook called islr if you do that islr you'll see the picture and you will get this you'll see the picture and you will get this page let me increase the size so that you can see it are you guys able to see this the cover of this textbook so this textbook is freely available it's written by uh two professors and two graduate students the professors are hasty and tipshirani hast The professors are Hesti and Tepshirani. Hesti and Tepshirani happened to be in a college, in a university near my house, close by. The university's name is Stanford University. Some of you may know about Stanford. It's a Californian university here in Silicon Valley. It's a pretty good university, one of the best actually, and so these two are very well-known professors of this field. It's a very well-written book and these two, when this book was written, these two were the graduate students but they're now, I believe both of them are professors in their independent, in their own right or assistant professors Daniel a written actually for those of you who are physicists perhaps if you're any Daniel a written happens to be the daughter of Edward Witten Edward Witten was considered is considered in the field of theoretical physics of physics as the brightest living mind at this moment so so anyway this book is very good it's unlike most books you know which are written quickly and have a lot of errors it's not like that it's a very well written book you can download the PDF free and when you get the PDF you when you start reading it you will realize that there is a it's very well written but it's also something that can occasionally feel a little scary so I So just do this. Today, just go and read chapter one and try to just glance through chapter two. Read chapter two, but it is OK if you don't understand half the things. Because as we make progress with this workshop, these things will become easy to understand. I've taken generations of students through this textbook, and at the end of it, they all find it very easy. So you will also find it very easy. So please get this book and try to read chapter one and chapter two. All right, guys, so with that, I will stop the session and i will take questions