 All right, this is going to happen. What it means is that the video on YouTube will be available right after the class. So topic for today. Now, we are moving on to a new topic, which is classifier. Let's do that. So one question that came up is, can we use something other than OneNote? If you guys come up with a good software for Windows or for Mac, let me know. I have half a mind of switching over, for Mac, let me know. I have half a mind of switching over, switching away from Windows to Mac. Unfortunately, on Linux, the writing board doesn't work. So a small announcement. So classifiers, what are classifiers? We realize that regression, just to compare, regression was a box, if you think of it it as that in which the input vector went in the input vector went in which is made up of x1 x2 let us say xn or xp p predictors went in and what came out a y hat came out y belonged to which class what type what was the type of y a number it belonged to it is a real number right in the simplest form we thought of y as a scalar scalar this is the most general case but actually i mean so this is the most general case, but actually, I mean, so this is the most common case commonly, but actually it is not necessarily that in general y hat can belong to a k-dimensional for example if you're trying to predict wind speed wind wind velocity remember wind velocity could be which direction also matters you're trying to predict that not just a speed with the velocity this would be an example of a regression model that is taking in inputs and predicting a vector right or one more traditional way of saying it is that you are predicting not one value one column one feature but multiple features at the same time right you're predicting the speed along X direction speed along by direction speed along Z direction when you're doing that this is. A vector right or multi multi feature prediction or whatever the lot of traditional words to use, but will stay geometric and just call it predicting a vector now this is regression there is another kind of things you can predict which are categoricals categorical categorical is to tell suppose i say that in this basket of fruits, the fruits could be an apple. I don't know, how does apple look? Something like this. And orange. It could be, I don't know, pineapple. Hopefully something approximating a pineapple. So suppose you have apple, orange, pineapple, banana, let's say. Banana, or something like that. There are four fruits in a basket. And your job is to look at the weight, the size, the everything and predict which fruit it is. So then when you're predicting or identifying what it is, this is not an example of regression, is it? You can't say that apple is for any reason more than orange, right? These are just different things. They are not comparable. And hence the phrase that things are apples and oranges. In other words, they're not comparable. They're just different things. You don't compare them, right? So what you do is you call these categories, right? You say that the Y had the prediction belongs to a categorical variable. Categorical is usually represented as a categorical variable because it will have to output. orange, pineapple, apple, and banana. It could be either one of those things, but you have to give your target value one of these four possible things. Are we together? Right? If you give the value to be now within this category there are certain nuances the categorical typically cannot be infinitely many right so you cannot say that the rain that for example uh rainbow you can consider it as seven colors or you can consider it as an infinite gradation of colors. And you say one of these, because if you do that, now it is not categorical. The set of possibilities must be finite. You must be looking at a finite set of possibilities. If it is infinite, it is not categorical, right? The other aspect is it cannot be an empty set because it would lose meaning. Like you cannot say none of the above is the only possibility. These are very common sense statements. And so I'm just setting the bounds of what a categorical variable is. A categorical variable belongs to a finite set, has a value that belongs to a finite set. That finite set is predefined usually or can be inferred from the data. You can just do a distinct on the data and quite often infer the unique values that make up the categorical, the set of categorical values. Common examples of categorical are days of the week, the animals in a zoo. These are categorical. Seasons, there are four seasons. So those would be categorical. But a very specific color amongst infinitely many colors is more a real valued function, a real valued vector, you can say. It belongs to, is a point in a RGB space. Therefore, it is not categorical. That's exactly categorical. So we will start by posing this as a, with a very, very simple problem. We'll do that. So again, let me just write it in a more formal way. Classifier, we'll do that so again let me just write it in a more formal formal way classifier classifies a box in which you again give it the x vector made up of p features xp x2 all the way to p predictors go in and what comes out is y hat belonging to the category to the g categorical right so i will once again just to summarize write the same words apple pineapple apple right orange and banana banana kyle are we recording kyle are we recording yes sir okay excellent so this is it now one more thing the order order of the set does not matter there is no order no order what am i writing there is no in this set at least no presumed order the classifier doesn't presume an order though an order may exist and you may choose to ignore it and there are there are things like ordinal predictions etc we won't go into it as we are starting out with simple situation just assume that each element of the set is distinct as unrelated to other elements of the set it's a simplifying assumption right not always true later on we'll realize that there are interrelationships in the categorical values and that brings up the lovely lovely topic very interesting topics later on of categorical embeddings and so on and so forth, we won't go there. But today we'll start by saying these values don't, they don't relate to each other. Apple is an apple and orange is an orange, right? And that's that. So this is, this is what a classifier is. Now, when you have a prediction machine, let's think of the example of children, cows, and ducks. This was the example we used to learn about classifiers. The way we frame the problem is, let us say that you took some children to a meadow. And in the meadow you could find cows and you could find ducks children don't know cows and ducks so you start train teaching the child the children start learning you say well look at this little thing this feathery thing with webbed feet and beak it's a duck now look at that big animal out there with horns on its head, a big body and four legs and a swishy tail. That's a cow, right? That's the way you would, as a parent or as a teacher, you would explain to the children the distinction between the cow and the duck. Then that is the process of teaching by showing it instances. But learning is the ability to generalize from the instances how would you know that the child has learned you would know that the child has learned if the child can from there look at an instance it has never seen and be able to correctly identify that big animal with the swishy tail and horn as a cow, isn't it? On the other hand, can look at that little feathery creature and say that must be a duck, right? So it has generalized from the instances that it has been exposed to and the properties that it has been made to observe of those instances, isn't it? The features of those objects it has observed it has learned from that the question then comes what is the empirical evidence of learning the empirical evidence of learning is that you have to see so let's see how would you know that you can ask this child you may believe that the child has learned but the child may have just memorized may have a perfect memory perfect recall and may be able to just regurgitate every single cow or duck it has seen and we give give the correct answer you have to show it examples it has not seen in other words in real terms what does that map do in our test in our data set we must split it between the training data set and some data set you hide under the pillow namely the test data set right so in the case of this medal you must deliberately keep a corner of the meadow with some cows and ducks which where you don't take the child while the child is learning if you want to test whether the child has learned then you take the child to that corner of the meadow and of those animals that it hasn't seen asked to tell whether it's a cow or a duck so what will the child do gradually as it sees the in the beginning the child will just randomly guess as we all guess as children right we think we know it and we guess and and our formation of idea of what is a cow or what is a duck isn't quite there yet you know the the concept of a cow the calmness isn't quite correct right likewise the concept of a duck or his duckiness is not quite correct but as it forms better we make less mistakes right the child will make less mistakes so the error rate matters now how would you quantify error remember in the case would you quantify error? Remember in the case of sum squared error, it was in the case of regression, it was easy. You looked at the residual, the difference between the prediction and the reality, right? So if you're predicting, for example, what were we taking the example of, the amount of ice cream that you would sell on the beach you would predict you would sell five gallons but if you sold only three two is the gap isn't it you you were off by two so that is a very intuitive definition of error when it comes to uh the regression and of course you strengthen it you realize that errors can be positive and negative yes you take its absolute value or you take it square, then you add it up and so on and so forth. In the case of classification, what can you do? So let's take this cows and ducks. So the target variable y hat belongs to cow, duck, a set of only two elements. It can be either a cow or a duck so what can happen let us say that the ground truth is you show it lots of cows and lots of ducks and the child makes a prediction this is the reality reality and let us say that it makes a prediction of cow or duck right i put hat on it to signify that it's a prediction so these are predictions and by the way some people write this matrix that in a transposed way they'll make predictions in the row and this it doesn't matter now suppose you showed the child 100 animals. Let us say that in the meadow, for the sake of argument, there were 50 cows and 50 ducks. And so of the cows, let us say 45 cows were cows are easy to get, I suppose, or maybe 40 cows were correctly identified as cows, and 10 cows were mistaken as ducks. Likewise, when it comes to ducks, it turns out that of the 50 ducks, 20 ducks were identified as cows and 30 ducks were correctly identified as ducks, right? Do you see this, guys? This is it. So what you're looking at is the first thing you look at is this is the measure of errors. We can see this is the first thing you look at is this is the measure of errors we can see this is the empirical data the empirical data on accuracy on correctness let's call it correctness on correctness let's call it correctness model i wouldn't use empirical empirical is observe the data the on the correctness of the model at this particular moment well empirical would be correct okay so how many answers are correct here can you look at it and tell me how many answers are correct 70 we realize that this is the the principal diagonal correct accurate is that accurate gives you the accuracy right principle diagonal is correct when you take the correct answer and you divide it by the total accuracy is equal to the correct over total. So what is the total here? 100. So it is 70 over 100. So that is 70%. So we know that our child has learned its accuracy is 70%. Isn't it? 70% accurate. That is a measure of learning. Now, there are other measures of learning. There are things like precision and recall. And there are things like we will get to that. I won't. We will develop the theory slowly over successive lectures because this is one of the things we get easily confused with in fact after all these years i still wobble my head sometimes and i know it i get it right most of the time and still get don't get it right but we will develop it in small stages and this is't. Now, let me bring up something else. Suppose your job was to detect cows. So one of the cases you take as positive case, let cow be the positive case. You can arbitrarily assign a positive case to any one of the classes. a positive case to any one of the classes. Traditionally, and I'll write this word, traditionally you call the, traditionally call the smaller class as positive. What do i mean by that a smaller class is positive so suppose you're trying you're not predicting cows and ducks but you're looking at a stones and you're telling whether the stone is just a stone or it has gold in it. So imagine that in San Francisco, this entire area was founded on a search for gold, gold digging. And the tradition of this place is people would just sit next to rivers and little water bodies and pick up stones and then hope that there was a gold nugget in there. So let's go back to the history of this place. You pick up a stone and you see, is it just a stone or does it have gold in it? Right, or something like that, gold nugget, conjuring up a simple situation. So what would be the majority situation? Most of the time it would be stone. And only rarely would it be a nugget of gold. And so it makes logical sense to associate the positive to the nugget of gold, because it's relatively rare. So that is a common convention. Now positive in classifier or in machine learning does not necessarily always conjure up positive psychological connotations. An example of that is suppose you are looking at mammograms. In a mammogram, most mammograms will come out to be pretty unremarkable. There won't be anything worth observing, right? But there will be occasionally something. There may be a presence of a tumor, either a benign or a malignant tumor, the mammogram may show. Those presence would be, let's just say the presence of a tumor doesn't matter benign or not um right a nodule so uh that would be one in let's say a thousand mammograms right or one in ten thousand so that is the more rare class. That would be the positive. In machine learning, that would be considered the positive class, even though, of course, psychologically, it couldn't be more negative, the findings. Obviously you do this. It is very, very bad news when a doctor says that she has found something positive. She has positive findings in your labs, in your x-rays or your blood test results. That is usually bad news, right? Because it means that there's something off. The best news you can get is everything is negative or it's there's nothing remarkable about your blood test or your lab work right so um go with positive coming in or covid you don't want to be positive right you want to fail the test that reminds me of a very interesting bit of news. One of our former presidents, I'll leave you to guess who, was trying to either run for elections or something like that. And so his medical officer, his doctor, supposedly came up with a new press release, which the president as a presidential candidate said in u.s that i just got my bill of health from my doctor and he says that everything is very positive and it is filled with remark it is very remarkable and positive and you can imagine what a tough position it put the doctor in he couldn't disagree with his patient his illustrious presidential patient at the same time his medical community would be laughing at him for calling somebody in good health as having a medical record which is remarkable and positive so remarkable and positive so yeah for all you know it was yes you know how to say who it would be uh say that again you don't have to say who would who would that be yes yes that is the difference yeah no yeah very right. We all know who that president is. But anyway, so I guess presidential, all presidential candidates to some extent have to be a bit of megalomaniacs. They have to have an emperor complex to go through the grueling polling and election process. I would never do that. No sane person would actually want to go through that process. But anyway, that's a different conversation. So that is about the positive and the negative cases. And so we'll stick with accuracy. Now look at this. If cow is the positive case, some cows were marked as ducks. So what does it mean? Some cows were marked as ducks. So what does it mean? Some cows were missed, isn't it? But this child missed some cows, missed identifying some cows and instead identified it as a duck. So these would be miss. Are we together? In common language, you would say this is a miss. If it was COVID, these are the patients who genuinely had COVID, but you missed detecting COVID. So there's a technical word for it. It is called false negative. False negative. So a miss is a simpler word. And what about what about these guys? This other element in the off diagonal. It was not a cow. But you predicted it as a cow. Isn't it? You predicted it as a it was actually a duck but you predicted it as a cow. So a negative case was marked as positive. So this is a case of a false positive. This is false positive, right? And so you notice that this thing together, I'll use some other color, this color, this off diagonal elements, what do they contain? Anything not in the principal diagonal, all other elements, they are errors. They are errors, isn't it? They are mistakes. Would you agree? This is the errors, right? And so error rate, error is equal to 10 plus 20, isn't it? Would you agree? There are 30 errors in this prediction right and so the error rate 30 percent because they we started out with 100 data set so this is the basic let's start with this and we'll we'll we'll develop a very interesting notions there's an area under roc curve roc curve and things like that precision recall type one type two and all of these things we'll talk about but i want to use simple language now for the first session so this is what a classifier is now what is a good classifier there are many classifiers just as in regression i mentioned that linear regression even with regularization with polynomials and with these nonlinear least squares and all of these, we have picked up but a few sort of pebbles, metaphorically speaking, from the seashore of regression. There are gazillions of regression algorithms. We have just picked up a few to get started with. More and more keep getting discovered, keep coming. There are many variations, many things, but the ones that we learned are the foundational ones and heavily used. In the same strain, today we will learn about only one classifier which is called logistic regression are we together logistic regression now when people teach this word has a whole bag of problems associated with it first of all the name is a misnomer. It is called logistic regression. So if you look at the name, what does it look like? An algorithm that does what? Regression. But actually it's not regression. It is actually, this is a classifier. This is the first thing you need to remember. So by the way, this is a very nervous era. If you look at the people in the data science community who do interviews, almost everybody has a joke of meeting a candidate who in the list of regressors said linear regression, logistic regression, and so on and so forth. So that would not really be a very well. And then they of course point out that logistic regression is a classifier. Well, yes or no, it is a classifier. We'll start about it. But there is actually a generalized way of looking at regression, which I will teach you at some point. I'll do an extra session for you. It's called generalized linear regression, which uses a link function. Should you start thinking about that, then there is a way, then the situation gets a little bit more, let's say, interesting. We'll talk about that later. Go ahead. Premjit, are you asking a question? No. Okay. So this is logistic regression. That is the topic for today. It's a long topic. We're going to cover it in the next two, three hours. It's a long theory class, and it's a very long lab class. And today I'll really expect you to finish your homeworks if you haven't done that, guys. So just, but anyway, I'll talk about that at lunch. We'll have a very brief lunch today. So we won start here we will get here slowly but let us craft a problem we won't use cows and ducks we will use a sim a little bit more complicated problem or amiable to this so i'll create a toy problem and i the biologist and the farmers would laugh at it so i'm taking a lot of liberties with reality here but go along with it the point is to create a toy problem that will help us understand suppose we are trying to distinguish between blueberries and cherries? So let's say that our axes are weight and size, two axes. So X1 is weight and X2 is size, right? Size is size. And now let us project the blueberry points. You would agree that blueberries are small. They would be somewhere like this. And I will deliberately oversimplify the situation. Remember, this is a toy example, motivating example. And then you have strawberries. Oh, no, did I say cherries? Cherries. So let's say cherries. This is a cherry. And then of course some blueberries can be a little bit bigger. And there's some region of overlap. And I ask you, how would you tell arbitrary point X, is it a blueberry or a strawberry? So let me ask this question. Let's look at point A. There is a fruit whose weight and volume and size puts it here. What would you guess? Is it a blueberry or is it a strawberry? Sorry, a cherry. A you would is it a blueberry or is it a strawberry oh sorry a cherry a you would definitely call a blueberry right what about b Cherry. It is definitely a cherry. Right. These two are very clear. What about C? C. So C is likely a blueberry. And what about B? Likely cherry. Now, why is it that you are sure of a but but not of c a and b are sure of and c and d are not sure of randik because they're close to the kind of outlier right on the basis of weight and the size no they're not outliers outliers are away from all data points yeah see the moment you look at this data and you i ask you to guess the points what your mind begins to do is it begins to draw imaginary something like this It is beginning to conceive of is this correct, right? And it basically says in your mind you begin to draw a line like this and you begin to say this side is blueberry, to say this side is blueberry, right? Let me use the right colors here. You begin to say that in this line, this side is blueberry. And on this side, it is cherry. Isn't it? That's how your mind is deciding, isn't it, when I ask you that? So because A and C fall on the blue side of that, the lower side of this line, you call it a blueberry. The things that fall on the other side of it, you call it a cherry. But you also notice that the further away you are from the decision, by the way, this thing has a name, it is called the decision boundary. And this is a very important term, decision boundary. In fact, it is the crucial term in classifiers, decision boundary. Decision boundary. Would you agree that if I have to create a classifier that tells whether a point is a blueberry or a cherry, the problem is equivalent to finding the decision boundary? Because if you find the decision boundary, then you can tell on one side is blueberries another side is cherries do you agree with that point guys yes isn't it the problem is equivalent so to create a successful classifier is the same as to discover geometrically the decision boundary right and so that is a very crucial observation. Remember the pursuit of a classifier is the pursuit of a decision boundary. In the feature space, in which space? The feature space, data space. Right? So let us find that decision boundary. Now the question is, what is this decision boundary? Some observations associated with decision boundary the further we are we are from the decision boundary boundary the the more sure or unsure we are sure the more sure we are conversely the closer we are to a decision boundary the less sure we are isn't it why are we less sure it could be both blueberry and the cherry right because data is not so clear-cut there's always noise in the data so there are some blueberries here and there are some strawberries all over the place here isn't it so all we know is that if we are sitting on if we are sitting on on the decision boundary itself then what happens what what would you say it is is it a blueberry or a cherry either way you could go equally either way isn't it so the way you would say it probabilistically is that the probability of it being a blueberry probability of a blueberry of that point x, let's say this is x, right, of the point x of blueberry. So here's the language, the mathematical language. Given point, if we are sitting on the decision boundary at x, right, you say that blueberry, probability of blueberry given at the point x, given x, is at this moment 0.5 half right likewise the probability at that point of cherry cherry given x is also 0.5 50 50 would you agree with that on the other hand what would you say now let's develop our language a little bit more carefully much of this math language is very elementary to get probability of blueberry at let me just look at the probability of blueberry huh because cherry would be the converse of it, one minus blueberry. Would you agree? If the probability of something being a blueberry is 70%, probability of it being strawberry is 25%. So this is it. So's go back to point A and see what it was. Look at point A. At point A, what would you say? Probability that it's a blueberry. Almost sure, right? So let us say that it is approximately equal to one. 100% probability. one right hundred percent probability right at the same time the probability of its being probability of its being a blueberry blueberry given point b is closer to zero isn't it This is the way we write the language. So now let us go this. We will only look at the probability of a blueberry because probability of a cherry is this. What do you observe? What is the mental intuition you have? The distance from that decision boundary, isn't it? Do we agree? Distance from the decision boundary. So now I'm going to use this tiny bit of space i seem to be going circular in my diagram let let me take a point a point this was a point x let me take actually let me not call that point x let me call that point just say P. And in my here also, I will change my name because I'm going to use X for something else, guys. I hope I'm not confusing you by changing the name of this point. Probability is P and this is Q. That will be terrible. Let me call it q probability at the point q do we agree we are still on the same page now i'm going to take an arbitrary point x from the origin let us say i take this point this right this point given by the vector x remember every point can be represented by a vector x isn't it this point and i ask you intuitively what is it you would you would say let me do one thing let me find the distance of this point from the decision boundary. This is your distance. Distance of x. This is distance from where? The origin? No. It is the distance from the decision boundary. And you can tell. Now I'm going to say a statement which is tell me true. Dist x greater than greater than zero means probability of blueberry actually let me change the language i will look at the probability of instead the cherry because that that will align with the language cherry is approximately one isn't it if the distance is much greater than zero means you are really far from the decision boundary in the positive direction it is this if the distance is less than less than zero means you're far inside like point a this point right if you're on the lower side of it distance is negative right because you take one distance to be positive on the upper side downwards you take it to be negative distance so here you would say that the probability of cherry is probability of a cherry is what close to zero zero it's close to zero right so then now let's carry this intuition forward let me summarize it because if you get this intuition all we have to do is use a little bit of simple mathematics to develop some very elegant formulations. Go ahead, Dantek. Oh, we'll learn that. At this moment, we are purely at the level of intuition, right? In fact, that is what we are going to do with the next time. But so far, you're clear with the intuition, isn't it? What we're saying is we need a decision boundary. It's very intuitive. Geometrically, you can look at it and say, classifiers are nothing but machines that discover the decision boundary. Once you have the decision boundary, the only question is how far you are from it. By the way, this is for the linear situation, but also for nonlinear situation, it will be true, but in a more complicated way. But okay, distance from the decision boundary matters. The further you are, the more sure you are. The closer you are, the more unsure you are. And if the distance is zero, oh gosh, you're not sure at all, 50-50, right? It's a toss of a coin at that moment. So that is the intuition we'll carry. Now we'll simplify this notation mathematicians see what we are looking at is probability of a cherry at a point x isn't it so we will say this is what we are looking for we will simplify the notation to to to be just x we'll assume cherry are we together we assume we are talking of cherries right we'll just assume so we'll use this the reason is that see here's the thing more formally we should use the notation on the left but more commonly people use the notation on the right in fact your textbook uses the notation on the right so we'll just use that simpler notation but remember that that we always talking about probability of cherry. Probability of blueberry is just one minus probability of cherry. So now let's think about it in terms of one graph in our mind. This is zero. This is D. D is distance from the decision boundary right so you realize that when you are really far away uh let me take this when you are really far away let me say that this value is zero. This value is, this is the probability, probability of a point dx. dx is here. Probability x. What is the maximum probability something can have? One. So this is one. This is a one value. What is the lowest probability something can have zero okay so at very large values of d very large values of d what is the probability that it will have that it's a cherry pretty yeah pretty high right so we can say that at inf at it will be like you know very very high be like you know very very high here close to one right at very negative values of the d means in the other direction in the lower direction if you go very far from the if you go back to this you go very far down compared to the decision boundary far down from the decision boundary what is the probability that it's a cherry you know it's zero it is zero so we are here now what happens as you come closer to the decision boundary at this at the distance zero what is the value here at half when you are literally sitting when dx is zero what is the probability that it is a cherry 0.5 0.5 right this is this is a 0.5 so we know we know three points the answer to now what happens let's think about it this probability you know rises up isn it? And you know that, so first thing is, is there any distance from the decision boundary where we will not know the answer? No, there'll always be a probability, isn't it? That speaks to the fact that this probability is a continuous function. Is there any reason to believe when you look at this thing, that the probability as you go along, as you go in the perpendicular direction to the decision boundary, like along this direction, as you go, any reason that the probability will make a very discrete jump, like from 25% to like 45% suddenly? Any reason to believe that? No, no no reason right probability is a slow increasing function right it's a slowly increasing function the way you say it is that probabilities rise smoothly slowly the word for that is probability more mathematically you say probability px is a differentiable function it's a smooth function px we will say now we say say based on our intuition visual intuition that visual intuition that px is is a continuous smooth continuous continuous function it's a smooth continuous curve now what is the smooth continuous curve which doesn't have pointy edges that you can draw which goes through or which agrees to the two things these are called the upper asymptotes upper the word i'm just throwing in the words upper as some third third and this is the lower asymptote means the value such if you go too far down the value saturates at zero isn't it saturation points and so what is the one curve that you can draw can i go like this is this okay now as the distance increases we and there is one more quality that i need to address the closer i come to the decision boundary, the more the probability, right? If I'm going from negative to positive direction, right? You would agree that the closer I keep coming, probability will increase. There's no reason for probability to take a dip. Would you agree or not? Isn't it? That brings us to the last quality of this function. So we cannot have this. This is not possible. so i'll erase this not this it has to be yes the word is it has to be a monotonically increasing function a curve that is mono to me curly increasing so what is the monotonically increasing function that you can draw? Well, my, this hardly looks monotonic in my just imagine that if I was a better artist, I would have drawn something like, let's see. Does this look better guys? I just make this fatter. Yes, and lovely color. Yes, Go ahead. Anil, go ahead. Yes, indeed. So all such functions which have, so now, so you just jumped the gun a little bit. So guys, look at this. Logically, can you convince yourself that there is no other possibility? The shape of the function must look like this isn't it there is a cl these functions so what does this function looks like there is an intuition it turns out it it looks like a like a stretched s isn't it if you take an S and you keep stretching it out. Does it begin to look like this? Right? And that is why this stressed S are called sigmoid, sigmoid. Now, contrary to popular belief, there are actually many functions, many mathematical functions that have the shape, many, many functions. All such functions are called sigmoid. So I give you a homework homework go discover as many sigmoids as you can by searching on the web and so forth i will tell you one sigmoid a couple of them we'll talk about today the one of them is of course the logistic function because the name of the logistic regression but there are many right there at least at least half a dozen are well known but there are many right so hold that thought in your mind we'll take again a five minute break and then we'll go ahead and take some of the parameters yes we can and we'll come to that. We'll come to that. In other words, not only that, you can translate it, and you can flatten it, right? So there are two parameters that you have. Actually, three parameters, because you can, even instead of rising up to one, it could have been rising up to two in a different situation. Probability can, of course, only go to one, right? So what is the amplitude? How, where is the center where is it hitting 0.5 mark or mid mark and is it very steep steeply rising or not that's why this particular thing is almost like what is often called a three parameter model and things like that so there's there is a lot going on here we'll talk about that. Let's take a five-minute break. As if you could pause the YouTube live streaming as well. One second, guys. Then I need a bio break. I'm going to keep going back to videos.