 You can share your screen now. Okay. Oh, I didn't realize I wasn't sharing my screen. Okay, let me share my screen now. So hello again everybody uh this is so this is now with me after we've set up you can actually install a lot of extensions you can set set put some settings get some some ready you can already you can even install the segment anything models and have them ready already over here so so we'll test we'll test some of what's happening and yeah so for starters we have our base our base model and the refiners but you can also get fine-tuned models the refiners but you can also get fine-tuned models so as you can see here you can pick from the fine-tuned models uh i pick dream shaper excel because that's the that's the top checkpoint right now for like photorealism or but you could check you can pick between a lot of different checkpoints it's's really difficult to say which checkpoint is good for which kinds of images, because it's just so vast and fine tuning doesn't necessarily guarantee that you can't generate something totally different from what the initial checkpoint was. But DreamShaper, ideally, the idea was to have something that's based on something that looks photorealistic. And this is DreamShaper XL. So this is already a fine tuning of stable diffusion XL. So we have stable diffusion XL already here, as you can see. But I'm using a fine tuned model. So let's do the same thing, elephant you can see. But I'm using a fine-tuned model. Let's do the same thing, elephant hugging the moon. Let's see how well it does without any negative prompts. Oh, I should have made it 1024 by 1024. Okay. So, yeah. So, this is the closest it can do to hugging, as you can see. For limps, at least, well, the other task is probably hidden, but at least it's not deformed. And it's looking pretty good. SDXL is actually 1024 by 1024 by default. So we can actually afford to go a little higher. This one actually downscaled it, I think. Or you can see it created some additional borders. But this is when you see my laptop starting to struggle a little bit. But yeah. Oh, it's still missing one task. Okay. so maybe not fully maybe not that perfect yet oh no there it is perfect it has the other task so sdxl works well but let's try something a little bit more interesting let's try uh say male warrior say male warrior riding a horse. And then let's do photorealistic. So you could see that this model is able to produce so that it started off with the base, and then you can see halfway there it started to refine. So it's not not so bad, right? Let's make it a little more interesting. Let's let's try one extension. So Roop is a face swap extension. So let's say we'll put in Marilyn Monroe's face. So pretty recognizable. And this time, let's try to see if, oh, it's gonna generate a random warrior again, because I put it through a random seed, so yeah. But you can see here, it's a male warrior first, and the base model, then it gets sent to the refiner model. And, oh, I didn't turn, sorry. Had to turn, I think I have to turn something on. Let's control that. Or was it this one? Oh, I didn't enable it that's why okay how silly but so let's say we generated this image okay now let me get uh let me get its seed number so that will generate the same image again so everything good feet are complete everything and it's a male male warrior i clicked on enable enable the face swap and then generate so it's going to generate since it's the same seed it's going to generate it's going to go down the same pathway with the exception of that last that last part the pathway with the exception of that last part, the extension. So you can see it's just slightly different, a little bit zoomed. But after the refiner model, so the refiner model is, OK, now it's probably being sent to the extension. There we go. See, we saw the phase change. There's Marilyn Monroe. Oops. Yeah. There we go. See, we saw the face change. There's Marilyn Monroe. Oops. Yeah. So just like that. So easy now to swap faces. So easy to swap colors and all that. Now, let's see something. So this one, this one was, this one's one of those interesting systems, but let's try something just a little bit even more interesting. I hope this works here. So we have a toy robot, toy robots in a line like this. Credit to whoever owns this picture. It's over there now let's use something something a little bit more recent which is let's do the same thing again was it this one oh no here segment anything so this is the model by meta you already have the model for the segment anything model and it says oh let me just add the robot again sorry so these are the robots now using grounding Dino this is a zero shot object detection model it a small, so it's less than a gigabyte. It's a knowledge distilled version. So essentially you could put some, it's almost like a semantic search, but it does bounding box and segment, does a bounding box on understanding semantically what you're looking for. So if I say toy robots, that's what I wanted. And I say, okay, show me a preview of what you're actually able to capture. You can see, so with just the text toy robots, it's able to already just create boxes of the toy robots. Now to make it more interesting okay let's say i wanted to create a mask on all these robots so we can see uh box zero one two three four five all right they're all highlighted already okay let's create a mask uh and then this will give you three ways to, three outputs and how it masks. So this one's pretty clear cut. Oh, that's not good. That's the way I say. I do have this working. It's not working here. Let's try the text image. Maybe it's supposed to be able to create a mask for, create a mask just covering exactly just the robots and then from there uh so from here you can then cover the oh it's really not working what happened oh out of memory what see this is why you need this this is why you need a more powerful uh hard drive uh hardware but it's gonna create a mask that just specifically covers just the robots and nothing else because it's utilizing the segment anything. And then from there, you can send it to like an image to image where this is masked already like this. You can inpaint essentially. Essentially what you can do is, essentially what you can do is it's such a it's going to do is it's already going to start um masking all all these parts oops so it's just masking the whole robot whatever something like that and then it's gonna and then you can generate something like a green toy soldier and then it will start converting all those robots into yeah a green toy soldier so so just like that you're able to you're able to play with the latent space uh and inject a lot of things so the reason why i ran out of memory here is because uh i had run a bounding box object detection model and then i ran at the same time it ran also a masking model and then it ran the stable diffusion uh for for it for for replacing this particular guy with the prompt. So all those things, I ran out of memory with 16 gigs of VRAM. So this works with the 24 gigs of VRAM. So we shouldn't have a problem with this. But yeah, and there are so much more stuff we could do with this like like i said uh from this whole uh from the whole uh system there is there's even a oh moves to move stuff but you can even do a video uh video neural style transfer so you have a dancing you have like a a you know someone dancing you can convert it into into like a monkey dancing so yeah uh stable diffusion has gotten so far advanced and we have so many there's so many knobs to choose from to tweak and all this. And there are so many guides out there on how to maximize. One simple example is we even have this, it's called an open post editor. So if you wanted to, let's say create, let's say we had Marilyn Monroe already, but let's say you want someone crossing their legs like this or bent like this and then waving at you like that. And then, okay, I like this one, send it to the Lady in a red dress waving hello. Oh, nope, sorry. I had, oh yeah, it's there. Okay, sorry, my bad. So it had sent already the coordinates. So I just added the text, lady in a red dress waving Hello. And now it's going to generate following keeping an amount of memory again. I think I think I just have to flush something and just you know, I think I'm running too many things at the same time. But yeah, let me cancel this out. Let me turn off this one. Let me turn off also root. I think all of these are just running all together. I'll put here no VRAP there. So lady in a red dress waving hello. And then it already has. No, it's I think it's. GPS. Yeah, just kill that and restart. see 16. yeah just uh kill that and restart that would be okay sure oh i think i think it's because i'm opening all of these are switched on so let me just turn all of those off so just just just the open post and the text prompt let's's see, this should work. Still out of point. Okay, I have to restart. So it's just launching everything again. There. This should work now. So text to image. Open post. Let's just do it again send to text to image so this is enabled enabled for no vram that's 512 by 512. Make it 1012. Okay, so it doesn't downscale. Yeah, that's for Excel here to have it in. Okay, good, good, good catch. Maybe it's running a downsizing model. Oh, there you go. It's looking good. Yes. Thank you, Praveen. I think that was it. So here you can see that it's... So yeah. Oh, it's... But it's the wrong hand. it's the wrong hand i think it flipped it over but but that's ideally ideally there are so many things you could do with this you could do uh or even oh it even says my controller is my part oh okay here it is you can do this again So there are just so many things you could do to the latent space right before. So yeah, it's able to, it's able to get it, but it's just mirrored mirror image. Can you run the refiner? The refiner? Uh, what are you? The refiner. What are you? Oh, sorry. Here. This is what I forgot. Open post. Let me just run open post. I think this will get it done. If not, I must be doing something wrong. Okay, but but yeah, that's that's essentially it. That's so there's no worry. SDXL is is highly other it is finally folding the legs and then hands up. Okay, I think you just had to to switch to switch first and then switch back again and I switched I put it to low vram because I'm using a laptop but yeah looks pretty good it's able to it's able to figure out that that yeah uh I think I think it didn't realize the left leg should be over the right leg, so it just put it in the back. But that's the closest step. At least you see the hand waving. Not really waving. Amazing. Yeah, there's so many other things you can really do with this. You can change the depth, the field of the depth. You can even make fancy QR codes. So there's like an extension where it's a QR code, but you'll use stable diffusion to convert the QR code into like a work of art, like a building with windows. And it will function as a QR code, but it looks like an artwork. So many different things. It will function as a QR code, but it looks like an artwork. So many different things. And there's really a lot, like just this whole control net extension, there's already a whole guide on this. This group is face swap segment, and we think can do a lot. So there's really a lot. So being able to have enough VRAM to really run everything. And yeah, if you're using SDXL, it's probably a lot more powerful as well. So if you want to use a lot of those functions, you might want to use something a little older like SD1.5. But yeah, this is just what we have currently out there. And just sharing it with everybody now if you want to know more or you want to look for checkpoints like this how like one question you might have is where do they get all of these checkpoints there is a an actual website like a google search for this it's called civet.ai and yeah they're even now like they're running promos because sdxl came out now they want people to actually train lauras and you might win they might win a 1490 for training a laura but here here it is you could do it you could do you could just search okay i want all my sdxls and i just want a laura and each of this is a work of art isn't it yes yes each of this is already a laura and uh yeah because because art art knows no boundaries so i had put it already to censor all the mature content so we could see that Yeah, so that we can pick something. Let's let's try. We could try a Laura. Laura, let's pick something. Something that's simple enough, but that's easy to pick up. This one oil painting. So let's get this oil painting one and then it it's under a gigabyte but it shouldn't take too long so is there any uh plug-in for a painting have you seen anything oh no you don't need what do you mean a painting you don't know for like a water painting or a watercolor painting oil painting yeah yeah there should be there should be more than enough everybody has also moved to this so so we want stable diffusion you go under bottles and then there's Laura and then you can just see so you have anime and all these kinds of things and then you save it so this won't take too long for me uh oops downloaded it again but this this so this this will show you okay this is a laura for stable diffusion excel it gives you some examples like this is some of the sample outputs this is probably their best work from from this laura and then uh yeah so so pretty good looks like an oil painting yeah it's pretty good actually right and then and then there's some descriptions and then right below they'll say this is this is other people's submissions so if you don't believe what they were saying you can look at other people's submissions and yeah they all look like really good oil paintings you might be able to sell some so yeah if we can scale up uh there are like scaling up also right website so we can scale up and probably a print on canvas yes yes that's that's definitely something we can do we can we can decorate support vectors with printouts of canvas from stable diffusion hey try to make a good a big something with the words support vectors on it in your station i think stable diffusion it's i don't know if it's still a challenge but just getting words or or text text for a logo used to be a big problem is it okay so i don't know if i hope if that had changed now what we can do is we can get so we can use the main the like we can use your the image already of the word support vectors and then we'll see how how let's say let's apply a lower to the to the support let's try that I tried on the support vectors logo from our support okay sure sure uh so here uh if you go back to that image uh they use the comfy UI right oh it works also so a lot of people have started wanting to move to comfy UI, but I don't have it. I cannot. I cannot copy the logo, you disabled the right click. Really? I did. I didn't know that. Yeah. Okay. Let me see. I must be having no, no, let me let me see if I could get it from it is facebook doing it okay i think it's there we go nice but i can't copy it no just right click and save that's it oh the right click is save. That's it. Oh, the right clicks the same. Oh, there it is. Yeah. Support vectors. And I'll see if I have a better logo. Sure. I said, but this should be good for now. Yeah, we can start with this and And okay, so yeah, the lower has been downloaded. Now let's test it on our on our model. Okay, so oil painting. So let's say oil painting. No, no, no, no, we're we're doing support factors so let's start with the image already of support vectors okay that'll work that that will initialize so we'll do now we want to introduce a laura so this one shows okay show the additional stuff you want to add to this network so this one shows okay show the additional stuff you want to add to this network textual inversion just adding embeddings hypernet versus i think it's like a bit of elora and then so here so let's look for the uh where did it go let me refresh refresh. It's not here. I'm looking for the oil painting. Is the Excel offset? Can't seem to find it. Maybe I have to restart my stable diffusion. But that should be in the right folder. You know what will be useful? If I give you a picture of the elephant in the moon and that can become an oil painting. Oh, yes. That's if we could do that. That would make more sense. Let me give you that. Let me go to that and graphics okay yeah it's here so you should be able to see that there's already been thing so image to image laura what is you just can't find yeah You just can't find. Yeah. Yeah, let me give you the other one that will be better. I think extra networks show all the extra networks. OK. Oh, I think it had something. Patrick, I gave you the elephant and moon. OK. Next image. patrick i gave you the elephant and moon okay i was part of a photography group there was one person who used to do a lot of these compositions based on photographs that he would take all right and we exchanged this yes Those were the days when people used to share photographs like you know, I once took a picture of Tahoe, it became very popular. People use that then, then you know, it is a smaller community. I asked this artist, can I use your image? He said, sure. Can't see. It should be in my tablets. No, it's not there. I can't see the, I don't know where they're putting the disc. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know where they're putting the disk. Okay, let's see. Open in browser. And I'll just save it from here. Okay, there we go. There we go. Elephant didn't move. Okay. For some reason that that Laura we got is not... Oh, just try anything else. we'll try okay laura carl zeiss see if this if this is not for sdx also i don't have to see so you could you could see here as if it's accessibility yeah so if you want to do well elephant grabbing the moon and then you want to do let's say some carl zeiss lens you wanted to have the carl zeiss lens effect and you want it to be well you don't want it to have the Carl Zeiss lens effect and you want it to be, well, you don't want it to be too close to its actual, like its actual pictures. So we just, we just reduced a little bit. I don't know if it's off-circuits, but okay. So and then let's generate fall goes well oh i forgot to make it 5 um 1024 by 1024 but it did must match the size of cancer Ah, this is not working for that. We have to use a different something. Okay, like some cyberpunk room. Oh, boy. So it will look futuristic. Sure. And it's not too big, too. So, yeah, this is good. Okay. So put this in the so that is the model right because one six yeah this is a Laura yeah 162 mb so you put it in Laura and then save and then that's that's see practically downloaded it already And then that's that's see practically downloaded it already. That that's small. 1 dot 5. So you can see it's there. Okay. Oops. What? No such thing. What's this called? Cyber. Cyber. cyber cyber it's missing let me try again okay there we go i. I think I got it. So let me transfer this to the LoRa folder. Which operating system are you using? This is Windows. So this is called pop OS as if it's based on Ubuntu. Okay, but it's it's it's package the distro is package for data science people. It's called what pop OS. Yeah, it's so weird. It's like this pop underscore OS. Oh, interesting. It's supposed to be lightweight enough enough but it has it installs everything for for uh data science okay yes but but it's ubuntu so yeah and it has no so so so let's say okay so this is the laura for cyber room. And then, okay, we have this here. Let's try running that again. Let's remove this part because this LoRa does not work for SDXL. Refresh. Let's do cyber. Okay, let's do this one. There we go. Cyber room. Now it's a cyber room. We don't want it to be the whole room. So let's make it maybe about just 50% influence. So elephant grabbing the moon. 1024 by 1024. Nice. 1024 by 1024. nice oh it said a tensor with all that is produced there's not enough precision to represent the picture produced in the unit huh what's this what was that no no it's saying like a tensor with all nines was produced in unitet. Like it's a very specific, all the terms, right? So you start reviving all your deep learning stuff. Yeah, exactly. It couldn't load the tensors into the UNet. Just try setting the upcast cross potential layer to float circuitry in setting stable diffusion or using the no half command line argument to fix this use the signal and check line command line okay let's use check check what what was that again um it said use check. So first thing is use disable then check like command. That's under stable. So it's under stable diffusion. So it says upcast cross attention layer to float 32 and setting stable diffusion. There's the settings, stable diffusion that's the settings stable diffusion upcast okay oh here it is okay hopefully this works apply settings it takes quite some time to become skilled at these things isn isn't it? Yeah. Yeah. It's so much. Okay. I'll take this call. One second. Sure. How are you? Something to do with the image size right? Yeah, maybe maybe you could try smaller. Let me just see if I could find. Oh, it's just a bug. Gracias. Okay. It's just it's just, it's just, let me just, I think, I think I'll just run with SDXL, SD 1.5. It's just, this is just, okay, I'll do Disney. Okay. So this is SDXL. And then let's let's change Let's just try this one. Give these. Okay. Ha, it's working. So SDXL is just so new, it's working so sdxl is just so new it just it's still causing errors so if we use sdx sd stability yeah but did it change to 524. oh no no no we didn't it's it's actually scaled up so yeah you're right Oh, no, no, no, we didn't. It's actually scaled up. So you're right. I don't know if we even set this though. Did we set this? Hey, this is a pretty good picture. Oh, you saw it? It's a pretty good picture. Yeah, I think SDXL is still not very friendly or I still have to learn it. I'm used to the older stable diffusion, but this one, yeah, let's try. So yeah, you see the elephant grabbing the moon. I don't know what to say. Multiple elephants. say multiple elephants let's say that's the issue so and then i just added a la's say like to make it look like oil painting oil painting yes all right let's try that okay hopefully this gets okay now so let's let's let's make it a little bit influential, so I want 70%. Let's see if this works. Oh, Tensor must be, oh, it, 6, 8. Maybe we could try making 7, 6, Nope, it's not a crime. Lot of. Yeah. Yeah, I think it's because any of most of this. But let's do a Carl Zeiss and then let's say, let's do elephant grabbing the moon for the realist. I know let's see something like. The SD SD 1.5. Just make it small. Just because I'm using. Okay, fine. But it's always the same, the same picture. I already had a random. Oh, interesting. Interesting. Yes, so you can see it has a bokeh because it's using the Carl Zeiss lens. Yeah, the lens thing. And then you can just add as many lowers as you want.