 The first data set is simple and it should basically give you a hang of how to do it. So this is the classifier one data set. What do we start with? We always start with EDA, classify a one data set what do we start with we always start with eda exploratory data analysis this thing as you start with let us visualize the data this is the data visualization can you see a decision by the way this hopefully should remind you of blueberries and cherries isn't it right so here you go i colored it like that so it would agree with your intuition so where is the decision boundary that your mind wants to draw do you see can you in your mind's eye see a decision boundary here yeah which way is it diagonally isn't it top left to bottom right bottom right yes I already took okay and so now let's also do uh the basic plot that I did a pair plot and all of that you notice that one set of values are clubbed around along x1 axis here and this so look at this graph guys this is the histogram smoothed out in some sense these are called kernel density plots right does this agree with this picture along x1 axis more value more Blues are shifted to the left more Reds are shifted to the right isn't it yes so you see it in this plot likewise of course this is just a direct plot now this is the curve it's not more informative this data set is very simple if you see one you pretty much get the hang of the rest now what do we do let's let's extract here the target variable was t and x1 x2 are the things let's build a regression model you can use any other solver i put newton cg not because there is a big reason for it i wanted to uh by the way cg stands for conjugate gradient right a newton method so So don't pay it. I mean, unless you're into numerical analysis, you can ignore it. The reason I mentioned it is you should know that under the covers, there are many choices. Sometimes if one choice isn't exactly working for you, try something else. All right? So that is that. So what is this? We instantiate. Does this code by now look very familiar? Except that it is, we are using logistic regression. It should look, the pattern should look very familiar. We create a model. What is the first thing we want to do? We want to create a confusion matrix. Let's do that. Now when you do the confusion matrix, you see precision, recall, F1 score. I decided that I'll leave it as a homework to understand what these things are. Next time, I will quiz you guys and I will review the explanation next time because we are running low on time. Simple enough, but I'll give you the physical intuition behind precision recall. And F1 score is the harmonic mean of precision and recall. Do you remember what harmonic mean is? So 1 over the harmonic mean is equal to 1 over x plus 1 over y, like two variables, right? So for example, one over precision plus one over recall is one over the harmonic, one over the F1 score. You can try that. So now remember that behind a logistic regression, there is a hyperplane, isn't it? So we can still talk about the intercept and the coefficients, the unit or orthonormal vectors. So let's look at that. If the coefficients are pointing this way, the unit vector, it is this way, right? That's what they are leading us to. This is the intercept. And we can look at the data and see whether it agrees with our intuition or not. So let's take this. Now, what happens is that a classifier in a regressor, you say predict and a number comes out. The way the scikit library is designed is interesting it will tell you uh how should i do that okay let me let me explain it here in scikit library uh what okay uh in scikit uh what okay uh in scikit for better or for worse the way it is designed is this when you have a classifier any classifier if you do predict so suppose you're predicting between a cat, dog, between cat and, oh, well, we love cows and ducks. Let's go back to our cows and ducks. Right. When you call predict on an input, you will get cow or duck, one of these two. Are we together? On the other hand, if you do classifier.predictProba, proba is for probability. So what it will give you is, it will give you the probability that it's a cow and probability that it's a duck. Right? Of course, because the two add up to one, you don't need both the columns. You can just be happy with one column. But if it was a multi-class classifier, it would give you, like suppose it was cow duck and horse then it would give you the priority of this probability of this priority of this are we together and we'll see that in a little bit so there are two prediction two important functions are there predict and predict proper predict will give you the actual class value, class value, the label. The more modern people often in deep learning use the word label. So we can say label. Is it a cow or a duck? It will give you the label. Or predict probability will give you the probability of that label, the probability of that class. So that is something to know about scikit-learn. By the way, is my cursor now visible? Sanjeev, is it visible now? See if you can see the mouse. Yes. Yeah, this time it's much better, right? Mouse is still visible, right? Yeah. Okay. So I think we may have solved the problem. What do you say? Actually, there's an issue with, I think it's the OneNote feature. Yeah. So I tried it myself. So when I write with the stylus on OneNote, I can see my mouse pointer moving along with my stylus, but others cannot. So the mouse just stops somewhere and then they can just see the stylus. Okay. Figure out if somebody has created a OneNote plugin to fix it, that may be worth it. Or see, like, you know our use case. Yeah. If there is a better software we can use okay maybe one note is not the right thing so i do want this because i don't want people to keep guessing where in the world my mouse is and where am i writing all right so that explains the proper Now you know why I'm looking at the predict proper. Because I want the property to one class cherries. Right. So there are two columns IP I happen to pick the second column. Right. And so now you get the predict. So there is a in yellow brick, there is a lovely bit of code that we can use to put all things together some crucial reports together first of them is what is the importance of the classes it turns out x2 matters more than x1 i think marginally a little bit i wouldn't read too much into it right because data is more or less diagonally separated what ah, this is the thing that you, I love best, the confusion matrix. Do we see the confusion matrix? So how many cases did it get right? 295 plus 404. Isn't it? And how many people it got? How many things it got wrong? 51. I would say it's doing impressively well isn't it would you say that it's okay yes then the next thing we look at is the precision recall and f1 score the precision for class for the zeroth class is 91 for first is because there's generally a little bit more data. 94. These are all 94. Recall an F1 score for 1 and 92. So these are all very good numbers. Now, I would like to explain in a little bit after finishing this notebook, something called ROC curve. ROC is one of those arcane terms. It stands for receiver operator characteristic curve. Now, what in the world is that, receivers and operators? And what are they doing here? We'll talk about it. It comes a little bit from signal theory or communication theory. We'll talk about it. So here is the way to remember. And I'll just give you the basic intuition till i explain it further this diagonal line that you are seeing it is the prediction that is the line that would be the roc curve of a model that generally is the null hypothesis kind of thing making random guesses it would look like this. Any model, any line which goes above it is better. Anything that goes below it is, remember in regression, we had things that could do worse than null hypothesis. This would be a similar situation. Now, the more it sticks, the more it rises fast and goes up here, the better. So let me explain why. It says, see, one easy way to increase the true positive rate, like how many people have cancer, right? Make sure you don't miss them. Oh, very easy. Just say everybody has cancer, right? Go scare everybody, then you won't miss any cancer patients. That's easy, right right so in other words if if you do that what will happen to your false positive rate that will go up but what do you want you want your true positive rate to be high you don't want to miss that you don't want to have true negative like false negatives right so? So what do you do? You want an algorithm that has the least false positive rate. It scares people the least. You know, it scares them that they are in trouble or so forth, but has a very high true positive rate. Most of the cases it catches. That's what you would like. So if that is the case, then this curve would rise up very fast. And if it rises up very fast in the area so the scale i made it horizontal but it's one to one it's actually a square so the area of the square is one but whatever area is under the curve is a good measure of how lifted up this curve is how fast it rises isn't it and that is why you use the word area under roc curve right and here it says for class 1 99 and 99 means when you area under roc curve is a very good measure of how well your classifier is doing right so it is very good here. Obviously it's a simple dataset, which is why it is doing so well. Let's visualize the predictions of the model. What we do is, whatever the probability of it being a cherry, etc, is there, I put it here and a blueberry is there. So I've plotted it here. When you plot it here, do you notice that something very interesting? Here it is pretty sure. Can you see the mouse? It's pretty sure it's a cherry. Here it's pretty sure it's a blueberry. But what about in between? That's where the probabilities are getting mixed up, isn't it? Like it's not quite sure. The blueberry gets less and less sure. And then you get this white area where you're 50-50. And then you start getting cherry. So this is a pretty good way. Actually, I use this kind of a visualization a lot, wherever I can, wherever it is applicable. Asif, can you pause there a moment to show how did you set up the colors for that? You kind of set a gradient of red, where it went down to literally white when it got to 0.5, right? Yeah. So what I did is I first of all set the color scheme to go from red to blue, because I was talking about my blueberries and my cherries, right? So this is a color map. There are many color palettes. I chose red, blue, because we're talking about that. The second thing I did is, do you see, this is the P predictions is the probability of it being a cherry. Okay. So if the probability is below 50%, it will be bluish color. If it is above 50%, it will be reddish color. Okay. Since you said red to blue, it automatically went to white in between. Okay. That is right. That's how it is. Now, what I want to do is see what a decision boundary does is it partitions the feature space into two regions isn't it for class a and for class like for red and for blue so let's see how well it did and this visualization i find actually more useful because it shows to me different regions of the feature space now do you see the linear nature of the classifier how you you know you can see these lines contour lines yes and you can see literally the straight line in effect the the shiny white line sort of as the decision boundary going through this data so if you look at this you would say that yeah this is a pretty good decision boundary i like it right looking at this visualization by the way some of this visualization code right is a uh i use it some past students have said that one of the big things they benefited from was literally learning how to do this with some of these visualizations because you don't easily find them or maybe find them with such aesthetics maybe or for whatever reason they liked it so you can make your own decision here then this is the area under roc curve pretty good right now let's do one thing this is all very fine you see the regions being a thing. Let us physically draw the decision boundary. So what I've done is I've taken the equation and I have converted it into the kind of equation that most people think of in high school as a line. Y is equal to intercept plus slope times x. Remember? Mx plus b kind of a thing or mx plus c kind of thing so i just converted it like this so that it was more intuitive to people and then i color i drew the decision boundary so here it is here is your decision boundary so would you agree that this this decision boundary is appropriate right you you would sort of like this decision boundary so all right we are here and now what do we do let's try another algorithm which i haven't taught you yet it is linear discriminant analysis i would like to use this tuesday session because we are see guys what happens is that there's a lot of material to cover so i will start hijacking theacking the Tuesday session to cover whatever is the spillover. One major spillover is the linear discriminant analysis. I will cover that technique. But at this moment, just think of it as one of those magical algorithms that we'll learn about in the future. But the application is straightforward. You notice that the code, all we do is we replace linear classifier, a logistic regression with linear discriminant analysis. We learn more about it. Everything else remains the same, class probability. The prediction accuracy is just as good. It's doing a pretty good job. Similar visual, almost similar visualization here i wanted to point out that for simple data sets almost all the algorithms will agree right and they are agreeing right uh draw it out the decision boundary for the lda is here and the thing by now you realize that switching one of the lovely things about scikit-learn is to quite often to switch from one algorithm to another is just changing the constructor and then making minor tweaks that's about it. Makes for a lot of quick efficient experimentation. experimentations. Newton's CG that you had. Yeah. If you had to use other algorithms, what would happen with the other methods? Some of them support, some of them don't. Like for example, the parameters that you do in linear discriminant analysis, the choices are whether you use singular value decomposition or eigenvalue decomposition or a couple of those those matrix linear algebra alternatives are there correlation based so you'll come to it see each of these things right is a little well of knowledge you have to dip into and there is some depth to it but obviously if we i'm taking you deep enough so that you are mastered. And if you want to go deeper, you can sort of keep dipping deeper into it. But I'll cover LDA in depth. LDA in particular is relevant because it has a deep, deep connection to literally singular value and eigenvalue decomposition, which we talk about in the engineering math class, math of here. So we will do that. Now let's look at a different data set maybe this was too easy uh let's look at this data set two we take it and we say aha many how many classes do you see here guys four four classes so um it will be a little bit more interesting graph you notice the four different uh density plots scatter plots and here you see how they are peaking that's interesting let's try the logic but you know logistic regression was able to do only separation between two classes how do we use it for for four classes what you do is you actually build four different models is it class one or not is it class two or not is it class three or not is it class four or not and then you take the probability that is higher you do a soft max like argument i will explain it in a separate session i'll explain those again those details i haven't covered the theory of how do you use you basically have to number of classes you have to build those many models separate models right and then compare the results that's how it. Because logistic regression in its native form can only do binary classification. That's an important point for us to remember. So you realize that the confusion matrix is pretty robust, you know. There are only 4, 6, 7, 8, plus it's 16 errors in a long list of data. The precision and recall and the accuracy are 97%. Again, very good. I wanted to just show you how good these algorithms are. How well this data has a lot of overlap. You realize that some areas you never can solve. Inherently, there is noise in the data. Sanjeev, you agree? You see this where my mouse is? You can't get out of this. So now the confusion matrix is more interesting. You can see the mistakes in yellow, but it's overall a very healthy confusion matrix. A precision recall, everything looks strong. Area under ROC curve is so good that you can't even see the curve. Do you see the top left-hand corner, guys? Yeah, it's bugging it. Yeah, that's your ROC curve. So I'll take some time in a little bit to explain ROC. I want to explain that. And then you see the predictions of the model, they are almost always getting it right. So we will leave it. So is it because they are like in four clusters separated out? Yes. So yeah, there's a big, so what Sachin asked is, is the classification so easy and good because the clusters are separated out? The answer to that is pretty much you got it. Those clusters are globular. Do you notice that they basically have a bell shape, normal distribution? If you look at this, look at the bottom left figure. Do you notice that they have the bell shape like any direction? It sort of rises up and then falls, right? Whenever you see this, what I use the word globular, whenever it has sort of a globular like look, generally classifiers, simple classifiers do very well. In fact, they do better sometimes than most. But if they will mix with each other, even then that would- Then it does. We will do that. In fact, that is one of our labs, so hold on. Okay. Right? We have a lot of labs on classifiers, about 15 labs. So anyway, that brings me to this fact, guys, the pace at which we are moving you realize that i can't go through every lab so i'll be posting a lot of lab solutions but i will trust that you will read it and at the same time do the lab see typically in the year 2019 2018 what would happen is lab would wouldn't be me talking i would talk for only 40 minutes or so then people would be around these rooms doing the lab doing the homework unfortunately i can't enforce the homework because so many people are remote otherwise people would finish the homework and go so anyway you look at this uh curve so now can we do it using linear discriminant analysis linear discriminant analysis. Linear discriminant analysis, one of its virtues is you don't have to build four different models. A single model does the job, right? Linear discriminant analysis inherently scales to multi-class classification. You will realize that when we talk about the theory on Tuesday. And it does also very well. Look at this AUROC. It's perfect, nearly one. Right? So if anything, let's go and look at this one. Where are we? Yeah. And this also has it one. So it was an easy straightforward problem. Whenever data is globular, it goes and handles it. So you say, well, so what? Let's try something a bit more complicated. Let's go to data. And I'm trying to like each of the simpler examples has a lesson in it. I will gradually go through it. You look at classifier dataset 3. But how can a single line classify into four parts? No, because linear discriminant analysis doesn't build a single line. It partitions the feature space along edges along, you know, with edges edges or tiles the tiles have straight edges okay yeah and in quadratic discriminant analysis another thing i'll talk about the tiles have curved edges okay so oh goodness now we are in trouble look at this data set data set three what does it look like i don't know maybe an egg well not quite an egg if i should have painted it yellow i don't know what you will relate it to or maybe an island in the middle of the sea or something like that looks like an eye oh yeah i like your exam your intuition best it's like an eye. Oh yeah, I like your exam, your intuition best. It's like an eye and this is like the pupil. So there we go. Then we do that. Now do you notice that the blue is, the purple is sort of scattered, but the blue is concentrated. You can see it in the two density plots. The blue density plot is peaked and concentrated. The purple density plot is spread out. And you see this very peculiar diagram inside here, right? This is the one that you say, how can logistic regression work, which is looking for a straight line? Binary classification, straight line. Can you draw in your mind's eye, can you draw any line here that will work? Not in two dimensions. Not in two dimensions. We can't do that. So what do we do? If you blindly apply this, you get something pretty terrible, you get for one class, you get certain accuracy, accuracy of 64% for one class. But for another class, which it doesn't give you overall accuracy is 64. But actually, look at this line. This is the most damaging line. What gives up. Yeah, it completely gives up. It assigns all the data to one class, right? So for classifier, let me introduce you to the concept of zero R rule. It's called the zero R rule or the baseline classifier. The worst classifier is the classifier. See, what is the equivalent of a null hypothesis of regression in classification? Whatever is the majority class, say that's the answer, always. Right? And remember that quack doctor that I became in the village, I was right 99.9% of the time, high accuracy. So that is a sensible way to proceed when you when you want to ignore all the predictors right or you don't have a medical degree right so that is what it is doing it is assigning all data to one class why is the accuracy 64 percent because it turns out that 64 percent of the data belongs to one class and the remaining 36 belongs to the other class, right? So this classifier, whatever it is, when you draw it out, you get this impression. Look at this. Do you notice that the confusion matrix is interesting? One entire column is missing, right? Because nothing is being predicted here because nothing is being predicted here everything is being predicted here as zero everything is being predicted as zero it's a disaster and if if you're not convinced look at the roc curve does it stay above the 45 degree line no no it, wild. In fact, it seems to have, if you want to have something worse than the null hypothesis of the baseline, here it is. You're doing pretty poorly. You're actually doing worse than the baseline hypothesis. That would be 50% here, 49%. So you'd say the diagnostics would not appear to be encouraging. Yes, it would not be. It would not be. Oh, appears to be encouraging. Oh my goodness. Yes, please help me fix appears to not be encouraging. Yes. Sorry, this is what happens when I work till late on Friday and then at early at 1 a.m you start writing notes and the confusion matrix is confused yes confusion matrix is certainly confused when you when you put this scatter plot actually this is wrong this does not even belong to this scatterplot. Actually, this is wrong. This does not even belong to this. Yeah, it belongs. See it has randomly drawn a line. This line has no meaning. Do you realize that? Because the outside was blue, inside was a different class. So would you trust this decision boundary? You wouldn't. It has no meaning. And so you continue this and you try to predict this is the real data the circles are the real data it predicts everything is the class one you notice everything in its mind is class one because what is the background color just one uniform color isn isn't it? Whereas if you compare it, for example, to classifier one, do you see two different colors? What a contrast it is to look at this. Do you see why this is a disaster? Yeah, it's a quack doctor. Yeah, it's the quack doctor. That's right.ack doctor that's right and the roc curve is terrible it's not working basically logistic regression is not working you can't even see the decision boundary it's pretty bad then you do linear discriminant analysis actually the word is once again a linear no quadratic discriminant analysis will work linear wouldn't directly so you do quadratic discriminant analysis which is deliberately a quadratic curve it builds curves right so what does it do oh it has worked look at that from class one was zero remember in the previous logistic regression model if you look at it the measure failed for class one precision recall f1 was were exactly zero it was completely failing but look here when we try this algorithm where are we okay when we look here what does it say extremely good precision perfect precision recall 81% F1 score 89% this seems to be really doing well isn't it let's plot it out and you see it here this is the confusion matrix do you see how well this is the confusion matrix do you see how well this quadratic discriminant analysis is working for this right so it worked and you can see the ROC curve here but they're way up there and the values are pretty good let's visualize the prediction aha look at this. Do you see the gradual transition from blue to purple? This is it. So this is what you want. You can see the wide decision boundary in between. Do we see that, guys? Yeah, looks nice. Quadrating discriminant analysis seems to have, now it looks even more like an eye. As long as it's not the eye of Sauron. Yes. Remind me me what was the what was that greek thing lord of the rings oh a lot of the rings i haven't seen don't worry about that okay so this is it when you try to paint the feature space again by the color you see how perfectly it does the job do you see the contour lines the equal probability contour lines are showing through so well. So well, it worked. So the lesson here is do that. But then I wanted to give this as a homework. But you can say, no, wait a minute. Didn't we learn that linear models, we can do feature space expansion and do curves using linear models? In linear regression, we did polynomial expansion, right? Let's apply the same trick to logistic regression. Can we do that? So there you did that. So what we do is, and this is one of those, by the way, I'm giving you one of my interview tricks. Anyone who can solve a problem like this using logistic regression in my interviews, I usually instantly give him a job. So well, here we go. This is on record. I shouldn't have said that. Now everybody will start preparing. Okay, I'll remove that problem. Remove that problem now. Logistic regression. How can we do that? We can do a polynomial expansion. I happen to choose a degree four. Two also works quite well. And look at this. Look at this. Is this good? Would you call this model good? Yes. It's very good. And look at this. Area under ROC curve is, it is perfect. It is, it seems to be outdoing even LGA, it seems. Right. And look at the prediction model. One of the nicer thing is, do you see that the probabilities are very tight? And here we go. Would you agree that it is working? And that is the lesson, guys. See, linear models are very effective if you give it some thought, you apply some of the tricks that people forget to apply and it works right so don't give up on linear models easily apply them it will take you to this why should i not give up on linear models what is the advantage of making a linear model work as opposed to using a more complicated model. By the way, QDA is not complicated, but yeah. Okay. It's expensive. Compute. Time. If compute is one reason, time. Explainability. Say that one second. Easy to explain. And Kate, you also said the same thing. Interpretability, guys. Linear models are highly interpretable. It is common sense it boils down to common sense you can say that if you because the coefficient here is larger if you do this you will see deviation in this direction isn't it what do you do when you have a deep neural network or you have a random Forest or something much harder to explain to somebody what's going on right that's the reason and so interpretability is of course a big topic will do Lyme and many other things. So, the lesson here was that don't give up on, just because logistic regression naive application of logistic regression failed doesn't mean that you give up you ask from the arsenal of techniques that you have learned, what is it that you can apply? Right? So what I will do is I will take a very short five-minute break and then we will continue and finish the last topic.