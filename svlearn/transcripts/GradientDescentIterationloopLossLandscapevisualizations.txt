 Now what happens is, let's look through the iteration loop. Learning iteration loop. Guys, I hope I'm making this all looks very simple. When you look at the learning iteration loop, you can say run through data they could run through the data for let us say e epochs right so you can have something like you can have something like, say, E is equal to 10, 10 epochs. Then for each epoch, run through each of the many batches. And people often use the word batches of data, whereas strictly what they should mean is mini batch. And then for each mini batch, for each mini batch, learn. In other words, take a step, i.e. take learning learn in other words take a step i take a learning step so now let's unpack this how would you write this in code you would say for for i let's say for epoch in let's say a range epochs so you decide how many epochs you're going to run let's say your epochs i hope epochs is equal to 10. So range would do what? 1 to 0 to 9. So it will give you this set of values. So for each epoch, so as you go through these 10 epochs, then what you would do, you would for, let's say, mini batch, or typically people just use the word batch. It's an abuse though mini is implied. Batch in and what you do is you enumerate over the data set. Enumerate over the data. In other words, you ask the data set enumerator to return you many batches of data. For each batch of the data, what are the steps you will do? Remember, how does learning proceed? First, you compute 1, the forward pass. So you compute the y hat is equal to whatever like you feed it in you feed it into the box the forward passes you take the input x collection xi you feed it into your model and then you get yi hats predictions the set of predictions for each element in the mini mini batch right so you just pass it to the network the forward pass then what do you do you compute loss so that could be for example the loss here could be y i hat minus y i for this mini batch over the batch over the batch let's say let's say that you're taking some squared error over the batch you would compute the loss are we together now that you have computed the loss, what would you do next? You would say, oh, I need to compute the gradient of the loss, isn't it? Now compute gradient of the loss, this, what remains? Very easy. So you have computed all of this. So for example, W, I, J, you have computed, right? So all that remains is to take a backward pass. a backward pass backward step pass what does that mean you will update your wij and again i'm sort of a of a given layer l of a given layer l is equal to whatever the the previous value was minus alpha minus alpha. Right. So now this is the backward pass. You would do that. Are we together, guys? You would go and update all of these. So first you have to compute all the gradients, right? Once you compute all the, because what will the gradients, right? Once you compute all the, because what will the gradients be? Gradient of L with respect to W will be the set of all of this WL with respect to some IJ loss for all values of IJ and the number of layers in the neural networks. Because there's so many, many weights that you will do. So you'll have to somehow compute all those gradients. And then you would have to do a back prop, back a pass. Like this is the learning step. So people often call it in the code, this is often written as step. Take a step. Step of learning take a step of learning so and when you look at for for go through the epochs inside an epoch go take data in many batches at a time each mini batch at a time and learn, take a learning step. And this is how you take the learning step. You realize, guys, that this is what you do, whether or not it is a neural network. You do, you do, we did it. For example, when we were doing linear regression, if you remember this code, and I'd like to vet your recollection about this code. So this is it. Now, there is one thing that we didn't quite address this alpha learning rate what is it how do we con what what does the learning rate do to your learning alpha learning rate how the question is how does the size of alpha affect learning now you may say why not make the learning rate huge or we will zero into the solution much faster the machine will learn much faster right One may be tempted to say that. But what really happens is learning rate decides how big a step you take. And let's take the example even of a basic thing like linear regression. Let's take a function. We took this function. What happens is that if you take a learning rate that's huge, then this learning rate will actually overshoot. Do you notice that it overshot the minima? And the next time, it again takes a step. It will end up somewhere here. From here, it will end up somewhere here. From here, it will end up somewhere here. And it will just keep large learning rate causes unstable oscillations around the minima without any and these things i'll show you in a beautiful way with visualizations in a moment across the minima without convergence do you think this will converge at all will it ever reach this point it's unlikely to, right? Without guaranteed convergence. So actually, without guaranteed I'm sorry without I seem to have scrolled down without going to the optima or minima it's synonymous here so it won't do that on the other hand large learning rate too smaller learning rate has its own set of problems. So imagine that this is your surface. What happens is that if your learning rate is very small, you'll keep doing like this, very, very tiny steps you will take. And what happens is, here what happens, you notice that gradient is the slope is already close to 0. If you look at the learning rate, the learning step, W, and I'll drop the subscripts, minus alpha dL dW. So here what happens, when you look at the slope here, this is the slope. It is small. When you are near the bottom, it is rather small. So if this part is small, and this part is also small, learning rate is too small, the product of too small quantities means your next learning step is even smaller. So what happens is that you begin to very slowly and painstakingly crawl towards the optimal solution. You spent a lot of learning cycles, lots and lots of steps, and you're just sort of at a very snail pace, inching your way towards the minima. So here too, there is a, you need to find the Goldilocks point. You need to find what is a good learning rate. What's a range of learning rates that is best to take you to the solution fast enough, and get you there, but not too fast because you may overshoot the solution. So learning rate becomes another hyperparameter of the model. So we learned in this learning, we learned two hyperparameters. This is true whether you're doing neural networks or any form of machine learning, two hyperpar this is true whether you're doing whether you're doing neural networks or any form of machine learning two hyper parameters parameters and there'll be more that will come two hyper parameters a is what was that mini batch size is what was that mini batch size b batch size b one let me just use one two one two the learning rate learning rate alpha right so what people typically do is they sort of will start with the default learning rate let's say 10 to the minus 5 quite common right and then play around either increase or decrease by then but when they increase or decrease they typically increase or decrease by powers of 10. In other words, you could go like alpha is equal to 10 to the minus two, 10 to the minus three, 10 to the minus four, 10 to the minus five, 10 to the minus six, and so on and so forth. You play around with the learning rate as with these values and see how well you learn uh in your process so far so good guys are we together any questions you all are very quiet here are we getting the hang of it so let us go back and recap. We covered quite some territory. What we are saying is that we are talking about gradient descent at this particular moment. So when you talk about gradient descent, the first thing is that gradient descent is the process of tumbling down the hill. The first thing is that gradient descent is the process of tumbling down the hill. Or when you're looking at something like a convex surface, which is the case with linear regression, which is why linear regression is so popular. You always keep hoping linear regression will solve your problem. For simple situations it does, but quite often it doesn't. But when it does, it's lovely because it's a bowl shape you will reach the minima easily but when it is not it gets more complicated we it's a convex loss surfaces is for linear regression and the neural networks have a highly non-convex loss surface i'll show it to you in a visualization then comes the question this topic many points, one step of learning is learning from how many data points? That is the three varieties of gradient descent you do. There'll be more, but for now, let's look into this batch size. When the batch size is the entire data set, you call it the batch gradient descent. When it is the just one point, you call it the stochastic gradient descent, and somewhere in between is a better solution. When you do the entire batch, the batch size is the entire data set, learning is slow. You can't see the learning. You have to wait for the loss to be computed over millions of records and add it together before you take the next step and the gradients to be computed there. And then you take the next step. In the case of batch size is equal to one, learning is very cheap, right? But you, and so quickly you take a step. The trouble is you are taking the step only partly in the right direction because each data point contains both signal and noise. So it's also misleading you partly. So you have a drunken man's walk towards the solution, number one, and number two, you don't quite hit the solution. You keep like a drunken man, keep walking around the solution. It's like, you know, you drink too much, you come back from the pub, and instead of knocking on your door and getting inside, or taking your keys and going home, you keep wandering around the neighborhood of your home. So that would be stochastic gradient descent. And so in between that is the Goldilocks zone. You choose a judicious size of batch, mini batch, 4, 16, 4, 8, 16, 32, so forth. And you learn from little batches so that progress is visible, but at the same time, there are enough points there in the mini batch so that hopefully, hopefully it dampens out the errors because errors tend to cancel when you take a sufficiently large batch size, isn't it? Especially if they have been randomized properly. So that is it. And so the path that you take is not quite the best path, the straight path, but it is good enough. It sort of is not crazy, too crazy. And you take that path to get to the optimal solution in the hypothesis space, right? Next, so what is our main loop when we loop through it? Our main loop is that this is our main loop for epochs. This is the epochs part. Epochs loop. This is the batches loop, mini batches loop, mini batches. So these are the two loops. For each epoch, for each mini batch, you do one step of learning. So this is your inner core, batch you do one step of learning so this is your inner core not loop but step of learning in a step in a core step of learning so how do you learn you first have a model with some weights so you give it the input it will produce and let's say that in the beginning you have some randomized weights that's not going to be good you you pass your data through it it will make some garbage prediction very very very off prediction but then you compute the loss the errors between the data what it should be and what it predicted and use the data to you look at the gradient of that loss to take a gradient descent step learning step or gradient descent step this is also the gradient descent step it's the main gradient descent step you take. Now, never mind how we computed all these gradients. We'll come to that. That is our next topic to come to. We'll do that. So now in here is the alpha, the learning rate. And we talked about how learning rate affects us. If the learning rate is too large, we are doomed. If the learning rate is too large, we are doomed. If the learning rate is too small, once again, you'll creep towards the solution, especially when you're very close to the solution, the optimal point. So you have to, again, choose a good learning rate. It's a hyperparameter of the model are what is the learning rate and what is the what is a good learning rate and what is a good mini batch size. You have to play around with it and in fact the search for these is part of automated machine learning which we'll learn about later. Remember that when you're learning when the machine is learning it's only learning the best parameters. It will start with whatever hyper parameter values you give it so far so good guys any questions yeah i said one quick question um between the scholastic and the mini badge right yeah so you mentioned that for the mini batch, there is a chance of canceling the errors. What does that mean? See, here's a look at this. Let's go back to our data points. See, suppose a mini look at this. If I took one point at a time, remember, we talked about it this point, this point will will cause the line to move up right another point comes where is it another point comes here it will tend to push the line down right it keeps vibrating but now suppose you took a mini batch which means a small random sample of the point so the small random sample of the points would be suppose i did this this one got selected this one got selected this one got selected and this one got selected so i'll just take these four points i'm just re drawing them i hope i draw it faithfully enough uh let me see this is how it looks and uh somewhere here now tell me what is the line that you can learn from this? Yeah, it's most likely gonna be in between all of them. The whole thing is the exaggeration of this is compensated for by, there's some other point here, their errors cancel out, tend to cancel out. That is what is meant by saying that when you take a sufficiently good mini batch it sort of dampens on the errors and your machine is not learning so much from the errors it's learning more from the facts from the actual signal yeah so that is it that's what we speak of so guys all of this theory if you got it let's show it to you in something in a real situation. Now, I will take a notebook, which was there for that. And where is that? A polynomial intro linear regression. So I will visualize. So first of all, we'll take a very simple data set. I'll set the context. Those of you who have taken the intro to machine learning with me would remember it. But just to better recollection, let me go through it for a moment. There is this data set, which is about a Yellowstone geyser. This geyser faithfully erupts every once in a while. But when it erupts, how much time that is between the two eruptions depends to some extent on how long or how strong was the previous eruption. Right, so if the previous eruption was really strong, maybe you have to wait a lot of steam or energy has been dissipated, you may have to wait a little bit longer to see the next eruption, right. If the previous eruption was a quick short one then you probably will get to, the pressure will build up pretty soon and you'll have to not wait too long to see the next eruption so here this is the visualization of the data right and how much time like uh obviously we have scaled the data here. Unscaled data, I haven't put it. When you scale the data, obviously things get a little bit trickier, but assume that, don't look very carefully at the numbers, but what it says is that the amount of waiting time, it depends on the duration, increases based on the duration of how strong was the eruption, the previous eruption. So this is it. When you look at this data, suppose you try to draw a straight line. You can practically see a straight line going through this. And let us assume that you want to model it with linear regression. There's a little bit of visualization, which basically says that the data is clustered. Nonetheless, we are going to build a regression plot. We are going to build the wait time as the target variable and the duration of the eruptions as the predictor. So it's a very simple prediction model. Only one input variable, that is the eruptions, and only one target variable, which is the wait time how long do we have to wait it's practical if you go to the yellowstone national park the first thing the kids will ask you is when is it going to happen next right so we're going to answer the question so when you do that you realize that you're trying to find these parameters beta naught and beta one the equations of a straight line isn't it are we together with this that's what we're trying to find these parameters, beta naught and beta one, the equations of a straight line, isn't it? Are we together with this? That's what we are trying to figure out. What is the best fit line? And you can do that by applying the linear regression model from scikit-learn, you try to fit it to the data, and it will tell you that the intercept is this and the slope is this. All very good. But suppose, and then you can do a residual analysis and all looks good. This is a basic exercise in now instead of using the library we're going to dig a little deeper we're going to do this ourselves so how do we do this ourselves we will write that inner loop that we just talked about we will do it ourselves so let's go through go through it from the top this was was the data, just a refresher. So how do you do the gradient descent? Look at this, guys. Here, I'm using the word beta instead of w, weight. But this is the gradient descent step. Do we all agree? Beta next is beta minus alpha, isn't it? Gradient with respect to beta. Here, beta, I'm making it a vector so if you if it helps you just think in terms of beta i beta 1 beta 2 beta not beta 1 sorry right so beta is the parameter vector our goal is to find the best beta vector or the best beta not beta 1 so how do we do that we take a loss function which is a sum of squares. Regression, as you remember, it is the error. What is the gap between prediction and reality? You take it, and then you square it, and then you look at it. But then prediction is given by this model, beta naught minus beta one. And so when you do it, you can compute the gradient. It's a little bit of basic calculus. When you do that, you'll come to an expression like this. So you have computed the gradient it's a little bit of basic calculus when you do that you'll come to an expression like this right so you have computed the gradient and therefore you can take a gradient descent step beta naught is beta one so if you plug these equations back into your basic gradient descent step you will come to the conclusion that for linear regression, it comes out to be like this, right? Now that you have it, let's run through this learning cycle. Remember, learning cycle, you need to set the learning rate. By default, I tend to take learning rate as 10 to the minus 5. It tends to work well enough for me. And then I move back and forth and see what is a better one if it doesn't work. So I'll do that. And here for batch size, I take the entire dataset. So I'm doing a batch gradient descent. So now let's look at it. Here is alpha and so forth. Oh, I think here I played around and made it just 10 to the minus four. You need to start somewhere. So you make some random guesses for the parameters and so forth. Oh, I think here I played around and made it just 10 to the minus four. You need to start somewhere. So you make some random guesses for the parameters, right? Or you can start anywhere. Choose how many epochs you want to train. I said 200, right? And then you take the data. Now look at this carefully. For every epoch, but because my batch size is like one step is one full data so now what what am i doing uh this is code obviously this is python code and if you're if you're a little worried about the greek symbols uh python supports greek symbols you can write your code with the actual symbols that you use in your nodes. So in your handwriting, or when you try to think through the mathematics, Python is very good that way. You can literally use the mathematical symbols. So you can see that up to a limit, it doesn't support subscripts, for example, or superscripts. That would have been nice. So here we are computing the gradients based on the formulas we wrote we are taking the gradient descent step then we update update the loss function right you compute the loss and you keep on going that and you store the intermediate values right so then you optimize the parameter. Let's visualize it. At each step, what we do is we save what the parameter values are, epoch, beta naught, beta one, and how the losses compared to the right answer which is that beta naught is very small close to zero and beta 1 is close to 1.9 you realize that initially you started with 4 4 so after one epoch you didn't learn much but as you go through the epoch you notice that this value begins to decrease towards zero and this value begins to decrease towards zero. And this value begins to decrease towards 0.9. All right. And your net loss is just 51 compared to the initial loss, initial amount of mistakes. And this loss you can't get rid of because obviously the data has noise in it. That noise you can't get rid of. So this is parameter optimization. And you can see how beta gravitates to the right answer as epochs run through. And likewise, beta 1 gravitates to the right answer as the epochs run through. And how does the loss go? You can see that the total loss or the amount of errors also falls very neatly down to zero, right? So this is it. When you do batch gradient descent, it tends to be pretty neat, right? For a small dataset like this, of course, batch gradient descent makes sense because you can, each step is, even though you're going through the entire data, it's extremely quick. it's not so in deep neural networks when you have millions and millions of data point okay so let us draw out the loss surface wouldn't it be nice to see the lost surface so this is a bit of code that draws out the law surface first in the hypothesis space or we have color these are called contour plots maybe you're familiar with from geology or geography that the deeper the color the lower sort of it's in the valley right and if you visualize it in three dimensions this is what i was saying the vertical axis is the net loss right and the two parameters are beta naught beta one you can see beta one and beta naught and you can see that for linear regression what a beautiful nice convex bowl it is isn't it right so visualize the whole loss surface it looks like this and so you see that suppose we started here four four and how neatly the learning takes place and takes the best shortest path down to the valley in between. And when you look at the contour plot, you see this beautiful thing. In the beginning, the learning is pretty fast and it takes the straight path home and it makes little then it slows down but ultimately it reaches here to show that this is an effect what what i've done is i've created a little bit of an animation here do you see this learning take place here right now i'm going to replay this uh hang Hang on. Keep your eyes here at this point. Look here because we are starting from some point here. And in the contour plane, in the hypothesis space, again, you will see the shadow of that line fall here and see how the shadow in the ground looks like. So I'm starting it now. Pay attention to this. Do you see how this is falling down to the valley and the shadow is making a straight line to the to the optimal solution here? It slows down after a little bit because the gradient is mostly flat. The gradient is vanishing gradually, and so you come to the solution. Are you guys seeing this visually? Yes. So you're seeing the gradient descent happen. Yes. Now, for linear regression, obviously, it looks beautiful. But you may say, now, wait a minute. What about neural networks, which has a highly nonlinear, highly non-convex loss surface? Will all these theories still work? So to see whether it works, I invite you and play around with it yourself. But for now, I'll give you a demonstration of a particular website. Okay. We go to this. This is how the lost surface looks for a deep neural network. Let me completely erase everything. Yeah, so let me take a background in which it looks actually let me get rid of the background altogether now. Not very good, not very good. Okay, black is terrible. Well, I give up. Okay, we'll stick with that. So look at this surface, it is a large surface for a neural network. It's a real surface, by the way. It's not an artistic rendering. This was one of the very, very influential papers that came out. Even though the large surface is in a very, very high dimensional space, thousand dimensions or whatnot, or a million dimensions, yet people found a way to represent it in three dimensions. So when they do it, I hope you guys are appropriately astonished at the sheer beauty of the lost surface. While the mathematics showed it, when you could visualize, I hope you all would agree that this is beautiful. Anyone feels it's beautiful? Right? So it's a beautiful lost surface. Now this lost surface, you'd notice something very interesting. There is a global minima. But there are lots of local minima all over the place, right? It's hills and valleys. You could be stuck here, you could be stuck here, you could be stuck here, God knows where you can get stuck depending upon where you start. here you could be stuck here god knows where you can get stuck depending upon where you start and so we're going to play this game we are going to say let us let us start somewhere and see what happens i'm going to start here and let's see the gradient descent happen i'll click here do you see how it has gotten stuck in a local minimum guys yes right and let's see what it look like let's let's pour over it and see and you can clearly see that there is a little bit of a crevice here we have gotten stuck in the crevice right well how in the world could we have gotten out of the crevice let's see we can we can increase the what happens if our learning rate is high and we start again from here ah it jumped quite nicely to the bottom but what is it doing is it finding the solution is this scribbling around you see it is bouncing around the solution do you see this guys that part it from here it took a nice big leap down to this and to to here but after a little while it doesn't seem to make up its mind where exactly is the minima it seems to be spanning a lot of territory and doing it and so let's let's say well you know learning rate too big doesn't help learning rate too small gets you stuck somewhere what about this now let me start here now with a medium learning rate ah this seems to be better it seems to be oscillating a little closer to the optimal solution good what if we make it even smaller and now we try it let's try here this is much better isn't itasing learning rate is better, except that decreasing learning rate does have the potential of trapping you in a local minima, right? So for example, if I start here, you're not guaranteed that, okay, obviously this picture, I'm not able to find the traps. Let me rotate this picture and then, yeah, do that. So suppose I do this. Somewhere or the other, it will stop. Let me make the learning rate very low. What happens with very low learning rate? It seems to have a great difficulty creeping beyond that little valley, isn't it? Now let's do something, give it a little bit of momentum. We'll start from the same point. This is a high momentum actually. I didn't explain the momentum part. Okay, momentum is something I'll explain, but take it as a fact. If I decrease the momentum, you realize that with low learning rate and momentum, it has almost no chance of getting to the minima. What will happen? It will get stuck here. Momentum is like just when you tumble, you have a certain momentum that takes you over a pothole, isn't it? Doesn't get you stuck in a pothole or a small crevice. But this guy will now now it is just oscillating that line by the way is the gradient vector let's see what it looks like now now do you see that this is a local minima guys you went from here to here you got stuck in a local minima, isn't it? So this used to be the problem that people used to allude to when they said non-convex surfaces are probably not a good idea to do machine learning with. Lost surfaces may not be. But those concerns are more or less addressed. After all, you just have to be judicious in how you start. Select your momentum and your learning rate appropriately and see let's see what happens here it will probably get stuck somewhere here let's see if you're unfortunate and you take a part now this is without much momentum. Asif, Hari has a question. Go ahead, Hari. So is there any way we can transform that non-convex function to directly convex? No, there isn't. There's a lot of body of research that people have been trying to do, but there isn't. Neural networks are inherently non-convex loss surfaces, right? But and it gets more interesting when you do when you do all sorts of regularization methods. You'll see what it does. Yeah. So you see that now it is just bouncing around in this region. But if you start from here, then of course, you're lucky. Your initialization points were good, and you're happily creeping towards it. But you may say that, you know, this is a bit too slow. Let's give it some momentum. Sorry, close. Let's give it some momentum. What happens if we give it some momentum? And I haven't taught you how to give momentum, but for now, just assume that you have some momentum, and we'll do you how to give momentum but for now just assume that you have some momentum and we'll do this again the same thing i'll take the same point i'll see and see how fast it goes see with a bit of momentum it tends to make a beeline for the real solution and the momentum helps you escape some local minimas. Let's try a lot. I'll start from here. Let's see, what does it do? It got stuck here, isn't it? So what could I have done? I could have increased the momentum or slightly increased the learning rate. The moment I increased the learning rate, what happened? It immediately jumped down. And so that is what when you do deep learning and you do, you have many hyper parameters. And depending upon how lucky you were in choosing the initial data points and what your good learning rate was, what your momentum was and so forth. Now you realize that with this high momentum, everywhere, wherever you start, you tend to be going to the best solution. Do you see it, guys? No matter where I start, you tend to get to the solution pretty quickly with some amount of momentum and a fairly decent learning rate you zigzag you pay a little bit and then when you get to the bottom because you have a learning rate that is not too small you still keep bouncing around a little bit but you're pretty close you're bouncing around near the optimal solution okay so that is it so i invite you guys all to go to this thing lostlandscape.com explorer play around with this see what it means for you to and this is not the only architecture sometimes but by the way it's not always easy the last surfaces can be pretty bad sometimes what about this lost surface How many of you feel that it's very easy to find optimal minima? Very easy. This is obviously hopeless. So you have to know this, that it's not always pretty. They're highly complicated situations where you have to know that I give up kind of situation. But now when you do the whole theory, now what happens is when you have something called dropout, it's one of the things I haven't taught you, but I'll just move forward a little bit and show you what it does. There is such a thing as a dropout. What dropout does is it makes the lost landscape very rocky. Do you see the rocky nature of this? The spiky rocky nature of the surface, it's almost like what is that thing called jackfruit? Very spiky things on top of the jackfruit. But nonetheless, even though it is there, do you see that there is a clear minima here? So let's try a gradient descent here. It's gone somewhere completely different. Let's try here. There you go. It went in there from here. It went in pretty well. And it's a very shallow valley. It's not a very deep valley. What does that mean? It means that any one of these points is a good enough solution, isn't it? It doesn't have to be exactly accurate, because if you start from, let's say. say here quickly you jump down now if i let me make the learning rate small so that we can see the path yeah very good yeah you can see it squiggling its way down towards the minima let's increase it a little bit oh and quickly it goes so it doesn't matter whether it goes here or here here you're not looking for the absolute, absolute global minima. But do you notice that quite often these global minimas, I mean, once you go sufficiently deep in the valley, there are many possible solutions that you see. Let me illustrate that point again. Which one was I showing in the beginning? Heaven. Yeah, this one. So if you look at this at the bottom, do you notice that any place at the bottom is good enough? Yeah. Isn't it? So you could do, you could say that, hey, you know what, suppose you came to this point versus, or you got stuck here. Not bad. Both are pretty good models. The loss is pretty low. But I want you to appreciate how absolutely stunningly beautiful the lost surface of a neural network is. Play around with it, become so see here's the thing the sheer power of neural network comes from this fact that it can models highly complicated highly. Real world situations, the universal approximate a part of it is there, but it also means that the last surfaces are complex beautiful. loss surfaces are complex beautiful and there's a lot going on there that you can play with right so with that let's take a break i i would consider the topic of a gradient descent finished i will take any questions that you guys have then we'll move on to the next thing back propagation so what do you mean by giving momentum right actually, I know, but how do you give it? Yeah. So, momentum, that whenever, so suppose you have been going north, right? But at this point in the landscape, the gradient is pointing, let us say, east, right? The gradient is saying, go east, but you have been going north. So what momentum means, you don't completely listen to the gradient right at this point. You instead go partially north and partially east. Why? That's where the physical intuition or momentum comes. See, suppose that with great, your car has been going north. And suddenly, you want to make a turn towards the east, you won't be able to make right, your cars cannot make 90 degree turns, when they are on the move. Why? Because they have momentum, you turn the steering wheel east, but it will go northeast, isn't it? because of the momentum. So what it is saying is and now let me relate that to here. See, look at this. If I am tumbling down this and I have momentum, it is saying that continue going, let me stop it here. Let me continue like I am going here, continue going this. Don't stop in the valley. Because once you're in the valley, that gradient will point in some random direction. It's small gradients, but you don't know which direction the gradient will point based on how rocky here it is in the local valley. But if you have momentum, this momentum of going towards this will carry you forward beyond that little pothole, this little mini valley, isn't it? And that is the purpose of giving it momentum that at each step, you don't just listen to what the gradient is telling you. See, at this particular moment, we are listening to what the gradient is telling us. So I haven't taught you the more complex theory of momentum based gradient descent. As I said, we are taking baby steps today, we learned about gradient descent and here there is no momentum term but then momentum terms will come in. At this moment, almost all the state-of-the-art learners or approaches to do gradient descent is momentum-based methods. I think graph it makes sense but in mathematics, how do you know that we have to give a momentum? We'll come to that. In fact, we have an entire session in theory, diversity optimizers, where we'll learn about momentum based methods principally that's what it will be about okay right that's good and uh maybe someone can share that website with slack what you just showed it is uh if one of you could and i'll put it on the thing it is called lostlandscape.com it is there on our website already of course but we'll'll explicitly put it on Slack also. Thank you. Lostlandscape.com. Kate has already put it up. It's beautiful. Actually, when this paper came out, it was stunning that they could visualize. Everybody assumed that such high dimensional lost surfaces cannot be visualized. How do you visualize a billion parameter, a billion dimension lost surface, which is what these transformers have these days? And yet, paper makes it possible with a very, very clever bit of mathematics that is just worth learning. So I talked about the Sunday paper reading. Now you guys have learned enough deep learning that we should start the tradition of Sunday paper reading. Now you guys have learned enough deep learning that we should start the tradition of Sunday paper readings. We'll do it on Sunday evenings. So we'll start with Ola's paper. And then subsequently, we will actually do this paper. And I'll explain a little bit of theory behind how they did it. It's worth learning. So this is that. All right, guys. right guys so with those as if i got one question um and this is a kind of a not so great question but when you talk about beta or w in the gradient descent equation right yeah is that the is that the transpose of that on the axis or is it that on the surface itself? Sorry, that's the part that's not clear to me. Let me explain that. See, this surface that you see, it is in the W space. The word that people use is the parameter space or I call the hypothesis space. So think of a line, you're trying to fit a line to the data. What are the parameters of the line, slope and intercept, beta naught and beta one. Now for every possible value, different value of slope and intercept, you're talking of a different line through the data. And each different line is a potential hypothesis that this is the real, this is the underlying reality or this is the best description through the data. And each different line is a potential hypothesis that this is the real, this is the underlying reality, or this is a best description of how this data was generated, isn't it? It's a good guess of a G, G or approximation to the underlying force. And so you say that in real world, the points are in XY space, but when you are deciding which line to pick you're actually picking a point in the hypothesis space between beta naught beta one and the lost surface there is this lost surface so let's go back to our lost surface this is a lost surface isn't it see look what is the plane the ground made up of? Beta naught and beta one. Any point on this represents a certain slope and a certain intercept, and therefore represents a line in this ground, isn't it? For each point, which is a point in the hypothesis space, a parameter space, it corresponds to some line in the real data space. But for each point, there is a certain amount of loss. You can vertically rise up and see how much loss there is, right, for that. Right, the vertical axis being lost. So in this world, you always take loss to be the vertical axis and all the parameters to be the horizontal. So when there are three parameters, you say, well, how do I make a ground with three parameters mathematicians don't even blink an eye they say as you can see on the ground which has three axes right there's r10 axis or whatever it is so they sort of mentally imagine that the ground is n dimensional whatever the number of parameters are and the vertical axis is the loss does that answer your question manage it does uh so in a way it's point on the surface that's transport to the to the other to the to the dimensions on the ground here that's right yeah okay yeah so this surface is casting a shadow on the ground which is the contour lines that you're seeing contours that you're seeing yeah yeah the hypothesis space not the real data space yeah the real data space is just simple like this where is the real data space this x y yeah x y X, Y. Yeah, X, Y. So all machine learning is hunting for the solution in the forest of the parameter space or the hypothesis space. So when you look at a surface like this, one mental model that I carry is I think of this as a fascinating world. Imagine that you're a journey of exploration and in the hypothesis space or parameter space you're finding the lowest point, you're hunting for your solution. That is all that machine learning is, systematically finding that. All right guys, let's take a 10-minute break, and then we'll continue. I hope you all are having fun.