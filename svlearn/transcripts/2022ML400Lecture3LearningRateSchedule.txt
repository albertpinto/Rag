 The topic now is the gradient descent. By now you must be wondering, am I going to do the entire Fundamentals 8 sessions on just gradient descent? We never seem to be making progress beyond it, it seems. Isn't it? Anyone wondering that? progress beyond it it seems isn't it anyone wondering that so see the equation for gradient descent was w weight right and i will just use the notation in this book guys just for the time being um in this book weights it's a weight vector right they write it as a theta vector it's just a convention right we write it as because i want you to review from this book w next is w minus alpha gradient of the laws with respect to w this is how we write this equation guys by now it's familiar to you. Raja Ayyanar?nilavarashivarotriya.com Right well gradient is implied to be with respect to w, but if you want to be really clear, you can stick in a little. Raja Ayyanar?nilavarashivarotriya.com This right any one particular w let's say w I J of the lth layer this next value actually we typically say i put next or i just put tilde here you must be familiar with my tilde symbol here tilde is equal to w ij the current value of the any particular weight this is the this is the address of a particular weight parameter minus is this. So this is writing it out into the component forms. This makes sense, guys? This is just recapping what we have been talking about all this time the gradient descent equation right this particular thing is from the ith of the l ith node in the lth layer coming from the jth of the edge connecting from the L minus 1 layer, the weight on this edge is WijL. Right? WijL. Right? This is what it is. The actual location of this edge. Where is it? It is the edge between the jth node in the L minus 1 layer to ith node in the Lth layer. That is what we call WIJL. This is a review of what we have done. So far, so good. Now, this is, of course, the next value of the parameter vector what in the world is this does does anybody recall what this alpha is anyone loss coefficient the learning coefficient. The learning rate. Learning rate. Learning rate. It's like how big a step learning rate, the intuition is, you know that you have to go that way. But how big a step are you willing to take in that? Because taking a step in the right direction is learning, isn't it? Decreasing the loss, changing the parameters in such a way that the overall loss decreases is learning. But given the gradient, this is what? This is the gradient, right? This is the actual gradient of the loss, gradient of loss. This is the learning rate. Given a certain gradient of loss, this is the gradient of loss is five. How much you change the value of the parameter, it still depends upon how big a step you're willing to take. That's why the learning rate is important. Now, if you remember, how do you know what is a good learning rate? Do you think big learning rates are good? In general, shouldn't we be in a hurry to learn? Take giant learning steps, quickly go to the minimum? What do you think guys? What's the counter argument to that? We will be oscillation instability. Yeah, you will hop across in your hurry, you will, sorry, let me do it in a more realistic way. Suppose your loss surface is like this, very basic, loss surface is like this, and your learning rate is very high, you will go from here to here to here to here. Do you notice what you're doing?'re just bouncing around right so you're not getting to the minima you just are bouncing around here and there and from this right uh you're again shooting up going this so it's just a bounce around you don't know putting up, going this. So it's just a bounce around. You don't know. You're not converging at all. But what happens if the learning rate is very slow? What's the problem? So now you know. Your rate should be very late, right? You go very slow or you may get stuck in the local minima. Right. See what happens is that good minimas sometimes are in a basin, in flat basins. Like if you think in terms of the lost surface, we saw those beautiful visualizations, but I will use this bowl from my hometown. You see this bowl, what does it have at the bottom? Do you see there's a flat basin here? The surface has a flat valley. Isn't it guys? The valley is nice and flat. It's like Yosemite Valley. Right? What is the gradient in the Yosemite Valley? If your lost surface is the Yosemite National Park, what is the gradient in the Yosemite Valley if you have been to Yosemite? Zero, isn't it? It's flat. Do you agree? It's a nice basin there, right? So when your gradient itself is very small, almost zero, not quite zero, but almost zero, then look at this term. Let me use a different color. Look at this. If this it's sorry, this itself is very small. And you take a small learning rate, a small number times a small number, fractional number times a fractional number is what? A small number times a small number, fractional number times a fractional number is what? A vanishingly small fractional number, isn't it? Let's say that your gradient is now already 10 to the minus 5. And your alpha rate is also 10 to the minus 5. So the step that you take, the step size is what? 10 to the minus 10 one tenth trillion isn't it that is one then in that case isn't uh isn't a close enough answer good enough as in should we even take a step further yes but now i'll tell you something bad suppose you are in this situation and you are here you're taking tiny steps and you take 10 epochs and you're out of a box Now what? You realize that you didn't quite reach a good minima. You get to a plateau. Right. So well, what do we do? Small learning rates are bad. Big learning rates are bad. Is there any learning rate that's good? How do we find that? You talked about momentum yes i did i talked about momentum and that is the topic of today today we are going to learn about two techniques that tells you so when you look at a situation like this and if you imagine that you have rolled uh marble by the way are you all familiar with what marble is maybe i'm too old a generation we used to play with marbles throw marbles at marbles there's a round are marbles still around not quite okay do you guys know what marbles are this actually do i have a book okay do we know what marbles are glass beads yes glass spheres right and children used to play in my generation. So suppose you have a marble, and you let it come down the path, if you just leave it on a surface, what will it do? It will roll down the path of steepest descent, isn't it? But as it rolls down, what will it do? It will acquire momentum stop here or will it stop here no what will it do it will just shoot past happily go up here bounce back lose energy come back bounce a couple of times and then finally settle here so now what was the difference between the marble and the way we are doing in our gradient descent equation? That rolling ball and us and the approach that we are taking, what are we doing wrong? Why are we getting stuck? But our familiar little marble, should it be rolling in this imaginary lost landscape, in this hypothetical surface lost surface it would go to the minima just fine what does the marble have that our equation doesn't have it is the momentum even though the gradient has vanished it has the momentum of past motion isn't it it has velocity and when we people talk of momentum in this space, you assume momentum is mass times velocity. But if you have unit mass, then momentum is velocity. Isn't it? Momentum. But we will use that momentum and velocity, we will use synonymously because there's a convention here. And we say that the marble had velocity it had momentum so it went past it didn't stop but our gradient descent is not smart enough so one thing that can help us is momentum we need so the lesson we learned from this is lesson we need momentum right and this momentum is important because the large surface could be like this oh sorry this is also possible so a little bit of a momentum see what happens is at this point which way is the gradient pointing gradient is pointing like gradient is saying that the direction where the answer is is this isn't it it is telling you at this point go here but what is this momentum so far telling you it is on a roll it is trying to go which direction it is trying to go this direction right if the marble has been rolling the momentum is in this direction and so if you consider the effect of momentum and gradient together momentum what will happen is the net effect will the momentum will still win and it will take you out of a minima local minima and tide you over and let you continue your journey now you say well that is well and good but what happens here because here also it will have momentum momentum will take it up but what happens here because here also it will have momentum momentum will take it up right gradient will try to bring it down gradient will bring it here momentum will take it up but that is okay it will just swing back and forth and finally stop here does that make sense guys so we realize that momentum is a good thing but there is something else we can do But there is something else we can do. What we can do is when we are learning, suppose we are running 50 epochs in a vast lost landscape, you randomly initialize the weights, the parameters. You know that you have picked some very odd point in the lost landscape. By the way, should i bring up that visualization again guys as a as a recollection would it help let's do this it's worth knowing guys this is the heart of this neural network theory we need to get this right make sure if you don't understand stop me ask again discuss with each other discuss with the yes uh just one quick thing i i doubt if i would follow uh you know if i don't ask this question the only thing is there was a delay between you know the your audio and the video and the two uh arrow marks that you draw just now uh could you repeat that also the two arrow marks that you draw just now, could you repeat that also? The two arrow marks, the momentum and the gradient. Yes, and absent-mindedness is not okay. See, what happens is if you have a marble rolling downhill, it has momentum at this point, which way is this momentum taking it? It's taking it towards this direction, right? Up in this direction. And which way is the gradient? The gradient is taking it it's taking it towards this this direction right up in the direction and which way is the gradient the gradient is taking it which direction the minus gradient is taking it which direction downwards yes right so what you do is if you have sufficiently high momentum it will sort of cancel out the it will slow it down this gradient will slow the momentum, but it won't completely eliminate it. The momentum will still win. The marble will keep rolling. Thanks. That's a basic intuition. Do you see how this physical intuition comes in here? Actually, if you get the intuition, the rest is just algebraic equations and in fact, not terribly important. We'll write it carefully and we'llic equations. And in fact, not terribly important. We'll write it carefully and we'll get it right. But it's not terribly important. So the first thing we learn is that we need momentum, isn't it? Let's see that. I'll bring up the visualization and we'll play that game all over again just to recollect. Ah, look at this. How many of you took the time to play with this beautiful lost landscape? Isn't it amazing? Do you look at this log? Just to recapitulate, guys, look at the sheer beauty of this. It is obviously a very high dimensional lost landscape that has been projected down to 3d so remember that it is not 3d it's a very high dimensional that through mathematical magic somehow been projected down to 3d where is the minima the pink is the minima isn't it the blue is the the deep blues are the highs let us actually do gradient descent the highs let us actually do gradient descent right so let's start descending from here what happens uh uh what happened here stuck very much you got stuck let's try from here again you got stuck repeatedly we are getting stuck right now let's see what happened what why it got stuck do you notice that if you look very carefully there is a valley here do you see the plateau here there's a plateau or a tiny little valley little bump pothole kind of a thing and unfortunately our not so smart descent got stuck here so what are the what are the things that we can do one is we can take bigger steps so you know a little ant can get stuck in a pothole but you would imagine that if you come with a big truck with big wheels it's unlikely to get stuck in a pothole right it's making big steps right or imagine that you have a dino walking the streets or a elephant walking the streets it wouldn't even notice a pothole the trouble is it's making big steps moving forward so let's try and play with that and see what happens what we are going to do is we are going to give it some first of all let's decentrate scaling panning real rotation let's do one thing let's give it some momentum let's give that marble a chance and what we are going to do is we are going to start at exactly the same place where did we start did we start somewhere here in the beginning maybe i'll start right here just so that you know this is it what happens do you notice that it went further this time around it went a little bit further but unfortunately it still got stuck maybe some more momentum let's try that is that what's going to do so asap when you set that momentum it's going to be constant throughout the journey, right? Yeah, for now, for now. Okay. But we will actually revise that. So hold that thought in your mind. Today's lecture is all about, it's very fascinating, actually. I find it very, very fascinating. So let's try to come down this path again. And I'll do exactly the same point and see how much it helped. For me too it's learning. I haven't done this experiment before. I realized momentum. Do you notice it came much further? But it still seems to be getting stuck because once you hit a deep enough pothole there is no escaping it isn't it let's look at it from the side see it came way way further than before but it got stuck here what is it that we can play with hey we can we forgot we did not look at the learning rate well let's make it even though it momentum, let's give it a high learning rate. Let's give it a big learning rate. Maybe I'll do ridiculously high learning rate and I'll start at the same point. Let's go here. That doesn't seem to be helping what is happening guys let's look at it what is happening it's dancing all over it's hopping hopping bouncing and going everywhere except the minima it even touches the minima and runs away from it do you see these Yeah. So this is the problem when your learning rate is too high, right? So now let's try the same problem. And I want to take the same spot. Where did we start from? Somewhere here, right? This point. Now we are going to... Yeah, go ahead. In case the learning rate stays this high, is it going to be any point in which or does it remember all the points that it it has traversed and maybe select the local minimum in the end no it doesn't that's what you would do what you do is you basically have to snapshot the model all along the way that is a terribly inefficient way of doing it so there's a better way suppose i make the rate more reasonable see i'm decreasing the learning rate in the lower right do you see me do that let's take a number that is more reasonable 3.3 i'll start at the same point we started here or there i forgot which side left or right i started from here, right? Okay, I'll start. Yeah. What happened? Yeah, we came down with momentum. We didn't get trapped in local minimas, little potholes along the way. And look at this. We never got trapped. We had enough momentum and our learning rate was good we are still bouncing around the minima look at this we if you look at the coloration it is still not sure which point is the minima is bouncing around right so so go ahead i think for a you know like for a general problem i don't know maybe you covered I think for a general problem, I don't know, maybe you'd covered that point. For a general problem where we don't visualize this kind of a loss function, right? Starting with a big learning rate and gradually reducing it in our journey and the momentum helps. Is that a general solution? That's sort of what we are coming to. So from this, we are asking the intuition. So what are we learning? If you look at it, when in the beginning part of the journey, see, suppose you start from here. Let me take another point. I'll start from here. Do you notice that you got trapped in this place? High up, you got trapped. So at this moment, you would really hope in the beginning of your journey, you know that you'll start at some very inefficient place. At that moment, good momentum, good learning rate, they all help you. High learning rate helps you. It gets you over the pothole the trouble is as you progress in the learning after a little while a big learning rate fights you it doesn't let you sit anywhere near the minima it makes you bounce around so the intuition that you take away from is, let's do one thing. Let's have an adaptive learning rate. In the early epochs, let's have a high learning rate. But once we come close to the solution, because high learning rates will help us get over all the false minimas and hopefully get us closer to the global minima. Right. But once we come come there then let us slow down let's not take big steps if if only we could have an adaptive learning rate that would be to a great advantage would you agree does this make sense guys so that is one lesson that the learning rate cannot be a constant throughout the epochs. Let us change the learning rate at each epoch. So and how we change that it is called the learning rate schedule. The formal term is learning rate schedule. But all of these schedules start with one principle high in the beginning progressively smaller as you come towards the end of your epochs because the hope is towards the end of your epochs you are very close to the solution right so to to be able to modulate the learning rate to have it adaptive based on the epoch you are and at each epoch or progressively bring it down you you are using a adaptive or you're using a learning rate schedule that's a formal term used pytorch also the api will call it a learning rate schedule now there are quite a few methods to do learning rate schedule, and I will walk you through one by one, each one of them. Before I do it, I want to mention something, two problems that happen in the world of gradient descent. One is the problem of exploding gradients. If your gradient is too big, it's tending towards infinity. However low a learning rate you take, you're still taking a giant step. Does that make sense? Because the step size is learning rate times the gradient. Isn't it? Are we making sense, guys? Is it because the valley is too deep at some places you notice that it is look at this look at this surface this part doesn't it feel almost like climbing mount everest where my mouse is right so there are regions that you can't avoid where the learning rates are where not the language right the gradient size is very high positive or negative it's very high in this you don't see very strong positive there are strong positive gradients see you see on this side if you're bouncing off and going up, there are strong positive and negative gradients. But it's just mountainous. In this high mountain range, gradients can be very, very steep. Practically, vertical fall means the gradient is close to infinity. So what happens is when your gradient is close to infinity infinite yeah so what happens is when your gradient is close to infinity even a modest learning rate will make you take giant steps or in situations when you are doing the back propagation and so forth your gradient may actually become infinity it becomes see computers don't have infinity they have a max number and those max numbers are intractable. The learning becomes haphazard, like it becomes problematic. So that is one problem. The other problem that you have is that of vanishing gradients, the opposite problem. Vanishing gradients is when the gradient tends to zero. And that too happens. Look at this. Do you see a lot of places where the gradient is close to zero? All these little valleys, local minimas and so forth. Right? So you want the gradient to vanish at the true minima, not just about everywhere. Not, you know, not get trapped into all sorts of places so that you stop making progress now vanishing gradient is a problem in back propagation in neural networks it's a nuisance because you're trying to propagate the gradient at any one stage if the gradient is already close to zero the layers behind it will not learn anything because zero, the layers behind it will not learn anything because zero doesn't transmit any further signal back, back propagate any further signal. Go ahead. What are the local minima are by definition? In the loss landscape, yes, but it becomes very practically, right? Imagine that one particular node and there for its parameters, the gradient vanished so it has stopped learning it can't learn so that neuron practically becomes a dead neuron and the it starts affecting the neurons in the prior layers because this is not doing anything it's just a dead neuron sitting there right so these are practical realities and so there is a whole bit of theory why and we will let us go through that now carefully. Now that we have done this, but keep this intuition in your mind guys. Observe the fact that neural networks are highly highly non-convex structures. The lost landscapes are very anything but like my beautiful convex bone right is the antithesis of that so with that intuition there and i'm deliberately going slow today so we get this right let's come back to it now what can happen let's go back to the basics and see what can happen and there are quite a few learning so see let's go back to this equation our equation was original equation so i will now see i wrote the equation as w next is equal to w minus alpha gradient of the loss this but so that you can review from this new textbook they use a new note they use a slightly different rotation they call it theta right and instead of calling theta tilde they say theta t plus one that is in the next iteration is equal to whatever value of theta is in the previous iteration minus and the alpha goes they call it eta this is the word for that is eta eta it's a greek letter eta is the learning it is still the learning rate and this is still the loss function but loss function is a function of theta right so loss function is still a function of theta right instead of w so it is just w gets replaced by theta and alpha gets replaced by in this book's notation alpha gets replaced by letter right so we will follow this convention nothing new so just for one moment absorb that I have done nothing new just uh this book follows a slightly different convention and you'll have to get used to the conventions of different books and different things so long as you can recognize the pattern you can always map back to your language so take a moment to absorb this because i want the reason i'm using the notation of this book is so that you can go back and review it and the next book you pick up it will use its own notation right so you'll have to become familiar it's like you know you're reading your colleague's code he doesn't follow your naming convention so you have to get used to his coding style so it's the same thing so far so good guys yes so now what it says is every time you take a step so this is step t at step t now what is a step remember our two main loops were for epoch epoch epoch i in let's say epochs let's say epochs is equal to a bigger number let's say 100 right example epoch for each epoch for step like for batch mini batch many by j in data set do the four crucial steps the inner loop loop. The inner loop, I'll just put it here. What is that? Prediction, y hat is basically your, whatever the function is, function of the, whatever current values of theta are, and x, like the input. Input goes in, given whatever parameters you have, if this is the same as whatever weights you have you realize that the output is a function of the input and the weights that is the number one step now what do you do the next is loss loss is some loss function of y hat y the actual labels right this is the prediction this is the actual what do we do next what is the third step compute the gradient gradients and what is the final step update and in the language of this new thing this is equal to theta t minus eta gradient the step step of learning now let's index the step of learning with t the the t t plus one value is the tth value minus this so do we, I hope, by now, this should be fairly familiar, this is machine learning. R. Vijay Mohanaraman, Ph.D.: And, especially in the neural network sense it is with it is true for all machine learning, but here we are talking your networks, this is how you train so far so good guys now comes this question if eta the learning rate is not going to be constant we just decided that in the beginning the learning rate should be high then progressively it should decrease right so what we really want let me just write it, from intuition, from intuition, intuition gathered where? By looking at that loss landscape. We learned, we want something like this. Suppose this is t, the step, step one, two, three, whatever, t is this. Step, step, one, two, three, whatever, T is this. And this is the etta for that given value of T. What we want is that the learning rate should start high and at the end of the epochs, it should end low, right? So now I'll put the constraints constraints what would be a good way to play with the learning rate do you think we should do like this no well you don't know peculiarly right it turns out that your first reaction is no, there shouldn't be it. You may say, well, this is a better one. But maybe this is certainly bad. This you don't want to do. Who knows? You don't want to increase and decrease it or something like that. What is a good learning rate? Or should we go like this? don't want to increase and decrease it or something like that what is a good learning rate or should we go like this right so i will mention right or the one thing is if you don't play with the learning rate at all then what happens it remains the original thing that we have been doing so far which we in hindsight know is not a very good idea. The initial learning rate and the final learning rate remains the same. Right? But we realize that gets us into trouble. So now what is a good learning rate? People have learned from experience. Some of them look reasonable, like the yellow one looks reasonable. The green one looks reasonable they have names actually this is the exponential decay decay this is obviously linear but linear is rare i mean i don't know you can play around with linear you can see whether it works there is actually another learning rate which is very fascinating it doesn't come, but it comes down in steps, but I need a color for that. Maybe I'm exhausted all color. Maybe I'll use white. Yeah. So, there is a learning rate that says like this. It just comes down a few times. You see that? it just comes down a few times. You see that? It takes a stepwise journey down, but it never actually goes to zero, right? So this is the step, stepwise, and there's a formal name for it. I'll look and tell you. But one that surprises you is that something that oscillates like this you know your first reaction to the pink one would be that that can't be right isn't it yeah this one can't be right but counter-intuitively there is quite a bit of theory that actually these learning rates are pretty good. A learning rate like this and there's a whole broad family of them. And so the word that is used comes from intuition from thermodynamics and material science, it is called annealing. There's a process called annealing. What is annealing of metal? See, if you have a metal that is very brittle and hard, and you want to make it soft and ductile, it's stretchable and nice nice. The reason it is hard, this is a bit of physics, is because when you cool a metal, like you know, you purify a metal and you cool it, it has something, it doesn't have a perfect crystalline shape. Right? So what will happen is it will have this defect. There'll be a micro crystal pointing this way another micro crystal like this another one like this so it won't form a nice joint lattice structure so there'll be little sub lattices and they will the boundaries at which they meet are called the defects and those defects contain a lot of energy so what has happened is that this entire metal it has cooled to a equilibrium i mean a stable state which is actually higher than the minima the real minima state would be a perfect lattice right one continuous light is no tension and there's none of these defects present in them so what people do is that they will reheat the metal and then use some form of cooling, either slowly cool it down or they will quench it for copper, put it in cold water and something like that. But all the time what they're trying to do is they're trying to reduce the number of defects, crystal defects. crystal defects right and when you remove the crystalline lattice defects it becomes more and more a more perfect lattice structure relatively speaking and the more closer it comes to be defect-free a more geometrical lattice structure the more it has uh ductility and the good properties that the metal is supposed to have right so and those energy states are low energy states they're minima's in the energy level whereas if you just take a piece of metal which is hard and brittle it shouldn't be it has just stopped a cooled off to a high energy state now does that have a parallel to what we are doing we also have the same situation we we fear getting stuck in local minimas so what do we need to do we need to reheat essentially the thing so that it bounces off and the the atoms start diffusing again and then gradually they get a chance to recrystallize and hopefully at a lower energy state with less defects. The same analogy is here. Now, suppose you get stuck in a local minima, right? Lots of local minima. You're here. What do you need to do? In a local minima, you have a certain learning rate. How do you escape out of it? Reheating is the same as increasing the learning rate are we together right you can i mean it will have past momentum but suppose it stopped here what you want to do is by reheating means you're exciting it you're forcing it to just bounce around a little bit and search for a better minima when it does that it will bounce to this maybe get stuck here then bounce off it and finally get to the minima but what what will happen when it bounces off here and there right it will skip it will stick there it is not going to jump back to one of the sub-optimal minima so this is the process of annealing and there's a vast amount this is simulated annealing because we are not doing it with metal we are doing it with a loss landscape our learning rate and progression we are trying to anneal the whole thing people use the word cosine annealing and there are many variants of it many cousins and many friends of it okay so this topic playing around when we say that that we are going to replace theta t plus one is equal to theta t minus not not the fixed learning rate but a learning rate sorry learning people use the l is unfortunately the symbol l is, which is a function of the starting learning rate and which step are you at? How many steps have you taken so far? So the idea is that at each step, you'll keep changing your learning rate. For example, here, the green line, it is at each step, it is decaying the learning rate. The yellow one is also decaying the learning rate. It is some function times the gradient of the loss function right it is this so this is called learning this function is called learning rate schedule learning rate schedule. Right, very important thing. It's one of the things that people often miss and you will often find that books, most of the books they either gloss over it or they don't talk about it so much, at least the older books. But the reason I'm recommending you guys get this is this book very nicely explains the learning and the various learning rate schedules yeah pytorch has excellent support for it all the good standard learning rate schedule functions are built in the the green one is built in the white one is built in that that weird oscillating one the cosine annealing is also built in. And there is one more, something called plateau learning. I'll tell you about it. That also is built in. And there are many more that are built in. So it's lovely. The beauty of PyTorch is when you scratch the surface and go deeper and you see all these treasures, then you begin to value it more. So obviously,flow also has it so these two are the sort of competitor ones they have a wealth of treasure built into them so so now let's take examples of learning rate schedules we have it's 906 i will go over them relatively quickly and you will see so let's take the green one the green one in this picture when you look at it how is it doing it's exponentially decreasing isn't it what could be a function for an exponentially decreasing learning rate do it minus six go ahead somebody said something please go ahead no okay so e to the power minus t very very close to it what you do is you say that the learning so let's take the let me use green color so it will match what we are saying. Exponential decay. See, if you're a physicist or mathematical physicist, this, if you ask them, I want something to go down, their basic instinct, I don't know, for whatever reason we are trained not to think linear. We'll always think exponentially decay, right? Because most of the things in our world in physical world they tend to decay exponentially. R. Vijay Mohanaraman, Ph.D.: So you could do it in many ways, it is basically the learning rate at a given point. R. Vijay Mohanaraman, Ph.D.: At a given step D is the original learning rate which you want multiplied by a decay factor. want multiplied by a decay factor. Now, one of you said you could do e to the minus something or the other decay factor, right? All of those are valid, but this also works. You take a certain gamma, which is the decay factor, and you exponentiate it to the power t. By the way, a gamma to the power t, you realize can gamma to the power t you realize can be written also using e how can we do that let's say y is equal to this log y would be t log gamma and so y would be e to the power t log gamma isn't it so your intuition is not far off right and if gamma is if gamma is between the range zero to one is smaller than one right if gamma is zero obviously bigger than zero what happens if you take log of a number between zero and 1 what is it it's negative and so e to the minus negative something step so it's a decay function but this works so let's take this as an example let's say that your gamma is 0.1 at step at step t is equal to one what will be your learning rate is it positivity or negativity please step which step you are on so start start step zero so l and not zero the first time one it will be 0.1 to the power zero is equal to just eternal because this will result to one anything to the power zero is one isn't it so this is your initial remains your initial learning let us say not one at the first time this will be uh naught times gamma to the power one which is basically 0.1 times the initial learning rate so it means that at each step you took the learning rate down by 0.1 isn't it then l naught 2 is what it will be you can convince yourself that this is 0.1 squared times right so likewise continue l 5 2 what is this uh eta naught sorry 5 basically step 5 0.1 to the power 5. Now, how do these numbers behave? 0.1, 0.01, 0.00001. You see how quickly it decays? Learning rate decays. Yeah, that is it. So it's a decaying learning rate. Now, typically you don't take gamma this small, right? You take gamma a little bit. This is too big. You take gamma a little bit like, I mean, it depends how you do it. 0.01 point, whatever it is, you can decide. The best way to do that is to decide what you want your final learning. Suppose you run for 100 epochs. Let's say that the number... Guys, this is very fascinating, so I hope you're paying attention. Number of epochs you have in mind is t say i don't know 100 right then you start let and not the initial learning rate be 0.1 let's say that your final learning rate where you want because you don't want the learning rate to be too small. What happens if your learning rate is way too small like 10 to the minus 10? In trouble because close to the optimal solution gradient will also vanish and your learning rate will also vanish. So the system will stop learning. So you will actually want to take a reasonable learning rate let us say that the learning rate that you take is i'll say 10 to the minus 4 right and this is equal to 10 to the minus 1 right so now the question is you decide to take these steps what do you want according to this formula your learning rate n eta min is equal to the learning rate gamma whatever the gamma learning rate is to the power t t being let's say 100 times eta naught so you you have a min max in mind starting learning rate and file learning rate and the number of epochs so you realize that from this relationship you can calculate gamma isn't it what is gamma gamma is essentially it is equal to to min over eta naught basically one one over t or another common sense way people think of it as a tth square root or it is the same as eta min eta naught to the power one by t you agree with that right so you can now feed in the numbers and figure out what is a good item and that is the way people do they they have a number of epochs that they have they want to run in mind they pick an initial learning rate they pick a final learning rate and so they can find a good gamma and it works right it works quite well so far so good guys it's just that see guys these are just mechanical details there's nothing magical about it so long as you realize that we want to do um exponential decay this is the way to enforce exponential decay good so far guys yeah okay so now that is that and you say well does it actually make a difference and why will it make a difference? It makes a difference because. You know, the analogy that people give and this book also gives you often get in the industry more or less the right analogy. It says that see when a train is coming, like, you know, you all take the BART. When BART is coming to a station, what happens? It slows down. Otherwise it will overshoot the station. You don't come towards the station at full speed, the same speed at which it is crossing vast distances. A train, when it is going through basically middle of nowhere, it is at full speed. Because it should be at full speed. But once it is out of the wilderness and it is coming towards a station, what should it do? It should lose speed. Does the intuition make sense? It should be losing speed. So the losing of speed is slowing down the learning rate you're coming towards the target slower you're approaching it so that you don't overshoot it is the intuition making sense guys yes so now let's take the next one the step one by the way i leave the linear one i i as a exercise for you think how what is the equation that you would write to have a linear decay of learning rate. Whether it's a good thing or a bad thing is separate, but just as an exercise, try to work it out. It's very easy. You'll work it out, but do it. Now, what about the step one, the one that takes two steps? experience shows that taking two three steps works quite well actually sometimes all you need to do is not exponentially decay the learning rate sometimes some people say well too much hard work let us just for first 50 steps let's keep one learning rate next 50 steps keep another learning rate and the next 50 steps keep another learning rate. And the next 50 steps, keep another learning rate, right? So learning rate, you change after 50, 50, 50 epochs, assuming that you're running it for 150 epochs. Are we together? Great. When you do that, guys, just give me a moment. This needs to be a virgin. Please pause it. One of my work team members in my team has just had a baby girl. He's very excited and he's giving a bit of news. It's always such a great, great experience to be a father. So the next learning rate we'll take is this, a step drop at this. Like just make a few steps don't get too fancy so what color did I use for steps white so well let's write this notes in white step adjustment let me write so now there is there is a bit of there's a one problem though with the exponential decay what happens is when you decay so slowly it's a little bit erratic for reasons that we won't immediately go into but i invite you to read in the book uh basically what happens is that you you're losing momentum and you are like you don't know how well you're converging but anyway for for many reasons we'll talk about it in the second pass when we go over this in greater detail so i will say stop drop step drop and i'm literally using the conventions of this book adjustment it's defined it's defining quality is it gives you better smoothing. Better smoothing. What is smoothing? Which smoothing? When you plot the accuracy, for example, let's say that accuracy is your measure. And as the learning progresses, as S progresses, what happens is your learning your accuracy could be going up it could be oscillating or it could be smooth right which one it is depends upon what kind of a learning rate scheduling you do amongst other factors gradient we haven't touched the gradient function itself we'll touch that actually i'm surprised we already took so long so we'll keep it for the next time but okay what is this smooth smooth it's it basically empirical evidence is it's a little bit smoother away there now this is very simple if you want to just take a few simple steps you need to say after how many epochs will you take this step let's say that you want to take step after every 50 epochs then how would you write so your s is 50 and you write your equation like this here eta t is eta zero the initial learning rate right uh which is basically this is your uh this is your l eta naught t is equal to this these are just notations and what you do is you still have your gamma but gamma the exponentiation of the gamma is not P. R. Vijay Mohanaraman, Ph.D.: But it is P divided by s and are you guys familiar with the floor symbol. R. Vijay Mohanaraman, Ph.D Floor is given a floating point number. The integer, so suppose it is 3.14. Forget the fraction. What remains? Three. That is your floor. You round it off, round down to the integer. You round it off, round down to the integer. When you round down to the integer, it is called float. So it's one of the things in your first like computer science 101 class you must have been taught but we tend to forget is the floor sample. Now let's see what happens. Suppose your S is 50. Then let's take T is T value 23. What will happen? What is gamma 23 divided by 50 floor? Can somebody tell me what is this value zero zero yes this would be zero so anything up to 49 will be 0 0 to 49 will be will give you the floor will give you zero 50 to 99 will give you what 50 divided by 50 is one right and 99 divided by 50 is still one point some number less than two isn't it so therefore the floor is still one then 100 to 149 floor is two right so now what happens look here there are only three values of the floor of this eta of the eta that you will get gamma what is gamma to the zero one and gamma to the two so this is one this is well gamma and this is gamma square right so let's say your gamma is at zero point uh pick your gamma let's say you're zero typically gamma in these situations gamma that people select is in the range of 0.1 to 0.5. Why? Because let's say that you make it 0.1. What is 0.1 square? So the first step will be 110th and the second step will be 100th isn't it the learning rate in the first step it falls down to 110th in the next step it will fall down to 100th does that make sense guys yes that's it and then you can work it out for 0.5 first step it will be half. Second step, it will be quarter, right? So the bigger the number, the slower the damping of the learning rate. So this is called the step drop adjustment. And then comes the crazy one, the cosine annealing, which actually, you can imagine that if you bounce around with the learning rate, it's not going to be terribly stable. But. Surprisingly, it gives you very good results and there is a whole body of research into it, and the reason it works is quite interesting. If you keep annealing out of local minimas, why would you want to do that? A whole bit of mathematical argument and research and experimentation has shown that local minimas exist close to other minimas which are better than this local minima. So there is a whole cascading set of minimas that you can journey through it is not that the local minima is isolated and then you'll climb a long hill and then go back to the next minimum it isn't like that and you can see it in this visualization in this real that's why i like that visualization where is it gone all right let's revisit this look at the local minima do you see these local minimas do you see how they are close to each other that next to this local minima is another minima that falls here next to this minima is this minima bigger minima right all these minimas they are not i mean i don't know if you look at it this angle, you see that these minima is all pretty close to each other. Isn't it? Right. So it means that if you bought if you boil yourself out in using the physics intuition, if you really boil yourself out of a local minima, you're on your way to the next minimum isn't it right and that is the that is the intuition behind the behind the next one which is the cosine annealing remember it's a very physics intuition here. So its quality is great accuracy. It actually ends up leading to models that have very good accuracy, but rather unstable, but can be rather unstable. Right? You have to play around with it. So what you do is, you want to make sure that, how does a cosine wave go? A cosine wave, if you remember, your basic trigonometry, at zero, what is cosine of zero? One. What is cosine of pi by two zero sine of minus pi i'm sorry pi pi is minus one right it is minus one here and then it again starts climbing back up Raja Ayyanar?nilavarapu?iqb2'9c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c?a?c? it goes back to so this is one entire wave like one wavelength right so this is 2 pi are we together now i wouldn't belabor you with those basic equations of motion wave motion and so forth suffice is to say that if you remember a formula like this y is equal to cosine 2 pi f t you are actually doing very well this is t this is y f is the does anybody remember what the word f might be connotating frequency frequency how many times it beats in unit time right so we will so now the problem is how do we use this well we don't want negative learning rate that doesn't make sense that's silly so what we do is we take a baseline. We take this amount, this range, minus 1 to 1, and we remap this range to this range, to eta naught. So the maximum is eta naught, and the minimum is whatever value we choose. So pick some minimum learning rate that you have in mind. Right. And now how do you map this to this? Oh, gosh. It is basically as a simple way to scale it. But what people do is the formula that we use is not that hard. Raja Ayyanar?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum?aum and you say eta not minus eta min right which is the range which is the range r because that is the range now what is the amplitude of this wave amplitude is half this maximum swing isn't it that is where the half comes from amplitude so this part becomes and again i am using reminding you of things you may have forgotten this is the amplitude of the wave right and finally the of course the cosine well i have screwed myself because i have written it cosine let me just write this term properly in a lower line and you will convince yourself that this works this is what it this is doing t right is equal to min plus because this is a minimum you want to start half the amplitude amplitude being min and the way i look at it is is the amplitude of the wave times the cosine cosine will be what and so one plus cosine the one plus cosine guarantees you see if cosine goes to minus one if you add one to it what is the range now from zero one to zero to two and a half of that will be 0 to 1. Isn't it? So which is what you're trying to do? You do 1 plus cosine and the rest of it is obviously by now the intuition is trivial. You remember the pi that I brought in? 2 pi f. So I'll let you figure out in this what is the frequency uh now a t max is what is the number of epochs that you want to run for right so let's say your t max is 150 or whatever it is do that right so this equation looks very complicated but if you are familiar with cosine wave this is a straightforward equation right right think about it play with it review the book and when you do that and what I would like to do is show you some beautiful visualization that this has the trouble is t max now becomes the hyper parameter of the model of this learning thing means you need to scratch your head and ask what is a good t max and play around with it so one intuition that people do is they ask how many oscillations how many times in the world of annealing people ask how many times you want to reheat and cool the system right the physical intuition how many times you want to re-increase the learning rate and bounce back you pick a number that i want to reheat it or do the annealing five times ten times or whatever it is right and let us say that you say i want to do the annealing two times right or whatever number of times so what you do is suppose you want s dips s dips means s times you want to go up and come down then there is a formula you say that your t max in this equation is t the number of epochs divided by 2s minus 1 so if you want two dips two times two is four minus one three so total number of epochs divided by three, plug it into this equation. And you can do this, by the way. You can derive it on your own if you understand what cosine is. These algebraic details don't matter. But the good thing is you need to end in a dip. Means you want to end your learning like you've at your last epoch. you want this learning rate to be at its minima are we together so you keep bouncing back from minima maxima minima but you want to end in a low note low learning rate because presumably you are in the you're in the valley right you are in the bottom you don't want to bounce back out with a turning rate you want to sit there you can say okay i'm done so this is it now let me do one thing uh today and there is one more plateau learning rate i don't know we are running out of there let me first show you guys the visualizations because i don't want to miss that a little further down little further down oh this one here we go yeah 2s minus 1 yeah asking how many dips do you want how many bounces do you want now all of these things let me visualize it let me bring the book and we'll visualize it time to look into the book. There is one more. It's called the plateau learning rate, which is very interesting. Let's do it next time. And then we have to still do the momentum-based methods, which we haven't done. This is the second half of the story. Guys, next week, I don't know how many days I'll be missing. I certainly won't be there on Monday. But the reading thing is, you guys must read these chapters um kyle and kate they will create some lab on the scheduler kyle i'll explain to you how to create some labs walk people through it at the same time there is a homework the california data set housing data set set, you need to, the homework for everybody is, and Kyle, work everyone through it, just create a simple neural network, three, four layers, two, three layers. And as a regression problem, just using the regression neural networks we have, apply the regression neural net to the California data set and see how good a model you can build use on the California dataset. California dataset is there are certain features about a home and you have to predict the price of a home. Okay. For your housing dataset. You remember that California housing dataset, right? From the- Yes. All of you must be remembering it from ML 100 to 100. So let us bring that back. In this week, this is a project for all of you must be remembering it from ml 100 200. so let us bring that back in this week this is a project for all of you guys please try it all the code is there the regression code is there neural network is there use that and apply it to the california data set and try to do it on your own guys and finish it and then of course take the help of teaching assistants do it all right so now that is your homework and if i return before no i don't think i'll return on tuesday itself but just in case i find i'm going there to seattle to find housing for my daughter but if i come back before that then we may hold a Wednesday session but don't don't be hopeful it's quite likely that the whole of next week will be washout but a Kyle and Kate they will be with you and they'll be holding some sessions so so have a session for this to help sessions. There'll be help sessions exactly. Right. So help sessions and when I come back, I'll obviously continue from next week where we left off. So let me make sure that I got my equations right here. See what happens is when you create a fully connected layer right if you if accuracy is your measure then do you notice that i pay attention to this part um look at this what is it doing? Is it going? Sorry, why is this not taking up? So this is not a very perfect tool, but is it? Is it smoothly learning and improving the accuracy? Or is it sort of bouncing around it? improving the accuracy or is it sort of bouncing around it? At each step, the accuracy goes up, goes down, goes up, goes down, what is happening? It's a bit stochastic. It's sort of bouncing around, isn't it? The learning accuracy for each epoch, the test accuracy, what matters is on the test data or the evaluation data. It's not doing well. It's sort of bouncing around. That is the problem that we are trying to solve. When you just use a simplistic fixed learning rate, fixed and no momentum and so forth, you end up with a situation like this. We want something like the red, which would be the ideal situation instead what you see is this it's just not using any of these things using just a simple plane vanillas to gradient descent yes now what happens is we will leave that. Yeah. See, what happens is that now let's look at this and I think I can zoom into the top one for the time being. No, I'll remove it. Yeah. So suppose your learning rate is high. Look at the picture on the top. What happens? You're taking giant steps. So do you notice that your trajectory, what is your trajectory? Are you reaching the minima? The minima is in the center the deep green place are you reaching that or you happily bouncing around it with energy do you notice that you're bouncing around it are we together guys so if you on the other hand if you, on the other hand, if you now, and let me remove this, look at this, look at the picture here. And if you look at this a bit more carefully, look at this part. Do you notice that the steps are becoming smaller now the size of the step also depends on this on the gradient if the gradient is high then you will be forced to take a bigger step but at least the learning rate as it progressively decreases do you notice that it zones into the solution? It goes and hits the solution. It doesn't take a straight path to the solution, but still it at least reaches the solution, unlike the figure above. So that is the value of a decaying learning rate. Now, learning rate now we talked about three different learning rate schedules let's look at those so one is the flat one like you don't change the learning rate at all then there is the blue one is the exponentially decaying learning rate and the green one is the stepwise isn't it the stepwise so the red is no learning no learning rate schedule just flat out learning rate this is how they look by epochs remember learning rates you change on a epoch basis then comes Then comes. Now let us bring the this crazy cosine one also. Now that looks pretty crazy to anyone till you think about the whole theory and you realize that the lost landscape is filled with local minima. And then if you have a background in material science and physics, you say, aha, 100 years ago, we figured out how to solve this. We need to do annealing. So a cosine annealing is quite popular and its variants are quite popular. They do the job. What you do is you essentially reheat it. Reheat the learning process. You just accelerate it a bit, then again cool down again accelerate you do all that so you hear your learning rate is bouncing back and forth are we together guys do you see right now what is the consequence of doing this let's look at this and I have highlighted a sentence now why is it that this whole bouncing back is good so we have learned and by the way the the hard math is obviously a lot to do with simulated any laying in the theory behind it but we won't go there so through experimentation and hard math we aren't going to look at there is a common phenomenon that suboptimal local minima exists on the way towards the better minima we saw that in the visualization guys on the way to the better minima you come across a lot of suboptimal minimas right so that is the point visually that you can see here so clearly. The book is saying so. So if we shrink and then later increase the learning rate and in my language reheat the system, you can give our model a chance to escape the current local minimum and find a new alternate. So look here, look at the picture above guys, this picture. And let me keep on. Do you notice that you start from here and you came here, if your learning rate remained fixed or any one of the other things, what will happen to you in this local minima? You will get stuck. Do you see that? But this local minima you will get stuck do you see that but this local minima is actually on the way to the global minima so if somehow you could reheat your way out of it and bounce out of it you would be well on your way to the better minima which is in the lower half of the picture do you see this when you do the cosine annealing or any any annealing technique the point of annealing is you you're always suspicious are you that you have reached the maxima the best minima you're always suspicious that you're trapped in a local minimum so what you do is you keep reheating and coming out bounce out a couple of times if you're truly at the best minima you'll bounce out you you won't be able to easily bounce out you'll stop there. Shubham Tulsiani, Right that's the point so here we go you notice that it gets a little bit into the local minimum it isn't that it escapes the trap altogether, but it reheats its way out of it and bounces on its way to the global minimum. heats its way out of it and bounces on its way to the global minima right or a better minima from there and it again points to the fact that we were seeing visually that there are many local minimas on the path to better minimas right so that is the work knowing about we won't go into the code aspects because we are going to eventually do it in the lab there is one more strategy which we'll talk about later next time and i want to see that show the experimental results yeah this part i wanted to show look at this see there is a rule in machine learning which is called no free lunch theorem means you never know what algorithm or which approach will work best data rules so any kind of a graph that you draw is very dependent on what data set you used but generally the plane sgd sort of oscillates a lot if you look at the cosine do you notice that the cosine, I don't know if the colors are very clear here, the cosine, I'll just point to this cosine. You see, this is the cosine one. It is doing quite well. It also has its oscillations, but it is doing quite well. But here, the green one seems to be doing pretty stably you see the green one is not that bad it's pretty close to the best one is doing so for this situation it is and the one that's doing the worst is it so happens is the exponential decay one in this situation right and then Right? And then the cosine one. Yeah, the cosine one is the best. And where's the plateau one? The plateau is the... And plateau is not far behind. It is the purple line that you can't make out on the screen but it is doing quite well it also so the top three winners are the cosine the stepwise and the plateau the plateau one i'll explain to you next time we seem to be running out of time and i would like to take questions now so guys is it fun did you feel you learned something fun today fun today yes yes sir yeah see a lot of it has to do if you want to be good in this field get your intuition from the math because libraries will come and go you know today's tensorflow python god knows what it will be tomorrow but if your foundations are strong you'll do very well because these things will remain and. Because these things will remain. Thinking about these things will remain. So we have covered only half of the part. Remember, we started the session by saying we are going to rethink the learning, which becomes a learning rate schedule, and we will even rethink how we update what we do with the gradient. So the gradient will become a different function. Did I say that or not yet? Yeah, here I stopped and said the eta, the learning rate schedule. But now the other part of the magic, the gradient, it turns out that leaving the gradient to be just be the gradient isn't good enough. We need to bring momentum in for obvious reasons. We went through the intuition, but all that. So yeah, I covered both, but the momentum intuition, we will now bring it down to details in the next session. And pretty much now we are coming to the end of the fundamental theory. I would like to finish all the fundamental theory in the next session, so that we start going to the neural architectures. We will do, after this theory, you'll find the architectures pretty straightforward, the convolutional neural nets, the recurring neural nets, and then the one architecture, the two things that I'll really focus on in this course, time permitting, one is the attention models and transformers. Today, they are ruling the the ai world and the next thing that we'll do is the graph neural networks i'll introduce you to that in this course so all right guys any questions uh as if uh quick question yeah uh i i don't see the previous classes YouTube recording. It's still a Zoom cleaned up YouTube recording. No, you go to the other. See, you are logged into the 2020 course, no? No, no. Asif, it will be. No, this session's videos, i've sent it to our joel he was busy for a week and that's why he's he he will be sending it this week to me i'll i'll upload it and post it on slack was that your question pravin but yeah yeah available you have access to them yes yeah 22 available you have access to them yes yeah you remember pravin that we didn't cover this last time yes yeah this was new here yeah so anything else guys any new things any questions What would be happening on the weekend? Anything or would you be traveling? Oh, I'm not. I'm flying out the day after tomorrow. Friday I'll be gone. Okay, so we'll have like help sessions Monday and Wednesday. That is it. That's right. And Friday, I mean this Sunday, there will be no paper reading. Okay. Any questions, guys? All right, guys, then. I apologize that we have to take a one-week break, but I'm actually taking a break after a long, long time. I think this is my first break in this year. I'll be back, then we'll continue.