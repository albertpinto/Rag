 This is Saturday. We are going to review the quiz for convolation neural networks. The first question is natural images tend to have inherent translation invariance. What does translation invariance mean? You guys are looking at my picture. Look at me. Do I change if I were to, if I go like this? Am I the same person or am I a different person now? Same. The same person. That is, in other words, as I move across horizontally on the screen, I remain the same person. So images, the objects in the images, they have translation invariance, isn't it? If you move them from one part of the screen, a picture to another, they would still be the same thing. A house will remain a house and a cat will remain a cat you don't expect a house when it goes to the upper corner of the screen to morph into a cat or things like that so that is inherent translation in various natural images have that next question Next question is, min pooling applies to an image, applied to an image tends to pick the darker features. See, if you are picking the smallest value in a window, which is min pooling, what will happen? You use it when the background is white and the features or the drawing isn't dark. And you want to end the features or the drawing isn't dark, you realize that most you want to pick or see the pixel wherever it is dark right The features are in dark. Somebody has made a sketch in dark on a white background. So that is when darker features from the image and then if you just apply it to an image let's say a flower or something what will it do for every four pixels it will pick the darkest of them right and because it picks the darkest pixel the darkest value it will tend to darken the picture isn't it so that is what min pooling does. Given and giving, oh no, there's a grammatical error. Given and min pooling. Would you mind guys if I fix it now because I won't get a time to fix it later. Might as well. Yes, thank you. Given min pooling, when it is applied to a region of the input it picks well it picks something we'll find out what it picks yeah given a min pooling window when it is applied to a region of the input it picks the minimum of the value is visible within the window. It is literally by definition. Right. So that's that. Min pooling. Oh wow. All the min pooling questions are together. Min pooling works best for obviously images with a dark white background. Because if the bright things don't matter, it's the dark thing that's matter. That is the case when you have a white background or a very bright background. Given a max cooling window, the opposite of this, when it is applied to a region of the input, it picks the maximum of the values visible within the window. Literally by definition, isn't it? Next is, consider a convolutional neural net with 10 filters applied to a color RGB image of 64 by 64. Each filter is a 5 cross 5 filter. Now, determine how many trainable neural network parameters are associated with the image. So the only formula in CNN that you need to remember is that, you know, the N plus 2P minus F over s plus 1 the floor function that's the only formula that i gave you in notes to be so here we have a filter is of length and with this channel is 3 therefore there are 75 each filter is of length this much so in in fact in this particular case you don't even have to look at the output image sorry this was this was a trick question. Most of the information is useless. You just have to look at the filter. If the filter is five cross five, right, then you have, and three channels, so you have 75 weights per filter, and each filter has a bias. And each filter has a bias. And so you have a bias term. So it's 76. And now there are 10 filters. So there's 760. In a deep learning, CNN is an acronym for convolutional neural nets, of course. I hope none of you believe that it was your completely neurotic neighbor. believe that it was your completely neurotic neighbor. So next is after the input has gone through the convalescent layer, the output is flattened before being fed into the fully connected layer. The reason for this is, and the real reason is, I mean, the dense layers can only take a one-dimensional vector, isn't it? So for a min batch, the congulation layer produces four dimensional tensor height, width, channel and batch size. Whereas a feed forward network expects a two dimensional tensor feature vector and a batch of them. Isn't it? That's how neural networks work when you're passing in mini-batches. So mini-batches are the extra dimension that always stay. But think intuitively. Your image is a three-dimensional object. It needs to become one-dimensional. So from three to one dimension, but then if you add the batch size, it will become from four to two. So that's the answer. the batch size it will become from four to two so that's the answer next is consider a convolutional layer with ten filters applied to the same problem assuming that we are using the same padding what is the same padding formula when do we use the same padding? What does same padding mean? It'll have the same shape. Yes, the output must have the same shape as the input. Number of channels may change, but the shape has to remain the same. Height and width have to remain the same. So each filter is a nine cross nine filter, nine cross nine. So if you want to have the same size, assume that we are applying a max cooling of size two, right, which is a standard, then what can we say about the output size and the number of channels? So you realize that if you're using the same, the output before the max cooling has to be 64 by 64 isn't it guys and then max cooling is going to decrease it by a factor of 2 and so height and width will become 32 how many filters are there there are 10 filters so there is this making sense guys think about it this way before you apply the max cooling layer the same same padding ensures that input and output are the same input is 64 by 64 so i'll put a 64 by 64 right and how many filters are there 10 so obviously there are 10 channels now and now once you put it through max what will you do it will cut the height and weight in half right so it becomes 32 32 and 10 channels so i've given all the the details here there the same padding automatically implies that the output size from the convulation would be the same as input so it will be this since there are 10 filters therefore the number of channels in the output attend max cooling a pool of two is a filter and so the stride is to therefore applying the same formula as a we get a final output of half that's that successive convolutions layer tends to have an increasing number of output channels isn't it the what happens to the image you tend to have smaller and smaller images the the input to the successive layers the outputs become smaller and smaller right from 64 you finally go to maybe 4 by 4 but the number of output channel keeps increasing this happens everywhere can you guys point to an exception to this one exception to this is the generator of the GAN remember in the generator of the GAN you run a convolation neural networks backwards isn't it do you remember guys that in a in a DC GAN not any GAN in a sorry what am I saying in a DC GAN architecture the generator is a convolation neural network run backwards Convulation neural network run backwards. Anybody remembers that? Yes. As if. Yes. So does that process to mean it's convolution? Yeah. You should call it decon. They call the operation, not convolutions for decon operations. So, uh uh that's some people i mean language they're a bit loose i've heard even people call it i don't know how correct it is to say that they call those things a decal let me take a decon network or something like that they'll say a location invariant feature extraction is a property of which of these neural architectures recurrent conduit this i hope is a no-brainer right the whole point of filters is that it will detect your edge no matter where in the image it is so it does location invariant feature extraction right which is one of the great strengths of modulation the condolation operation is by the way this is also something i mean just put as a side calculations are not the only things we are beginning to realize that transformers have a similar property if the if meaning wise two things are related in a sentence, you change the sentence in such a way that you preserve the meaning, those words still remain related, even though their positions have changed. So to some extent, this property seems to belong to transformers also. form or solve. Condulation operations are considered in deep neural networks. The operation as considered in deep neural networks differs from the mathematical and signal processing definition of the condulation operation. So the choices were false. Cross correlation has nothing whatsoever to do with CNN. That's totally wrong. In fact what we do, do mathematicians would call cross correlation. Another signal processing folks have it backwards. So one claim is that we do combulations, the other guys do it wrong. The third is that well, it is true. We lose an amount of accuracy too and damn the mathematicians. That's not true. The convulation of CNN matches the mathematical definition of convians. That's not true. The convulation of CNN matches the mathematical definition of convulation. That's not true. See, we don't do that in versions. But it really doesn't matter. It's true that we are not strictly the convulation operation, but the little extra bit needed to make it the strict condylation definition is unnecessary especially because of the translation invariance property of the filters so true but it really does not matter since the operations to make it strictly correct brings no added advantage so why not save those operations next question activation functions are not necessary for congulation neural nets since the main mechanisms are the congulation operations and the pooling operations. True, false? False. If you don't activate, you don't get nonlinear deformations. max pooling applied to an input image picks the writer highlights because you pick the maximum maximum value in a box in a window consider a convolution layer with 10 filters applied to RGB or 64 64 same problem assume we are using same padding in the input in a straight size of 1 each filter is a 7 what is a padding size to be so this is the formula of the padding size F minus 1 over 2 we did that in a notes if you use it so the answer sir namely yes oh there is a typo here. Why does it say one? I don't know why the correct answer. Maybe there is a bug in the way I wrote the question. Is it a multi-choice question? Hang on, let me go fix it in case I screwed up. One answer only. This looks okay okay but we'll leave it next question the images with the white black main cooling let's go okay we have to go much further down okay question 9 Okay. Question nine, the same padding. We did all of that. Question 10, successive convulation layer tends to have increasing number of channels. I think we did all of that too. Really doesn't matter. We did this. Convulation operations. 14, max pooling applied brighter. Consider convulation, this is is a formula applied application a real activation function cannot be used in corn etc of course it can be used and really does introduce non-linearity so that statement that it fails to introduce non-linearity is not true so this is wrong in both columns considering max pooling and average pooling, which of the following statements are generally true for images with a dark background? Max pooling tends to outperform average pooling, isn't it? So consider that in a convolutional layer, we are using a kernel size of five and a stride of one. What would be the appropriate padding size to ensure that the output of the congulation layer is of the same thing? Once again, just use that F minus one over two, right? So five minus one is four divided by, like, what is it? Two will give you two right so there we go consider a convolational layer see this this all comes down everything you realize that comes down to this this formula the if you can remember this formula this is all you need to know to do convolutions right so remember this formula that I gave in class. Consider a connet with blah blah blah layers, etc. I won't go into it. If you plug in the formula, you will see that this is what comes out. It's just a direct application of that. Convulation neural networks can be applied to datasets pertaining to? Well, images, video images video audio natural language processing and other types of data it is surprising how effective cnn's are people often think that it's only applicable to images and videos now it's applicable to audio it's applicable to words sometimes people are surprised that you can use convolutions for natural language processing and we will use that in this workshop fully connected layers in a continent usually follow the convulation so you know fully connected layers are the end so first you do feature extraction then you vectorize it you make it into a one-dimensional vector and then you feed it into the dense layers that That is it. So the purpose of the first part, the convolational parts, is to do the feature extraction. The part of the second one is your classification or whatever it is that you want to do. Given an average cooling window, when it is applied to a region of input, it picks the average of the value. This is by definition. Which of the following neural architectures is modeled after visual mechanism of living organisms as we understand it cnn cnn was discovered by studying the brain the way the brain of a cat responds to images average pooling apply applied to an input image smooths the image obviously Obviously you take the average. Average is a smoothing operation. Compared to a fully connected layer in a neural network, the convulation layer in a neural network tends to have far fewer trainable parameters. Isn't it? Why? Because the same filter goes all over the image. So that's a big deal people make about it, that in some sense it is doing parameter sharing between the neurons if you think about it. But that is what it is. It has far fewer, is there any doubt about this? We see that a typical convulation layer will have like 760 parameters that we just saw in the previous example. Whereas a typical dense layer will have something like thousands and thousands of parameters, tens of thousands of parameters. So for example, if you come from 512 layer to 512 layer, you're looking at, what is it looking at? You're looking at 250,000 parameters approximately. 200 and yeah, 250,000 parameters. Massive number of parameters, isn't it? Whereas here is 760, much smaller number. And that is it. Oh, that is it. Only 20 questions. Terima kasih.