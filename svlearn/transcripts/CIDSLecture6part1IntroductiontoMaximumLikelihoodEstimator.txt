 All right, folks, welcome to the sixth session of the workshop. Today, we are going to continue our discussion on classifiers. We are going to cover the loss function for classifiers. If you remember, we have covered the loss function for regression, but we haven't covered the loss function for classifiers. If you remember, we have covered the loss function for regression, but we haven't covered the loss function for classifier. It turns out the loss function for classifier takes a little bit more mathematical machinery to understand, and we are going to build that machinery from scratch. We'll reason our way through it today. The other thing that comes with classifiers is, what are the model metrics? How would you know that your classifier model is good? For regression, you remember that we built a model and then some preliminary measures were just quickly look at the r squared, look at the mean squared error or some square root mean square error, whatever, some flavor of it, look at that, I mean absolute error, and there were a few metrics you would look at. And then you would look at the residual analysis to see if the residual errors, they show homoscedasticity and lack of pattern. If they do show homoscedasticity and lack of pattern, then you feel good about it. You feel, okay, you're moving in the right direction. And then you finally, if you're in lower dimensional space you plot your model predictions over the data and you see how good your model predictions are over the data and for higher dimensions in one of the subsequent labs and i think in one last lap i did introduce the partial dependency plots we also learned about something called feature importance how would you how much does each feature contribute to the prediction is relevant? How much does it matter? So those were the things we learned in the past. But for classifier, we need to learn similar, equivalent things now. So that is the context for today. So the theory today is the review of last week's topics. Then I promised you that I'll make you friends with Emily. So that's there for today. We'll do cross entropy loss function. We'll do model metrics and discriminant analysis. Now guys, some of these topics are topics that you may have encountered. Almost all of you have taken some online course or are in some degree program or have been taking Udemy, Coursera. Almost most of you have taken Andrew Ng's class or some other such good courses. So you may have some background, but we will assume no background and we will develop the theory from absolute scratch for all of them. What are the what are the labs that we are going to do today, the labs we will do today is the California housing data set, which is a spillover from regression, then we'll do three labs, three specific synthetic data sets that I created for classification. And those are classifiers one, two and three, we will do that. So that is our scope for today. So with that there, let's now go to my OneNote writing stuff. I'm now about to get started. I'm searching for my OneNote on the desktop. There we go. So let us say what we did the last time. Sorry. What we did last time was, how did we end up here? Okay, a coefficient of determination. Let's go to the very end. Yeah. This looks like it. So if you remember, we talked about a distance function. And I'll start the discussion here. For linear classifiers, the most relevant, the decision boundary, what are linear classifiers? It is those classifiers that tend to build a straight, a hyperplane decision boundary. Intuitively think of as line, and now from there generalize to higher dimensions. When you do generalize to higher dimensions when you do generalize to higher dimensions it becomes a hyperplane so if you do have a hyperplane one way an elegant way to define any hyperplane in any dimension is to think of the unit orthonormal vector if you can quantify if you can have the unit orthonormal vector, which I'm representing here as beta hat, then what happens with that in place, you know the tilt of the plane is well established in the feature space or in your space. The only question therefore that remains is, there are still infinitely many planes that you can draw at that particular tilt in the hyperplane. You can fix to one particular hyperplane by now picking a certain distance from the origin, the origin of the feature space, of the Cartesian feature space, whatever it is. And once you get the origin, you can then make progress. So that is the distance t here i mentioned it as t here and so from that the we went through a little bit of geometric argument to say that if you know the beta beta naught and if we know the x vector the position vector of any point in the feature space then it is pretty straightforward all we need to do is remember that this is your a beta naught direction, and this is your vector x direction. So this distance dx is basically, this from here to here, this distance, like the entire vector, if I do the total vector is this, x dot beta naught is the full base of that triangle. If you look at this particular triangle, a triangle that starts from O, A, and X, O, A, X triangle. If you look at it, then x dot beta hat is the base, is the base of the triangle i hope you can see that of the right triangle and thank you please go ahead beta hat is the unit vector orthonormal to the plane perpendicular to the plane it is this vector imagine this you have this line the vector that is perpendicular to the line, right? And now generalize it to higher dimension and think of hyperplanes. The unit vector that's perpendicular, the word you generally generalize this to, orthonormal. Something that is orthonormal to the plane. Are we together? So you take that vector and you would agree that if you look at the triangle OAX and the OAX triangle, right? So maybe I can color it with this little line here, this triangle. If you look at this triangle, if this is X and you would agree that the base of the triangle is X dot beta hat. Is that straightforward? It's pretty uh it's pretty obvious from there so now with that thing there now let me see if i can yeah this decision when you say that yeah do we assume that this plane is like kind of a sheet of glass which is like straight yes absolutely no no no no bench the the nature of a plane is every it has a single orthonormal vector which doesn't change okay right no change in the perpendicular vector orthonormal vector anywhere so other planes where they have no play you don't call them planes you just call them hyper surfaces that is it but not a plane you don't call them planes. You just call them hypersurfaces. Hypersurfaces. That is it, but not a plane. You wouldn't use the word plane for that. OK. So with that, so this is it, guys. And so this triangle, the geometry is, when you look at it from a geometric perspective, all of these ideas that go into machine learning, they become very, very straightforward and easy to understand. So let's keep to that. Then if this relationship holds, then it follows that through a very simple set of step that we can write a dx as this minus t, and then you can follow the convention, define beta naught as this. And so you come to this lovely realization that the distance from the decision boundary is this. There is no mouse on the screen share. Okay, let me find a way to fix it. I wonder how to do that. Does anyone know in Zoom how to force the mouse to show? I don't know, unfortunately. But how about this? I'll take it as a homework. I'll figure it out some way. So if I just tap here, then is the mouse visible? Okay, I'll try to tap and bring the mouse close to that. So we have this equation at the bottom left, and I'll also give the location now, bottom left, which just says this is the distance from the decision boundary. This distance people often in literature also write it as ZX or quite often just Z, right? So you will find these abbreviations common notations in the ml literature so uh watch out for that these are common things and once you do that then you realize that suppose we are talking about cherry. Cherry is your positive case. You have a question? Yeah, I was saying that. So given R, we don't use hyperparameters. Those are parameters, not hyperparameters. They are parameters of your hypothesis. Remember, those are learnable parameters. That which you can learn are parameters. Those which you can't learn directly while the more through gradient descent are your hyper parameters excuse me they're just they are just no they are the they are the weights of the features they are the parameters associated with the features the features are x1 and x2. All right. So through a chain of reasoning, we came to this realization that this is given by this very complicated, what looks like a transcendental function. And where in the world did this transcendental function come from? So there's a bit of history to it. It belongs to a class of functions called sigmoid and i gave a homework to find sigmoids can somebody tell me what sigmoids you found besides the logistic arc tangent excellent arc time dan h is another very much used in deep learning anything else error function error function very good erf e r f is an interesting function it is actually the integral of the gaussian up to uh so what is the Gaussian? 2 pi. If you're looking at a normalized curve, then it is e to the minus x squared. Let me just say, t e to the, let me take a dummy variable t, t squared dt from minus infinity to x. This is the error function. And it turns out that this integral, like most integrals in real life you cannot solve for there is no analytical close form solution to this so you just leave it at that and whenever needed you compute it numerically so obviously it's a little bit hard to deal with this but the beauty of this error function is at least its derivative is easy what would be the derivative of the error function it would be the normal function itself it would be the gaussian function itself it would be this right so if you do error derivative of error function let me at the bottom of that screen i am if you see uh error function derivative of the error function dd, it will of course be, what will it be? It would be nothing but back to your error function, 1 over 2 pi. We know it's derivative, but we can't solve for the integral in full form. So there are many beautiful largest, I mean, sigmoid functions that you can think of. And I said, sigmoid functions matter. And the reasoning that we have to get to a sigmoid was, remember the odds and log odds? How do you squash something? See, the distance goes from minus infinity to plus infinity, infinity to plus infinity, right? And with X, the distance increases. Let's say that the distance is something like this, right? How do you squash it to a narrow band? So how do you take this stale sort of, this is one very rough hand-waving argument. How do you do that? So you use a squashing function. And so you can think of sigmoids as squashing functions. They squash this thing into an S shape. Are you seeing the intuition, guys? So this is what we covered. That's a review for last time. So this is what we covered. That's a review for last time. So this is all very good. Now we know. So to summarize, what we have is given, given, I suppose, given, let me use the white marker here, given, given blueberries once again, and I won't draw so many of them this time because you I hope you remember and cherries. boundary which you want to draw like this. This is your decision boundary. And so there is a distance function dx and based on the distance function there is a probability function which is you have a probability function which basically says probability of x being of a cherry you can pick something either blueberry or cherry let's say cherry probability of a cherry at the point x given the point x is equal to it is the squashing of the distance function right 1 plus e to the minus d dx do you remember this guys this is where we stopped last time now the question is this is a probability how do we learn these parameters of d d ultimately is made up of these parameters of d. d ultimately is made up of... So what happens? We have a beta vector which is made up of beta naught, beta one, beta two. We need to learn these parameters. So what is the path we take to learn the parameters? If you if you recall, how do we learn the parameters, guys? Gradient descent. We use gradient descent. Our big magic is we need a loss function. And then the problem is essentially solved because the moment you have a loss function, you can gradient descent. Are we together? And by now, you have become good at gradient descent. Are we together? Right? And by now, you have become good at gradient descent. We can gradient descent. The question is, what is an appropriate loss function? So let us reason our way through and see what could be. Suppose we take the positive case, let the positive case, let us say that you have some measurements, some measurement x1, x2, and then you get, you know the y, actual y, right, the x1, x2, and actual y. And so's just say that you have some uh some specific value uh pick any point let's say two a point and three the coordinates of a point is two and three and it could be of course floating point need not be integer and y is cherry so let's just decide that we will mark cherry as one what is the probability of probability of the the probability of py the actual probability of a cherry is one isn't it let's say that it is a cherry so then there is no doubt about it in reality there is no doubt we know that at point two and three there is a cherry that's what the data is the question is what is so this is a fact let me just i even though it is a probability of cherry i'll just write it as but i'll put it in quotes because most people in the literature they just write why what is the y value but it is actually the probability of that particular thing, which is a guaranteed probability, a certainty rather, not a probability, but a certainty that it is one, right? Now, what are we looking at? We are searching, we always will make a prediction. Our y hat is the probability of it being a cherry at point x, of being a cherry at point x of being a cherry at point x right which we will just as we say there's a sloppiness of notation and we'll just mark it as probability at that particular x let us say that you use a sigmoid function you you just start by taking random values, start with random guess for beta. Just take some random values for beta naught, beta one, beta two, and you did that. And happen chance, your prediction says that this is equal to let's say that it says pick a number guys between zero and one anything anybody 0.45 1.45 all right so we will take that suppose you get 0.45 right now and then there is some other point, let's say 1, 0.7. And here, the actual predicted value turns out to be, this happens to be blueberry, zero. So probability of it being cherry is actually zero or rather Y zero. Then, and your prediction happens to be, let me just say, a zero point probability that it's a cherry is, let's say, 0.7. Right now. And let me take another point just for the sake of argument, let me just take four, five. We know that it is actually a cherry and our prediction says that this is 0.9. And then there is another point, let's say, let's take another point, 0.5, 0.5. And this we happen to know is a blueberry, not a cherry, and our machine is telling us that the probability that it is a cherry is 0.2, right? So now, if I look at the four cases, let's look at these four cases, four data points, and see how we can think about and reconstruct some sort of a loss function for it. How are we doing? How good is our prediction for A, guys? How are we doing for A? Not so good. Not good. Not so good not good not so good what about our predictions for b pretty bad bad it's actually worse pretty bad and what about c pretty good okay yeah it's good and what about c it is good okay yeah it's good and what about d i mean okay d is good right because 0 and 0.2 are pretty close right so good you would say good right and how do you do good you are basically looking at you're comparing these two things, how close they are. Isn't it? So your first temptation may be, hey, why not look at y minus y hat? Can that be the appropriate measure of doing it? Can I just use the square of this measure of doing it can i just use the square of this for the analysis it turns out for a variety of reasons and the typical reason people give is that if you use the sum squared error you will not be you will end up with a model which where probabilities don't just stay between zero and one it will predict numbers bigger than 1 and smaller than 0 sometimes. So that of course is not a nice thing when your probabilities are beyond the definition of probability itself, isn't it? And it has very natural consequences. So that is often a reason given. I would actually not reason it like that. I'll reason it in a more formal way, or sort of what I think is a more appropriate explanation, mathematical explanation, why you don't do this. Right you you don't do that, but what is it that you do, I will give a mathematical explanation, but before I do it see this magic and I will just keep it. If I multiply these two things. This is zero. Right, so you realize that for positive cases I could just see how off we are if my prediction is good. If my prediction is good actually let me not bring that reasoning, but because that will bring one minus etc, etc and i'll bring that in a separate way so let's go through the reasoning part of it. See guys now, let me talk about MLE. Right? So I always think of this MLE. But it's M-L-E. What is that? Let me introduce this with a simple example. How many of you here are familiar with MLE argument in the mathematical sense sense like if everybody knows where i'm going, I will rather skip it, but in this class anybody who's familiar with the Emily argument now you are. Maximum like. You like it, can you explain it in full detail uh so it is like i think it's trying to look at the distribution and trying to see like with every combination which gives me the maximum likelihood of like the sigmoid function it tries to look at like all the combinations and shift it by like a value and then yes support again to get the maximum value okay that's that's that's good uh anyone anyone else otherwise okay can i i'll just assume that you'll all benefit therefore for those of you who know it may be a review i apologize but for the rest of you i'll introduce you from skype so i'll Suppose you and your friend disagree. You have heard of a city called Seattle. One of you believes that Seattle is a rainy place. Another? Seattle is not rainy. Raja Ayyanar? Right, so is a is a desert right now only one of you could be more right in view of data, how would you know who's right well you never know there's always a. Raja Ayyanar?nilrohina.org is the easiest subject to learn because once you get to the examples it becomes all looks very easy two hypotheses um let's say let's take two names right let us say we will take two names ram and shiam believes seattle is a rainy place and Shyam believes that Seattle is a desert mostly so on a given day, given day, hypothesis of Ram says the probability of rain is, let's take a number, a high number. Believes that Seattle, almost every day rain. So let's say that believes that there is a 90% chance of rain. Right on the other end, the hypothesis of sham says the probability of rain in Seattle is like 0.1. Are we together? It's a very small probability that it's going to rain in Seattle because it's a desert, right? And so now let us see a data, what it will favor. Suppose you have the data. Data is this. On day one, day one, two, three, let's take day four, just four days. Let's take day four, just four days. The first day it rains, rain, no rain, rain, rain. Three days it rained. So according to Ram, let's see, according to Ram, see, each day is an independent event According to Ram, see each day is independent. In reality, it's not like that. But if it rains today, the probability that it will rain tomorrow is quite high. There's a way, there's sort of auto regression in the data. But we'll forget that. Imagine that each day is separate in a very simplified weather model and so if these are independent assumptions so let me put this caveat if we take the simplistic belief that rain on one day does not affect rain the next day suppose you take this belief so you would say according to ram let's say ram the probability of rain was zero point. So it is all we need to look at is he got, the event that happened is it did rain. Probability of no rain, probability of rain, probability of rain. Isn't it? Because the hypothesis says that no range, so we have to take 0.9 times 0.1 times 0.9 times 0.9. Are we together? Does this make sense, guys? Right. does this make sense guys right so that is equal to and that is equal to uh let us say a 729 is that correct 81 yeah 729 into 10 to the minus 3 right and according the probability of rain. According to Shyam, it was no rain. What was the chance of no rain? This. And the chance of, sorry, again, the same thing. But what is the probability of rain according to Shyam? The same thing. When you do it for Shyam, how much does it work out to be? According to Shyam, 0.1 times 0.9 just the opposite 0.1 0.1 what does that come to would you agree that it comes to 10 to the power minus four minus four i apologize minus four yeah there are four terms here you're right so each term brings 10 to the minus one good so 10 to the minus a good catch so now you realize so it turns out that we we just look at that. If two things are independent, if two events are independent and both of them happen, the probability of it's happening is the product of the individual probabilities, isn't it? You remember that we learned in basic things that suppose you have event A, event B, B, and then the joint probability of AB is assuming independent events, probability of A times probability of B. Isn't it? So, generalize from that. If four days it rains, what happens? According to this, we could have taken only two days to prove our argument but I just took four because two looks too little data is the joint probability according to Ram of rain is 729 right into 10 to the minus 4 of this seeing this event and the according to sham the chances of seeing this event is far far, but this event is there it's a fact. So which hypothesis makes this event now listen to the way i'm saying it which hypothesis makes this the data this event that is actually happened, the joint event of rain and a three days rain one day no rain. Which hypothesis favors the data? Or the data favors which hypothesis? Either way. Shams hypothesis. No, Ram's. Ram's hypothesis, right? Ram's hypothesis, by Ram's hypothesis, you're far more likely to get the pattern than according to Shams hypothesis. In other words, by Ram's hypothesis, you're far more likely to get the pattern than according to Shyam's hypothesis. In other words, by Ram's hypothesis, you're far more likely to see three days of rain and one of not. By Shyam's hypothesis, you shouldn't be seeing anything like that. You should be seeing mostly dry spells and maybe a day of rain. Does this make sense, guys? So which of the hypothesis would you choose? If you have to say the data who is more likely to be right? I'm getting confused here like rain, three days of rain. Three days of rain and one day with no rain. So just how did we get? How do we get Shams more than rams? Sham is not more than ram. Sham is far less than ram. Sham is only 9 into 10 to the minus 4 and ram is 729 into 10. Oh, yeah. Sorry. Okay. Sorry. Sorry. So, what we are essentially that the probability that we written down there, right? 729 into 10 to the power of minus four, essentially the probability of a compound event. Yes, a compound event being rain on the first day, no rain on the second day, rain on the third day, and rain on the fourth day it's a compound even exactly said like that we cannot summarize it as a compound event which is rain on one day and sorry rain on three days and no rain on one day that's a different event which will we need to do a little more arithmetic to get to that event no no no uh independent even if you rearrange it it doesn't matter the fact of the matter is three days it rained one day didn't but then we'll have to add the combination term as combinations also yeah yeah you could you could see when you do the joint probability the likelihood that it it is like that at this moment i've taken it separately up to some factor okay it doesn't matter but would you agree that the same see whatever same factor will be true for sham also so barring all this 10 to the minus 4 and some factors here and there you you agree that this ram's hypothesis says it is far likelier to rain than Shyam's hypothesis, isn't it? Data favors whose hypothesis? Ram. Ram's hypothesis. So we could alternatively make it, you know, you all deal with it in real life experience. So let's say that there is some airline, like some new airline that comes through, right? Let's call it, I don't know, Goose Airline, right? So in the Goose Airline, your hypothesis is it's always late. Another person's hypothesis is it's always right. Whose hypothesis would be correct? All you need to do is wait and see the data, how many times it's on time and how many times it's late. The data will favor somebody's hypothesis. Isn't it? So one way to know who's hyper, go ahead. Yes. So when you came with the hypothesis, you said Islam's hypothesis is 0.9, Shams is saying 0.1. Yeah. Is the sum of that has to be 1? No, no, no. I could have done anything. It needs not. Actually, since you said I took an unfortunate number, let's make it 0.2. Actually, since you said I took an unfortunate number, let's make it 0.2. So now, nine, eight, 72. So now, okay, they do not have to add up to one, so 72. So you realize that still RAMS, this product, the probability of this joint event is 10 times more, more than 10 times more than Shyam's probability probability isn't it so did no no no and there's a 0.9 also sitting in between oh point oh sorry yes you're right oh yes of course the converse nice catch so yeah so i'll give it to you so it's just 64, let's say, very good, 64. I hope it's 64, yeah, 64, right? So this is a good catch, guys. So the point that I'm trying to make is that who would you believe in view of this data? Ram. So what you say is that the joint probability of the data being there, data being true, given a hypothesis. So pay attention to the wording that I'm using. of the data happening given a hypothesis H, right? Is basic, this is what it is, right? Are we together? When I multiply those probabilities, I have some hypothesis. This is what it is, right? Are we together? When I multiply those probabilities, I have some hypothesis. A hypothesis will have some probability of the individual events. Given a hypothesis, the most important word is given a hypothesis. This particular thing has a name it is likelihood it is the likelihood of this data given this hypothesis are we together remember it is not probability it is hypothesis that's like what am i saying it is not probability it is likelihood What am I saying? It is not probability, it is likelihood. So far true, right? And this is a very crucial concept, folks. Most people, it's a very elementary thing, but probability is something where we all tend to stumble on elementary stuff in real life. A probability, probabilities of something happening and not happening adds up to one. Likelihoods, on the other hand, there is no such thing. It doesn't behave like probability. It is just a joint probability conditional on a hypothesis. So without a hypothesis, there is no likelihood, right? So if there is no bound likelihood, then how do you compare? We'll come to that. We'll come to that. And it goes into the very lovely thing. You may vaguely remember if you took the math course, is that bias box, the toolbox. So that's beautiful. I won't cover that because today is just classifiers. And I want to keep the discussion fairly elementary. So, guys guys this is important to remember likelihood is associated likelihood of the data given a hypothesis right but how how are hypothesis in regression and classification given in the case of linear regression and logistic regression our hypothesis is parameterized by beta 1, beta 2, beta 3, et cetera, right? The betas, isn't it? Now, in the case, so now let's go here. And I'll show you some interesting magic. This reasoning, guys, is foundational to machine learning. So pay attention to it. Let's go back to linear regression for linear regression what happens is that you predict the the data is y is equal to beta naught plus beta 1x plus beta 2x2, so forth. Isn't it? On the other hand, in classification, in logistic regression, classifier, probability of a given class, let's say cherry, Probability of a given class, let's say cherry, given x, so y is a function of x, is equal to, let's say, 1 plus e to the minus z. And it belongs to the set of 0 to 1. It only goes from 0 to 1. So these are the two realities. Now, see what we say. And it's quite interesting we say that suppose you fix your betas your betas you have fixed probability of x remember it is based this is what z is equal to beta naught plus beta 1 x 1 plus beta 2 x2 in our example right so basically the probability is parameterized by the betas i hope i'm making an obvious statement so now comes this question suppose a two different people have two different hypotheses in in this classification setting, two people, Ram has a hypothesis, Ram, a set of theta, let me just call it theta actually, sorry, not theta, beta, because your textbook uses beta, has a hypothesis B, right, which is this beta naught, beta one, beta two associated with RAM. And let's say that there is another another hypothesis. These are two different friends and they have completely different So, for example, in the hypothesis plane, this may be Ram, right? And this may be Shyam. Oops, sorry. I apologize. And this may be Shyam. Shyam's hypothesis. For the same data, there are some blueberries here and there is some red berries. There are some cherries here and there. For the same data, there are two different hypotheses of the decision boundary. Now the question is who is right and who is more likely to be right? Which of the two hypotheses is more likely to be right which of the two hypotheses is more likely to be right in view of the data when you visually look at the data it's clear that ram is doing better isn't it yes but how do we now quantify it bring it down so let's ask this question for every point that ram gets right so ram says that at every point there's a probability that something is a cherry. So let's say that x, we have a table, let's go back to our table of data, there is x1, x2, the ground truth y is equal to 1 means it's a cherry, y is equal to 1, cherry. It's a ground truth. truth and again it's a bit of an abuse of notation what you should really say is the data says that the probability of a cherry is one because it's it is a cherry right and then you have your y hat y hat is equal to probability of x right probability of it being a cherry so let us say that you have a data point, something, something, something, something. It is a cherry. And you come up with some answer. Let me just call it, this is your first data point. It's a probability of this. Let me just call this, this. At the first point, it is this. It is really a cherry. Something, something, something, something. Let's say the second point also is a cherry. So let me map it somewhat to your weather example. Rain, didn't rain, rain, rain, or something like that. Well, OK, I'll mix up the order. Something else. And it turns out that it was not a, it was actually not a cherry, but ultimately what prediction model tells you is probability of a cherry, right? So third probability of a cherry, and fourth is also a cherry, four cherry. And let's say that the fifth is not a cherry, probability of this. So now let's reason through and see how we will somehow create a likelihood. What is the likelihood of Ram's hypothesis versus Shyam's hypothesis or any other hypothesis? So you would say that, see the hypothesis has the parameters built in, right? So now I'll just change the notation Ram Ram given, well, people say, sorry, I'm used to writing theta, but your textbook writes beta. Given the hypothesis, each of them have their own hypothesis. Ram has the hypothesis of beta, has a preferred set of values for the beta, and Shyam has a set of preferred values for the beta. Each of them is their individual hypothesis. Would you agree that the joint likelihood of seeing this event is like this? Probability of seeing it is P1. And if you don't mind, X beta. I'll just remove it. Probability of again seeing it is X beta. Now, if there's something very interesting, you have the likelihood when you don't see something happening, what should you take? You have to look at the probability of it's not happening. The model is telling you the probability of it's happening. But when it doesn't rain or when it is not a cherry, what do you need to look at? Probability of it not not a cherry what do you need to look at probability of it not being a cherry which would be one minus probability of a two two three x beta because it didn't happen it wasn't a cherry isn't it just as we said probability of not raining is the is the one minus that and then we look at probability of this probability of the fourth data point x beta right actually if it is with a little bit of abuse of notation let me just remove this subscript from here it's more meaningful for me to say x1 x2 and remember that x3 x4 i'm not looking at the components of the vector i'm just looking which data instance it is and the subscript is subscript here is here refers to the specific data data specific datum right first row second row third photo of data right so uh if data let me write the word properly specific datum now this is what our probability is would you you agree? Now, the only thing is, this thing is called the likelihood. The likelihood given, what is the likelihood dependent on? Data is there. You can't fudge with the data. When you are learning, see, think about it this way. When you are trying to learn, what is it that you can play around with? The hypothesis. You're jumping all over the hypothesis space, finding, okay, where is the likelihood going to be better? Isn't it? So given the data, assuming that the data is a ground truth, the only knob that you have to turn are the betas, isn't it? Right? So beta. And that's why you often see that it is referred to as beta or just beta, or it is also referred to as a beta given the data. By the way, I'm using the scripted D through all the quizzes by now. You must have noticed that i referred to the data the set of the entire data as b b b is the data set think of it as the ground truth given the ground truth now likelihood is a function of beta, given the ground truth. This vertical line, always say in your mind, given as, given. Given data, what is the likelihood of beta? So now, whose likelihood is true? All we have to do is plug in the probabilities, isn't it? We just plug in their probabilities and see which one is true. So now, whichever hypothesis maximizes this likelihood, would you agree that that hypothesis is the best we can have? Now we'll worry about how to learn that hypothesis, but let us at least agree on the truth that we now have, we are very close to quantifying the error. We say, hey hey you know what i know one way to give the error is or when close very close to it we still have to go a little bit of a journey but likelihood is a pretty good way i need that hypothesis that maximizes the likelihood of what I am seeing, that it's been raining three days and not one, and dry one day, or in the case of cherries and blueberries, that these many times, these points happen to be cherries, these points happen to be blueberries. So far, so good, guys? Yes. The data that you do, suppose that the original data you have to test and test rain, I don't want to confuse, but then you will always, the drain data has to be constant across both the guys, right? Yeah, they both are looking at the same data. So yeah, they have to. So just like in the case of rain, the reality is three days it rained, one day it didn't. That's a reality staring both Ram and Shyam the face right in the same way some parts of the data no no no no no then you become a politician yes you apply the hypothesis yes yes that's right that is true that is it so data yes that's right that is true that is it so now given the whole data set and see you actually asked a very good question uh what sachin asked is that uh will these two raven sham see the same data the answer is yes the same training data not only that true. Do you remember what IID is? Pradeep. IID. Yeah, go ahead. You go ahead. Identical data. Independent and identically distributed. What it means is that independent means because I took this data, it shouldn't affect the next data. Right. So, like a toss of a coin is really independent you toss a coin it doesn't matter what was the result before. Next result is exactly the same. Right. So in other words, data are not one is not affecting the other. And identically distributed means that they are taken from the same ground truth. One rough way of saying it. They represent the same reality. It shouldn't be that one guy's data, like see for example, if you pick one data from Arizona and one data from Seattle, and you want to make a prediction about Seattle, it would be unfair. You have contaminated it means the distribution of the probability distribution of rain in the more formal language in arizona is different from the probability distribution of rain in seattle more more simply put that is a different reality from this so i can't mix the two up iidID. That's what IID stands for. So they all have to be the same. Okay. So guys, now we are coming to the end of a very interesting intellectual journey. We all realize that there is such a thing as a joint probability given a hypothesis. The joint probability of this data happening at all, given this hypothesis. And that joint probability is called the likelihood. The likelihood is a function, given a ground reality, given the data, likelihood is simply a function of the hypothesis that you pick, or of the parameters, therefore, parameters. And so which hypothesis would you pick? That hypothesis that maximizes likelihood, isn't it? So common sense says, and this is a big truth we will stop at, a big realization that we will stop at. It represents, and then I'll take questions. So we realize that common sense says, well, I say common sense. Later on, I'm going to revise that. The Bayesian way of looking at things is slightly different. We will revise that. the hypothesis that maxi mizes L beta given the data set. Or in your book, it just refers to L beta. Right? Probability of the that hypothesis beta right so more formal languages what is the arc max what is the beta star that maximizes the probability what is that hypothesis what's the value of the beta that maximizes this given the data set this is our main goal we want this now from this we are very close inches away uh from creating a loss function yeah are we together we'll see how to do that in a little bit uh your question Your question. So on the data, we're assuming that it is like time of balance, right? And what is the data in the balance? This is still true. Invariant of that. Invariant of that. But if you have a lesser sample structure in a forum, then in that case, the probability is higher on the... No, no, no. Probability is not a proportion of blueberry or this. See, what you're talking about is yes you're talking about an important