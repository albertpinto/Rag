 Today, we will start with this concept of machine learning. What is machine learning? And it's become a dominant theme. Wherever you look, people say, oh, machine learning, and theme wherever you look people say oh machine learning the exploding number of jobs of machine learning exploring number of applications of machine learning it is hard not to find machine learning people often use the term artificial intelligence interchangeably so the question therefore is what is artificial intelligence it's sort of part of the zeitgeist. You hear it every day. You hear it in the news. You hear it in popular conversations. We all, irrespective of what walk of life we belong to, we have all heard the word artificial intelligence. We have heard the word machine learning, perhaps less frequently. There are movies about artificial intelligence and robots and whatnot, and obviously Terminator and so on and so forth. There's so much of fascination with this entire concept of artificial intelligence. So what is the relationship of all these things? Machine learning, artificial intelligence, robotics, all of these. We will today be a little bit more precise about what they mean. See, the term artificial intelligence is a fairly, I don't know when it was coined, but it's been there for decades now. But it is a millennial dream of human beings. It's sort of older than any of the technologies we develop. You go and look at the mythologies of just about every civilization and you will see an aspiration of man to be the creator of intelligence. To the extent that we believe that God created us in God believing nations, right? And that we are created beings, we are creatures. There has also been an aspiration amongst human beings to create of their own forms of intelligence. For example, in just about every civilization that I can think of, for example, in Hebrew culture, there is the story, I believe is Golub is the word. You would make a mud doll and something like that, a figure. And then with the appropriate invocations, you could bring life into that. And if you did, it would do things, it would do extraordinary things. In the Aladdin and the magic lamp, you again have this character who can do whatever you want. It's a creation. You just rub the lamp and lo and behold, there's this amazing magical creature that comes in so people have aspired to create things of their own that are intelligent not just dumb machines not just uh steam engines and and ships and planes and so forth which they know are mechanical devices at the end of the day marvelous Marvelous mechanical devices, but we all acknowledge that these devices are mechanical as opposed to intelligent. They exhibit no forms of intelligence. We have always wanted to create machines that exhibit intelligence. The first prototype of a machine, or at least the concept of a machine that could compute, was by Charles Babbage, I believe. His design at that moment was ahead of its time. It could not be realized, we tried very hard to realize it couldn't be until that it has been realized now and it is there in the Technology Museum in San Jose, or the computing, I don't know, which museum is it? Museum of Computing? Yeah, Computing History, right. So people have actually recreated that machine and found that it does actually work. So even before the computer, the first computer actually worked, the creators were dreaming not of using computers to compute, per se, but to create intelligent machines. So creating intelligence machines has been a pretty long millennial dream of people. So today I will ask this question, what is intelligence? When we speak of intelligence, what is it? Let us be more precise. Now, artificial intelligence has many sort of definitions, and it has evolved over time. In the beginning, people thought they could create, they were pretty optimistic, they could create strong forms of AI, what are called forms of strong AI, strong artificial intelligence. They could actually create thinking machines. There was even a legendary company here in Silicon Valley literally called Thinking Machines, into which some of the great Nobel laureates like Richard D. Feynman, etc., came and contributed some excellent work. Those were great efforts. They didn't quite succeed. It turns out that that was too ambitious. Today, we have a more pragmatic definition of intelligence. We say that anything exhibits intelligence if it can learn. Are we together? So intelligent machines are thinking, are not thinking machines but learning machines machines that can learn and apply and therefore the theory of machine learning right so now let us quantify what is learning uh learning is how do you know that we have learned? Let's take an example. You take children to a zoo. Let's say you take some kindergartners to a zoo. In the zoo are all sorts of animals. But let us simplify it. And you show the children an animal and you say, say you know this is a cow and do you notice the horns on its head and the long swishy tail and the four legs right in the big size and so on and so forth you express all sorts of attributes of the cow and you say this is a cow then after a little while you happen to encounter let us say a duck and then you say well look at this animal it's small it's feathery it has webbed feet and it has a beak right and this is a duck and then the child is maybe trying to make head and tail out of what you said generally adults say a lot more than a child can comprehend right so the children move forward and after a little while you show more examples you say that is a cow because this and now look that's a duck and you keep on encountering different enemies and let's say in that meadow that you have taken the part of the zoo or the meadow that you have taken your kids to uh it's all cows and ducks. And you show all these cows and ducks. How would you know that the child has understood what a cow is and what a duck is? Learned about cows and learned about ducks. So one way that you could do is, as you travel, you can point back to the cow that you showed and said, what is it? And if the child says duck, you know the child hasn't yet learnt, isn't it? But if the child says cow, you might you may be inclined to believe that the child has learned what a cow is. But there's a subtle flaw in this reasoning. Would anyone like to point out what the flaw in the reasoning is? Go ahead. Guesses, yeah. So you ask many such examples. Very good. You ask many such examples and you look at the error rate, how often the child is making an error. If the child is just guessing, the error rate would be high. But there is one more subtlety. Suppose the child with fairly good low error rate can tell cows to be cows and ducks to be ducks, the ones that you have already shown the child would that convince you that the child has learned what a cow is and learned what a duck is and to distinguish between the two memorize some feature that is right the child may just have memorized those specific instances of it some people have perfect recall they just remember and they remember that this is called this was cow cow cow duck duck duck but the child has really not understood it because when you show a cow that the child has not seen the child is stumped or or a duck the child has not seen the child is stuck so in other words and therein is the crucial idea Learning is the ability to generalize from data. Are we together? You generalize from the data that you have seen to beyond it. That is the distinction between learning and memorization. To make it very practical, all of you have been through the education system, right? Which is, which can be, it can range from brilliant and absorbing and great professors to absolutely very courses in which pretty much make you hate that subject. Right? So you have the whole range and then we all have to somehow get through this process. So the ones that you don't like, what do you do? Well, I can tell you from my experience in the IITs what you would do is you would have something called the important questions and question bank in those subjects. So you would just have a question bank of about 40, 50 questions, right? And you just hated the subject. So the day before the exam, you would just go and perfectly memorize those questions and the solutions. And so should they appear in the exam or anything close to it appear in the exam, you would be able to solve it because you have just memorized how to do it. But as you would agree, memorization was not understanding. I had not learned that subject. I had just found a way around it by memorizing it and still getting a reasonably good grade to then put the course behind me. So that is the distinction between memorization and learning. Learning is the ability to generalize. You can solve a problem that is not there as part of your question back. Isn't it? You can solve new problems. That is learning. So that is machine learning. Now artificial intelligence, these words are very often used in a broad sense. So I will just draw a picture. Suppose this is artificial intelligence. Then machine learning is the theoretical core of it. This is machine learning. Within the field of artificial intelligence, there has been other things, for example, the application of machine learning to all sorts of areas, for example, you apply to robotics. Examples of robotics are your gazillion examples, for example, your self driven car, right? Your Roomba, your this and that, your vacuum cleaner these days, and it's hard to point out places that you don't have. So this is the theoretical core. theoretical core. Now what happens is that within machine learning there are many many algorithms. One class of algorithms that has gained considerable popularity these days is deep neural networks. So let me just call it DNN, deep neural networks, and I will just call it here, a deep. And in this world, there are many things like SVM here and ensembles. The countless drills in the world in the theoretical world of machine learning. There are literally countless jewels, marvelous, wonderful jewels. One of the jewels is deep neural networks that is very much in work these days, especially for unstructured data, especially for images, sound, and text. These are unstructured data, data that is not tabular or as a spreadsheet for deep neural networks are very effective and deep neural networks are occur. These are also called also known as deep learning. Deep learning is an interesting word that they have latched on to actually. Hats off to the marketing genius of who gave the word deep learning, right? Because it somehow looks very deep, isn't it? But it is yet another class of algorithms within the machine learning world. Now, one of the abuse of terminology that is happening these days, and in fact, many companies are culpable is that they tend to equate artificial intelligence with just deep neural networks or deep learning. Right. So they will, I actually have sat through some client calls in which they're saying, yes, machine learning everybody is using, but are you doing AI? Right. So you see the absurdity of that, but it is because these people are not technical. And it is partly the fault of the marketing from companies is that people have given the buzzword AI to deep neural networks or deep learning. Quite often you say, oh, I'm doing AI. I have run neural networks and so on and so forth. So it is sort of a part of the abuse of terminology that's happened. But this is the real picture. This is the relationship of all of this. So this is machine learning. Why would you put robotics completely non-interceptible? Oh, no, no, I should not. I should not. I should not. This is, these are all, this feeds this. Feeds this, let's say. The diagram they should overlap. Yeah, yes. The way, yeah, the way I would look at it is machine learning is that theoretical core robotics is the implementation that uses a theoretical core the actual mechanical implementations because there's a lot of mechanical engineering and other things that come into this right so. Vipul Khosla, Ph.D.: That is that, so this is a broad sort of relationship don't take it very literally but. is that so this is a broad sort of relationship don't take it very literally but think of it as a containment hierarchy artificial intelligence contains many areas the key areas are machine learning robotics etc there used to be expert systems but we don't talk about that anymore these days then within machine learning there's a large number of algorithms absolutely wonderful drills. We'll start with one today. So one of the drills that is very much popular for unstructured data these days is deep neural networks or deep learning. Right. So, and we'll learn about it but this particular workshop this data science workshop will predominantly focus on, at least in the first part on structured data on tabular data right we will have occasion to learn deep learning at the very end a little bit but there's an entirely separate workshop we run dedicated to deep learning for which you're invited right all right so with that relationship out of the way, I would now ask this question, learning. When we say that machine, like generalization from data is learning, how do you quantify it? Ultimately, it is science. We are talking about we are engineers and scientists. For us, things have to be measurable. So what is a measure of learning? So let me pose this question here. What is the measure of learning? This is the crucial question. We don't know how to quantify thinking so that we could never create thinking machines but it turns out we can quantify learning. So let's go back to the story of the children and the teacher in the meadow or the zoo. Now you ask a child, say one child, you keep showing and explaining the cows and the ducks and in the beginning the child doesn't know so the child is guessing so when you show it an instance of a cow or a duck it will guess and you would observe that the child is making a lot of mistakes so a lot of you can count the errors and quantify count, quantify, quantify errors. They said that the error is this, right? The amount of errors you make is this, maybe out of a hundred samples, the child is getting 30 samples wrong or something like that, okay? But when would you begin to get the feeling that the child is learning when the errors keep coming down isn't it the child is able to answer most of identify most of the cows and ducks correctly because that would be a measure that the child has is learning are we together right so learning is the simple idea, I hope is clear, because this is the heart of it. Learning is a reduction of measurable error. Learning is the process of of of of of of of of of of of of of of attack. It's the process of systematic reduction in the errors. This is it. So what is the problem? Whenever we create a machine or an algorithm, in the beginning it will make certain errors with the data and then it needs to find a way to decrease those errors. So those are the two legs of it. Errors. Now, so we need in machine learning two fundamental things, let me just say. One is a quantification of error, E, right? It is also called the loss function. Let's remove that E. And the second thing that you need is an efficient and systematic way to reduce the errors. Error E, isn't it? To reduce the error E, or the word that you use is minimize the error E. Right? And so your model is, and I'll just use, let's say that of all the possible hypotheses that you can make explaining the reality, that hypothesis is true, which produces the least error in prediction. So all of this, we will make it much more concrete as we move forward now. So an efficient way that we will learn, I will just throw a word here for future reference, but it should mean nothing to you at this moment is, one of the efficient ways is gradient descent that is pretty much at the core of much of machine learning often used for this purpose. We'll see that today. So two concepts that we will learn today is quantification of error and systematic way to reduce the error. So let's take a real example with data. Suppose I take this example. Consider an entrepreneur, a young entrepreneur, selling ice cream on a beach. So suppose you want to open a shop and sell ice cream on a beach. Now, this is a toy example. So take it in a lighter window. Don't super analyze it. So the point is to just frame something we're going to learn so when you want to sell you want to open an ice cream shack on the beach ice cream now is a thing that has a very short shelf life isn't it it's a perishable item you go to the dealer you buy a few buckets of ice cream, a few gallons of ice cream, and you better sell that ice cream by end of the day, most of the time. Let's say that it is because ice creams don't last long, especially, I mean, it's just as a very quick expiration date. So now you have a problem. You have to estimate how much ice cream you would sell on a given day before you go in the morning and purchase ice cream in bulk from the dealer. Isn't it? If you purchase too little, then you will have a lot of customers, you'll turn away a lot of kids that you will turn away because you would have run out of ice cream, not a happy situation to just sit there and watch all the kids going to the other ice cream shop. As an entrepreneur, you would be pretty sad about it. On the other hand, if you buy too much ice cream and you can't sell it, well, that's a loss, isn't it? You paid money for something, good money for something, and it went to waste. Therefore, you have a motivation, real-world motivation, to predict how much ice cream would actually sell on the given day. So let us say that the amount of ice cream that sells on a given day is a function of temperature whatever is the uh outside temperature let's say approximate outside temperature the average temperature of the day or the noon temperature a picker value a temperature at a given time whatever the temperature is at a given time you realize is a good indicator of how much ice cream you'll sell realize is a good indicator of how much ice cream you'll sell. Out here in Northern California, that's a pretty good predictor. If it is a cold day, nobody will come to the beach. If it is a hot day, lots of people are on the beach and they have their families and so forth. So there are multiple factors, for example, whether it's a weekday, holiday or a workday. Even on a nice pleasant hot day, because it's a weekday, our parents are not free to bring the kids to the beach. So you may not have many people. So there are many, many factors that we'll consider. But for now, we'll take only one factor. Let's take temperature as the factor right so we will say let x be let us make data plot of the data x which is temperature and we'll hypothesize remember it's a hypothesis we'll look at the data and we will hypothesize a relationship. We will say that ice cream sale is a dependent variable. This is the independent variable. This is often called the predictor dependent variable, depending upon which literature you're reading depend sorry independent variable independent not different independent independent variable predictor regressor input and so forth there are many names for the basic x right right, driver essentially. And based upon which tradition you're looking at, statistical this or that, there are a lot of different traditions that have contributed to data science. And the y is often called the target variable or the response variable. or the response variable, which is also called the regressant or the dependent variable. These are all synonyms. Synonyms, and these are all synonyms. In various literature, you use different words for this kind of thing. So now let's look at the data. Here's a big mystery. How does the data look? Let's say without some data point, I will take take suppose data looks like this and i'm taking a very simple hypothesis i i don't believe the real world may look like this so this is sort of a contrived way of putting it suppose your data looks like. Each of the points is a data set. So what the entrepreneur has done is taken a methodical approach, seen how much ice cream cells are in every given day, or maybe bought that data from somewhere, I don't know, one way or the other, has acquired this data. And this data, you look at it and you may hypothesize looking at this what do you see do you see a positive correlation negative correlation or no correlation at all it is a direct positive correlation a direct positive correlation implies that there's a linear obviously there's a linear relationship implicit here. So you would like to imagine that y seems to be proportional to x, right? The amount of ice cream you sell seems to be proportional to the temperature. So you might want to posit a linear relationship. Based on that, you may hypothesize, for example, that y is equal to, what is the equation of a straight line? y equal to mx plus c. mx plus b or c, depending upon which textbook you're reading. So this is your slope. This is your intercept. Just as a recap, what is a slope the unit rise of y for every unit increase of x isn't it if you increase x by one unit how much does y increase that is slow how steep is the line right and intercept is where exactly when x is zero then how much is y when x is zero that is your intercept right now remember that this equation which we learned about in our high schools and so forth we will just reframe it in based upon roman and Let's reframe it based upon Roman and Greek thinking. So is y a measurable? Is the amount of ice cream that you sell a real measurable? It is, right? As an entrepreneur, you would know how much you sold, isn't it? So y, we can keep a Roman letter for it. Let us rewrite this equation. Slope, is slope something that you can see? Is it an observable? Sorry? Is it an observable? Sorry. Is it an observable slope? No. It's a concept. So we will give it a Greek letter. And how about intercept? Also a concept. So typically, and this textbook of yours uses beta and beta 1x. and beta one X. This is nothing but your B slope or slope or whatever you look at it. And this is your, oh sorry, not slope, sorry, intercept. Sorry, I apologize, intercept. This is your slope. Are we together? Your M in the previous equation. If you try to compare this equation with this equation. So far, so good, right? All we have done is rewritten the same thing with a slightly more standardized notation that is common in the machine learning literature or the data science literature. Now, whether you use beta or you use something else, another thing that you often find using, in fact, I am much more familiar with writing it like theta naught plus theta one x. Is it any different? No. I just replaced the Greek letter, one Greek letter with another. Instead of using beta, I'm using theta. Also a common. But observe one thing. These are equations of a line. So what we are saying is there is a linear relationship between X and Y. It's a line relationship. But when you look at the line relationship, right? So let me draw the perfect line here. Well, as straight as I can be. This has some value of beta naught, beta 1. Isn't it? A unique value of beta naught. But you also notice that y is not exactly, any given y is not exactly sitting on the line. The real data has a little bit of a, what does it have? Yeah, and this is your difference between, it is called the residual, the gap between reality and prediction, right? So we will now refine a convention by seeing that what you predict points on the line, like for a given value of X, given value of Xi, this one is Yi, the reality. And this one is the prediction, Yi. And predictions traditionally in machine learning wear a hat right you make the predictions where I had just to distinguish it from the actual observable right y hat so what we are going to predict is going to be on the on the line right or no yes because if you make a straight line model hypothesis the best value that you can predict for a xi value for a given temperature is that you will sell this much of ice cream on the line isn't it but your data says that actually you sold y i so there is a gap between xi and y i mean y i and y i hat So that brings us to the concept of a residual, residual error. The word is residual error. It is the, for a given data point i is equal to y i minus y i hat right it is the gap between the prediction and the reality right obviously you want to keep small residuals go ahead you mean here time so is that why the first one i'm going to add you mean here the first one y i equal to epsilon the one in the box oh this one this one right yeah you can so people use different letters for it people often use the word epsilon i and sometimes in your book you use the word r i also your textbook often tends to use little ri obviously epsilon i is a bit more clear it's the residual error now what happens is now comes the learning So, so far are we clear what is a residual error? So, it can be both positive negative. Yes, in fact it is. So, for example, let us take another blue point here. Let me deliberately exaggerate and put a point here. x j for x j you notice that this is y j the reality and this is y j hat isn't it and so y minus y j hat would be a negative amount the residual would be negative so as if so what we are saying here is when we go from one to n our residual if it is close to zero or zero then we have a good model no what we are no so we are developing the intuition you are there almost there there is only one catch to it see you have lots of data points for every data point your model is making some error you want all the errors to be in some sense small the cumulative error to be small are we together now the thing is how do we define from this picture how do we define the concept of a cumulative total error of the model? What we want is total errors of the model or the hypothesis hypothesis model is nothing but the hypothesis the hypothesis that you made every time you make more realistically the line the specific line is your hypothesis line with a certain value of slope and intercept is your hypothesis now what is the total error this is what we want so one one way that you could do is you could say hey you know what maybe i will take can we use this so the question is can we use e is equal to sum over E is equal to sum over, like basically, I will first use a more compact notation, sum over all points of epsilon i. Just add them, which is equal to epsilon 1 plus epsilon 2 plus epsilon all the way, 3. Can we use this? Can we be used think about it can we just add up all the errors to get a total error yes because there will be some negative some positive but the problem is they might become zero the sum might be zero well that would be a good situation to be in right eventually well let's think about that i'll give you a situation let me let me contrive another hypothesis consider the hypothesis okay um consider this hypothesis and again i'll use the same data point I hope more or less. Raja Ayyanar? Suppose you have this data point, but now consider this line as a hypothesis. Raja Ayyanar? I hypothesize that I mean this is just some line hypothesis h would you consider this hypothesis to be a good model for your uh data because see all the negative for every negative i can find a positive residue isn't it for this i can find this so if you look at it the the error the total error would be close to zero but something tells you this is not quite a good model isn't it it is not as good a model as the previous model that we built the yellow line model that you built here isn't it ramon do you see that yes i do i do. I do. Yeah, I'm trying to. So now we have a problem because just adding up all the residuals, residual errors is not a very good idea. But then we look at the fact and you say, you know what, it is the magnitude of the residual that matters, not its sign. The pluses and minuses cancel out. But if you just take the absolute value of the residuals, perhaps that's a good idea, isn't it? Because those would all be positive quantities. And if you notice the residuals, if you just took the magnitude of the residuals, right? And we say this, for example. So let us say that this is def one. The second definition that we can come up with is, let's take another definition too. Can we use, and reason through this guys, I'm taking you literally through the discovery process of all of this mathematics of machine learning is best to rediscover it yourself so that you understand it. Suppose I did this epsilon I absolute value, the mathematics of machine learning is best to rediscover it yourself so that you understand it. Suppose I did this epsilon i absolute value which is equal to the absolute value of... Now you realize that in situation B the white hypothesis would do very very badly that it would have huge error compared to the yellow line hypothesis. Isn't it? Right? So this looks to be a good candidate for error. Would you agree guys? So this is a legitimate so well, this looks like a promising candidate. There is another to make this magnitude here or could we use this will this work this too will work isn't it so we have two promising candidates that will work right and now what people do sometimes is this is the the it turns out that both of these both of these are valid ways of quantifying error. Are we together? There are names to it. So the first one, when I write it like that, let me just use the word SSE. Oh, maybe because now we are creating definitions. Let us entertain ourselves with a new color. Which Which color? Let's try this. I haven't used this. Whatever this is. SSE. Right. It is also called SSE RSS. So let me put these words. SSE stands for residuals sum squared. Your textbook tends to prefer this and this is this. And there are people like me who don't like to type so much. So we tend to just write it as E, right? E total, or maybe E total E is the total error. And this way, sum squared error, let me just write it. All of these things is equal to, all of these are equivalent definitions. Let me just write it this way, is equal to summation of the squares. Are we together? Which is the same as i and yi minus yi hat square. Are we together, this is your definition of some squared error or residual. R. Vijay Mohanaraman, Ph.D.: This has been there now, there is a variant of this that is also used. R. Vijay Mohanaraman, Ph.D.: Which is mean squared error. R. Vijay Mohanaraman, Ph.D.: m s. M.S.E. mean squared error is nothing but your sum squared error divided by the number of points. In other words, the average of the sum squared errors, which is the same as 1 over i hope this is all very obvious now hat square is this simple guys people use the mean squared error so I say a quick question right so I got the formula right but if I am looking into the model the one you have slope 0 and the one we have slope equal to some angle so you said that the one that we have slope 0 the one which is a parallel to the x-axis is not a good model so yes on what basis because the sse would be like if i get the data and if i'm able to plot something like a with a slope equal to zero parallel to x-axis then how like what is the how can i quantify that it's not a good model yes so what will happen is think about this if you look at the sum squared you realize that for the white line the residuals are huge and the squares will also be huge so the total error that you will get so let me just say the error in the error i'll just use the word e by here e you can use any one of these expressions that you like a mean squared error sum squared error whatever you like e of the white line will be far greater than e of the yellow line. Would you agree? Yes. And you say that the yellow line is a better hypothesis. It's a better model. So that depends. In this case, your data is a kind of, if you see the dot that you have it's going from the positive correlation but if the correlation is zero then it's going to be like more better to yes see a very good question actually so see if there is no relationship if correlation is is zero then you cannot make a linear model because a linear model would be a mistake. So any line that you draw, any linear line, any line that you draw are all equally wrong. In that case, all of them will be equally wrong. You'll notice that the error from each of these hypotheses that you draw, any line you draw through our data where there's no relationship all of them will have more or less the same error okay okay understood thank you yes good so so folks this is it how do you determine that you have learned suppose now okay so here's the thing which is the hypothesis? Go ahead. Let's say you have like outliers. How do you guard against them? Very good question, but hold that thought. So let's learn to crawl before we run. All right. So we outliers the whole topic and we'll come to that. Now comes the interesting point here. Then the other definition is the mean absolute error M A E, which is, what is the mean absolute just what we thought the other other meaningful right it is equal to i y i minus y i hat absolute value right this so this is another way to quantify error so in the literature you will find many many things many many definitions now there is one more thing there is something called root mean squared error r m s e root mean what is that it is nothing but the square root of mse right which is therefore equal to 1 over n square root of 1 over n i square right so rmse so now which one should you use like see when it comes to the squared family doesn't matter whether you use sum squared error mean squared error or root mean squared error because minimizing one will effectively be minimizing the other they are just different variations on the same formula do you agree if you can minimize the sum squared error you automatically minimize the average as well as the square root right so those are equivalent so fundamentally the two kinds of error functions that you learned here the two variations that you learn is the mean absolute error or the sum absolute error if you want but mean is quite commonly used and the mean squared error now the question is which is preferable means squared error right or mean absolute error now it turns out that some different times different things work but uh one of the great works by uh by one of the results of all of this has been the so-called blue theorem right uh blue stands for best linear unbiased estimator quite a mouthful isn't it and if you do do many fields like econometrics and so forth, you encounter this. So there is a blue theorem, best linear unbiased estimator. And it says that Mse pick mse mse or the sum squared error is actually people often use the sum squared error it basically says and or sum squared mse so sum squared error is the one to be preferred now why is that so a blue this more to it to the blue theorem we won't go into that best media unbiased estimator we always like unbiased as soon as now. R. V. correction in the image one by and. R. V. Oh yes, thank you for correcting me. That's right, I get sloppy. That is it, thank you. So now the best, this theorem. So there's a bit of an interesting history guys. You realize that we have just quantified error and all that remains now is the second half of the journey. To find the best hypothesis, we have to take that hypothesis, which has the least error, isn't it? Like, for example, the white line is significantly inferior now to our yellow line in view of any one of these estimators. Go ahead, Albert. I lost you on that SSE and msc so what is the difference between ssc msc is just the one over n average just divided that that's it some square error just add all of them don't divide by n oh okay that's it so we will think if you minimize one you of course minimize the other so now what happens there's a very interesting history folks to that and but before i do that you realize that i'm saying something fundamental for this establishing this relationship this process by the way is called regression right building the best hypothesis to fit to real value data x and y is regression a very strange name regression now regression is a terrible thing in software whenever you hear that there has been a regression in the new software build everybody panics it means that the software quality has gone down regression is the opposite of progression right regress is the opposite of progress now why in the world would you give this name to one of the most foundational pillars of machine learning there's a very interesting bit of history now i'll just take a small digression for that and then i'll give a break and then we'll move forward with this see what happened is that machine learning how how, I mean, these ideas, this foundations of machine learning, how old are they? Can somebody guess none of my past students can speak up. And so, because you know, the answer, I only want the new ones to guess. Can you guess when this was discovered? 20 years ago. 20 years ago. Good. Anybody else? Go ahead. A hundred, a hundred plus years ago. A hundred plus years ago. Good. Anybody else? Go ahead. 100 plus years ago. 100 plus years ago. Who's this saying? Raman. Raman. And what makes you say who discovered it and how? I'm just taking a guess. I mean, there was some good mathematicians back then, I guess. Yeah, that's right. Yeah, go ahead. What's the name of the Turing machine was? Turing machine and yeah, Alan Turing 1940s, 50s now. So that is one good guess, actually. Alan Turing, by the way, he created the first real computer, the Turing machine. It is the computer, the first real computer. And today we call it just computer. And guess what was his dream? It was also to create artificial intelligence about learning machines. But anyway, when it goes a little bit more back, I'll give you an idea guys. There was a, this is, this goes back to work, a puzzle actually. There's a bit of history here and uh what happened is that in europe there was a tradition the royalties would encourage and patronize the development of science and mathematics stem fields by throwing grand challenges in data science the tradition is still there there's kegel competitions and and so forth. So you would throw a challenge, some challenge, and different mathematicians and scientists, they would try very hard to win in some measurable way. So there was some challenge, apparently some sort of a heavenly body, I believe it was some either asteroid or planetoid or something, I forget what, which was in the sky, observed in the sky, but had disappeared. And people knew that it's because of its position, the sun is coming in the way or whatever, you're not seeing it, but you will see it eventually. The question was, where will it show up, where will it show up? And when will it show up? Right? Well, that was quite a person. People, it was thrown as a person, and then people tried to all make guesses and submit their guesses. And they were all wildly wrong. But there was one person whose guess was so uncannily on the dot, some people actually thought there's a bit of witchcraft going on here. Remember those days people still believed in that sort of nonsense, right? Or something like that. So he made a prediction and he wrote a paper. This person's name, many of you have heard of him, is Gauss. Carl Frederick Gauss, I believe is his full name. He's called, rightly so, the prince of mathematics. He was a coal miner's son. The coal miner had absolutely believed that it's a complete waste of time not working in the coal mines, but being interested in studies. Somehow he managed to, because of a teacher who patronized him and encouraged him he managed to thrive in mathematics and do mathematics from a very young age i believe from the age of five or something like that right and he grew up to be the leading mathematician of his time lived to a long age i am of course very fond of him. Machine learning owes a lot to him, the foundational ideas to Carl Frederick Gauss. So Gauss was the one who solved that problem and he wrote a paper in 1793. But Gauss was a very interesting character. He used to believe he had a very interesting definition of genius. So if you ask what is genius, people come up with different definitions. And if you look at the workplace, you notice that people have a tendency that the moment they do a little bit of work, they'll immediately make sure everybody in the company knows or the bosses know, the peers know that they did this excellent work, right, to get credit and so on and so forth. Goss had the opposite sort of notion. He said that the best way is that to work really hard, to toil in the night, right, produce a result, and then like a wily fox, go wipe your trails, right? And then when somebody says, okay, this result, and says, oh, this was easy, and walk away, and then let the person figure out it wasn't so easy after all to find that, right? So interesting character. So anyway, he did that paper, but he didn't explicitly say that he used this technique, minimizing of the sum squared errors. In other words, the least squared error, the technique is least squared error, right? The sum is implicit in that, least of the sum squared error, the historic word is least of the... of the... So another word is hypothesis with the least of the sum squared error is the best. That is what we are trying to say, isn't it? In the discussion so far we have been leading to. So he basically used this technique. Now there is a story I heard, which I don't know whether it's true or not. I'm told that he was actually in school and some high school senior many years, the senior student came to him a friend came to him and he was doing some chemist chemistry, chemical reaction equation and he wanted to help the friend find the answer to something and in the process of doing that he had actually discovered it even more many years ago this concept right when he was still a kid anyway he wrote this paper in 1793 that famous paper then what happened and he said but he didn't explain it very explicitly. Then another mathematician, Lee Jandre, great mathematician, he wrote in 1805, he read the famous paper, least squares, method of least squares, I believe it is called. He was the one who coined the least squares, the method of least squares, which is exactly what it is. He gave it the name and so the method of least squares has remained. Except that the moment he did that, Gauss rose up and said, no, wait a minute, I should get the credit. I discovered it first. In mathematics, these sort of debates and science is very common. These are called the debate of the prior, who is the prior, who really invented something, the prior inventor of something. And many people have studied this topic because this is such a profoundly important concept in machine learning. It is the root concept in many ways. So Stigler, a great sociologist and statistician himself, he studied this and he found that actually three independent people had discovered it more or less simultaneously. Legendre independently discovered it, Gauss discovered it, and there was a person in US also, I forget his name, who discovered it. It's in my lab notes. When you read the notebook, you'll see his name. He had discovered it. So this was 1805 when this foundational idea came. So just to know that you know much of all these things that you see today, their roots are deep and old, right, of these ideas, of these great ideas. So now I will take a break and we'll go to the next question. All this is fine, but how do we minimize it? Right, the second part of the journey still remains. How in the world are we going to minimize But how do we minimize it? The second part of the journey still remains. How in the world are we going to minimize this error? So that, let's take a break for 10 minutes. Are you guys hungry? Would you like to take a lunch break? I hope not. No, we'll have another 40 minute session and then take a lunch break. So make it quick guys, 10 minutes break and we'll have another 40 minute session and then take a lunch break. So make it quick guys, 10 minutes break and we'll come back. To recapitulate, we learned that machine learning needs two legs to run on. One is you need to quantify the error. Then once you have quantified the error error the learning process is to systematically reduce the error so that you come to a hypothesis which exhibits the least error. and it turns out a really good way is to look at the sum squared error you can look at the sum squared error or the mean squared error or the root mean squared error they all are equivalent essentially because they all are the summation the inner core is the summation of the squares of the residuals errors right so that is it now why is this best? It turns out that when you look at the mean absolute error and you can come up with, for example, you could ask why not the fourth power? Right? Why not the absolute value of the third power? Why not many other different ways? So then, as I mentioned, the history of it is very interesting. 1805 is the Legendre paper. 1793 is when Gauss thinks he did it before. And he was right. He did do it. In, I believe, 1812, there was a landmark result that Gauss published. It's called the Gauss-Markov theorem. So the theorem is Gauss-Markov. So which says, and I sort of, I think I missaid it when I said blue theorem. Blue theorem is the result not the the theorem is actually gauss i just remembered that i sloppily said that gauss marco here here it said that the least squared error is the blue. When you square the errors and you look whichever formula you take, it gives you the best linear unbiased estimator. Quite a mouthful and we won't go into the proof or the too much details of it, but basically consider that it is a good idea to take that. And I'll give you sort of an intuition. I don't know if this intuition is mathematically rigorous. Most likely it is not, but I'll sort of give you. See, one of the rules of parenting is when your kid makes small mischief or mistakes, you deliberately look the other way around. Try not to notice it. Back parenting is to micro correct the kid for every mistake. We all know that as we parent it out, you deliberately make sure you don't look at the small mistakes. You let it happen. You treat it with a form of benign negligence. But if the child makes any mistake that's dangerous, that can hurt the child, right? Or that can form a really bad habit that will hurt the child, right? Or that can form a really bad habit that will hurt the child later on. Then you step in, right? And have one of the dogs. Outliers. Stronger, yeah, exactly. Bigger residuals. So what you do is you have amplified response for big errors, but small errors, you just let it be. I often think that that is a good intuition because when you're building a model and you're learning, think of your hypothesis of the line, it's a learning process as a child. What you wanted to do is the small errors, you sort of want to ignore and you want to amplify and make the big errors the teachable moments, isn't it? So when you square the errors, big becomes bigger, right? And small remains small relatively. So the square of 2 is 4, but the square of 10 is 100. You see the difference, right? So the bigger ones get amplified. right so the bigger ones get amplified and so when you take the sum squared error you are much more sensitive to what may be real deviations real residuals small residuals can often be because of something but because of noise in the data every data that you gather has instrumentation error or some form of error and we'll talk about it the next concept we'll talk is irreducible error in a moment uh the word make sure that today I do cover irreducible error so you want to not be learning from noise that would be foolish you want to be learning from the real signal which is the actual uh residual significant residuals go ahead so if you want to make the application more would you then use powers yeah so that is it the trouble with that is using very high power so now from two is good why not power of 10 right the power of 10 what it will do is only the outliers will speak The power of 10, what it will do is only the outliers will speak and they will completely hijack your model. So you don't want that either. In the past, I've also seen one more error measurement of mean absolute percentages. You didn't mention that. Is there a reason? So there are many such things. I'm just mentioning the big ones. But it can have all of that. Right. So it is mean absolute error. From there, you can go to mean absolute percentage error. It normalizes in a certain fashion. That is it. That is all it is. Right. But the big idea is these are what is called the norm first norm or the second norm like typically you look at that right and we'll talk about the norms a little bit later and cost you know so there is that so you know this is the trade-off and that's why there's a gauss mark of theorem that says hey uh too much of a good thing can be bad right don't go about taking the 10th power of it or something like that then only the outliers will speak and they'll dominate the learning process right you don't want that either and it so turns out that the square is the best you can do in fact most people don't even know that mean absolute error also works actually i suppose a lot of people know a lot of people also don't know they just know that the only way to do compute errors is some squared errors right for a reason it's become ubiquitous in most of the uh programming libraries so now so easily is there a wrench that this ssa will like or it can be anything i didn't follow is there a range no no no isn't. There isn't. This is a good question actually. We'll see in the data as we go to real life data, not today, but in the next step. See what happens is that you try to see, you see to ask the question, what value of whatever error you pick is good value. The number, it is not an absolute, it is from the data. The way you say that is given a data, it doesn't matter the size of the error. What matters is the relative size of the errors. That hypothesis, which beats other hypothesis in having the least error is the hypothesis you want to go with right so let me explain let me say this by a landmark statement in machine learning or in data science see guys data is manufactured by some causative force Data is manufactured by some causative force. When you see data, you don't know the causative force. People have not given you the equation because if they gave you the equation, the whole point of data science goes away. It's already done. Your whole point is to discover those or hypothesize what those causative equations could be. Now, here's the thing. You can come up with many equations or many models or many hypotheses that fit the data so so long as they make reasonably good predictions and have small sum squared error they are all good models you just are picking from the best right so there is a statement in machine learning in data science it goes to the great data scientist or statistician named box right a box literally box he said famously that all models are wrong you will never know even if your model makes perfectly good predictions, whether it is exactly that or there's some other correction to the equation. This is a broader statement in science, no theory is right. You can only prove it wrong. You don't remember the falsifiability of theories. You can falsify them, but you can't prove them to be true. so bach says all models are wrong but some are useful right so the pursuit of a data scientist is to find useful effective models effective hypothesis not the correct hypothesis in fact whenever you say somebody say oh my model is correct it is a sign of ignorance not only have they not understood what they are doing they haven't actually understood the whole point of data science and science itself science is not about correct is a constructive definition you say if it agrees with data it aligns with data it is in quotes correct and it's simple it's correct right generally you say that anything that aligns with data and also agrees with the occam's razor principle namely of all the models is the simplest one right the simplest explanation the simplest the occam's razor principle says that the definition of correct in sciences the simplest effective explanation is considered or defined as the correct explanation. Are we together? So, for example, let's take Newtonian gravity. You say gravitational force is proportional to m1 m2 over r squared. I hope all of you are familiar with it. Well, you know, you could write all sorts of complicated equations. R. V. But this is amongst the simplest equations that perfectly agrees with the data at least unless you do very fine like long range of corrections in which einstein's gravitational equation needs to kick in. R. V. Right Einstein's equation in the large right Jimmy new is proportional to our menu which basically says the energy at a given point in spacetime is proportional to the curvature at that point, which is again proportional to the mass sitting there. So, very simple explanation. It basically says that a heavy object just changes, if you think of spacetime as a fabric. You put a big object and the thing develops a dip. You take a stretched out fabric and you put a big object, it will develop a dip. And the amount of curvature the dip it will develop will be proportional to the mass. And that's all that Einstein's general theory of relativity says. Utter simplicity. Of all the complicated explanations you can come up with for gravitation and so on and so forth this is by far the most elegant and simple understanding of gravitation right and so simplest explanation is correct one so just keep that as a background we are going off on a tangent but the basic point is that you look for effective simple models that is your purpose. And simplicity is the Occam's principle. It has to be right. It has to be working. It must work. I mean, a simpler explanation can be wrong. That is not the definition of correct. You define correct as the simplest effective model or hypothesis as the correct answer. It's a constructive definition. Come again. You define or you choose? No, you define. Occam's razor principle says that in science, we define correct to be that effectively. So it says that the simplest explanation is the correct one. But implicit to that, that simplest explanation should actually work. It should be effective. And is the correct one means it effectively defines what is correct right it stays that that's the occam's razor principle right so uh anyway we'll leave that now comes the interesting thing can the any one of these error measures so i'll just focus on the least square error some square error and so forth can the error be zero can we minimize it to zero Can the error be zero? Can we minimize it to zero? And so for that, I will ask you to look back at this data. Do you notice that there are residuals? Can you ever make a line that goes through every point? No, right? Right. So what happens is that there are two aspects to the errors that you are left with finally, after you're done fitting the best model. One is called a reducible error. One part is called the irreducible error that remains, remaining error. So once you've done the best fit, then there are errors that remain. So one could be the reducible error is your hypothesis itself is barking up the wrong tree, right? So for example, if the real relationship is like this, and we will do this in the lab today afternoon to illustrate this point, suppose the real relationship was like this. Data points like this. Data points like this. Right. In this data point, suppose you make a straight line hypothesis, you say i'm going to fit a straight line to this data a linear regression what will happen is a perhaps your best fit straight line is this hypothesis. A. Right a linear hypothesis. hypothesis, they can be a hypothesis b which may be b which of the two hypothesis will give you less error. B, right? Now what happens is the first one says fit the best line. The second one says fit the best two-bend curve to the data, right? And the least square method will help you find either the best fit line or the best, this pink line, pink curve, right? So the HA suffers from more reducible error compared to HB because you have chosen a hypothesis which machine learning will just fit the best line, but it is not a line, isn't it? So these sort of errors are reducible errors. And this goes to the heart of things like bias and variance. But I'll give you a taste of it. What it means is that your hypothesis, our yellow line hypothesis, is simpler than the ground truth. Isn't it? It is simpler. It is simplistic. It relatively oversimplifies the ground truth. When you oversimplify the ground truth, you suffer from a kind of error which are called bias errors. The pink line hypothesis, pink curve hypothesis, is in this case, it's appropriate. It seems to be aligned with the ground truth more or less, isn't it? But let's take yet another hypothesis, which goes like this. What about this? It's a far more complicated curve, right? You say this hypothesis, would you agree that it is more complex than the underlying ground truth? It is too flexible, too complicated. Generally, when you take a hypothesis, which sees more in the data than you should see basically, right? Which sees that, then you have what I call variance errors, right? So see, when you have data, you don't know a priori which of the hypothesis will work. It is your job to fit the best yellow line, the best pink line, the best green line. The least square error will help you just make the best fit within its class. The straight line class, the pink class or the green class. But you have to know which of the three hypothesis you should have started out with. Is something you have to know which of the three hypothesis, you should have started out with. Raja Ayyanar? is something you have to do by trial and error, so that is often called a hyper parameter of the model right, in other words, you can learn it, you have to try and do it and see. Raja Ayyanar? Which is the best hypothesis right and so those errors which come because you didn't choose the right hypothesis you can have a better hypothesis these are your reducible errors right or for example you take a line you fit a line that is like this you haven't done your learning you didn't run your learning algorithm long enough and your line still says like this you realize that there is a journey from this line to the h c to h a there is still an error that you can reduce by running your learning process longer these are all generally the ideas of your reducible error now what are irreducible error do you notice that even if you take the pink line the pink line doesn't exactly predict all the all the points but there are still residual errors these errors you can't get rid of these are irreducible errors why do these errors occur think back at your ice cream situation that's a simpler situation of the ice cream and the entrepreneur could you explain if you say the sale of ice cream only depends on temperature you you have a best fit line and you have irreducible error what is the cause of that irreducible can you make some guesses i think it depends on some more variable yes Yes, it could be based on flavors. Somebody has more flavors, sells more ice cream. That is right. That is right. Whether you chose the right flavors that you brought in that day. Right? Other thing is, is it a workday or a weekend? Is it a holiday? Weekend or holiday? Because given the same temperature on a weekend, you'll sell far more ice cream because parents are free, they'll bring more kids there than on a workday. So that which the model doesn't know or cannot learn from, the data that is missing, the important features or predictors that are missing, they cause the irreducible error. So what if you ask this question, what value of sum squared error or the error, whichever error you take, tells you it is good? There's no clear answer. But the only answer is when your sum squared error is pretty high, or mean squared error, whatever, error is pretty high, it generally means when your irreducible error is pretty high. It generally means when your irreducible error is pretty high, your minimum irreducible error is still pretty high. It is an indicator that there is a lot that you missed. There's a lot that is unknown about this. It happens, for example, in in advert sales whenever you try to sell and you advertise and do things generally those people they build models in which the sum squared error remains very high so there is one way to quantify learning and which we will come to right now it is called the coefficient of determination. Let me get to that. We will now learn about a concept. Quite a mouthful, isn't it? This is often written mathematically as R squared, capital R squared. And people often, most people colloquially call it the R squared. It is one of the most popular measures of learning, how much your model has learned. So how do we do that? What you do is you compare it to no learning, right? So let me explain what it means, this. Consider back the same data, oh, what just happened? All right. Consider the same data. Or should I measure it in blue? Because the last time I did it in blue, it is the same data. See, this is your x, y. Now, you can build all sorts of hypotheses. One hypothesis is called the null hypothesis. The null hypothesis. This is a special hypothesis. See, on this page you can draw any line that you draw. Here's a hypothesis. So, for example, this line, this line, this line, this line, this line, this line. How many lines can I draw on this? Infinitely many lines. Each line is a hypothesis about the relationship between X and Y, about the amount of ice cream that you will sell and how it depends upon temperature. One hypothesis says the more the temperature, the less ice cream you'll sell, right? Another says, no, it's more, and and to what degrees and so on and so forth there are different hypotheses of all of these hypotheses one hypothesis is special this hypothesis says this is the null hypothesis it says that there is no relationship whatsoever between how much ice cream you'll sell and the temperature. Are we together? There's no relationship whatsoever. Now, if you, if null hypothesis says effectively that it is pointless for you to try and find a relationship, there is none. That is why it's called the null hypothesis. So the null hypothesis would say, just take the average value of y. y hat will always be y mean. Take the average value of all the observed y's and irrespective of x, it will always be that. That is your best estimate. So now this is your base error, total error total sum squared error whatever error you get for this actually the book uses this term if you forgive me i will use the term as e phi the error of the the residual errors of the sum squared residual error whatever means you want to take residual errors of the sum squared residual error whatever means you want to take sum squared error of the null hypothesis are we together sum squared error actually your book uses the word rsa so we'll use rss some square of the null hypothesis, right? Now, let us say that you take another line, you come up with a hypothesis, a different hypothesis. Let's say that you come up with a hypothesis like this. Let me just call it H. What should I call it? One. And let's take another line. Well, I have used, I foolishly used pink for the axes, which I shouldn't have, but let me use something else. Let us take another line, which is uh green let us say that i have a hypothesis like this h2 and i i can have a hypothesis which is which color should should I take which will stand out? Let me take yellow, I took green, I took blue, I'll just use blue. Or let me take this. Let's see about H3. Just looking at this picture, you would probably agree that the error of H3 will be even worse than the null hypothesis. Isn't it? So this is actually an important point. Most people don't realize that you could do a learning exercise and what you have learned is actually terrible right yeah you actually can learn worse than the null hypothesis which is this error is greater than i suppose h of h2 the green, would you agree with this? Actually, let me color the lines with the error words appropriately by their color line colors. Would you agree that this is true and this is greater than E green of the green line, which is H2, and that is greater than e error of the small one would you agree essentially to this inequality just uh just by doing a visual inspection of the data of the plot here isn't it now comes the question how do we quantify that one is better i mean instead of looking at the total error what people have come out with is they said this find the if you take the error of a hypothesis of any hypothesis actually let me use white because i didn't want to use pink here because I didn't want to use pink here. E of a hypothesis, error of a hypothesis or a model is equal to the sum squared, I mean, sorry, not this, there's a word for it. It's called R squared for historic reasons, R squared. I take the error of the hypothesis, subtract the error, sorry, the initial error of the total of the null hypothesis you know that this is hopefully positive number isn't it would you agree that hopefully positive, negative. And then you ask yourself relative to the initial error, because you know, this will be a number, but let's scale it down and say proportionately how much did you learn right the initial error the null hypothesis error right would you agree that this would be a pretty good measure of learning so let us let us unpack this and see if there is no learning if e h equal to e phi approximately equal to like very little learning very little learning r squared would be numerator would be if the error of the hypothesis is very close to the error of the null hypothesis what would be if the error of the hypothesis is very close to the error of the null hypothesis what would be the numerator and so 0 over whatever total it is this will be close to 0. if on the other hand let us say that there is perfect learning there is perfect learning right if e h is close to zero let's say that there's very little irreducible error remaining what will happen when r squared is one equal to one it will be a little less than one because there will always be irreducible error it will be so means good models good hypothesis will have a high r squared and not so good hypothesis will have This is a coffee pot that was filling this space. Okay. So what do we conclude from that? R squared is a way to quantify the amount of learning. Quantify the fit, the goodness of fit. People use this word goodness of fit. Offer model to data. Are we together? This is it. It takes value. So R squared is always less than one, less than equal to one. Can it be zero? Some people think it is between zero and one, which generally two, but if you look at the blue hypothesis, what do you realize? R squared can be negative right so it has picked up some junk right it has learned some junk it does happen actually it does happen so this is it this is the meaning of r squared it is the coefficient of determination come again why is it called square Come again. Why is it called square if it's . Yeah, see the word R squared is historical. I wouldn't put anything to it. The right word is coefficient of determination, but people don't use that word. Most of the Python and R libraries, they keep using the word R squared. It's a fact. But obviously, the point remains that you don't call something a square if it can take negative values right it's it's historical right so i don't know the question for the normal purposes you said that you take the y to be the green right yeah so which means that it depends on the distribution of what you took as a sample exactly yeah but if i put some other function which kind of says i need to give a little bit more priority to the guys on the right that value of the y would have been further up yeah now you're like changing the whole dynamic so how do you so you're basically saying this yellow line i could lift up and down right so yeah see you have to as a convention pick one of them as the null hypothesis so by definition of that convention people have said that the null hypothesis is first y has no relationship to x it's flat okay the second is now which value of y just take the mean of observed rights no but do you like take a sample say suppose you have thousand points right yeah you take like say 200 200 like that random get then you know the mean and do it or no no no you just typically typical of if you went and did such a so typically what happens is that when you are learning the data you have the data you don't know whether it's the full data or it's the sample but whatever it is you say for that data the null hypothesis is whatever is the mean okay yeah that's how you do it is, you say, for that data, the null hypothesis is whatever is the mean. That's how you do it. And then you always hope that if you never build a model once, you build a model many times over. So then the center limit theorem will kick in because the mean of the means will be stable. So that is it, guys. So now we have a way to measure, least one way to measure the goodness of it. But the fundamental question still remains, how in the world do we minimize this error? Right? So there are two ways of doing it. So two good ways. So one is of course, a silly way. One is so I'll exemplify it with a simple thing. You know, you do the same thing in normal software engineering. You do sorting, right? Is the base of all undergraduate classes. The moment you enter undergraduate algorithm, the first thing you do is sorting. There's bubble sort, there's reddick sort, there's merge sort, there's, you know, a quick sort, and God knows how many ways of doing sorting. I mean, it's a whole world of research, sorting, efficient sorting. So the pursuit is always for the best sorting algorithm, but there is actually a worse sorting algorithm too. Right? So what do you do? Suppose you have to sort some items, comparable items, numbers, let's say. What you do is you just shuffle them and then you check, is it sorted? No. Oh shucks. Let me shuffle it again. And then you see, is it sorted? Oh no. Oh God. OK, let's shuffle it again. And you can keep doing it so that one day you'll end up with a shuffle in which it's truly sorted. It's a valid algorithm because one day it will converge, it will terminate, but surely you don't want to try that. It's like buying the lottery ticket. What's that? Is monkeys writing Shakespeare? Yeah, typing out Shakespeare, right? Buying the lottery ticket. Or buying the lottery ticket, yes. So in same way, or one way of finding the best hypothesis is to just keep on drawing lines. R. Vijay Mohanaraman, Ph.D.: What does it mean it's. R. Vijay Mohanaraman, Ph.D.: Each line is uniquely defined by a slope and intercept beta not beta one isn't it just take random values of beta not beta one take ten thousand random values and for each value right for each value compute the r squared and find out that one which has the lowest r squared or the lowest sum squared all of these are equivalent are we together and then you say ah i got one. Totally silly as the sound, actually many times when I see software engineers do work, because we live in the world of big data and distributed computing, you often find them finding brute force solutions like this. Take lots and lots of experiments because you have so much computing power and pick the best. Sort of like our sorting. Now there's a problem with that. First is it's computationally intensive, may take forever, long time. And you never know whether any one of those solutions are really close to the optimal solution. Isn't it? It is really close to that H1, the lines that you pick. Because there are infinitely many lines. Even if you picked a thousand lines, they may have all been far from the right answer. So picking the best amongst them is still no guarantee that it is an effective model. So there is a way actually to systematically find that. And that brings us to the other profound concept, which is that of gradient descent we'll learn that it's a very important concept we are going to learn that today and that would be the last theory topic for the day okay then we'll all take our hungry stomachs to lunch so gradient gradient descent. What is that? The topic now is gradient descent. So gradient descent is something very simple. First, we will try to go back and look at some basic mathematics that you may have forgotten, but I'm sure coming from STEM fields you have all done at some point. Do you realize what, what, when we write y is equal to the function of x, some function of x, right, we plot it out as this. Given x, we can have a curve curve let us say the curve is just by choice let's say that the curve is like this this sort of curve are interesting curves see i could have drawn all sorts of wiggly curves like this or whatever it is. I didn't. What is different between this curve and the curve, the big curve that I drew? Simple. It has one bend. Do you notice that? It has only one bend. The word that people use is that it's a convex function, right, bulge. These are different, and then we'll go to that. But more importantly, these are convex functions, but it need not be convex. In the world of machine learning, it turns out that non-convex functions, et cetera. But the point is, it has a minima. This point is called the point where y achieves a minimum value. So this particular value of y, right, and this particular value of x, let me just remove it here, x is here, x axis is here, this particular value of x and y represents a unique point, it's the bottom of the valley, isn't a unique point, it's the bottom of the valley, isn't it? Bottom of the curve, x star, y star. This is called a minima. Right? So you say that x star is the argument is the argument of which x value will minimize y. Which value of x will minimize y. It's a minimum. It's a fancy, actually forget argument. Let's not use all of this. Minimize, a minimum point. Right. Now, how do you find this minimum point let's do that suppose that you are here suppose i take this point here this arbitrary point to the left let me call this point a right now observe we will look at the slope here if i move unit distance positive delta x does y increase at this point or decrease please okay delta x leads to y decreasing positive can you please mute yourself guys what about b suppose i take another point, let's say, b. So actually, let me put b here and a also here. So a and b are points in the xa. So let me just actually, I could use, let's agree on some convention. Xa and this is xb. We'll call this point a b right now what about this what about b at b at a delta x if you move one step forward delta x if you move one step forward delta x leads to y increasing right so what you say is that at b the curve is rising it has a positive slope that's literally what it means slope is is defined as delta y over delta x how much of greater than zero isn't it and delta y delta x at a is less than zero would you agree with this guys this is visually obvious isn't it right now suppose well you could say that if you want to find this place, this is the point you want to find, right? Go to somehow. Right? So let's call this home. You want to find this point, the optimal point, it's your home. And you're a little ant right imagine yourself a little ant on this curve and you are want to go home but you have the ability to tell what the slope is which way are you going to fall right if you don't grab onto the slope can you find your way home it's very easy it's very easy at x what do you do you take a step in the direction of the slope or against it when they look at a slope here is negative means if you take a step forward y will decrease do you want that to happen yes because so at a you want to keep making steps forward right what about b at that slope is positive but you want to make steps like this against the direction against the direction of x axis opposite to that so we can say this statement that there's little steps that you take that we put it here the next at b at a your your next value of x should be x next should be x a minus you take a tiny step but in which direction because slope is negative negative of a negative is positive so suppose i do this a plus minus slope would that work because my x would become x next this would be positive right because minus would go against the slope minus of the slope and it will become a positive quantity but then how big a slope how big a step you take you can control may say, let me take a tiny step in the direction of the slope, against the direction of the slope. Are we together? So then you would be going in the right direction at A. Does that make sense, guys? Isn't it? Slope is negative. So suppose I go minus of the slope and a tiny bit of it means I took a tiny step in the right direction. At A, at B what happens? X next should be XB. Now look at it, slope here is positive. But you want to go, you want to go this way, you want to go back. So is this the right way to go back? Right? Let's make a smaller step, not make a big step, just in case the slope is huge. Would this take us backwards? So in both of these situations, it would take us to the correct place. And what about this place when we have reached home what is the slope here zero so we we won't be making any steps anymore isn't it because you don't know where it is see uh in in in a function like this you could say hey you know what let me take the slope and set it to zero the problem that happens with this is uh in this picture it's true but suppose you grab i mean there's a whole complication this real simple curve doesn't actually happen in machine learning often right what happens is that you get a world in which you get a reality first of all multi-dimensional reality and then you get a curve like right so so many places you see that right so those are the issues that come with this go ahead why are we just taking one step? Can't we progressively change the amount of steps we take based on how close we are to the zero value? That is right. So that brings up to this alpha, the size of the step. See what happens is, okay, so I'm coming to that. Hold that thought in your mind. I'll gradually embed into it. So let's generalize from this fact. Do you notice that whether you're on the left side of the answer or the right side of the minima, the equation looks exactly the slope, right? dy dx. Now, we can generalize this to higher dimensions. So, okay. So, before we do that, this is the gradient descent equation. Now this is called the learning rate. How big a step are you willing to take? Typically you take tiny steps, 0.01 times the slope and so forth why because some like let's say that you're here and you take a big slope like suppose you're here where should you say you're here and you take two bigger slope you might end up rising getting to the wrong place right so you don't want to do that so learning rate and we will come to the learning rate in the when you come to the deep learning workshop it's a very important concept you worry about the learning rate and should the learning rate keep changing at different stages of the learning process right quite a bit there's a vast literature there right but at this moment we'll take it to be a constant and just pull it out of your hat pick a number small number just keep it small right don't make it too small because then you'll just be sitting in front of the computer and waiting for it so so in our profession actually data science is a very easy way to goof off in the office you're playing ping pong your manager comes and says what are you doing says oh my algorithm is learning right i'm babysitting it right so no one easy way to do that is very low learning rate it will take forever right not that so be judicious about it now let's take a generalization of this to higher dimension what is dy dx in higher dimension multivariate catches you know when y is a function of x1 x2 x3 x4 the gender is the same thing is generalized to the symbol dy dx generalizes to like what you may call effectively dy d the x vector in some sense because now it is x1, x2, x3, x4 but this is equal it is called it is this symbol this symbol is the nabla symbol or people just call it the grad grad of y or the gradient of y are we together but no change there's nothing magical here we just generalize it to higher dimension right this is it and so this equation therefore becomes the x next would be if it was not a curve but a surface right a two-dimensional surface or three-dimensional surface or so forth this would be x minus alpha the gradient of y right and x would of course now be a vector. This is what it would be. This is your famous gradient descent equation. What it basically says is that, and it's a common experience, those of you who go hiking, what is the path of steepest descent? What is the fastest path to the bottom? You don't want to take that. But you all know intuitively what is the fastest path. Go down the steepest path. But you learn fast also. You learn fast also. So every time you slip and fall in the hills, you are taking the path of steepest descent. But while you don't want to do that to yourself, when you're in the world of machine learning, you want to get to the answer as quickly as possible. So you do take the path of steepest descent. This is also called the path of descent right so this is it now comes to think how is this basic theory applicable to our loss function we are going to come to that now now what, what is the time? It's 1.24. I will... How many of you would like to take a break at this moment? You guys would like to take a break at this moment. Okay, guys, let's do that. Let's take a break for lunch. After that, I will relate it now to our error function and put the two together and so you will learn you will actually know what the learning how the efficient learning happens in machine learning so let's pause the recording kyle at this stage so guys look at this bowl. What was a curve in two dimension? What does it become? It becomes the shape of a bowl, right? This curve that I've been showing, if you look at the screen, this curve and look at this bowl in two dimensions this is your surface the function surface so if you're inside the bowl imagine that you're inside the bowl what is the path the shortest part to the valley to the bottom you want to literally tumble down the path of steepest slope isn't it that is your path of steepest descent fastest part the bottom is if you're a little ant and the fastest thing is you just go like this and you'll tumble down straight the steepest path do we agree with that that is why it's called the steep as opposed to most of you when you are hiking what would you do Let's say that when we're hiking, it's more like this. You're at the top. You want to come to the bottom. You will gradually circle around and around and around and around. Is that the steepest part? No. It is just gentle gradient to the bottom. If you're inside also, you'll do that. Imagine that this is the Yosemite valley and these are the hills around yosemite what will you do when you're hiking you'll slowly make your way down isn't it and that is the difference right that is what we are talking about this uh this gradient descent or the path of steepest descent the reason we learn like this is because it's the most efficient way of learning as opposed to randomly drawing lines and doing it. So now what does this mean with respect to this graph here? What happens is. This thing, right, this is a surface you could have taken a path inside like gradually coming to this but the steepest descent path basically says you are down to the bottom right the steepest part you make little hops from here to here to here to here to here and to this part. Now, one interesting thing that comes up, you don't want to make two bigger steps because in the extreme case, if your steps are too big, let's say that you are making this bigger step. A is very big. What will happen? You will overshoot the minima, isn't it? You instead of reaching home, you'll go way past it. And then you'll again want to make a jump, and then you'll keep jumping. So you'll keep oscillating around the minima. Right? So that is why learning rate is important. Small steps are better. But too small a step means learning is very slow. So this is why learning rate is important. Small steps are better. But too small a step means learning is very slow. So this is it. Now the whole question is, this is the degree. Let us now relate it to our problem. Our problem is this, once again. And now I will teach you about two different worlds, an abstract world, a space of hypotheses hypotheses and the real space of data what is the real space x y's what people use but if think of two different worlds data space it is made up of x y right in the x y world data manifests itself the data that you get from which you have to learn is here right let me show some more data here, forgive me for my bad art. But we'll go with this. Are we together? These are actual observables. Right? Right. Now, any hypothesis that you make, let us say you make a hypothesis. I'll just make a random hypothesis. Let's say that you make a hypothesis. H1. This hypothesis is a line. It is at this moment we're only talking about lines here. This is uniquely specified. Uniquely specified or in common sense is defined by slope and intercept. If I give you the slope and intercept, there is but one line that you can draw, isn't it? So the line is same. Therefore, h1 is the same as beta naught, beta 1, intercept and slope. A unique value of beta naught beta one isn't it that is it so now what we do is we think of another space here you would agree that this thing belongs to some point in this case slope is negative and intercept is positive. So it is probably a point here. Actually, let me use the word A. So this is beta naught, beta 1 for point A. Isn't it? This is beta naught, beta naught axis. And beta 1 axis slope axis in this this imaginary world the hypothesis space. Raja Ayyanar? Would you agree that this is it, then you can see that the a line corresponds to a point in the hypothesis space a particular value of beta naught and beta one this is simple isn't it likewise if i make another hypothesis let us say i make a hypothesis like this h b this gives you negative slope, a negative intercept, let us say, and a positive slope, negative intercept in a positive slope. Let me call it B. So beta naught, beta 1 to the point B. Would you agree that here, this is your point B in the hypothesis space right if i take a another hypothesis which is like this at c positive this and positive that c in the hypothesis space it is this point and then perchance you end up hitting it quite close to the right one let us say hd hd may be somewhere here right d more intercept than c but the lesser slope so this is it you you're positioning each of your hypothesis in the hypothesis point so in other words there is another world of hypothesis space and what are you doing in your hypothesis space you are saying how can i suppose i start with a random line suppose i start with a the question that we have to ask is what is the most efficient path from this to this from this to this from this to this from all of the different hypotheses to d isn't it how do we go from this not so good lines to the best line? So I can pick some random values for the hypothesis. Initial hypothesis can be bad. It'll make a huge error. Now, how do I improve my hypothesis systematically so that I can reach the hypothesis d as quickly as possible right in other words how do i find if at all possible a quick and shortest path from here to here from here to here and from here to here that is our problem isn't it that is what we would want to do so now observe that at each point in the hypothesis there is also the error associated with hypothesis a error associated with hypothesis b error associated with hypothesis c, and error associated with hypothesis B. Isn't it? At each point in the hypothesis space, we can compute the sum squared error because it is that hypothesis will produce with respect to the data, a certain error in prediction. So far so good guys, are we understanding this? And so we can now look at this data in a more three-dimensional way. Let's look at it. What we are saying is something interesting. Let's say that this is the beta naught axis, this is the beta one axis, and this is the error associated with a given beta naught beta one axis. And this is the error associated with a given beta naught beta one. Right. So now look at the error. Your error is, let's say that we are looking at the sum squared is equal to summation of y i minus y i hat squared over n this is your error i'm just taking a sum forget 1 over n and all of that right they're all equations now what was our hypothesis our hypothesis is y i minus beta naught minus beta 1 xi all i do is substitute the fact that this is equal to beta naught plus beta 1 xi isn't it the prediction is the value by plugging in the lines formula you agree with this right so far so. This is a very crucial point. Please make sure you understand that. Divide by n. Oh, forget that. Forget divide by n. Who cares? I mean, ultimately, it's the same thing. If you want to, you can divide by n, right? Oh, of course, I forgot the square. Right? So now, when you're learning, when you're moving from one line to the other think about it is the data changing data is a given you're learning from the data so in this equation data is fixed so this e is actually the as you change the value of beta naught beta 1 in other words you change your hypotheses the error value for the hypothesis keeps changing isn't it so e is actually a function of beta naught beta 1 isn't it and it is equal to this or also written as e as a function of the hypothesis a point in the hypothesis space the hypothesis, a point in the hypothesis space, right? And that is it. E is here. So what it means is that in this plane, if you take any one point, there would be a certain error, right? Let's say that this is D. And what will happen is, now let's look at this equation. Does it look in beta naught in beta 1 does it look like a quadratic equation it's quadratic right if you expand the terms will it be quadratic in beta naught and beta one that's true and when you take the sum of squares can it ever be negative no right so however much you minimize it it will still be a positive value. And what does a quadratic curve look like? You would agree that a quadratic curve looks like this. The only question is, is it pointing up, pointing down? We know that it has to be pointing up because it has to be lifted off the ground. You know, there is a there is a residual error irreducible error that will remain right so now generalized to beta naught beta 1 this is a surface right so let's draw the surface out what will happen is it is looking at uh well okay i did not center it i'm terribly with this plotting so let me take another color it is actually what is a parabola becomes a paraboloid kind of thing right isn't it what's that the last thing that we have the last the worst right right exactly it's sort of that right so or it is like this too the same thing the error surface right so that's why you need to keep this when you're learning machine learning right so now this thing has a minima and you realize that d is the minima has a minima and you realize that d is the minima but now you can look at the contour lines if i project the values the points of this down you would agree that they form contour lines these are called contour lines you know what are contours points of equal value of the error on the surface they when projected down form this circle on the surface. They, when projected down, form this circle. Ellipsoid rather, not circle. These ellipses, they form in the beta node beta 1 plane. And so what happens is that suppose you are here. What does this correspond to? Let's say that here. Suppose you happen to be this hypothesis for the sake of argument, pick a number. Let's say A. Right. You are here. This is your hypothesis A. This is the error for hypothesis A. This point is the error for hypothesis A, the height of this. is a this point is the error for hypothesis the height of this right what do you need to do you just need to use the gradient descent to keep doing this reach here right so you need to find a path to do this and the fastest path is gradient descent so basically you are you do the gradient descent in the hypothesis space this is very important in the beta naught beta one space are we together and this is how your error surface looks and this is the iconic diagram in this field, guys. Try to remember this, right? That you are doing gradient descent in the hypothesis space. People often use the word, say, I use the word hypothesis space, but I'm probably sort of not very commonly people use it. It is called the parameter space. That is the common term that we have. What are the parameters? Beta naught, beta 1. Because those are the parameters of the hypothesis, isn't it? So the circular thing below is the... Projections. These are the projections of the contour lines. So that is called the parameter space. This is the beta naught, beta one is the parameter space. And if you can include the error also, the three-dimensional space is your parameter space. I just call it... So parameter because hypothesis is uniquely defined by its parameters. I tend to... I find it easier to think of it as the hypothesis space in which you're wondering and looking for the best hypothesis. is the hypothesis space in which you're wondering and looking for the best hypothesis right but that word is not commonly used the more commonly used word is the parameter space go ahead no it won't be straight it will vary right so it will be a curve kind of a thing now in linear regression life is very simple. But actually, when you come to more complicated situations, it's sort of a zigzag path. Gradually, gradually come to it. Also, the whole question is, we are this kind of gradient descent that we're talking about. How do we look at the error of the entire data set at each step or small batches of data and so on and so forth? So there are all of these notions of batch gradient descent, mini batch gradient descent, stochastic gradient descent. There's more complications to that, right? But let's focus on the key ideas today. And then there's more happening there under the covers. So now I would like to say that we have covered two big ideas. We say machine learning is quantifying error. For regression problems, sum squared error is a pretty good way of, a simple way, linear regression without, these are called ordinary least square regression. You will realize that I will change it a little bit. It gets more, new nuances keep coming in as we move and do regularization and sector. But for simplicity today, error is what you minimize. When you are minimizing the error function, the best way, the fastest way to do that is using gradient descent, right? And when you do gradient descent, it will take you home. So you quantify the error, you minimize the error. Minimization of the error is the learning process. The learning of machine learning is the minimization of error, which you're doing here using gradient descent. Right? And that is the heart of machine learning, guys. So it guys i will just some it's is there any point that i need to now this is a lot of big ideas that i brought in i will just summarize i don't know if i need to summarize i will repeat some of these ideas in the next session and by the way all these handwritten notes i'm going to post to the class discussion group so you can read my scribbles right it will be there with that if you don't have does anybody have questions before we take a lunch break not everybody is hungry okay folks so it is exactly 2 p.m how long a lunch break do you do you think we should take after that there is three four hours of lab should we take an hour and a half of lunch 90 minutes is it okay or two hours i think one hour should be good 90 should be good yeah no because some people have to how many of you have to go to the restaurant to get lunch only one person so those people who are going to restaurant give a realistic time okay almost everyone so the restaurant people give a realistic time how much do you need i think hour and a half hour and a half let's go to a basketball a half hour and a half let's go to a passport something that will get us back to you when you don't speak no no don't do quickly because you have a long long four hour session who does this thing get in and out okay yeah if you can take out and bring it here and so forth so one night 60 minutes or 90 minutes 90 minutes. 90 should be good. All right, 90 minutes. Let's go with 90. I don't want to start with the half of people missing. All right, folks, welcome back from lunch. We will continue now to the lab part. As per our lesson plan, today's lab will focus on linear regression and some variations to it. We will devote the next couple of hours to stepping through carefully through a few data sets we will be dealing with the data set shortly but before we do that there is a small visualization the two visualizations one kyle created and posted to slack i don't know if you noticed it a very nice plot of six figures six subplots that shows you how correlation varies for different values of uh different value i mean how the graph how the data looks for different correlation values now here is a little visualization that where you can see this is all in your code when you download it from the lab the guided lab section you will get a file called correlation.pegz just unzip the file and read the readme now I'm going to at this moment just show it to you but at some point do make sure during the break that you play around with it yourself it's a little visualization i created and if you look at the screen as you change the correlation row the data seems different so for example when you go closer to zero the data shows no relationship do you notice that the data at this particular moment close to zero, it is just looks like random data. It has no relationship. X and Y are unrelated. For any value of X, Y could be anything. On the other hand, when you go and have a strong positive correlation gradually, it becomes more and more stronger related. Now I encourage all of you to please try out this visualization. It gives you a good idea of the basic concept of correlation for data. Remember, if there is correlation, there is a relationship, linear relationship. But absence of correlation does not mean there is no relationship. So we talked about that, just to review it. Now, with that being there, this application that we use, it's very popular, this library is very, very popular amongst data scientists. It is called data scientist dream. You don't have to learn React. You don't have to learn Angular. You don't have to learn the whole web technologies. You can write your UI in interactive UI in Python, just a few lines of Python and run it and lo and behold, you have a perfectly good web application running. As you can see this is running on kate's local machine you can therefore quickly create the application if you look at the code it's a i will i suppose at this moment i'll take over and show share my screen and this And this. And, oh no, not share that screen. Sorry. Yeah, I will share that screen itself. But is that better? Yeah. So if you go into this, whenever I give you a zip file, you will always find a readme. It is customary in our field to create directories of code or notebooks and then have a readme file there. These readme files are typically written in Markdown. What it says is if you, this is pretty much, and to run it, you need to give this instruction by streamlet run main.py, right? So if you give this thing on your command line, it will, you can run it locally. I won't do that. it will you can run it locally i won't do that but i will now start with the three data sets that we have the first data set is okay so please download these three data sets from either the internet i mean from the class course if you want to keep it locally otherwise you don't need to it is available in github you can directly load it from github without needing to download it so i will now go through the i think zoom is not sharing this what is zoom sharing oh so i'll stop that again actually let me do one thing for the for the duration you know okay um yes i'll do that let's see what it takes to make it look better is it now readable? Is this better? Okay. So folks, we are going to take a simple data set. It is a univariate data set means there is one predictor and one response x is the predictor y is the response and we will go through the traditional uh data science approach we'll just do it methodically and this sort of a methodical approach that you will learn here i would encourage you to always use in practice go very slowly methodically through data now this is the outlines as we advance in this course in this workshop i will add more and more to this method this data analysis pipeline which will start with the basics now typically on my machine on the linux i have set certain style sheets which obviously you don't have but just so that it looks and of course, on this laptop isn't there. So what I've done is the first cell you can ignore, it is just the some HTML styling for the page, you can ignore that. So let me make sure we run. Let me make sure we run it. Yeah, so this is it. Now, sorry, I gulped down coffee. This dataset is available on GitHub, support vectors ML100. You'll see a lot of datasets there. In the course of this workshop, you will be analyzing all of them. But for now, we'll start with one simple one, univariate one. This particular data set is quite a simple one because we are starting to learn how to do it. As we analyze this, and the two things we'll do, we'll build an exploratory data analysis, we'll visualize the data, learn to visualize the data, and we'll also learn to build a simple linear regression model on the data. So what are the goals for this lab? The goals are we will explore this data, observe its statistical characteristics, you understand all of the basic descriptive statistics and visualize it. That is one goal, which is the exploratory goal. The second goal is we will take a systematic approach to build a regression model and then use it to make predictions and then see how good those predictions really are. So those are the goals of this lab. What is the outcome that I'm hoping for? What is it that we plan to learn from this? My hope is that at the end of the lab, we should have an understanding of the following, each of these eight items. What is a data frame this is a concept we learned shortly how to load data into a data frame and describe it how to use the pandas profiling to get some basic understanding of data it's a library that's quite commonly used these days how to visualize the data using matplotlib is one of the data visualization libraries. And then next onwards, so the first four are data explorations. Then we build a simple linear regression model. We will learn how to do that. We will learn to do residual analysis of the model prediction. We'll learn about this words may not mean much, but it will mean something after a while. Model diagnostics. Is the model good or bad? How do you determine that? And finally, can you confirm the quality of your model by making predictions and visualizing those predictions. Now these steps that I write, the last all of these steps, all of these things, these are crucial to data science, basic data science. So we'll start with it one by one and make progress. For those of you who are remote, let me know if you are able to see me. For those of you who are remote, let me know if you're able to see me. Are you folks able to see me? We can see your screen. Okay, in a box or somewhere. Oh, I should be visible. I don't know. Yeah, we can see. Oh, yeah, we can be visible. I don't know. Yeah, we can see. Yeah, we can see you. Yeah. We can see you. Unfortunately, my table's arrangement I have to fix. I apologize that I'm visible in a corner of the screen. But OK. So what we do is this is first step is to import the necessary libraries. What happens is your notebook is running as a process and basically the libraries of python that you will use you need to sort of bring it in right and by looking at the import at the end of any jupyter notebook you can often get a sense of where it's all leading so i'll what'll line by line explain what each of these means. So we start with some of the standard imports which you are likely to do very very often. One of them is NumPy. NumPy is the library which gives you amongst other things the n-dimensional array. Arrays and matrices right and higher dimensional arrays they come thanks to the numpy library in python now the numpy library has a lot of hundreds of functions very very useful you can spend months gradually mastering them but at this moment and for quite some time we'll just focus on just the ability to create arrays arrays of data right so that is like pandas pandas is a library that gives us a representation a standard representation of data which is more or less a canonical representation sort of the way data scientists think of data when they are doing analysis this structure this data structure is called data frame the easiest way to have an intuition about data frame is to think of it like a single sheet of spreadsheet, single spreadsheet, not with multiple tabs and this and that, just a simple rows and columns. Another way to think of it could be like the results of a SQL query, rows and columns in a database, right? But this, it is not just a sort of an inert repository of data in a rectangular form, rows and columns. A Pandas data frame is more than that. These data frames typically come with a lot of functionality built in. They help you manipulate the data. They help you do descriptive statistics and other things with the data, a lot of conveniences and functionalities built into a data frame typically. Now data frames are the foundational unit, whether you're doing work in R or you're doing it in Spark, you're doing it in Python, everywhere the word data frame, it is part of the sort of the vocabulary the first statement that people will say have you loaded how is the data looking in the how does your data frame look or how does it look just show right so we'll use that then the next are the pre-processing libraries obviously it's a little overwhelming here if it is too much of new stuff at this moment you can ignore some of it see when you train a model how do you know that your model is good model algorithm has seen the data how do you know that it hasn't just memorized the data one way to do that is to hide some data sort of under the pillow not show it right and give it only a subset of data to train from when you give it only a subset of data to train from and you hide the rest later on you can ask the model to make predictions on the rest of the data and see the predictions that it is making the y hats how closely does it agree with the y you can then look at the residuals just as we did we talked about it a little while ago before lunch so we'll do that so what you do is you take the data and you do some sort of a split 70 30 split 75 25 split or one third two third split whatever is your favorite number 50 50 split you can split the data keep and hide half of it the part that you hide is called the test subset of the data or test data people just say test data The part that you hide is called the test subset of the data or test data. People just say test data. The part that you give to the algorithm to learn from is called the training data. So we will split it into just two parts. More sophisticated way would be to build it up into three parts and so forth. But here we just break it up into three parts and so forth, but here we'll just break it up into two parts. You also notice that there is a standard scalar. Remember, we talked about Z valuing things with the random variables, you convert them into the Z value equivalents. Right. So the standard scalar does that it helps you do that. It's so turns out that in this lab, I decided in the interest of simplicity, I didn't scale the data. And for linear regression, you can get away without scaling, but you don't get away without scaling for a lot of other algorithms. So we'll let the scalar be there, but I thought I'll mention it. Then you have something called polynomial features. Why we need that, you'll see in a subsequent lab and also make pipeline. You can ignore the polynomial features and make pipeline for now. Just the most important thing to remember is the train and test split of the data. So Asif, quick question. So what is the difference between the train test one and the data frame itself? In the data frame as well, we can split it, right? So. Yeah, yeah. So when you get the data frame, it has so many rows and so many columns. So what you do is you take a random number of rows and you consider them to be the train data you create so you divide a data frame into two two data frames two subsets one data frame you call the train data the other data frame you call the test data and basically it is built out of the original data frame by breaking it apart into two pieces right so some rows go into the train data set and so the rest of the rows go into the train dataset and the rest of the rows go into the test dataset. And all those datasets are data frames. Does that answer you? Yes, sir. Yeah, yeah. That is it. That's pretty simple thing. You just chop it off. The only thing is that you don't want to do it sequentially. You don't want to say, okay, the first two-third rows make it train the last one-third row, because there may be a pattern in the data. For example, data may be sequential by chronological order. So what test train will do is internally, it will do the shuffling. It will randomize it, make sure that you get a random selection of the rows. So that is what it is. Now comes the, where am I? Give me a moment. Yes. So next we go to linear regression. See, today is the day we are going to learn linear regression. So this is what we have been talking about, simple linear regression. This is it. Now, when we said that we are going to look at errors, how much error is there? Do we recall that we talked about the mean squared errors? Right? Mean squared error is the sum squared error divided by the number N, the number of data points. That's the mean squared error is the sum squared error divided by the number n, the number of data points. That's the mean squared error. And the R2 score, can you guess what that could be? R2 score gives you the R squared, the coefficient of determination. We talked about that, if you recall, right before lunch, the coefficient of determination. So these are two key model diagnostics to get a quality of fit, a goodness of fit of the model to data. We'll look at that. Then comes a lot of graphic libraries. Why is that? Data visualization of the data is very crucial in this field. Sometimes a lot that you can literally when people say a picture is worth a thousand words, it is very much true here. Sometimes you may do all sorts of analysis and this and that and get a sense of the data. But the right approach is to also include visualization and emphasize visualization because a human eye is a massive computational engine, well evolved over 100 million years. It grasps things in the blink of an eye, literally in one single glance, it absorbs a lot and sees a lot and learns a lot. So you do want to have a very rich visualizations here. So in this field, plots, graphs, et cetera, diagrams, they're not just sort of pretty things. They are at the core of the subject, data science, a lot of emphasis you put on data visualization. So the default data visualization library that comes built in, that most people use when they do this thing, Python based data science is matplotlib. And pandas is a very, very simple and direct integration with matplotlib by default. So that is one good thing. But generally the criticism of Matplotlib is that the default plots that it makes leave a lot to be desired with respect to the aesthetics. They don't look as lovely or as striking as the plots produced by other libraries. So here I'll show you some other libraries. One of them is Seaborn and the other is Altair. These are libraries which bring their own virtues. And it is good to be familiar with two, three data visualization library. They start out with Matplotlib and then gradually venture into other ones. Then these things, by the way, are a little advanced things. What happens is it goes to the aesthetics. When people make diagrams, or it is my habit that whenever I do that, I tend to be particular about what the size of the figure should be. The default values won't look good. I want all my figures to be the same size. I want the fonts to be a certain size. I want the label fonts to be a certain size. So these are just basically styling parameters. So you can ignore most of these styling parameters. And lastly, the set option plotting back end matplotlib. Sorry, which line are you saying? The pd.setOp. Oh, yeah, yeah, yeah. So one of the things with pandas is the backend, you can set it by default, it is matplotlib. You don't need to say that. But it also has integration with another library called bouquet another library called plotly right python world thing is there are so many data visualization libraries it gets a little bit overwhelming and everybody will come and say my library is better right my general recommendation is first master matplotlib which is why i changed the default to matplotlib it was the default actually that line of code is not essential but if if i put instead of matplotlib if i say plotly then it will start rendering things in plotly the matplotlib has a simple syntax it looks but it takes effort to make it look beautiful which is why you see me do all sorts of things right below it in an effort to make it beautiful. Now, one of the things you do, because I make diagrams which go into some technical reports in my work and like into articles that I write and things like that, there's some, there's a general feeling in the community that if you write something formally, you cannot write, you know, pay a lot of attention to the community that if you write something formally you cannot write you know pay a lot of attention to the text and what you're writing in your equations and data but create substandard plots substandard graphs it must look it must look aesthetically pleasing and professional so i tend to use something like text labels etc i tend to use latex form uh like text labels etc i tend to use latex for the latex is a typesetting language by far the best it's the work of donald newt the great god of this field of computing his classic is the art of computing and i invite all of you to go browse through those lovely volumes so anyway a latex is what people use most of the scientific or most of the papers written in our field, in any of the mathematical fields are written using LaTeX. They are typically not written using Microsoft Word or I don't know, Google Doc or something like that. People typeset it beautifully with LaTeX. So LaTeX though installation uh kyle put those installation instructions for windows those of you who have windows god forbid but if you have linux it's a very simple install if you have ubuntu you can just say apt install x live or something and i can put all those instructions there and it will install the whole the tech system there like latex and everything else on the other hand if you have the same applies to Mac very simple and clear instructions guys be a little bit not so loud all of you I wish not so loud okay so latex is something at this moment i would say that uh if you are working if you're not familiar with it do you see this line of code it says true on my screen do you see where it says uh use latex use text? Guys? Yes. Yeah. So I would say that unless you have LaTeX and you are familiar with it, mark it as false. So then you don't have to worry about it. You don't have to worry about installing LaTeX or anything like that. So by the way, how many of you are familiar with writing LaTeX documents? A couple of you are. Okay, so, yeah, it's just more professional quality things. The next is just setting the font size and so forth. Import warnings. What happens is when you run your cells, Python libraries, they throw a lot of warnings and messages, and often it becomes a clutter it let us have the notebook and degrades its aesthetics if you know exactly what those warnings are and you feel very comfortable ignoring them and then you add these lines otherwise of course you should pay attention to the warnings i've done that then what you're looking at is something called a Jupyter Notebook. We talked about this notebook last time. I hope I took you to the place at which you could launch the notebook and do things. What I would encourage you to do is, anyway, that's part of your homework. You'll have to create a few notebooks um for a few data sets i have here given you the analysis for three data sets there are eight data sets there of the eight data sets three i'm giving you notebooks the rest five are your homework are we together so and please do take the homework seriously guys see at the end of the day however hard the teaching staff here works if you don't put in the effort to do the lab it's all it all goes waste because it is practice that drills things into your mind so this week please do do those labs and when you do the labs remember we are there to help you reach out to us once you finish the labs come come to us and review i will be releasing the solutions to these labs at some point when all of you have tried if all of you don't try then i will not give the solutions out right so this is a this is a thing incentive if If you all try and do the labs, I will release the official solutions, otherwise not. I see one quick question to the data sets that you're referring to is on the GitHub page, all on the GitHub page, as well as on the course page, and three years classifiers and five with the no no no forget that forget the classifier. So, the course, the anyway we'll come to that. Hang on, the homework is mentioned here. Anyway, since we are jumping ahead, I'll just mention. In one of these notebooks, you'll see your homework. You need to analyze these datasets, these five. That's your homework. Okay. Right? And if it helps you, it is repetition, to a large extent, it's repeating what you have learned, what you are seeing today but doing it for different data sets but when you do it don't do it blindly i have created these data sets after very careful thought they have been designed to teach so each one of them has its own unique lesson to teach it isn't that it's just five data. Here are some five things and you just practice on them. Each of them has an element of surprise. Each of them has something new to teach. Are we together? And as you analyze it, you will learn it. In the three data sets that we are going to do today, you will realize that each data set teaches you something very specific. that each data set teaches you something very specific are we together and we'll see that and so the rest five also teach you something very specific when we come to that when you do that so please do try it otherwise what happens is if you just see the solutions after a little while you you lose confidence that you can do it on your own this is very easy stuff actually but this is very easy stuff actually but so our journey starts with loading the data so let us load the data from the specified url into a pandas data frame you have two choices either you can load it from the download it to your local machine from the course portal right all of the links are there if you click on on it, it will download it. So you can load it locally. Pandas has a lovely function called Read CSV. And the argument to that, the source could be your file system, you know, C colon blah blah blah on Windows. Right. Or on Linux it could be slash, you know, home and whatever, your home and the data. Or it could be just a remote URLl and that's the beauty of it in this case i don't bother to download it it is just coming straight i'm just reading it straight off github okay so this is a way to read the data when you read the data you just have to say data dot read csv is this thing clear easy to to understand, right? Simple and elegant. One line will load the data. CSV is of course comma separated file. Each row of data, the fields are, field values are comma separated. Now in Pandas, part of the convenience method is, now you have a rectangular data frame. Out of curiosity, you would want to look at the first few rows or the last few rows or just a random sample of rows right it is always a good idea to just preview the data always preview the data see if there are surprises right this is essential if you by accident download the wrong data. It has happened in production and real life it happens all the time. I've had developers come in to me, yes, yes, yes, we put the right data in and this and that and so forth, and the results are not coming. And sometimes the silliest of the reasons would be there, like the wrong data is being fed into the pipeline. So always, always preview what you fetch. So preview the data. Now, this method head will give you the first few rows, the tail will give you the last few rows and it will typically give you five rows. But you can give n. By n you can choose, like give me first 20 rows. So just say head 20 or tail 20. so here if you like i said head and i'm not giving any argument so it will give you the first five rows will you see that guys you have the first five rows of data right so from this data right away it is obvious that we are looking at a two-dimensional like basically one variable x and one y univariate data one predictor one response isn't it well that is your interpretation thing that we are doing it in view of the discussions that we are having before lunch you can look at the last few rows by saying tail by the way the word head tail comes standard from unix if anyone of you works on linux you must be very very familiar and doing head tails all day long uh data.sample will take random samples right and there are more nuances to it it's like sampling with replacement without replacement and so on and so forth so there's more to it but let's keep it simple. I got the five rows from here. Now, once you get the data, one of the first things you would want to do is do a descriptive statistics on the data. What is it? Remember, we do a descriptive statistics. Each of the statistics is like, how many data points are there? Mean, what is the mean? What is the, well, in this case, case i haven't done the median i leave it to you folks as an exercise to find the median of the data for what it matters in this case it's not terribly relevant but why not mean standard deviation what is the minimum of x and what's the maximum so what is the range of x values? 0 to 10, right? What is the range of y values from minus 11 to 92? That's the range of the data. So it gives you some gut feeling for this data. Do you notice that the standard deviation of y is significantly more than the standard deviation of x, isn't it? So y is more spread out, the values of y are more spread out. Now, one of the things, and it's a nuisance, but a fact of life that whenever you get a data, sometimes it will have holes in it, right? So certain rows, certain cell values, or certain predictor values will be missing, right? So it's a part of life. So I'll just read out this thing that I wrote for you and tell me if it is further discussion. Oftentimes, the data set will have missing values. Certain instances of data will have one or more, it should not be or, or more features missing their their values this can happen for a variety of reasons for example a value there may not make sense for example if you have a data set on mammalian animals one of the features may be the length of the legs so when we think of mammals most mammals come hopping to us on four legs isn't it right so well a dolphin is a mammal but it does not have legs so in the traditional sense therefore a datum representing the attributes of a particular dolphin will have missing values for the attributes specifying the length of its leg. Would you agree with that? There's no way you can do that. It's missing value. So that is an example of missing value. Another common reason could be that that specific feature, while it could have been observed, happened to not have been. So somebody forgot to take measurements. An example could be the number of fireplaces in a house when looking at the housing data set. And we'll encounter this in a little bit. So in this data, let us check if there are any missing values. So you look for those rows of the data that have null values somewhere, and then you see how many of them are. It turns out neither X nor Y have missing values. So this missing value analysis is sort of moot here. It makes it moot, but you will know it only after the fact, after you have checked it. You wouldn't know beforehand. beforehand right there is an excellent library called a missing na that presents the information visually once again here it is not very informative because there are no missing values all it says is there is no missing values but this bit of code you'll find it terribly useful when you deal with data that does actually have missing values right so it shares that i all the data all thousand points of data are just fine right so so we don't need to worry about missing values so if they're missing values what do you do then you have to do the missing value treatment it is called attribution you need to attribute some value there you can put an average value you can take the value of the previous record and stuff it there. You need to find some sensible way to fill the holes, right, with data. Otherwise, you won't be able to work with the data. There is a useful tool called Pandas profiling. So if you give this command, pandas profiling, in one shot, it will produce for you a lot of data visualization, which here I don't see. Maybe I'll have to run this to get it. Oh goodness. Okay, let me start running this. So I don't use this laptop for actual work, I use it only for teaching. So obviously none of this has been run here. Oh, obviously, a pandas profiling is not installed on this machine. So forgive me, this has been run here. Oh, obviously a Pandas profiling is not installed on this machine. So forgive me, I won't run this code here because it won't. Then maybe next time I'll bring the Linux here. It's, what was that? Partial. Yeah, why don't you share your screen and show this? In the meanwhile, let me go and insert a cell and see if i can That's right. Yes. Yes. So when it runs it produces a lot of sort of exploring data explorations it will tell you quite a few things like if you look at the overview, how many variables, how many variables are there missing cells. etc, etc, it will also give you for each of the variables all sorts of statistics, for example, how many distinct values are there are there missing values and do you notice that the histogram of x is it's uniformly distributed right the x value seems to be uniformly distributed what about the y value does the y value seem it seems to be more centered a little bit and let's scroll down and you can see by the way all the descriptive statistics do you see that standard deviation kurtosis mean skewness variance etc etc all of those things are present here right so these are all examples of statistics. So interaction is not very informative. We can move on. Correlation. So it says that, well, X and Y don't, they seem to have a certain degree of correlation. In fact, a very high degree of correlation. What does blue signify? High, high values of correlation. Are we together? So which means there is a linear relationship between them all right let's scroll down so missing values again no missing values right first few row sample this is your head pd pandas dot head and pandas tail basically and let's keep going down thank you that is it so kit from here i'll take over thank you for this So Kate, from here I'll take over. Thank you for this. And while it is happening, let me just start this. On this laptop, I need to have it .. Let me get this going. So as we go through, where are we? So missing value treatment we did, funders profiling. So now comes the point about visualizing the data. We need to learn something about how to visualize data. Beautiful thing is that if you need just simple plot, quick glance at the data, most of the time you can do visualization with one line of code, right? with one line of code right just one line of code suffices so for example here we want to make a scatter plot of the x and the y in the data frame so do you notice the syntax that i'm using a data is the pandas data frame so going back at the top you must have noticed that i read the cse file into a data frame called data I noticed that I read the CSV file into a data frame called data. We can't see the notebook. Oh, you cannot. So what exactly am I sharing? Once again, I'm wrong thing. Oh gosh, I apologize. So thank you for pointing that. So alright, so the point is that we need to do data visualization. The first library we'll use for data visualization is matplotlib. The visualization, I hope you would agree that it could not get simpler than this. Right? One line of code does it. Now you may some people with Python say, Why are you putting semicolon in the end? Isn't that something that people do in C, C++, Java? Why semicolon here? There's a reason for it. It turns out that if you don't put a semicolon here in a Jupyter notebook, it will just put some junk in the beginning before you see the actual plot. To suppress that junk, you just put the semicolon and it keeps it clean. Otherwise, you see some clutter here. suppress that junk, you just put the semicolon and it keeps it clean. Otherwise, you see some clutter here. Now, data in square brackets, you give the name of the feature. The features are X and Y. So you give these features and then this data comes up. With just one glance at the data, you can see the high correlation, isn't it? You get a strong sense of the data. Literally you look at it and you feel like drawing a straight line through it, isn't it? You feel like taking a marker and drawing a straight line in this data. You can see the relationship and that is the power of the human eye instantly grasps what is it that you're looking at. Now, which is very useful when the data is one dimensional or two dimensional and so forth but gradually you will encounter data in higher and higher dimensions unfortunately much of the data that we encounter in machine learning these days are so high dimensional it's mind-boggling typically we deal with data in 500,000 or million dimensions or three million dimensions. Right? So we will get there gradually but we'll as again we learn to crawl, walk before we run. But the principle is the same everywhere. Right? Whenever possible do visualize the data. Whatever possible, do visualize the data. Do remember to visualize the data. And so when we visualize the data, here are some observations. Whenever you visualize the data, do note down your observations. It's a basic thing. It's a scientific discipline. Observe that the data appears to be linear with a positive correlation. Would you agree with that, folks? You would, right? The plot of the data in its default form leaves some scope for improvement. So for example, if somebody just got this plot, do you think they can make anything out of it? They don't know what the x-axis is. They don't know what the y-axis is. What is related to what? There is no label, there's no title, isn't it? And frankly, even from an aesthetic perspective, something could be better. So the title, x-label, y-labels are missing. It could be more aesthetically pleasing. And then this is the optional part. If one would like production quality labels and title, one can use the power of latex typesetting too. So that at this moment, you can do it if you feel like doing it, otherwise skip it. In the below code snippet, we have added some basic aspects. So all I did is that, that line of code, one line of code, I have now added more to it. And this is sort of the difference between quick and dirty versus being polished. Typically, it turns out that for graphics, those of you who do user experiences or who are in graphic art, you know this, that it takes a tremendous amount of effort to create a polished picture, right? And that is true in this science also. You'll often see that while visualization code is relatively easier, you spend a lot of energy doing it a lot of time doing improving the aesthetics so i'll explain every line you notice how the points are solid red yeah right just a little bit i don't know if you would agree would you agree that this looks a little bit more muted more aesthetically pleasing yes agree that this looks a little bit more muted more aesthetically pleasing yes so the way i did that is by making those dots a little bit transparent right alpha is the keyword for opacity like transparency people in art often use the what's the alpha channel how much is the alpha value the size of these dots i increased it to 150 and because it was red and red was sort of strong on the eye i sort of muted the red down to salmon color now beauty is in the eyes of the beholder so each person's aesthetic could be different but generally i'm just giving you a sense of how you would do it so these these three attributes i just made it look a little bit hopefully aesthetically pleasing then i added the title now this looks like a very complicated uh very arcane mantra out here this belongs to the language of later you don't have to do that you could have just said a scatter plot of x versus y or y versus x simple text right but this is in the language of latex so it may look as scary but you don't have to do that this is optional but what it does is if you do it do you notice that this looks how does it look does it look very textbooky right this is how things are there for example in islr isn't it that because islr itself is written in latex so or i think so so in the second what do they mean the dollar why dollar versus oh those are those are those are latex syntax and you at this moment let's skip it okay yeah those are mathematical notations in later so do you notice that the x looks in a different way it doesn't look like normal text it is the way you find x in math textbooks so dollar makes it a mathematical variable. That's all. So as if you print the title, you just use the same command and just change the text? Yeah, just embed LaTeX into it. And which is one of the niceties of Matplotlib, that it has such a good integration with LaTeX. So, well, this is it. Now, there's another... Is that an integration of Matplotlib with LaTeX. So, well, this is it. Now there's another, yes. Is that an integration of matplotlib with LaTeX or with Jupyter with LaTeX? No, matplotlib with LaTeX. Oh, because it's dotted up with this. Yes. So you could have saved this part to a PNG file and could still have all of this formatting. Another very popular sort of library people use and often you'll find code for this in medium etc is using cbot c1 uses matplotlib as a base but it claims his main thing is that it makes it easier to do some tasks and it puts a more pleasing layer on top of it. So just out of the box is supposed to be a bit more pleasing though in this particular case, probably not. Right. So here, here is the same graph using C1. I won't go into that. You can read the code and get to another library. So this is a static both matplotlib and C1, they produced a static image, a plot, right? Sometimes people like a bit of visualization makes sense. So in the visualization world, one of the big things that has happened is there is this lovely, lovely library, which is called D3. How many of you are familiar with D3? Some of you are, right? So D3 is actually created by Michael Bostock. And it has become a runaway success. It's become the de facto standard now. So many libraries, but it's a low-level library. So many people have written libraries on top of D3 to make it easier, quicker to work with. One of them is the VegaLite. Again, a JavaScript library, just like d3 is a javascript library well we are dealing with pandas and then some we are dealing with python so somebody had this excellent idea why not put a python layer on top of vegas vega light right library which is sitting on top of d3 so that in a few quick lines of code, you can produce what would take a lot of code to do in just raw D3. And you're doing it in Python rather than JavaScript. So this is it. This is Altair's, they're creating a chart with circles of certain size, X, Y. I hope this code is self-explanatory. You're going to mark in the in the scatter plot you're marking circles x is x y is y two retips you're given you're giving a property how much will the size of the image be oh my goodness i did not run it but if you had run it where's the output there is pushing if you had run it if you run it on your local machine on my machine i'm having all sorts actually it might have installed let me go and see things may have installed yeah just bear with me. No module main finders profile still thing. You can install help there yeah oh yeah it succeeded so now let me run this thing from the beginning just bear with me for a second guys i will run only the key sections okay and i'm not going to run the pandas profiling because that may take uh quite some time so i hope okay let me just run the crucial sections i need to load the data there we go uh head tail descriptive statistics all there finders for filing i'm not going to run because it will take time let's go and run to the data visualization plot scatter plot c bond and altair let's go and try a lettered out there yeah see when you look at the graph generated by altair you notice that it's dynamic i can look at the tooltips it's very basic amount of interactivity because ultimately it's just a couple of lines of code but one more thing you notice about this, you notice how you can zoom in and zoom out, right? You can just pick, you can move it around and so forth. So this is a full blown dynamic interactive graph. So that is the beauty of it. With Altair, you can do that. In fact, that correlation, interactive correlation that you saw in the streamlet, that graph I had generated using Altair. And by the way, the source code of that is available to you in the download. You can read through the source code, all of you, and you'll see that it is... If you want to understand that source code, please do sit with us any one of us and we'll explain it to you so that is about data exploratory data analysis and visualization our next goal is to build a regression model out of it. We want to build a model that relates x to y. y is the response variable, a target variable or the output variable or whatever, and x is the input or the feature or the predictor. These are all synonymous words as we talked about. So we'll do that. And it is quite simple actually the first thing you need to do is in Python in like you use a library called psychic learn the fundamental machine learning library that is most popular is psychic learn. This psychic learn expects that you separate out the input and the output in this case, what is the input. In this case, what is the input? X. What's the output? Y. But then it expects the input to be a multi-column data frame. It expects it as a Pandas data frame. But output it expects as an array response variable. So that explains this data's X. Remember remember do you notice this double square bracket it is basically syncreted funders data frame another data frame called capital x right so capital x is this and cap little y is this now there's a lot happening here. First of all, notice, guys, that you could not have used the syntax in other languages like Java or C. You can't write the syntax. It's not valid. What it is saying is capital X is equal to the first term here on the right-hand side, and little y is equal to the second term. Now, this double bracket is just creating another pandas data frame which happens to have only one column collects this is it now another thing that you uh so i'll just read out the part that i wrote let us build a simple linear regression model for this data set in order to do so you go ahead so the double one is getting a so capital x is a data frame and how are the capital the small y it's a series why the small y is just as yes think of it as a series or a array it's basically a one-dimensional array okay right and so because you know response variable is just output number like one number, whereas input could be many things, but many features may go in the predict that. So, I'll just read this. So this syntax. Now there's more here guys. It is customary in this field to use capital X for input. in this field to use capital X for input, a data frame, and little y. We could have named this variable anything, PQRS, cat, dog, whatever. But it is a convention in the field that you give these names to input output so that it becomes very easy for people to read your paper. Remember when I was explaining to you in the earlier session, morning session, what did I use for response variable? I used little y. Do you remember that? So it is a convention in our field, in this field to do so. So hold on to that. When you follow conventions, it becomes easier for other data scientists to understand your work. Our next thing is we want to split the data into, remember, a training set and test set. Test set is the one that you sort of hide under your pillow in a metaphorical way. Don't let the model see it. Don't let the algorithm see it when it trains a model when it trains itself so what you do is very simple actually you build a you take a algorithm here we are taking a linear regression as a model as an algorithm and then we are fitting the model to the data so the fit is the train part it is the learn part it will go learn from the data, but not the whole data, only the training data subset of the data. Now, just for your recollection, whatever we talked in the theory part today morning, I've written it here. So Y is made up of the part that is the actual model Epsilon is your irreducible error. Remember, irreducible error comes from those things that the data didn't contain but are effective of the response. But it also contains other things like instrumentation error. If you take a very sensitive thermometer and you measure the temperature of the same thing, you will realize that it sort of fluctuates. There's a lot of error in that. So measurement error, et cetera, et cetera. And sometimes people actually make measurement errors. So what I have done here is model is built. Then let us look at the intercept and the slope because what is the model? Model is this. This is the model, right? So it will have an intercept and it will have a slope. Let's go and see the intercept and coefficient. So anything beyond the beta naught, these are called coefficients in the language, in this sort of way of thinking. So our intercept is minus, well, very small, 0.1, minus 0.1. A slope seems to be 8.3 now let us see does it make sense would you agree with that let's go and look at the data or any one of these let's say i don't know pick one let's say pick this the latest one would you say that in your mind if you drew a line to it in your mind it would be around close to zero minus 0.1 so close to zero the intercept seems to be zero is that fair you agree right if you build a model imagine a model in your mind the intercept will be close to zero right a little bit negative to zero and what about the slope let's we can find the slope very easily. For unit increase, let's say from one to two, that is one unit increase of x, how much did the y increase? So here the x, the y seems to be approximately, what should we say? Would it be reasonable to say a little less than 10? Right? And here y seems to be a little less than 20. Right? And here, y seems to be a little less than 20. Right? Somewhere here, maybe 16. So let's say that it was 8 and it has gone to, so one unit increase, it has increased by about 8. Seems right, isn't it? 8, 9, 7, 8, 9, right? Something. So, and this is important guys that never trust the code. Always go and verify that what you find makes sense. Here it seems to make sense, right? It says intercept is very small, that easier. Sloop is about 8.3, right? So give or take, your own eyes may have said, well, somewhere between seven and nine or whatever it is. So it does seem to agree with your estimates. Now that you have a model that you think might be of value, let us go make predictions. But make predictions on what? Not the training data where you suspect it will do well but you test it on preferably the test data, like the testing data, the data that you hid under the pillow. When you look at the testing data, you will get what? Y hat. Remember in our morning session we used the notation Y hat, right? So obviously in code we can't make it Y wear the hat on top of it so we literally spell it out as y hat and so it says that the mean squared error is this 32.46 but look at this the coefficient of determination is 0.9476 close to 95 percent right that's that looks pretty good remember that the maximum value it can achieve is one isn't it given the fact that the noise does have some i mean sorry the data does have some noise you can see the noise there's some irreducible noise the a value of a value of 95 approximately of r square seems fairly good. We seem to have built a good model quickly. So now what happens is this is where most people stop. In fact, unfortunately, most textbooks also stop. They say, okay, good, right? We have a good model, but you don't stop here. You need to go further because these values can be misleading remember guys are not a model cannot be. shown a proven to be correct or effective that can only be displayed so you have to look at all sorts of areas which may worry you go ahead. uh go ahead okay question on that cell there you can scroll up uh that one it says print mean squared error and then there's a function mean squared error so where did that function come from oh we imported that it's one of the functions built into uh the scikit-learn library yeah let's go and see that whether it's true where it is since you ask Yeah, let's go and see that whether it's true, where it is, since you ask. It is standing on its own without having a reference. Do you see this line from the scikit-learn? Mean square data. We have that right? So. So now it looks pretty good. And this is about string formatting, etc. You'll learn all of this, how to prettify strings, the output and so forth. So residual analysis, what is the residual? I use ri because your book tends to use ri right otherwise i would have used epsilon i remember in the lecture i used epsilon i right so this is it and and once again guys those of you who do you notice that the math is formatted as math and so on and so forth. This is because I am injecting in my markdown the LaTeX syntax everywhere. This sort of thing is very typical of the sort of LaTeX language. You don't have to know this. And if you can't write statements like this at this moment, obviously you don't have to worry about it. So we will look at the yellow. Now there is an excellent library called Yellow Brick. You can do it by hand, but it's much better to use a nice professional library. So I'm using the Yellow Brick and in the Yellow Brick I'm doing something called residual plot. So what is it doing? It is for every value of output like y you're trying to find what is the residual right is like how much residual you see now here is a rule it will take you a while to absorb and and you do it both by making predictions on test data as well as train data you do it both by making predictions on test data as well as train data now the interesting thing with residual is residual plots if it let's put it this way if it doesn't make sense to you it's a good thing if you don't see a pattern if you don't see a i mean any any sort of noticeable pattern if it just looks like mostly noise like this it is a good thing in other and also when as you go from from left to right in other words for different values of y do you see the spread of the residuals do you see that do you see that the spread of the residuals is more or less same constant right there is not any significant variation That is one thing to notice. When you have this, when residuals don't show, so what you're seeing is that the variance of residuals doesn't change for different values of y, or the prediction, the predicted value, it doesn't change y hat, head right so this has a lovely word and that word i'll make you familiar with the words is you have now i want one of you to try to pronounce this word it's a lovely big word that's cadastrous yes almost cadasticity excellent so you know i'm reminded reminded there is this story, most of you if you grew up here in this country know about Mary Poppins. So she is trying to boost up the, make the kids feel confident. So she teaches them a word, a big word so that they feel really good about it. And then the word is something like supercalifragilisticexpialidocious. Right? And they all think, oh, good. So as you're learning data science, well, here is a big word for you. What it means is it means exactly that, that when you don't see a variation in the variance itself. The variance doesn't change as you go from left to right. Other things, do you notice that if you look at this part of the plot, do you realize that it has sort of a bell shape, right? The errors, the residuals, the histogram is bell shaped. Most of the residuals are small. Some of the small amount of residuals are big. Isn't it? Do you notice that more points are closer to this black line than away from the black line? As you go away from the black line, it becomes thinner and I mean it becomes more and more sparse. That is what this histogram is showing. It is a good thing. When errors show showing which is a good thing when errors show a normal distribution which is generally a good thing yes so when he split the sample that was we didn't do any judgment sampling in terms of splitting right because no random sample no random split so why are the error if you look at the height of the residuals oh right right the reason is that the test set data is very small i believe it's just 25 percent okay that is why the histogram can't rise i mean it is not the the frequency plot there isn't enough test data there's less test data than train data train data is almost twice or twice as much well that's just a frequency that's just a frequency it's not showing the night yeah it's not scaled down it's not scalable it is not scaled up right so that is it is an issue so yeah so we said like on the graph we are looking for patterns and we don't see any pattern moving left to right right and then yes so i mean if we find some pattern here in this example we don't have any pattern moving left to right right i mean yes so i mean if we find some pattern here in this example we don't have but let's say that we find a pattern like will we go away in the steps like removing outliers from that pattern trying to identify if it's a pattern yeah okay so uh if you see a pattern then you will say something repeat after me. Oh shucks, I need to do more work. Okay. Right. So basically it means that this is maybe a reasonable model but there is a better model that can, you can do better than this. All right. That's all it means. So, well, let's play around with it and you'll see it in the next data set exactly that we'll see. So, well, let's play around with it. And you'll see it in the next data set, exactly that we'll see. So you have homoscedasticity here. But in the next one, you will see heteroscedasticity. So we now finally, everything looks good. R square looks good. Residual plots are lovely, no patterns in it. We are feeling pretty good about it, isn't it? Let's go ahead and you plot one final thing you must always do, especially when data is low dimensional and you can visualize the predictions. Make, create new data predict, put the prediction line, you know, the straight line, the hypothesis line over the data and see how it looks. So this is a little bit of code what i'm doing is i'm generating new code and then making predictions on the new code and plotting it when i'm plotting it i'm plotting the prediction line on top of the data so when you do that does the does the prediction line seem to agree with the data is it is it making a good representation of the data? It is, right? So now, this is lovely. So we conclude that there are multiple indicators for what this data said. We have multiple indicators that we have arrived at an effective model. The coefficient of determination is good, actually very good. The residuals exhibit homoscedasticity and there are no patterns. Finally, the prediction plot when superimposed over the data set indicates a high degree of agreement. All three things, isn't it? At this moment, you have strong confidence that you have a nice effective model, right? So take a minute if you were doing this, take a minute and congratulate yourself on the successful data science journey. Because usually while this sort of graph is very common in textbooks, in real life you rarely see them. Linear relationships are not very common, but nearly linear relationships are much more common and they are relationships that you can make linear through transformations and whatnot and that's sort of the journey of evolution we'll go through. But for now, this is as good as it gets. You build this first model that you try just works. Are we together? So this is it, this was your first notebook. Any questions guys? I hope, so this code, right? You can ignore the aesthetic aspect of it, but I hope you find, and it will take you a little bit of time to become familiar with the code, which means that you have a tremendous amount of homework guys repeat this for the next five data sets that is first that's your homework cringy one second and the second thing is that you have to have to start learning pandas numpy a little bit of numpy etc see those are vast things but you need a very tiny like you know from a bucket you're just taking a cup full of water are we together and that's all we need for our purposes for a very long time and pick up other things to go deeper on a need to do basis need to learn basis right start with simple things start by getting a hang of this code but really understand this code properly and begin to use it and then uh go for that premium on the last cell i think on the code can you show us how you superimpose see this here is a plot yeah so i say you see that i put a scatter plot what does it do it makes this nice salmon little bubbles isn't it okay but over the same plot it's called axes actually in the length the second yeah I I superimpose that okay that is it so guys do please pay attention to it oh we are almost at five o'clock right so we are done with only one notebook. So remember, you'll be here till dark. That's right. Are we willing? The second notebook gets more interesting, you may say, Alright, this was great. I got a good introduction to doing data science. But reality is more complex. Let's try something a little bit more complex and see what happens. Albert. So I have some errors on the notebook, I can see everything. But so then the notebook is running on anaconda. So what does that mean? Does it mean that I'm missing the library somewhere? Yeah, you need to, for example, you may not have done pip install yellow wick. Okay. So remember, guys, when all of these libraries when you whenever you see import this, and it fails, it means you have to do pip install that. Just go install those libraries. And please reach out to our peers. Just say, all you do is you can open a new cell, exclamation mark, pip install whatever, and run it. But do it only once. Otherwise, it will slow your notebook down. So that is that, guys. let's go now to data set two okay in this we will learn another variation of linear regression, still linear, because in, believe it or not, a polynomial equation, if you add higher degree terms, you know, a function of x and x function, also x squared term and x cubed term, it is still considered linear in the language of higher mathematics, basically, most of the time. Non-linear is different. It was one of the things i was explaining but okay so one of the things that i will tell you is that whenever you see a bend in the data right you can see a bend count the number of bends and at some point i'll explain in the three section what it is but or maybe well today we don't seem to have enough time what it is but or maybe uh well today we don't seem to have enough time i might as well do it properly one second there is my writing pad one note okay guys i think we all need a five minutes break i can see people are going to the restroom etc let's take a 10 minute break actually not five ten minutes break i'll see you guys after 10 minutes so guys here is a fundamental fact of algebra that you may have forgotten observe something very basic. This is a straight line, isn't it? I'm sorry, I don't know what happened to that. How many bends do you see in this? What is happening? Using it just here again. No, I think it is gotten into some sort of No, no, it was abating itself, unfortunately. OK, so let's do it. Let's try again. We'll go to the bottom here. Observe something, a straight line, something with one bend. I don't know. I'll make it like this. Something with two bends. Right. And something with three bands like this, right? And by the way, the bends could be any way, it could be like this, whatever, these curves. This equation is y is equal to beta naught plus beta 1x. You know, it's an equation in linear in x. This is this is quadratic. Those of you who still remember your equations of parabola would remember that you need to go to the quadratic term. Are we together? If you try this out in the same way of beta two x squared plus are we together if you try this out in the same way for beta 2 x squared plus x cubed you will need at least a third degree what do you conclude from this so i'll just write it in order one order two let's not poly poly one i'll just use a poly one not poly poly one i'll just use a poly one polynomial of degree one this is poly two poly three so this has how many bins one two three four three bands three bands means what poly four do you see a pattern can you generalize from here right so what happens is when people encountered the non-linear relationships one of the tricks they thought okay we won't write it in just x but x squared and x cubed we will add them as extra features and we'll treat it as a linear regression model in three features or four features one is x one is x square one is x cube and so forth and we'll still do linear regression we'll apply linear regression to it and it should work does this make sense guys by the way if you want to prove this thing to yourself it is a fundamental theorem of linear algebra of algebra which says that a polynomial equation of degree n has how many roots how many times does it cross the zeroth axis right a certain number of times so this is where it all comes from so i'll leave it as that so now using this relationship one may be tempted yeah go ahead you have x and x x is a one feature and x square is a other feature exactly okay yeah so you're literally treating them as independent features and building a linear model in those additional features right so maybe it's a digress here just quick question so the polynomial four looks like uh technometric function do you deal with those things at all or is it yes very good question you will see that the data set two does seem reminiscent of a trigonometric function sine x isn't it yes right so we will come to that too in a later lab so there are many ways that we will solve this problem. That is in particular non-linear least squares. We'll do that. Solve the same problem using other means. So, but nice that you asked that question actually. Now, coming back to that. So that's what we'll do. So what are the prerequisites for this lab? Of course, you must have done the lab one because I would notebook one. I wouldn't be repeating the things here. What are our goals? Standard, we'll apply polynomial regression models, not to make the prediction. At the end of it from this lab, what do we expect to learn? I expect that you learn the importance of residual plots or residual analysis. And you will learn about heteroscedasticity and what it indicates and oh polynomial i have my typo here excuse me a polynomial regression you'll learn imports i are the same i don't want to repeat those load Load the data exactly the same way. All of those considerations remain the same. I'll skip over it. Missing values. It turns out there is a 2 also has no missing values. Pretty good. So missing value, we don't have to do any treatment. The point is moot. You can do Pandas profiling, which we we won't you can look at the results of that it is interesting right and finally let us now go plot this data using matplotlib exactly the same code do you notice that quite often that the same code here is working just fine the same code that i had before now ah you look at this data and the first thing that strikes you is is it a linear relationship now there are two bends two bends means what is the polynomial degree i need three minimum three should get our job done so let's try our luck what will but suppose you don't do it and this is what happens see guys how many books look books, look into the books, how often they talk, some talk about a polynomial regression, most don't, right? So it's one of the things that is very crucial, very useful, but often missed. build a regression model and you realize that it is saying the intercept is this and slope is this all right you try to make the predictions from this you do a residual analysis when you do a residual analysis the very first thing that strikes you is what do you see a pattern in the residuals very clearly you see a pattern in the residuals isn isn't it? The whole thing has a certain shape to it. So it has patterns to it. And therefore, there should be alarm bells. Means there can be a better model. Surely what you're doing is not good. And if you persist on and try to impose the model on the predictions, you'll learn something, actually. Look at this graph. What do you learn something actually look at look at this graph what do you learn from this graph do you realize that the prediction model if you believe that straight line is the right relationship right you you have a you build a model that is simpler than the ground truth, isn't it? Your hypothesis was simpler than the ground truth that just a linear model would do. And what has the learning done? The machine has learned the best line that could possibly fit this data. Just pay attention to it and you can convince yourself. There is no better line that you can fit to this data. Isn't it? Right? You can't think of any other straight line that will do better and this is interesting and this is the point that you have a model yeah so now some part of it is a reducible error we can do better than that we'll do that so clearly the you see patterns in the residual and the predictions have very not as good fidelity with the with the actual data as you would wish so let's try better can we fit a polynomial of degree three yes we can so let's do that creating a polynomial of degree three is not hard actually everything remains the same the rest of the code remains the same the only thing new feature is you bring in this polynomial features you say how many degrees three degrees and by the way play with it guys go to five degrees and so on and so forth see what happens so now you you create a data frame x poly which has x x square x cube as three features are we together three features and then the rest of it is simple you build a model here you fit the model to the data you then if you if you go polynomial expansion on the training data you have to do the same thing on the test data before you make predictions isn't it because the model is expecting three variables, three input arguments. So here we go. You make the prediction and this code guys, step through it. Any part of it looks hard, do reach out to us. But absorb it. Model.fit, it is the same code, R squared. So what is the coefficient of determination look now? 96% or 96 plus and a half percent what was it before before we did it in the previous model it was no no it was 53 percent so from 53 percent we have gone to 96 and a%. Huge improvement, isn't it? The previous model is marginally useful, somewhat useful, but it hasn't picked up. It hasn't sort of done as good a job as the second model. Let's look at the residual. So you're looking at the residual. Do you see a pattern in the residual? No? Lovely. So you have homoscedasticity here. Lovely. So then have homoscedasticity here. Lovely. So then visualize the third part. Visualize the model predictions over the data. What do you say to this? Pretty good, right? So polynomial regression seems to be a very powerful tool. Use it judiciously. Do use it as often as you can. And this is all it is. Oh, by the way, there is a homework, but I have put it in the second data set. Your homework is analyze all the data sets that I have not analyzed or created the notebook for. Each of these data sets, trust me guys, has a unique lesson to teach. Like for example, this data set 2 had a lesson to teach what was the lesson that it got polynomial regressions isn't it and now i'll go to the third data set this is it any questions i hope this was simple by now you notice that there's a certain familiarity to this thing by now right we are following a systematic a a method systematically. And the method remains the same. But as we explore data, our findings change. What we see in them changes. And how therefore we treat them changes. But keep your method more or less, go on there. The third data- Can I ask a quick question? Yes, this is, sorry, sorry. Quick question. Sorry. Go ahead. So the distribution, it doesn't seem completely non-linear. What does that mean for residues? Nisarg, I think it is Nis uh you have two computers or maybe you have a headset and a laptop separately attached so i'm getting we are getting echoes and i can't so either you can put the question on the chat and i'll watch it or you'll have to mute one of the machines would you like to try again uh is this better well let me try it's not actually but let let we will all try to understand what i think i say if i've got what he's asking he's asking for uh the linear linear like the distribution has some gaps why exactly are those gaps meaning am i right mr you're looking at this oh you mean gaps here which plot are you looking for mr Yeah, see, no, this is it. Gaps are okay because the data distribution itself underlying data distribution. Oh, he has put it in the Yeah. So let me answer that. See, what it means is, it turns out that the data has not been, the data, the errors or the residuals are not uniformly spread. Sometimes it is the nature of the data. If you see pronounced patterns in that frequency plot, very obviously something skewed or odd, then you worry, but generally you don't worry about this. You let it slide. I mean, you basically say this is harmless. This does happen with real data sometimes. Does that answer your question you said uh i hope so okay nice so this is that guys so we learned about polynomial regression i can't emphasize enough guys uh use simple techniques to analyze your data before you bring in the big guns, right? Polynomial regression is just one couple of lines of extra effort over linear regression. Try it out. See if it works. What does it give you? Very often it does work. Now, the third data set that I'm going to analyze in the last for the day because i can literally see tiredness on everybody's face here uh is our third data set is the ranch phenomenon by now you must say wow polynomial regression is really powerful now most uh non-linear data i can fit polynomial polynomial i can do polynomial regression and win so the lesson you will learn today that there are many reasons why polynomial regression does not always work. R. Vijay Mohanaraman, Ph.D.: One of the reasons i'll show you in this lab the second reason you will discover when you do the labs on your the remaining homework on your own, but. R. Vijay Mohanaraman, Ph.D.: It is a fact see if point i always worked for all non-linear relationships the rest of machine learning would have been redundant isn't it you did linear regression polynomial regression that's it end of chapter right but it isn't that the the reason for that is at least one of the reasons you learn today but there is a deeper reason which is that there are functions which can never be represented by a finite polynomial right those functions are called what are they called transcendental functions transcendental functions those are marvelous things basic transcendentals are what people often in textbook call early transcendentals are your sine cosine trigonometric functions and your inverse trigonometric functions and all of that and exponentials e to the x and so forth and logs and so forth so these functions can these functions can never be represented as binomials if you try to represent it as polynomials, you will end up with infinitely many terms. So they have infinite polynomial expansions. So the word transcendental, they transcend the ability to be expressed as polynomials. Now, why are they important? Why, who cares? Well, it turns out that transcendental functions are the fundamental language in which nature is written. If you were to put it more poetically, if you were to read the thoughts of God when he was creating the universe and the language in which he created the world, it would be in terms of transcendental functions they're everywhere you uh you you drop a pebble in the water the ripples are your trigonometric functions you know sine cosine waves right you're approximately right but actually the the amplitudes are i believe believe if I'm right, yeah, they're Legendre polynomials. The beating of the drum has that same expression. Do you see? Close to the center of the ripple, the way you drop the pedal, the amplitudes are high and then it gradually drops down right you have that the atom itself right uh the modes of the atom the spdf and so on and so forth i'll leave it as a question for you but you'll be surprised that the that electron cloud itself follows a transcendental function distribution. Those are the modes of the transcendental function. So transcendental functions are everywhere. You look at the cable holding the golden bridge up, and you write the equation of that, it will be a transcendental function. Wherever you look, it's transcendental functions, right, in nature, and in artificial things, in engineering, in medicine, in the body, everything is mostly. So what it means is that a lot of data that comes to you, the underlying generative forces are transcendental, expressed as transcendental functions, right, which is why polynomials work. They are good approximations quite often, but they don't always work because so often nature is written or data, the forces that created the data, underneath it, the more appropriate models are models using rather exponential functions and complicated relationships. And those cannot be captured. Those nonlinearities cannot be captured by polynomial. That is one way. The other is actually something pretty simple and interesting, you see it. So in this, we take this data set. So outcome is we learn about the limitations of polynomial regression and a phenomenon called the Runch phenomenon. What is the Runch phenomenon. What is the Runch phenomenon? It is this. We'll take another data set now. This is data set three. Pretty much the same analysis. Let's go straight to its visualization. Oh, here it is. Is this reminiscent of some curve that you are quite familiar with? Bell curve, right. It is actually this. So now let's try to do the standard analysis if you try to build a linear model obviously that would be a rather foolish effort and your residuals would look like this practically a mirror image of your bell curve, laterally inverted, not actually horizontally inverted. Visualize visualization of the prediction over the model. See, this is your prediction, the line, the best line that you could fit to this data is this line. Does it have any fidelity to your data? Almost none, right? And it shows up in the values that you get for r squared remember i told you that your r squared can be worse than zero right here is a situation basically i've lost it right so that is that, we need to do better. So you can then try polynomial regression. You say, well, just now I learned about polynomial regression. It is something very useful and I can use it. Let's do that. When you do that degree 2, degree 3, degree 4, you can keep on going. And you'll realize that you have to go up to degree 7 or so to get, I mean, high degree, I mean, I'm not fixated at seven, you may say six or eight or whatever, nine, whatever it is, a pretty high degree to get a good model. And the code is exactly the same, degree seven. When you do that, you get a pretty good model. But when you do the residual plot, that's when it comes as a shocker. You thought you had a good model and yet what do you see? There seems to be discernible pattern in the residuals, isn't it? And you say, oh shucks, what do I do now? And this is it. Let's try to plot your model over the data. What do you notice? Actually, it's not a bad model. your model over the data what do you notice actually it's not a bad model depends upon what purpose you'll use it for but do you notice this what i call the dog's wagging tail at the end right so at both sides left and the right you see these oscillations like more formally these are called oscillations this is the fact that happens when you try to fit an unnecessarily complicated polynomial curve, high degree polynomial curve to data. What will happen is in the edges you'll start in the periphery, you'll start seeing this oscillations of the curve or the prediction model. Right. Or more simply, I call it the wagging tail right on both sides you have a wagging tail right so when you have this this was actually this the mathematician who discovered this and who proved that it will always be served is ranch and you can learn more about it as a Wikipedia page which is little technical but if you are curious we can do and he showed that it happens more than a hundred years ago right in 1901 so that that is all i'll say so what it means is that polynomial regression is a powerful tool and you will learn in machine learning that there is no silver bullet that every tool has its strength and weakness, which is why the field is so rich and filled with such interesting ideas. Because no one idea is so good, is a silver bullet for every situation, something else works. So a bit of a start note about how all of this started. You can read about it the thing that I told you about how it all started at least actually it should be 1793 not 95 but be as it may okay so I already also told you about exponential functions or transcendental functions sorry now by the way can you guess you realize that the equation of the bell curve is e to the minus x squared right at the top numerator forgetting setting new sigmas out it is basically e to the minus x squared to normalized way so obviously that's a transcendental function right so if you know your math you would say well of course i expected it to not work So if you know your math, you would say, well, of course, I expected it to not work. Isn't it? Right. But of course, that's hindsight. You don't really know. It could have worked. Right. Because you don't really know whether this was a bell curve or not. Right. Or what it was. But anyway, be as it may, a high degree polynomials run the risk of ranch phenomenon when you model with them and that concludes today's labs guys was it useful oh yeah definitely wonderful so all these labs are already uploaded to your class portal uh please do download them run them and the first one the the correlation interactive visualization do play around with it to get a sense um you may have noticed that the pace one the the correlation interactive visualization do play around with it to get a sense um you may have noticed that the pace of the class has changed right this this session was a little bit more in-depth and hands-on than the previous session now i cannot over emphasize emphasize enough guys please please please form your projects, do these labs. Even if you form your team and you do the labs together, the rest of the homework, that too is fine, but do it. Because without doing it on your own, there is no learning. All that you have learned will fade out. And the best way to learn is social learning. You guys notice that around this room are all of these meeting rooms or conference rooms. right? Each of them is equipped with a state-of-the-art audio video system, large TVs, right? The table with power literally embedded and ethernet embedded in them. Come sit here, form your groups, discuss, do your homeworks. You're most welcome to, but do it guys. The social learning or doing things as a team is an integral part of the learning process. It makes you learn better because different minds think differently and approach a problem differently. So you get enriched by the other person's thinking process. So do form your teams quickly, do all the assignments. And that project that I gave, which was to find a couple of types of trees, and for each type of tree, go pick the leaves of that tree and measure the attributes, length and weight and color and so on and so forth, and create at least 200 data points. You will see why this will be very useful as you move forward, right? Please do that project, put some energy into that project. I want us to become, see what is the outcome we are looking for from this workshop. I want you to come out as stellar data scientists. As far as tabular data is concerned, you folks should be able to do exceptionally well in your analysis you know good high quality results not run-of-the-mill results that will come only if you practice it's a do practice please with that i'll conclude the recording