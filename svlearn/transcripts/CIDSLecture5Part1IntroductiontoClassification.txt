 There we go. So this week we are going to study classifiers. I put a cat and a dog because in the world of machine learning, one of the favorite things that you classify is cats, distinguish cats from dogs. So well, today we won't be doing that but it's a good start we'll learn about it today we will review the topics of last week very quickly then we'll study the classifiers and their metrics a completely new topic we are done with all the theoretical aspects of regression linear linear regression, not all regression. Regression and regularization, we are done with. What does that mean? What it means is that we move on to the next topic classifier. It doesn't mean we have covered everything. We still have a lab on linear regression today. Besides that, I will release material on a few more topics. For example, there's a crucial topic called multicollinearity. I paced the lab and how much time the lab will take in the afternoon, and I realized I won't be able to cover this. Today is a very long lab. In view of the very long lab, we won't be able to get to it. Now I can see everybody. Okay. I won't be able to get to it now i can see everybody okay i won't be able to get to see it i sorry get to cover multi-collinearity uh but i will hold a special session what i was thinking is this week weekend i mean this week's paper reading we replace the paper reading time with this topic of multi-collinearity right let's do that because I do want to cover it's an important topic, I do want to make sure that we cover it completely. But having said that today, it's all about classifiers, the metrics, distance function, logistic regression, it's a theoretical topic in the morning, as always, I will take you into some geometric depth, you must have noticed that when I teach machine learning, it's from a heavily geometrical perspective. When I teach machine learning, it's from a heavily geometrical perspective, right? When you take the quizzes, it tries to establish a baseline of how much you have understood. Please do take your quiz because it helps me learn what you have and have not understood. When I find that people are making, all of them are making mistakes in a common area, what it tells to me is that I need to repeat the topic you haven't gotten it and i will repeat those topics right so feedback is important in the learning path so that's that the guided labs we will do some solutions to homeworks then we will deal with and a data set that pertains to the old faithful geyser in the Yellowstone National Park, then we have been talking as a closing day of linear regression. By now, you're familiar with the basic terminology. You're familiar with the sum squared error, mean squared error, mean absolute error. You're familiar with the gradient descent. You are familiar with what the coefficient of determination is. And for univariate regression, how it relates to correlation. We talked about correlation and so forth. So today as a final exercise in the theoretical aspect, we will do gradient descent from first principles. Means we will not use scikit-learn right we will actually do it by hand doing it by hand is very important because as you go to the more advanced aspects of machine learning as you start doing deep neural networks most of the time you have to write the inner loop of learning yourself right you have to do the gradient descent yourself. So it is a good start today on this very important topic of learning to do gradient descent by hand, like from first principles without using any library. It is also one of the- Can I ask a question also? Yes. So you had mentioned sometime back that you will cover two years right no all of them gradient distance step is so easy it's there in every language but i would say that easiest in yeah julia i mean see julia notation is easiest to read because it is scientific notation python is also using like when i write this code, you will notice that I use the Greek notation. Right? So it is also fairly straightforward to read. I would say next easy is Python. Doing gradient descent in any other language, example, if you look into the Spark and you look at the stochastic gradient descent code, obviously that is more codey, more programmer-like language, as opposed to very close to the mathematical notation. So that is the difference. So, but when you mentioned with deep learning, the neural network, that part of it is what I was- Yeah, see, here's the reality. All deep learning libraries are written in C, C++. So when you have written it in C++, it is much easier to put a layer on top of it using, let's say, Fortran and so forth, using Python or R. Julia takes a completely different approach. It says that you don't need this two-tiered language system. Julia gives you the performance of C and Fortran, but the expressive power that exceeds in my view, even that of Python. So you write code as is and it gets compiled, right? And it gets run. So for that reason, it has a problem. Now, how do you integrate it with TensorFlow and PyTorch? Now, some developments may have happened recently, we should go check, but to the last I checked, you couldn't, you had to write the neural network by hand. But the neural networks that you write by hand in julia are very elegant they're very they can be very good to write yeah yeah julia supported in like something like oh of course remember jupiter j-u-p-y-t-e-r stands for julia python and r right so definitely it's a first class support very much right see guys here's a thing there is a bit of a this is called in i suppose in learning in this aspirational gap right in education okay so let me talk let me take a bit of a digression having taught for 30 years especially when you teach adults as opposed to kids and when you teach in college these kids have no motivation to learn. They just want grades. If magically a fairy could come and wave a magic wand and all their courses developed an A plus and A's next to them, they will go happily without needing to learn, right? We all have had the same attitude in college, sort of, to different degrees. Adult education is different because people want to learn. So there is a huge aspiration to master these deep topics. Anytime we hear a great seminar, a great presentation, or some great work done in your company, I'm sure you get inspired to learn all these things. So the aspiration is there. And your aspirational goal is to master a lot of things. So in the aspirational goal in this course, my aspirational goal for this was that if I got a batch that was 100% engaged, not doing anything else, and was putting a job, theoretically on the on hold, maybe even the family life on hold was completely dedicated, I was trying to do it in three languages, our Python, this. I was planning to do a whole lot more data sets, a whole lot more projects. But we all know that it is never going to be a reality because adult life is a conflict between competing priorities. You have home, you have work, you have social life, and you have to sleep and rest sometimes. And then you have to take this course. So you carve out time, what little then you have to take this course so you carve out time what little time you have in your life for it so what is the reality the reality is we have been reduced to one language the previous batch by the way did it in two languages those of you who were there some of you may remember we did it in two languages r and python this time around i focused on only one languages the pandemic times everybody is stretched and stressed also so we are doing it in one language projects you notice that i plan to do six projects in the workshop actually i started out with the aspiration of 10 i reduced it to six now four weeks into it we are going into the fifth week and i know that still some groups haven't done project number one right so these are the realities of adult life so i can go as fast as i can carry you forward but that is the crucial word i cannot just go as fast as i can because that will leave people behind and that defeats the whole purpose of instruction so i will go at the pace at which we will go having said that if you guys form a band and say a sufficiently large band and say we want to do this all of these labs in julia 2 or in r2 approach me we will start those extra sessions free right we'll make it we'll incorporate we'll make our carve out time in the weeks and we will do all of that in julia and r i would be most happy to do that. Right? But we have to find, you have to find a dedicated group that is passionate enough to come and ask me and actually attend those sessions. Right? So we will take that. So today, well, okay, gradient descent will do from first principles. But there is a, there is a data set. So there's a few data sets, you know, they they are sort of the rights of passage as you learn data science you you go and analyze these data sets because there's a tremendous amount of learning or experience that is embedded when you analyze these data sets that's why they are so popular. They have become classics. They are subtleties. They are things that you learn about. And this Old Faithful Guide is a very simple one, but then AutoDataSet has those good lessons in them. And California Housing Data Set belongs to the same category. Now, last week we presented Harini's notebook on diamond dataset, which is now online. So please do browse through it, study it carefully. This week, another of our teaching assistants, Kyle, she has done a lovely project on the moringa compound leaves, the drumsticks, a project on the moringa compound leaves, the drumsticks, the drumstick plant. And it is literally from our own house. So that would be another of our labs. So these, this is the scope of studies today. Right now, we could do it. Today, actually, we will start with classifiers now, theory part. Any questions before I start? Anything, guys? So let us see where we stopped last time. We stopped last time at, one second, ElasticNet. Oh, I forgot to add questions on ElasticNet to you, but we'll do that. So let's go a little bit back and recap regularization. Regularization. We use regularization to address overfitting. If you take a model that's overly complex, especially polynomial model, and then many other classes of models that we'll encounter in the course of this workshop. We invariably end with overfitting in the data, right? Complexity creates, the more parameters you have, the more likely you are to overfit the data. If you want intuition, there's a very elementary fact. If you have endpoints, a very elementary fact if you have n points you just need you just need an a polynomial of degree n minus 1 including the beta naught term there'll be n n parameters and coefficients right or the betas so the system of linear equations you all remember that if you have x and y are the unknown, how many equations do you need to solve it in linear equations? Just two linear equations. So if you have n points, so long as you go to a polynomial of degree n minus one, you will have an exact fit. And every polynomial above that will have an exact fit. Right. So you have more. Technically, you have lost all degrees of freedom you have a perfect capture there so you do have overfitting something or the other will just fit exactly to the data now but that that is fixed to the training data that the test data is entirely different real life data is entirely different and so your model has ended up learning too much. It has learned not only the signal, but it has learned from the noise also, given the fact that it has learned from the noise also. How do we not do that? So there are many, many tricks. The simplest one is just go get lots of data. If you have a lot of data and then you try to, then they have a damping effect because all the data, the signals will amplify and the noise will cancel each other out because hopefully the noise have a Gaussian distribution. They fall on either side of the zero. So they will sort of cancel each other out, right? So that is one advantage. On the other hand, if you can't do that, which is a reality, often it's very hard to get more data. You all must have noticed by doing the leaf. One of the lessons in the leaf project was when you actually go and gather data, you realize that data. But anytime you look at data, it's somebody's hard work or a lot of people's hard work somebody has taken a lot of pains to gather the data so there is always the thing that if data is sparse or scarce how in the world do we do the best learning that we can build the best model and still not overfit and so that there are techniques more and more techniques will learn in the course of this nine months techniques more and more techniques will learn in the course of this nine months that you folks are with me between this and the next workshop but the most common technique that you start out of the basic technique you start out is the l1 and l2 regularization now l1 and l2 they point to the minkowski norms so we'll talk about it, if you don't regularize, what happens is that overtly complicated models lead to large coefficients. Those coefficients cause oscillations and your solution, your beta star, the unconstrained optima shoots away from the origin. It just runs away from the origin, right. So in other words, if this is the bowl, the error bowl, and suppose I am the origin, the more complicated you make the model, the more it completely runs away from it, from me. So that's the problem. And we don't want that. So what do we do? We apply a constraint, very simple. We just say, no, my hands are only this long. So maybe this is the constraint. The best that we can do is find the solution, right? At my arm's length at most, right? And when you do that, we did a bit of geometry, where we realized that when two surfaces touch each other, tangentially, just about touch each other, the gradient of the two surfaces are parallel, or rather anti-parallel to each other they point in opposite directions that is the main insight right and this insight by the way i won't tell you more because they are part of your review quiz now so which by now you should generalize and by the way it's not necessarily true only for circular constraints it's true for any any constrained surface or any surface in general any arbitrary surface constraint surface or any surface in general, any arbitrary surface, the gradient of the surface, the gradient at any point in the surface will be orthogonal to it, right? We'll be piercing it perpendicular, right? And it will be pointing in the direction of maximum increase of whatever function is representing that surface. That surface is the contoured surface or the constant surface, constant value for that function. Whatever function g it is, it will be orthogonal to that. And that is the insight. I have one question. Yes. Yes. Back to the prediction, right? Yes. For the back. For the back for the back yeah so this piece that what you showed right yeah these are basically non-intercepting uh kind of of course which kind of go towards uh is that a property because of the way that you have set up that polynomial and you don't have things which are breaking in them. Yes, very much true. So, okay, I'll just repeat his question. A very interesting question. The contour surface, it just looks so perfect. They're all like elliptical curves, right? And they're radiating outwards and the outer ones have higher things. It is because of the convex nature of the error surface. In deep learning, for example, convexity is lost. When convexity is lost, that is when the whole beauty comes in. And you have the mad, mad world of trying to optimize in a non-convex loss landscape. We don't know what is happening. Is that why everybody throws up their hands and says, it just worked, but we don't know? SRIKANT DATARANANANANANANANANANANANANANANANANANAN yeah all right so guys those of you who are um just getting into machine learning i apologize i'll take a one-minute digression because this is a very important question that sachin has asked so let me give you an answer to that it is such a beautiful and fascinating world and we know and we understand so little about higher dimensional geometries at this moment that every practically every day we are finding new things. For example, if you remember, you were there in the ML 400. Last year when we did ML 400, one of the important research papers we found was that when you project the lost landscapes, what you find is that there are gazillions of minima. And you would say, my goodness, how would I know which is a global minimum but here's the sheer beautiful thing large number of those minima are actually. Dr. G R Narsimha Rao, Ph.D.: equivalent to the global minima and not only that they seem to be interconnected to ravines. all of these beautiful hypotheses. We used to think that, for example, the reason the neural networks, we can do dropout and therefore get to the optimal solution. But actually we realize that dropout brings a lot of noise into the loss landscape. It's very beautiful geometric visualization. There is an alternative hypothesis, which is quite likely correct, which is the lottery hypothesis, which is more complicated, but I'll completely sort of oversimplify down to the statement that when you have a very complicated neural network with lots of parameters, you know that you don't need 1 million parameters to solve this problem. What really happens is, because of random initialization, only a subset, it's like a lottery, only a few neurons win the lottery. And they collectively form a hidden sub network and it is the sub network that goes and finds the minima right the other neurons are just bouncing around they're not doing much right most of the neural network is not doing much right so it's a very interesting hypothesis and there is emerging evidence that that is true the only question is we don't know how we will land up with that subset of that. Ranthik? So for regularization right now, we're trying to get rid of like parameters today, right? Yes. What happens is it's very small. Because I would think it's still centered on the origin, but then it's so small. No, what happens, Ranth what happens is let us say that the data the ground truth underlying truth is a straight line right and you try to um do it with a fourth or fifth degree polynomial a fifth degree polynomial will ask for five four bends at least isn't it so what in a straight line how do you get four bends so what will happen is presumably the data will always have noise so it will mix bends around the noise now here is what happens suppose you have very little data right just a few points of data so now the these curves can be wild the curves will try to be as wild as possible bends bends. So there'll be strong bends in the data. But your question is still valid. What if there is enough data? The more data you bring, the more the bending suppresses, it flattens out, right? So even if you're using a four degree polynomial, more data makes those bends almost imperceptible, right? As the asymptotic limit it becomes almost imperceptible unless you look very closely at what's happening where are the bends you see that right so whether when you take let's say four degree polynomial the question is do you need to further regularize the question is if there is enough data remember more data is itself a technique for regularization so you may end up starting from a point at which it's pre-regularized the beta is already small so then doing a l1 l2 regularization does not add much value right so you the lambda that you will come up with will be very small the regularization needed will be minuscule or non-existent on top of it does that answer you yeah good so see just to summarize what we just discussed so from the optimization perspective what's essentially happening to the first images yeah those coefficients are small then yeah even though you do regularization it doesn't have any effect it won't have any because in the cross validation remember hyper parameter tuning you will find out that the best lambda parameter is close to zero here unregularized right and that is the value of the hyper parameter optimization right and so the higher degree polynomial is that what you go at some point the diminution returns and you're just they're close to zero if you're using lasso they will actually disappear yeah so that's the that's the point of it so that is it guys so this is the geometry i highly encourage you to review the video is the video have you how many of you actually go and look back at the video you do go back and look back at the video okay good so you will find all of these i won't cover all of that now um for rich regularization remember your edge surface is a circle and for this but then there are many definitions of a circle minkowski norm the more common definition that smooth round figure that that we call a circle is a circle in a euclidean space but in a non-euclidean space for example with a minkowski with a manhattan norm or some other norm it is something else it could be a diamond it could be a square it could be somewhere else so it goes from less than less than one is diamond less than one is it becomes concave inside and then a greater than one becomes convex right d2 is a circle perfect circle and the extreme limit is infinity you'll have you'll get a square now this is what we did so dampening is elastic and by the way there's an error in this expression i was only talking i i just noticed that i this is not the exact expression there is more to it. It is almost like this. Not exactly this. Not exactly this. The way you do it is one minus lambda and lambda. How much of this and how much of that there is. So I think there's some constraint like lambda one plus lambda two is equal to one. I'll have to look up the exact thing, but something like this is an effect. So there's a further constraint to apply. So you're basically saying how much of ridge regularization and how much of this will get the job done. So this is what we learned last time. With that, we will close the chapter on regression. There is one topic that I'll teach you in labs, not in theory. It's a very specific implementation-related topic, but beautiful. It has a nice geometry to it. It's called multicollinearity. One day. Let's take the Tuesday session for multicollinearity. All right, guys. So we have been talking now for about forty minutes. What I intend to do is just take a five minutes break, no more than five minutes, just a five minutes break, and then we'll launch straight away into our classifiers a completely new topic. okay you can make that as the instead of public yeah yeah that's what we'll do but it i can't make it private then i'll have to give individual access but what i can do is make it unlisted yeah understood yeah all right this is going to happen um what it means is that the video on YouTube will be available right after the class. So topic for today. Now we are moving on to a new topic, which is classifier. Let's do that. So one question that came up is, can we use something other than OneNote? If you guys come up with a good software for Windows or for Mac, let me know. I have half a mind of switching over, switching away from Windows to Mac. Unfortunately, on Linux, the writing board doesn't work. So a small announcement. So classifiers, what are classifiers? We realized that regression just to compare regression was a box if you think of it as that in which the input vector went in the input vector went in which is came out? A y hat came out. Y belonged to which class? What type, what was the type of y? A number. It belonged to, it is a real number, right? In the simplest form, we thought of y as a scalar. Right? In the simplest form, we thought of y as a scalar. Scalar. This is the most general case, but actually, this is the most common case, commonly. But actually, it is not necessarily that. In general, y hat can belong to a k-dimensional vector. For example, if you're trying to predict wind speed, wind velocity, remember wind velocity could be which direction also matters you're trying to predict that not just a speed with the velocity this would be an example of a regression model that is taking in inputs and predicting a vector right or one more traditional way of saying it is that you are predicting not one value one column one feature but multiple features at the same time right you're predicting the speed along x direction speed along y direction speed along z direction when you're doing that this is a vector right or multi multi feature prediction whatever. There are a lot of traditional words to use, but we'll stay geometric and just call it predicting a vector. Now, this is regression. There is another kind of things you can predict, which are categoricals. categorical categorical is to tell suppose i say that in this basket of fruits you the fruits could be an apple i don't know how does apple look something like this and orange it could be i don't know, pineapple. Hopefully something approximating a pineapple. So suppose you have apple, orange, pineapple, banana, let's say. Banana or something like that. There are four fruits in a basket and your job is to look at the weight the size the everything and predict which fruit it is so then when you're predicting or identifying what it is this is not an example of regression is it You can't say that apple is for any reason more than orange. These are just different things. They are not comparable. And hence the phrase that things are apples and oranges. In other words, they're not comparable. They're just different things. You don't compare them. So what you do is you call these categories right you say that the y had the prediction belongs to a categorical variable categorical is usually represented as g categorical variable because what it will have to output and this belongs to the set of apple orange a pineapple apple and banana it could be either one of those things but you have to give your target value one of these four possible things. Are we together? If you give the value to be now within this category, there are certain nuances. The categorical typically cannot be infinitely many. that for example, rainbow, you can consider it as seven colors or you can consider it as an infinite gradation of colors. And you say one of these, because if you do that, now it is not categorical. The set of possibilities must be finite. You must be looking at a finite set of possibilities. If it is infinite, it is not categorical. The other aspect is it cannot be an empty set because it would lose meaning. You cannot say none of the above is the only possibility. These are very common sense statements. And so I'm just setting the bounds of what a categorical variable is a categorical variable belongs to a finite set has a value that belongs to a finite set that finite set is predefined usually or can be inferred from the data you can just do a distinct on the data and quite often infer the unique values that make up the categorical the set of categorical values right for common examples of categorical are days of the week the animals in a zoo right these are these are categorical seasons they're four seasons right so those would be categorical but a very specific color amongst infinitely many colors is more a real valued function, a real valued vector, you can say. It belongs to, is a point in a RGB space. Therefore, it is not categorical. That's exactly categorical. So we will start by posing this with a very, very simple problem. We'll do that. So again, let me just write it in a more formal way. Classifier. Classifier is a box in which you again give it the x vector made up of p features, xp, x2, all the way to p predictors go in. and what comes out is y hat belonging to the category to the g categorical right so i will once again just to summarize right the same words apple pineapple apple right orange, and banana. Kaya, are we recording? Yes, Azhar. Excellent. So this is it. Now, one more thing. The order of the set does not matter. There is no order. No order. What am I writing? There is no, in this set, at least no presumed order. The classifier doesn't presume an order. Though an order may exist and you may choose to ignore it. And there are things like ordinal predictions etc we won't go into it as we are starting out with simple situation just assume that each element of the set is distinct as unrelated to other elements of the set it's a simplifying assumption right not always true later on will realize that there are interrelationships in the categorical values and that brings up the lovely lovely topic uh very interesting topics later on of categorical embeddings and so on and so forth we won't go there but today we'll start by saying these values don't they don't relate to each other apple is an apple and orange is an average orange right and that's that so this is this is what a classifier is now when you have a prediction machine let's think of the example of children cows and ducks right this was the example we used to learn about classifiers the the the way we frame the problem is let us say that you took some children to a meadow and in the meadow you could find cows and you could find ducks children don't know cows and ducks so you start train teaching the child the children start learning you say well look at this little thing uh this feathery thing with webbed feet and beak it's a duck now look at that big animal out there with haunts on its head a big body and four legs and a swishy tail that's a cow right that's the way you would as a parent or as a teacher you would explain to the children the distinction between the cow and the duck. Then that is the process of teaching by showing it instances. But learning is the ability to generalize from the instances. How would you know that the child has learned? You would know that the child has learned if the child can from there look at an instance it has never seen and be able to correctly identify that big animal with the swishy tail and horn as a cow isn't it on the other hand can look at that little feathery creature and say that must be a duck right so it has generalized from the instances that it has been exposed to and the properties that it has been made to observe of those instances isn't it the features of those objects it has observed it has learned from that the question then comes what is the empirical evidence of learning the empirical evidence of learning is that you have to see so let's see how would you know that? You can ask this child. You may believe that the child has learned, but the child may have just memorized, may have a perfect memory, perfect recall, and may be able to just regurgitate every single cow or duck it has not seen in other words in real terms what does that map do in our test in our data set we must split it between the training data set and some data set you hide under the pillow namely the test data set right so in the case of this medal you must deliberately keep a corner of the meadow with some cows and ducks which where you don't take the child while the child is learning if you want to test whether the child has learned, then you take the child to that corner of the meadow and of those animals that it hasn't seen, ask to tell whether it's a cow or a duck. So what will the child do? Gradually, as it sees, in the beginning, the child will just randomly guess, as we all guess as children, right? We think we know it and we guess and our formation of idea of what is a cow or what is a duck isn't quite there yet you know the the concept of a cow the cowness isn't quite correct right likewise the concept of a duck or his duckiness is not quite correct but as it forms better we make less mistakes right The child will make less mistakes. So the error rate matters. Now, how would you quantify error? Remember in the case of sum squared error, in the case of regression, it was easy. You looked at the residual, the difference between the prediction and the reality. So if you're predicting, for example, what were we taking the example of, the amount of ice cream that you would sell on the beach, you would predict you would sell five gallons. But if you sold only three, two is the gap, isn't it? You were off by two. So that is a very intuitive definition of error when it comes to the regression. And of course, you strengthen it, you realize that errors can be positive and negative. You take its absolute value or you take it square, then you add it up and so on and so forth. In the case of classification, what can you do? So let's take this cows and ducks. So the target variable, y hat belongs to cow, duck. A set of only two elements. It can be either a cow or a duck so what can happen let us say that the ground truth is you show it lots of cows and lots of ducks and the child makes a prediction of cow or duck right i put hat on it to signify that it's a prediction so these are predictions and by the way some people write the this matrix in a transposed way they'll make predictions as the row and this, it doesn't matter. Now, suppose you showed the child a hundred animals. Let us say that in the meadow, for the sake of argument, there were 50 cows and 50 ducks, right? And so of the cows, let us say 45 cows were, cows are easy to get, I suppose, or maybe 40 cows were correctly identified as cows and 10 cows were mistaken as ducks right likewise when it comes to ducks it turns out that of the 50 ducks 20 ducks were identified as cows and 30 ducks were correctly identified as ducks right do you see this guys this is it so what you're looking at is the first thing you look at is this is the measure of errors we can see this is the empirical data the empirical data on accuracy data on accuracy, on correctness. Let's call it correctness. Model. I wouldn't use empirical. Empirical is observe the data on the correctness of the model. At this particular moment, well, empirical would be correct. It's okay. So how many answers are correct here? Can you look at it and tell me how many answers are correct? 70. We realize that this is the accurate gives you the accuracy right principal diagonal is correct when you take the correct answer and you divide it by the total accuracy is equal to the correct over total so what is the total here 100. So it is 70 over 100. So that is 70%. So we know that our child has learned its accuracy is 70%. Isn't it? 70% accurate. That is a measure of learning. Now, there are other measures of learning. There are things like precision and recall. And there are things like, we will get to that. We will develop the theory slowly over successive lectures because this is one of the things we get easily confused with. In fact, after all these years, I still wobble my head sometimes. And I know it. I get it right most of the time and still don't get it right. But we will develop it in small stages and this is it. Now, let me bring up something else. Suppose your job was to detect cows. So one of the cases you take as positive case, let cow be the positive case. You can arbitrarily assign a positive case to any one of the classes. Traditionally, and I'll write this word, traditionally you call the smaller class as positive. What do I mean by that? A smaller class is positive. So suppose you're not predicting cows and ducks, but you're looking at a stones and you're telling predicting cows and ducks but you're looking at a stones and you're telling whether the stone is just a stone or it has gold in it right so imagine that in san francisco this entire area was founded on a search for gold gold digging and the tradition of this place is people would just sit next to rivers and little water bodies and pick up stones and then hope that there was a gold nugget in there. So let's go back to the history of this place. You pick up a stone and you see, is it just a stone or does it have gold in it? Something like that, gold nugget, conjuring up a simple situation. So what would be the majority situation? Most of the time it would be stone and only rarely would it be a nugget of gold. And so it makes logical sense to associate the positive to the nugget of gold, because it's relatively rare. So that is a common convention. Now, positive in classifier or in machine learning does not necessarily always conjure up positive psychological connotations. An example of that is, suppose you are looking at mammograms. In a mammogram, most mammograms will come out to be pretty unremarkable. There won't be anything worth observing, right? But there will be occasionally something. There may be a presence of a tumor, either a benign or a malignant tumor, the mammogram may show. Those presence would be, let's just say the presence of a tumor, doesn't matter benign or not, right, a nodule. So that would be one in, let's say, 1,000 mammograms, right? Or one in 10,000. So that is the more rare class. That would be the positive. In machine learning, that would be considered the positive class, even though, of course, psychologically, it couldn't be more negative, the findings. So you must have seen in medical literature, some of you are there, Patrick, if you are there, you probably know this. Obviously you do this. It is very, very bad news when a doctor says that she has found something positive, she has positive findings in your labs, in your x-rays or your blood test results. That is usually bad news, right? Because it means that there's something off. The best news you can get is everything is negative or there's nothing remarkable about your blood test or your lab work, right? So COVID positive. COVID positive. You don't want to be positive, right? You want to fail the test. It's a different conversation. So that is about the positive and the negative cases, right? And so we'll stick with accuracy. Now look at this. If cow is the positive case, some cows were marked as ducks. So what does it mean? Some cows were missed as ducks. So what does it mean? Some cows were missed, isn't it? This child missed some cows, missed identifying some cows, and instead identified it as a duck. So these would be missed. Are we together? In common language, you would say this is a miss. If it was COVID, these are the patients who genuinely had COVID, but you missed detecting COVID. So there's a technical word for it. It is called false negative. False negative. So a miss is a simpler word. And what about this guys? This other element in the off diagonal. It was not a cow. But you predicted it as a cow, isn't it? You predicted it as a, it was actually a duck, but you predicted it as a cow. So a negative case was marked as positive so this is a case of a false positive this is false positive right and so you notice that this thing together i'll use some other color this color this off diagonal elements what do they contain anything not in the principal diagonal all other elements they are errors they are errors isn't it they are mistakes would you agree this is the errors. Right? And so error rate, error, is equal to 10 plus 20. Isn't it? Would you agree? There are 30 errors in this prediction. Right? there are 30 errors in this prediction right and so the error rate 30 percent because they we started out with 100 data set so this is the basic let's start with this and we'll we'll we'll develop a very interesting notions there's an area under roc curve roc curve and things like that precision recall type 1 type 2 and all of these things we'll talk about but i want to use simple language now for the first session so this is what a classifier is now what is a good classifier there are many classifiers just as in regression i mentioned that linear regression even with regularization with polynomials and with these are non-linear least squares and all of these we have picked up but a few sort of pebbles metaphorically speaking from the seashore of regression you know there are gazillions of regression algorithms. We have just picked up a few to get started with. More and more keep getting discovered, keep coming. There are many variations, many things, but the ones that we learned are the foundational ones and heavily used.