 Welcome everyone. Glad you could join us. This is the first of a three-part education series for executives, managers, leaders, solution architects, and technical leads to understand how to develop a business for AI-centric enterprise. I'm Kate Amon, data scientist from Support Vectors, and I've been with Support Vectors for several years. I enjoy learning and working with AI. It is now my honor to introduce Dr. Asif Kumar, founder, CEO, and CTO of support vectors. Asif has decades of experience in data science and AI and has delivered over 12 AI-based products on top of educating over 1,200 engineers and entrepreneurs. With decades of experience, support vectors has been providing best-in-class enterprise AI products, platforms, and implementations, helping its clients, entrepreneurs, and aspiring data scientists to achieve their goals and solve the toughest business problems. The building blocks of Support Vectors' capabilities include technical and business consulting, product and solution implementation, and corporate training, if all things AI and data science. Now let us dive into the topic of the day, which is how do you develop a business case for AI-centric enterprise? Asif, what is generative AI and why is it captured so much attention these days? First of all, welcome to this session and thank you for being here. With AI, for the longest time we have been training different models for different tasks. But in recent years, there has been a shift. We started with transfer learning. We realized that if you have to train powerful models, it takes a lot of compute power. And there was an effort to create this foundational models in which we would feed all of human knowledge, all that we know, all that we can scrape as text and so forth. We would feed into it. Once you have trained this models, this foundation models with great effort. Now they contain the distillate of much of humanity's knowledge. And when you use them, let's say that you fine tune them for a purpose, or you use prompts, and they respond to you, what they respond with is not regurgitating data that they have memorized, they don't have space to memorize. They have to bring to bear the distillate of that knowledge that they have assimilated and used that to answer that. So in AI, it has been a step function. It has led to, for the first time, models that are not meant for one purpose only, but that solve a whole variety of problems. That is generative AI. Awesome. Can you provide a couple of real life and proven use cases from an enterprise perspective that emphasizes the power of generative AI and AI as a whole? Yes. Today, when we look at AI and we look at its application in enterprise, it's actually hard to find a place where it couldn't be applicable. Education has been transformed. In education, the big problem has been that there are far fewer instructors and mentors and professors than there are students. For example, Khan Academy has managed to create a use generative AI to create a personalized tutor, which means it remembers, it answers, you can give it to a generative AI and say, phrase it in words that make sense to me, and it will do so. That is transformative in education. Health care, for example, looking at medical notes and looking at even a conversation, and it's one of the projects that we are doing here at Support Ventures. Can we not only infer some amount of medical notes given a conversation and it's one of the projects that we are doing here at support vectors can we not only infer some amount of medical notes and the diagnosis which needs review from the physician because there may be error a generative AI is not uh is not error-free but what is more interesting is a can it infer the diagnosis or things that a busy physician may have missed and point out could you consider this too we can use this generative ai for example to index all the documents in your enterprise and once you have indexed it whether they are pdf or whether whatever they are and then to ask it natural language questions to have a conversation with it the way you have a conversation with chat gpt now knowledge has been growing exponentially but a problem we have in enterprise applications and enterprises is that access to knowledge has become harder and harder you know it is there but where do you look for it traditional search engines don't do a good job and Where do you look for it? Traditional search engines don't do a good job. And when you use the modern AI systems, they are actually quite very good at it. And you can do question answers with them. You can have a conversation with them about the document and the knowledge base you have. So these are some of the use cases we have. Then more specifically in the movie industry, in art and things like that, generative AI, the visual part of it is having a lot of effect. When we speak of generative AI, there is the concept of a language model. What we consider language is very broad in AI. For example, there is one research that showed subjects, pictures, let's say a giraffe or a horse, and they observed the functional MRI of the brain. Now, functional MRI are very dynamic images. It shows the blood flow to different parts of the brain and so on and so forth, activity levels. Then it treated the fMRI as the language and then asked the generative AI to tell what is this person looking at. And with fairly high accuracy, it could reproduce the image from that, which has tremendous applications. So these are some of the ways. At this moment, it's very, very hard to think of an area that you can't apply as generative ai to or or just ai not just generated the whole field of ai it has gone through a step functioning increase in performance awesome can you define what an ai-centric enterprise is please an ai-centric enterprise is an enterprise that asks the question that first of all is rooted with the DNA in AI. Today, to contrast what is not an AI-centric enterprise, today let's take any traditional business. Let me speak from experience. I worked for many years for a leading corporate education company, corporate training company, Cornerstone. The CEO, when he brought me and the startup that I worked for, I was the chief scientist for, got acquired. And he acquired it specifically to get the AI team that I led. And he succinctly put it, he says, we have a lot of data. that I led. And he succinctly put it, he says, we have a lot of data. We are the leaders in corporate training. We have 100 million users who are employees of different companies. If people are taking a training in Amazon or Facebook or anywhere, they're actually taking a training on our platform. They just don't know it. But we know that AI can make transformative difference. We don't know how. Can you do that? So when you look at that, first of all, there has to be a belief that AI has a place. And we looked at it over eight years. We transformed the organization to be AI-centered. For example, they had 110 million pieces of content to provide education from. But they were unsearchable. They were using traditional search engines. First order of business was to understand that content, make AI have a semantic understanding of the content so that you can have a natural language conversation to find that content. The other was in education, you have different levels of understanding. Can you take something and say, can you simplify it in words that make sense to me? It's too technical, right? So that same piece of content becomes much more accessible. Can you tell me based on what I know and don't know, what is it that the next thing I want to learn? So the AI-centric organization starts with having first a belief that AI can make transformation, then having a team that goes through each area. This is what our team did. We studied each area of the business and we asked ourselves, what are the things that AI can do? And what are the risks involved? Because there are different governance laws you have to uh guarantee that there is no bias that there is no that there's a the ai alignment in other words ai will do exactly what objectives we set out to do not something different it will not first do no harm right things like that and then quantify what what would it cost in hardware and software what would be the effort cost? And what are the benefits? To go like that and then to say, then to create a strategic goal for a company that let's go and do that. That is one aspect of it from a leadership perspective. The second aspect is how do you put together a team that thinks and breeds AI and AI-centric? You need a team of high- power data scientists. And quite often, those data scientists, those AI engineers cannot be, it is far better to train them in-house because you have engineers who know your business. They just have to be taught AI. You build them up. Then you need a platform engineer, system engineers who are really good at large-scale software systems. You need operational DevOps people need to be retrained and upskilled into AI operations, ML operations. How do you create an AI pipeline so that your models keep improving over time as the data changes? Because data has a drift and your AI models have to stay fresh with that. And for that, you need a continual pipeline of update and learning. So that's how you build an AI-centric organization. Okay. I think you covered some of the next question, which is, can you, elaborating on the aspects of data that plays a key role in developing an AI-centric enterprise, if you don't, didn't already fully cover it, if there's anything you want to add that would be perfect? Yeah for data I would say that see the generally it is said that the more data the better because the AI gets more context. What you have to be careful with date with this in particular the generative models is that what are the biases in the data if you think there is bias in the data you have to make conscious efforts to exclude the data you cannot include the data the second thing you have to really worry about it is data privacy issues you absolutely have to guarantee um you know k anonymity l diversity and so forth there are care, anonymity, ill diversity, and so forth. There are measures of anonymity that you have that it should not be able to say things or do things that helps identify people. And lastly, you have to, with data, you have to ask that if I feed it this data, will it preferentially give advantages to certain sections of society or sections of people and disadvantage some other? So what will be the consequences of using? It's surprising, actually, how much data you have to exclude. And it is a conversation that I find enterprises are currently not having, or not having as robustly as they should be having. That's unfortunate. Ethics is important. Speaking of business, how should an enterprise approach developing a business case for becoming an AI-centric enterprise? See, AI is a tool. There are two ways of approaching it. And this has been true. Let's say that to give a bit of context, whenever something revolutionary comes out, you have to ask, do I know a problem that this will solve? That is one way of approaching. The other way of approaching is, given this tool, what are the applications that I can make of it? One famous scientist on a discovery was asked, what use is this? It's remarkable what use is this? And the scientist famously said, what use is a newborn child? And generative AI for the purposes of enterprises is so new, so fresh, and people are still sort of looking at it and trying to understand what it is. It's like a newborn child that you're still thinking, what will it grow up to do? Now, somewhat like laser, when laser came out for the longest time, it was a useless thing. It was just a scientific curiosity. Today, we can't imagine a world without lasers. It took a while for people to really know the potentials of that tool. Now with generative AI and with AI in particular, the broad field of AI, our experience is the moment you take any one domain and you start looking at the problems that the enterprise solves, very soon it doesn't take long. Within a week you have a very strong sense of how AI can be transformative for that work. If you look at 10 special things that a company does, quite often seven or eight of those can be transformed with AI to be far more performant, far more efficient. And what is more is you can think of new business models, new products that you can build that will bring value to your domain. But you have to have a due diligence committee. You have to have people who study it, who have dual experience, who sit with domain experts and have some level of domain expertise, but at the same time are AI gurus. Awesome. You touched a little bit on this question with ethics, but what are the key risks which an executive must be transparent about about regarding the adversarial effects effects of ai centric enterprise what control needs to be built from the ground up to mitigate those risks so today the biggest risk that you face with generated vi so broadly speaking is that these machines are trained to optimize on plausibility. What you do once these machines learn a lot of knowledge, distill it, then you go through a process of reinforcement learning with human feedback. In which case, you make it give multiple answers to questions and then you rank those answers, human beings rank those answers, and the machines pick it up. Once they learn to produce the answers that human beings like, what it does, the unintended consequence of that is that these are what I call plausibility optimizing machines. It's a term I coined up. They maximize the plausibility so that you believe it's a sort of a term i coined up they maximize the plausibility so that you believe it's a good thing that is they are not truth machines we do not know how to create truth machines it's a huge danger when a machine will always answer you whether it knows it or not. Imagine that you're traveling, or you're working through a shop floor, a factory floor, where there are a lot of dangerous machines in operation, robots moving and there are sharp edges and whatnot. And you ask a person, how do I go from here to there? The person doesn't know, but nonetheless will give you an answer, right, with great confidence. That represents perhaps a single biggest threat at this particular moment. And then you can derive consequences from that. The second problem is the question of bias, what data you feed in. People often feel that if you give it good data there won't be biases what what it says won't be biased actually it's not true uh once again they optimize on errors and minimize the errors a loss function even when you give it good data it may there are asymmetries in data and the way the loss functions are crafted you may end up with fundamental algorithmic bias it may create its own winners and losers and you should know that it can create winners and losers you need a very very robust suite to check for that when today you see i mean there's a lot of irrational exuberance around generative AI. It is a marvelous tool. We should all go for it, but with open eyes and with tremendous caution. It is the way you approach fire. Fire is of great use, but you approach it with caution. And that is where a lot of it comes from. Yeah. What are the key aspects of team formation for getting buy-in from the sponsors of an organization? Can you also highlight the recommended governance and controls for such transformation? Yes, actually governance, what is happening with generative AI is, one of the risks we face is that we don't know its capabilities. Every little while later, we find that people are observing these machines are developing unexpected ability. Recently, there was a paper, and if I understood it right, it sort of claimed that these machines are developing a theory of the mind. They are beginning to figure out how you think. Because they can figure out how you think, they will give you answers that is tuned to you. Right or wrong, they will figure out a a way an answer that you would like right and the fact that they can come up with these abilities and we don't know that they have these abilities theory of mind it was believed that it is a unique thing about human beings animals don't form a theory of the mind right likewise for example many many abilities are emergent abilities as you make these models, they develop abilities that you don't know. Suddenly it pops up. They can suddenly do arithmetic correctly. They can suddenly answer. You have trained to answer questions in English, but they are answering questions also in Persian. So you have to know that governance comes in from understanding the risks. First, the risk that it can harm the human alignment issue. How aligned is what it does to human objectives and goals has to be there. Google used to at one time have a motto, do no evil. First, do no evil, which is, I suppose, a reformulation of the Hippocratic Oath. First, do no harm when you try to do something uh from what i understand they don't it's not their motto anymore but some revised version of it is there but nonetheless these companies are all recognizing that there is a risk to ai they they're creating an ai policy what the governance rules are they have an ethics board ai has a google for, has a pretty robust ethics board. First things first, if you are getting into AI, start with the ethics board. Start with the governance body. Make the governance body very well aware of the regulatory environment, not just SOC 1, SOC 2, FedRAMP and GDPR. But they are now, Europe is formulating the AI Act, the AI governance things. Be intimately aware of not just what it says, the do's and don'ts, but the directives and why did they come up with it. And to continuously put, you know, assertions into the system, it must pass certain assertions. It must be able to convince you beyond reasonable doubt that it doesn't have bias. You have to continually test for bias. Like in our case, we used to test for bias every month when the model would get retrained. You need to do that. You need to look at the alignment. You need to have a healthy debate within the company about all of this. And you need to make sure that all work goes through such a process of due diligence and debate. It shouldn't be that three people in the company can foist upon mankind a large language model just because they believe that it will do no harm. Yeah, wow. Can you define the key building blocks of an AI-centric enterprise from the initial formations to the operations standpoint, please? See, when you build an AI organization to be of service to the enterprise, we obviously, from a leadership perspective, you look at multiple things. How will it help the bottom line? How will it help the top line growth what new business opportunities will it create um there's the fear of missing out what will the competition what are the competitors up to that we haven't really thought about so while all of those are there that's a leadership level thought when you put an organization together it has to start with people who have deep experience with ai which which means you get all things, people who are deeply geeky about the algorithms of AI, but also people with some experience who have been burnt, potentially or nearly burnt with some of the harm that AI models can do. And they sort of trapped it to the last moment and prevented things from happening. You need a process of walking cautiously through landmines. You need some of those people. You need domain. It has to be a very good, healthy technical debate between your engineers who are platform, who can create large scale. Like for example, in my team, we had the systems engineers who were absolutely the gurus of large scale, scalable architectures. Their language would be how many queries per second can be processed? And they would say that anything is unacceptable, any model we won't like, unless with the right hardware, it can have a throughput of at least 100 queries per second or something like that. You can choose your number, what's your query per second in your enterprise that makes sense. So people have to be fixated on key performance indicators and usually they are different stakeholders. Very much like I often say that AI teams are very much like a NASA team. In NASA, if you notice, when you have a countdown, every single subsystem lead has to say, it's a go from them, right? And then when it is all systems go, you go for a launch. We used to practice something like that. Our systems engineers had to say that this whole thing will scale within reasonable hardware budget. They have evidence for that. They would have scalability and performance metric. Our architects, the people who are very passionate about design patterns and how the API should look, et cetera, they have made sure that it is well tested, there is enough harness. Then our AI, we used to have a process to show that if you deploy a new model, there has to be evidence that it improves upon the previous version, right? It used to be part of our ML pipeline. You have to ensure that. You need that. And finally, you need the integration of the application developers who just say, all this fancy AI, but how do I rate the product managers who have a sense of what it means in real life and how much value will it bring to our customers who are boots on the ground, who are taking everything you do continually and talking to stakeholders, to clients, to people in the company and doing, if we did this, what value is it? How would you want it changed? You know, there's a design process called, how may we do a Google sort of a design sprint, who are continuously boots on the ground, organizing design sprints, right? And bringing back feedback from the field. So, and then of course, not to forget the fact that as things evolve, you need the cooperation of yet another stakeholder, namely the ethics board the people who are very concerned about the security the ai alignment the ethics the bias in all of this absolutely asif can you briefly touch on the key steps for enterprises to prepare their infrastructure and employees to stay ahead on top of what you've already said see it all starts with the first step is due diligence you have to set let's just say that we are a company let's say we are a garment company for for the sake of argument and we sell garments and you want to say how can ai transform that would be a case of let's say we want to create the next generation recommender engine that has computer vision built in that will dress up a potential client that will talk to the client help decide a particular fashion or stylistic element and so forth you have to first start by saying fashion or stylistic element and so forth you have to first start by saying what is it that would be high value that the current software that deterministic software cannot do that only ai can do once you have identified the the first rule is always the lab you have to do experiments a lot of experiments to see what works and what doesn't work. And at that moment, predominantly it's the work of the data scientists. You don't get engineers involved to a large extent. Once it is validated that these things work, then comes the next phase of asking what are the hardware and software implications of it? What is the infrastructure implication? Many ideas, brilliant ideas may die on the, may wilt on the vine because the sheer hardware cost is astronomical. And it is a fact, it's a fact people don't realize today. These machines are digital machines and digital computing compared to analog computing is a point Jeffrey Hinton makes quite eloquently. It is one of the most computationally intensive form of doing anything. What the human brain does as analog computing, or even a mouse's brain does, these digital machines do a tremendous cost of hardware and electricity. So you have to factor that in. How much will it be to train? How much will it be for inference? Then the next question is, what's the software cost? What is the team you need to organize to integrate that AI into a systems architecture? Because ultimately, enterprise architectures are robust, scalable, high-performance systems. You have to bring in the whole engineering aspect. And the rest of it is essentially mainstream engineering from there. Thank you. Thank you, Asif. And we will continue the enterprise preparedness in detail in part two of our education series on Monday, July 10th at noon Pacific Standard Time, which is 3 p.m. Eastern Standard Time. Thank you all for attending.