 All right. So today we are going to look at how the neural networks work. And what are the details of training a neural network? So let me give you a basic sense of a neural network. Remember, we are going to create the standard dense feed-forward network. What are dense feed-forward networks? There are many layers stacked, many layers of nodes stacked next to each other. The node in one layer does not connect to any other node in the same layer. Instead, it connects to all the nodes in the previous layer and all the nodes in the subsequent layer. So when we use the word previous and subsequent, it is conventional to lay out the neural networks in such a way that the layer that gets the input data is kept on the left. And we imagine the progression of the signal of the computations to be from left to right. The way we would write English sentences and on the right most end is the output. Are we together? That's how we think of a neural network. Now, we will start with very simple, what I call feed forward networks. And we will start with a very basic dataset, very much like we did in the course on machine learning. If you remember, we started like with univariate data sets, which means Y is some function of X. It may be a nonlinear function of X, but we kept it to one input dimension and one output dimension. The advantage of doing that is we can visualize it on a page because in a page we have two at the x and y axis if x is the input y is the output we can visualize both the data and the predictions so now let us recap usually what are the what are the so in we're going to play this game build a neural network make it learn something from the data, learn to make inferences from the data, predict y given x for the data. So in other words, it will build a model. And then we'll see how good the model is. So what are the things we do? First, we need the network, the layers of the network. Then at each layer, what are the layers made up of? We have the weights and biases and the signal that propagates through them, and it goes through the activation function. Now, activation function is a choice. We may choose to use, if you remember, either ReLU, we can use many other things. We can use a sigmoid, a tanh, a relu, a leaky relu, right, a swish function, and so on and so forth. And I hope when you played around with the loss landscape on Monday on your own after the class, I hope you saw that different activation functions lead to a slightly different sort of a loss surface. Obviously, it will lead to different loss functions because each activation function does a different kind of distortion. Right? So we will look into all that. Now, typically, when you encounter Jupiter notebook, so this is a Jupiter notebook you all are familiar with. We do data science typically in a Jupiter notebook. It is not a good idea. It's an anti-pattern to clutter your Jupiter notebook with a whole lot of code. Code should not belong to your Jupiter notebook. your Jupiter notebook with a whole lot of code. Code should not belong to your Jupiter notebook. Your Jupiter notebook should be more like the steering wheel and the brakes and the accelerator in your car. You don't put the whole engine and the details, the pistons, the crankshaft, the, you know, and all of those things, the gears in front of the driver, in front of the user. Instead, what you do is there is an engine block and there is the things below in the chassis, which has all of this. And then inside the car, you just have the steering wheel and the brakes and the accelerator. I often give this example because I would like to compare that to a Jupyter notebook. Keep heavy code properly factored into Python libraries. your code, like literally a Jupyter Notebook with the reams of code. Now, this may come as a surprise because quite often when you surf the internet, you come across all these articles in which most of the code is right there in front of you in Jupyter Notebooks. While it serves a pedagogical purpose, it is simpler for the author to just show the code in the Jupyter Notebook itself. Actually when you do disciplined programming, it's a terrible idea. I would go so far and as many people have pointed out that Jupyter Notebooks have literally created a culture of bad coding practices. I mean obviously nothing against Jupyter Notebook is the most marvelous thing that has in many ways happened to the data science communities, but with great ease has come somewhat indiscipline. Coding as a discipline requires people to write proper libraries, packages, modules, and so on and so forth. Instead, when I hire people, when I hire data scientists, for example, in my team, on a regular basis, I have seen time and time again, you have to break the habit of writing reams of code in the Jupyter notebook. You need to have them refactor it out into proper Python libraries and just have the Jupyter Notebook invoke those libraries. It makes the code reusable. It also opens that code for unit testing. When you write your code properly, then you can do test-driven development and many other good things follow from that. So the way that you'll see this Jupyter Notebooks, it may come as a bit of a surprise to you, but we will keep much of the code away from it. When we were doing machine learning ML 100 or ML 200, the code was not too much. And to illustrate that I had just put the code along with other people, just literally in the Jupyter notebook. But now it's getting more complicated, we have a lot more code. So we are going to create proper libraries or proper assets, proper packages and modules. So you'll see that. And so that is why when you look at your project, you'll see that there are two directories. One is called the SV learn, which is our main library. And then you have the notebooks, notebooks contain the Jupyter notebooks. So this is a As if this notebook is not available on the course portal, or this is version where we have linear regression. Really? Okay. So do you have access to it? I didn't. You mean on GitHub? Yeah, or in local thing. If you do, please post it to the course page. Okay. Post it. Everybody should have access to it. So, guys, at this moment, follow along, and then we will make sure that you do have access to it and you can run it. So, what we do is, for the time being, because there's a little bit of a mechanics of making a library into a wheel file and then doing sort of a pip install of that library. I avoided that bit of mechanics by simply adding the library to the path. Just saying this is the search path in the system in Python where you should look for the libraries. So that is that kept it a little simpler. But later on, as we make progress, one of the exercises we'll do is we'll learn to make proper libraries, well tested libraries into real files that become portable that you can just give to somebody, and they can just do pip install. Right. So that will be a second stage. So now let's move forward. You notice that there is a library SV Learn, Approximator, Regression Network. We have a few simple things whose name hopefully is descriptive of what they are. A simple feedforward network means we'll just put a few layers, maybe 128 nodes in the first layer i mean it's sort of a conical structure very high number of nodes in the first layer lesser number of nodes in the second layer lesser number of nodes in the third layer and finally one node in the last layer why because we are predicting a number if y is a function of x we are predicting a real number right so we will do that now now one of the basic things is if you remember we we are used to creating data as just numpy most of us for ml 100 200 so i created a simple class what it does is if you just give it numpy data it will internally do the tensor part of it. The tensor part and conforming to the dataset API, because dataset, remember last time we talked, gives you, when you enumerate over a dataset, it will give you many batches, isn't it? So there's a little bit of mechanics and today we'll very carefully walk through that code. I'll walk you through the mechanics, but first let's go through the overall flow and see how it works. So let's say that there is a network, there is a data set from which you'll take many batches and feed into the network and see what prediction comes out. The predictions, as they are wrong, you will get what? A loss function, isn't it? Because your predictions wouldn't be accurate, you'll get a loss. Now, the question is what kind of a loss? Loss has to have a formula. Now day before yesterday, we implicitly, or rather all the time using the loss function y hat minus y square. That is the sum squared loss. If you average it over the number of data points, it becomes the mean squared loss, right? If you divide it by n points are there and 1 over n,'ll get a mean squared loss but it is very common in the neural net community to by default use mean squared loss for regression right you don't have to there are some other loss functions that can be used but for regression the default is mean squared loss msc loss which explains this function now we are of course importing numpy and the torch library tensors are of course there now we also notice about adam and sgd adam and Stochastic Gradient Descent. What was Stochastic Gradient Descent? Do we remember that? It is the gradient descent that you do in which you learn from one instance at a time or whatever instance you're given one at a time. Adam is one of those momentum-based methods that we talk about, very successful. And there are some newer optimizers that have come up. What do they do? They represent the optimization step. For example, w is equal to the previous value of w minus alpha times the gradient of the loss. You remember? By now, it should be sort of engraved in your mind that the optimization step or the learning step is W is equal to the previous value of W minus alpha, alpha being the learning rate, times the gradient of the loss. So then that was the simplest form of it. But when you bring in momentum and you bring in extra things, it gets more interesting because optimizers are a whole session in this series. We'll deal with them carefully at some point. Now we need a data loader. So here here is what it is. We have data set data loader is the date what happens is that the way tensorflow thinks there's a little bit of mechanics here there is the data set but who loads the data set and gives you many batches right that is the then you bring in the data load so we'll see all of that code matplotlib of course you're familiar with data load so we'll see all of that code matplotlib of course you are familiar with so let's let's create the data let's look at this code we go and create regression data create regression data and we'll see how it does but let's see through it as the name suggests it will create an x and y one dimensional essentially data even though it's a though it's a tensor, it's a tensor in which for all real purposes, there's one dimension, even though there are multiple dimensions attached to it. So we will then create a simple feed forward network. Just assume that we have stacked a few dense layers together, right? Linear layers together. So see this wording or interchangeable linear layer or dense layer is popularly used. Keras and TensorFlow, they use the word dense. PyTorch uses the word linear. They're synonymous. It's just that two different library creators use two different words. There isn't anything necessarily new about it, or sort of different about it. This is my allergy to heat. So when you learn, what is the optimizer going to optimize on? What is it going to improve or do the learning step on? Surely it is going to do that on the network's parameters. Parameters being the weights and biases, isn't it? As we did in the theory session two days ago on Monday. We need to learn better and better values of weight and biases, weights and biases. Those are called the parameters of the model. Then we also remember that when you say W is equal to W, my previous W minus alpha times the gradient of the loss, a gradient of the loss. What is alpha? It's the learning rate. So we need to start with the value of the learning rate. Remember, i said that i typically tend to take 10 to the minus 5 right because in highly complicated loss landscapes small is good otherwise it bounces around we saw that uh we saw that effect but because the problem here is small and i want this session to move faster forward this lab to move forward faster this session to move faster forward this lab to move forward faster i've taken a slightly aggressive learning rate which is 10 to the minus 2 0.01 right a one person sort of learning rate now let's come to the main loop what do we do well i've created a list in which I'll keep track of losses at each step. At each step, what's the loss? Let us run through it. Now, the first example that we do, notice that I mentioned that there are two inner loops. You go for every epoch, you decide how many epochs you want to go. Here we have taken 2001 epochs, which means why? Because the Python's thing, if you do range epochs, it will exclude the last value, right? It will go from zero to 2000. So, okay. It doesn't, doesn't terribly matter, but you can write it as 2000. Then dropout is a concept. It's a regularization thing. I'll give you a very brief understanding of it. What happens is neural networks are complicated beasts. They have a lot of parameters. When you make a very complicated model, if you remember your bias variance trade off, what happens? Overtly complicated models tend to suffer from overfitting. They overfit the data. They learn from the noise also, not just the signal, which is terrible news. So they have many techniques to regularize neural networks. And some of these are the usual ones applicable to all machine learning, like L1, L2 regularization and so forth. But there are certain techniques which are very specific to neural networks. One of them is dropout, by far the most popular is dropout. What you do is at each stage of learning, you randomly go and switch in each layer some of the neurons. So at each time you cycle through the data, each step that you take, every mini batch of data effectively sees a different neural architecture it is slightly perturbed it's not exactly the same as what the previous batch learned you know was given here some different nodes are turned off though that is called dropout and it turns out that it helps you prevent overfitting. Now, if you remember, we saw the visualization, what does dropout do in the lost landscape? You saw those spikes, right? It makes it look like a, what was it? Like the surface of a jackfruit. This bumpy spike show up by doing dropout. So I wouldn't talk more about dropout because we have again regularization is an entire session. We'll leave it as that. Now notice that I told you that there are two loops and inside is the learning for every epoch run through n epochs and each epoch or take a mini batch and then take a step with the mini batch. But when you see this loop, do you notice that the mini batch loop is missing? Do you see that missing here? Deliberately, I left empty space. There's a ghost of a space here. And what does that imply? It implies that we are not using mini batch. We are using the entire dataset, isn't it? We are using the full dataset to make a step. When you use the full dataset to make one step, what form of gradient descent it is? The batch, it's a batch gradient descent, that's what it is. So here do, now this is a little bit of a mechanics of it. When you use an optimizer, let's say, Adam or whatever, you have to, for each cycle, you want to reset the gradients. You don't want it to remember the gradients that were learned from the previous one. Just a bad so uh it is necessary to reset it it's just specific to pytorch another library maker may have done something simplicity now look at this to the network i'm giving the input and a certain dropout rate dropout means go turn off this percentage of your neurons that is okay but to get the prediction what do i really need to give to the network the input if i give it input it will produce to me the results but remember input is not just one dimensional suppose the data set has thousand points it's basically the whole array of thousand points and it has to do uh results the y so a thousand x's go in and let's say a thousand y's come out results come out y hats come out so i'm using the word results you'll often see me in code use the word results or use the word y hat right in the beginning stages i don't use a lot of uh you know hats over the y because which is customary in this field to show predictions. But as you become more familiar with the conventions of this field, you will start seeing that I use special symbols in the code. For example, you may have noticed yesterday that I was using Greek letters quite generously in two days ago when we were doing gradient descent by hand for the geyser data old faithful geyser data right but here because it's a first lab i've sort of pursued that so we take a result think of it as your y hat once you know y hat what can you do you compute the y hat you compare the y hat to y to know the reality the actual labels to know what the loss function is so let's say that the entrepreneur build a model and the model says that the entrepreneur needs at a given temperature it needs to will be able to sell about 20 buckets of ice cream, right. But what actually sold was 18 buckets of ice cream. Data is it. So now we have a gap between the prediction and the reality. And out of that gap, you will create the loss here mean squared loss, in other words, 18 minus 20 squared, right. and then of course normalize it divide average it down to the number of data points so this is the forward step isn't it guys you're giving the network the input and it's producing a result this is your forward step what happens at each layer of the forward step? Data hits each of the layers. Z gets produced. You know, the W dot in the matrix, you have a tensor multiplication. In simpler terms, think matrix multiplication. Your input vector gets multiplied by the W weight matrix to produce the z right the linear it's a linear transformation right so far and then you add the bias so far it's still affine but the next thing that the neurons do is apply what apply an activation to the Z. Each of the neuron, whatever it produces, it then applies a nonlinear distortion to that, the activation to that. And then it produces the output of the first layer, which again goes and hits the second layer, where there is again a weight matrix, right? So the output of the first layer gets hit with the weights of the first layer gets hit with the weights of the second layer and bias term and add it to the bias term so and that is again a linear transform in the second layer followed by a distortion an activation that distorts the result from the second layer starts the result from the second layer. And so it propagates forward, right? Except with one little addition in each, like what happens is as every time you're doing this batch going through, you just go and physically switch off some of the neurons. It's like go turn off some of the bulbs. You don't let it learn, right? When you don't let it learn, what it means is that it retains the learning from the previous cycle. So you do that, it will produce at the end of it, you'll get a result, you'll get a y hat. From the y hat you now take the difference and you create the loss. This is the loss computation. Now from loss what do you compute you compute the gradient of the loss because you need the gradient of the loss and that is where back propagation comes in and this line needs to be unpacked how does the gradient get propagated how does the gradient get propagated right it turns out that where pi touch differs or tensor flow differs from let's say numpy is in a very very interesting and profound way in numpy when you create a variable let's say you create an area of numbers Numpy, when you create a variable, let's say you create an area of numbers, you get what you see. You get that area of numbers. That's all there is to it. But in their frameworks that know that ultimately that input will eventually go into some function, which will, where, whose gradient would be computed. Are we together? So what happens is that whenever, if you so much as touch it or feed it somehow into a function or an operation where you need to take the gradient, you need to be careful. You just set it something called autograd is equal to true. When you set the autograd variable is true the these these frameworks like python as they say aha we need to compute the gradients of this function and it will allocate separate memory not to just have the values of the values of that very of that variable right but also its derivative so you essentially have so you think you have created an array but uh in a simplified way think that there is a hidden array also that gets created which is going to store the gradient of that of that but those gradients will be computed when you call the backward function right the backward function will cause the gradient to be computed and populated into your array but the interesting thing with gradient is to compute the gradient everything that went every other input variable that went into the function their grade they also get their gradient so something else is there something else is there you can see the gradients all over the place have taking place right so effectively even if you have just numbers it will have this value auto grad is true and autograd in true doesn't mean much because you know that's a raw input vector so it's its gradient is essentially not of much relevance it's just once but that is it that part the fact that it can do automatic differentiation is one of the big big things with the new um new computational architectures go ahead of it so where in the code have you specified that it requires gradient very very good see what happens is that you didn't but because you used a function m, this internally has set gradient is true, internally. So what it means is that the moment you go here, now it comes with dot backwards built in. And everything that gets into MSE, what goes into MSE? Y and Y-hug. Look at this. To the loss function, what are the things you are giving it? This. And so it will go about computing the gradient, but it will wait for you to do this. This will cause gradients to be computed and also back propagated. If you had a single layer, of course, it would be gradient. And let's say that you had just one neuron, you would have just a gradient of that neuron there. Loss function of the gradient at that and there wouldn't be any real back propagation but you generalize the word back propagation to apply to that also you think of it as a forward pass loss computation and a backward pass i mean together so that is the back so then the gradients got computed but learning has not taken place for learning to take place a step of learning to take place what you need to do is on the optimizer because optimizer knows the real.D.: The step forward the simplest ways w is weight, the value of weight is now a change to the current value of weight minus alpha times the gradient with respect to that weight right, but we saw that in in the theory part. R. Vijay Mohanaraman, Ph.D.: But that is for a simple us like a gradient descent the way we learned. But actually Adam is a little bit more sophisticated than that and the formulas are different. Because the formulas are different therefore you ask the optimizer you ask the optimizer and say whatever your internal way of learning is go take one step of learning because now you have all that you need to do the learning you have the gradients and you have the current value of the parameters you have the current value of the weights and biases and so go update them are we together and updating them is just very simple arithmetic at that particular moment. The hardest part was the gradient computation where the back propagation takes place. Otherwise, it is just subtracting alpha times the gradient. That is it. So now once you do that, the question is, how much of the loss took place? So loss is a function. This loss function, because it was differentiable, you used it to do the backprop of the gradients, compute the gradients and backprop. You even did a step of learning, but one step still remains. Let us save that. Let us figure out how much was the loss value, this loss value. I just happened to store it somewhere for display. Not necessary to the learning, this part. This is just for us to keep track and put out a table later on of what was the loss at each stage of learning, right? And we are saying that if epochs, so we run through a lot of epochs, 2000 epochs. So I'll give or take one. If you, for every 100 epochs, print out what the current loss is, what the loss at this moment is. Not for every one of them, otherwise you'll end up with a long table with 2000 rows. You probably don't want that aggressive level or that so you guys can play with it you can change it to 50 you can change it to 20 to see more fine-grained learning happening so now let's look at this code first we did we print the network do you see that in the beginning we printed the network what does this network look like here is. So guys, I'll invite you, give you a homework. I printed out the network in a textual form. Right? But there is a Python library that will visualize a PyTorch network. Are we together? There is a visualization library that will visualize a PyTorch network. Your homework is to discover the library. I deliberately didn't put it here because that's your homework. Your homework is to discover that library, use it and augment this notebook with a proper visualization of the network. Right. This feed forward network, visualize it. but at this moment from the textual description we'll say the first layer this is fc0 right i give why is it fc0 these are the names we gave and you'll see where it is a linear layer input is one and output is 128. why is the input features 1 why is the input feature saying it is the first activation cell? No, because the data is one dimensional, isn't it? I'm saying y is a simple function of x, x is one dimensional data. So input features refers to the dimensionality of the input vector. What is the dimensionality of the input vector? One so it is that and then what you're doing is this you're feeding to the first real layer how how many nodes are there how many neurons are there in the first layer according to this sentence 128 and you you are saying do that and of course also have the bias term. I think even if you don't say bias is equal to true, default is probably true. So then from 128, the next layer narrows down to how many layers? How many nodes in the second layer? 128. 64. Second layer has 164. Sorry, look at this right input feature 128 output is just so the output is 64 uh out out features yeah so it will produce 64 outputs okay those 64 outputs which have been activated you know they feed into the next layer which does what takes those 64 outputs and then further you feeds it into a layer with how many nodes 16 nodes so how many outputs will i get from this layer 16 16 you'll get 16 outputs so those 16 energies or 16 uh sort of light bulb brightnesses you feed it finally into the last layer all of them then converge into just one node right what is that node doing it's producing an output a single out why am i producing a single output because my output is also one dimensional i'm just trying to write a function a simple function the way you learn in basic algebra y is some function of x one dimension right so we are taking the simplest possible example and so you see this as a table you see the the first layer, input is 1, output is 128. So how many weights will there be? In this layer, how many weights will there be across that? 128 weights. One weight attached to each of the neurons, isn't it? Then how many biases there'll be because there are 128 neurons now here's a simple thing just count the number of biases and you'll always know how many nodes are there in that layer right now how many how many parameters are there well weights and biases put together they add up to 256 right now look at the second layer second layer is getting the output of the first layer, 128 features or 128 activations. They feed into this. And the second layer contains how many elements, how many nodes? 64. And what is 128 times 64? Yeah why because it's a cartesian from every node in the previous layer there is a connection to every node in the next layer so lots and lots of weight lots and lots of edges and each of the edges have a weight so there are lots of weights and this comes as a little bit of a surprise the first time you encounter it. You say, oh my goodness, so many weights, so many parameters, 64. And this is the total number of parameters in the second layer. Wow. Then you go to the third layer and so forth. And you notice that this is how it is. So when you look at this very simple neural network that is why the word dense people use the dense neural network you see how dense it is in terms of edges and therefore weights isn't it even though this is actually a pretty baby neural net right it's a neural network just three layers with 128, 64, I mean, three layers, 128, 64, 16. These are the hidden layers. This is the input layer and the output layer. Three hidden layers. And yet it has close to 10,000 parameters. So what is the problem here? When you have a model that is so complex that has so many parameters what can go wrong it can have a lot of overfitting to the data right so it can have a lot of over so you need to watch out for those overfitting to the data and let's see if there is a sign of that as we make progress overfitting to the data. And let's see if there is a sign of that as we make progress. So as we run this code, do you notice that we do a print at every 100 epochs? We print what the current loss is. So that shows up here in this table. So what can you tell about the loss? Do you notice that the loss in the first 100 epochs, it crashes down from 151 to 16. isn't it and then it keeps crashing down but after a little while you notice something funny what do you notice in the losses here after the first thousand cycles the learning is slow actually and it sort of bounces back up and down up and down right because now it is trying to fit to the noise up and down, up and down, right? Because now it is trying to fit to the noise. Your data obviously has noise. It's trying to fit to the noise. And so let's take this thing and let's see. Now, once you're done with the training, what you should do is you say, now I'm going to use the network for inference you want to freeze the weights and biases isn't it next time you give it the data you don't want the network to learn accidentally right so one safe thing you do is that you put it in the eval mode the moment you put it in the eval mode now the gradients are not going to change all if you're sorry gradients are not going to kick in and whatever is there is there but those weights those parameters have frozen at that particular moment and so when you take the output when you want to make the prediction on the entire data you can make your final predictions on the entire data one last time let us go plot it now these data that you have you have to do the word detach what is detach and attach attach and detach are a little bit complicated see what happens is your code could be running not and this is a technicality it could be running in the cpu memory or it could be sitting in the gpu memory right so you may have to detach it from that imagine like plucking a fruit off a tree you might have to detach it from the gpu bring it back home right and then do whatever it is that you want to do. So unless you do a detach on the tensor, you can't convert it to, for example, numpy and so forth. So here's the thing, we are creating a plot. Do you see how in the beginning, the loss function quickly crashes, but after a little while, what does it do? It keeps on, it very slowly improves. The loss with respect to the iterations or the epochs, do you see how it goes? Rapidly decreases, and then it sort of stabilizes after a little while, isn't it looking at this you could say that you know we could have stopped learning at a thousand epochs we're not learning something terribly much looking at the finger now is that true well sort of maybe we could have not between 2.2 laws and 1.7 laws there is not much of a gap. But you also see overfitting. Do you see that it jumps down to 1.5? You see some indications of overfitting and then it is coming back up. The losses are coming back up, yeah. Now you can see more overfitting by comparing the mean squared loss of the training on the training data versus on the evaluation of the test data which we haven't done but we have kept the problem very simple at this moment we haven't done this bifurcation into a training test etc etc let's see now look at this i have plotted here x y and y hat x y are the initial data are the those little circles do you see those scatterplot that is your initial data what is the prediction this is your prediction curve now if you look at it we started out with the sine curve you remember that actually we haven't shown you i'll show you but take it, we started out with a sine curve. You remember that? Actually, we haven't shown you. I'll show you, but take it as first. Okay, so hopeless. So it was a sine curves are smooth curves. What you notice is that you notice that does this look like a smooth curve? It doesn't. So it was a very simple network it tries its best to fit to the data. Now I invite you to do this. Make this network more complicated. Add more layers to it. Play around with it. Change the activation function. So there are many knobs to turn. You can change the architecture of the network. Add more layers. Make the size of each layer bigger. Play with that. Play with dropouts. Play with the activation function change that this is your homework guys do that and then see how the prediction the shape of the prediction how does it look do you see evidence of overfitting here guys look at this curve it should have been a nice smooth curve. But do you see, for example, this region? What do you see here? It seems to have overfit a little bit, isn't it? So there's some slight indications of overfitting. Now, this one we did using the whole batch gradient descent. Now let's do mini batches. Not much changes. You just choose a mini batch size. Now here, by the way, this was the function that we used. Right? Function. So the dad used 7x. Now let's do that. So do you see the two for loops that I talked about? The rest of the code inside is exactly the same or almost exactly the same there's nothing new except that some little steps things have taken care what we we reset the optimizer at each step we compute the this is the forward pass computing the loss a back propagation to get the gradients then doing the optimization step do you see that this is exactly the same and we happen to just save the losses at each stage for our thing network is exactly the same but notice something when i do I run it through actually a less number of batches here, only a thousand epochs. And the loss, mean squared loss seems to have crashed pretty drastically to this. Now let's plot this function using many batches. What happens when you plot it through many batches? Does it look a little bit smoother? But you also notice that there is some evidence of overfitting still. Interestingly, look at this loss function. What do you think happened in view of the visualizations that we saw last time? What do you think happened here? Got stuck in a local minima. Very good. It got stuck in a local minima. You know, there was some pothole there and this whole thing was wobbling there bouncing around a little bit until it bounced off it. And again, started the gradient descent after that. So you see this happen quite a bit in neural networks. Right. And this should be like, you know, this is how you see, keep that picture, the visualization you saw last time in your mind. So that was that. Now let's do Stokoe. And do you notice that there is still, when you do a batch gradient descent, there is a little bit of oscillation here. It better it does worse and so forth you can see it once you get down to one it sometimes goes up to 1.3 then gets back to 1 1.2 1 1.19 so forth so you see that it is it never quite hits the minima what will it do it's sort of beating about the bush isn't it sort of beating about the bush, isn't it? Sort of beating around what would have been the optimal minimum in our imagination. Now let's do stochastic gradient descent. In stochastic gradient descent, what is our batch size? One. It is still the for loop of this. What do we do now? We learn from each instance of data at a time. When we do that, so here's the batch size. The same thing, we set the batch size to one. What happens to this? The same network, you realize that learning is pretty rapid because by the time you go from one to a hundred epochs, 100,000 learning steps have taken place. And so you notice that drastically, the loss has gone from 185 already down to 0.1, right? Compare this to the previous case where the decrease in loss was more gradual. So here, it has pretty sharply gone down. And let us see how it looks. Do you see how catastrophically, I mean, how rapidly it bounces close to the optima, except that it just keeps bouncing around the optima. Like a drunken man, it just keeps bouncing around the optima. Like a drunken man, it just keeps bouncing around. It's like, you know, it never knocks on the door. It keeps on knocking on all the neighbors doors. So. And look at this curve that you get from stochastic gradient descent. You see a lot of wiggles are there and obviously there's some evidence. Clearly there is evidence of overfitting and so forth. So this is it guys. This is your basic loop of learning from this. But now let's peel the onion. Now that we have understood the overall flow and guys, this is it you have to know always this will be the inner loop of learning these one two so this is just an initialization of the parameters i'll leave it this is these four you can say it captures the essence of machine learning isn't it forward? Forward pass, compute the loss, compute the gradients, but take a gradient descent step. Those four things are literally written in four lines. And that's also the power of a framework like PyTorch, which makes it so simple that if you know the theory, the code is practically obvious. You can't think of an easier or simpler code, more intuitive code then. Are we together, guys? Now what we will do is we are going to step and look behind the curtain and see what was the network and how did we build the network, right? So for that that let me go to where let's go and look at regression network i will look at this code from the beginning and let's see if we can make head and tail out of it this time now that we know what it does let's start from the bottom well bottom is just a for loop whatever we did uh what and this is what i usually do before i put things into the jupiter notebook quite often i will test it out make sure it all works and then copy over now you notice that this is what i had copied over to the jupyter notebook but this is the main those of you who have been used to c c plus plus java or python and know know that you can have a main function i'll leave that aside can you guess what this create plot function does plots function does in the ui guess what this create plot function does plots function does in the ui in the jupiter it's the loss plot and yes this plot these two so there are two plots here so in the language of uh matplotlib you will say that there are two axes language of matplotlib, you will say that there are two axes. Two subplots. Subplots, exactly. And that's why you use the word axis one, axis two. The plot is divided into two subplots and the names are axis one, axis two. So what is you, you start out by creating a grid with to one row and two columns. R. Vijay Mohanaraman, Ph.D.: For subplots that makes sense guys isn't it, this is the figure size, what is it 20 by 10 is the proportion let's see if the proportion looks like that, and this is a bit of matplotlib but for the I will mention it only for the first time, if you look at the total plot is it twice as wide as it is high it is right because each of the subplots is a square if you put two side squares side by side you will get twice the width as compared to the height right so that is what is reflected in this. Now we plot what? For all the epochs, we plot the losses for each of the epochs and we happen to choose the color blue and align with two. Line width is how, these are just aesthetic elements if you don't do it you'll be blessed with black color a black plot which isn't nice then you set the x label y label then that is you finish with the first part then you do the second plot very similar now in the second plot it it gets more interesting. First is just plotting the loss. Second one, you notice that you plot the prediction. Now in matplotlib, when you just call plot by definition, it will make a line plot. And then the scatter plot of the original data. Remember, y hat is our predictions and y are the actual values. So for every x, you have y and y hat. So you can plot both of those. And this is in red color, let's say. Transparent red color. And this, y white hat is, we'll see what color I got by default. I believe maroon or blue. Okay, blue. So you see this, right? This is a semi-translucent, sort of a translucent red, and then you have the blue color. So this function is easy to understand. No brainer, right? This is just matplotlib stuff. Let's go and try and see if we can understand this other function. Oh, by the way, do you notice that I give type hinting? I could have just said x, y, y hat, apoc and so forth. But a best practice says you always give the type of the data so that it is easy for people to read this code and figure out what it is otherwise you have no idea what x is is x a matrix tensor is x a 10 dimensional thing is it an array is it just a number you wouldn't know but because you know the python is a scripted language the downside is it's rather hard to read somebody else's code right you have to but when you give type hinting it makes reading somebody's code easy i hope you would agree that this makes the code reading much easier it's called type hinting now the same thing i do create regression data so let's create a regression data in which i'll produce two tensors of input in the label in which i'll produce two tensors of input in the label so how do i do that i first create a standard numpy array of some sample size so in your mind imagine so by default the sample size is 300 right so so you can give it thousand ten thousand motivators i am creating those number of x values between zero and 1 but then i'm doing x numpy array i'm converting it to float 32. this is sort of a technicality what happens is that numpy decimals are 64 bit decimals high precision decimals whereas when you deal with gpus etc 32 is already going quite far right so you want to build your tensors out of 32-bit numbers not 64 bit numbers just more efficient and this so this is a bit of a technicality. And so what I do, I then create a tensor. I say torch from numpy will produce a tensor. By the way, instead of doing this, I could have also used the tensor constructor. So in other words, let me say that I could have done tensor x. That also would have worked. But I thought from numpy would be more intuitive because it declares the meaning of it. It says that from this numpy array, create a tensor. Once we created a tensor and you do y is equal to some function of x, of x right what happens this and then you again do the same thing float 32 and then what do i do i add some normal noise to it some random noise to it y plus equal to means to whatever value of y is there just add some noise what does the do? It gives you this jitteriness. You notice that the data points, they are spread out a little bit. They are not perfect. You deliberately inject noise. Otherwise, it won't look realistic. So once you do that, the rest of it is easy. So this function, would you all agree, folks, that this is straightforward? This function is easy to understand. Now, let's look at the data set. This is a little tricky, guys. And now, of course, there's a library called Scotch, which does some of the things that I'm doing. Somebody has open sourced a library. But basically, it does the same thing. It numpy arrays and pandas and so forth, data frames, and converts them into tensors. But here, I do it, the whole code by hand. So you see me do that, a numpy array. So you're saying data is that. So when you have a data set for prediction, the data set contains both x and y remember x train y train basically right so this is your definition nothing unusual i just do a sanity check to make sure that length of x is the same as the length of y if they are not it's meaningless you cannot have input array and output array of different sizes after that this by now must be looking to you very obvious what I'm doing with that, creating it into a proper data frame. Now, this data set, simple NumPy data set, inherits from the data set class of PyTorch. Data set Py contains these methods, getItem and getLength. When you say getItem, you have to decide, give it an item at a time. It helps you iterate over the items. And length, it tells you how long it is now. And notice that underscore, underscore. Whenever you see methods like that with underscore, underscore, what it means is that you don't expect people to call the method, you expect the underlying framework to call those methods. PyTorch framework alone to invoke those methods, you shouldn't be invoking those methods directly. Right? Those are constructor section. This one is the constructor. This is a constructor. But this is not. This is the underlying methods, hidden methods. So think of them as what in Java C++ you would call private methods, sort of like that. Now, but here also, so now let's look at another function called define, a pretty table str what was that pretty table well pretty is an exaggeration but pretty enough this thing as you can imagine printing this takes a little bit of careful uh fudging around with blank spaces and so forth and white spaces and so forth so this is not pytorch this is just me or producing things in a way that makes it easy for the user to see the structure of a network so that is what it is. A pretty table. Now, this requires you to understand what this, does this thing make sense, guys? Colon, hat 16, hat 4. What do these mean? These are formatting arguments. Say, put it in the center here, right? Or put it here, etc, etc, of different precisions. So that is all there is, you have to know a little bit of string, Python string formatting to understand what is it that I did. Right. And so how many these little braces are there 123456. And so that's what it is you have at the first line is you take the template and you feed in this string six strings one two three four five six so that produces for you the uh header here let's verify is it six here one two three four five six 1, 2, 3, 4, 5, 6. Yes, it agrees. So this is a pretty printing of it. Well, all of these are auxiliary things. Now let's come to the real matter. How did we create the network? So obviously, this is the constructor in which I'm taking the dimensionality. Input dimension 1, output dimension 1, I assume. Now, the simple network, by the way, i designed in such a way that you could actually give it two three four or whatever dimensional input you want and have as many dimension output you want typically for regression you commonly go with one but anyway you can change it by the way this is way of python to give default values this is just some sanity check now look here what am i doing i'm cr i'm putting together the layers do you see so how many hidden layers are there three hidden layers are there right hidden layer zero hidden layer one hidden layer two right where have i defined the size of those hidden layers out here size of the hidden layer is defined out here and then the rest of it is easy but now comes the forward pass when i when i do the forward pass you know when i say network and here's the input give me the y hat how do i do that let's see how we do that what i do is you given the input x first thing you do is you you apply the the in the first hidden layer acts on the input isn't it would you agree the first hidden layer takes the input, multiplies by the weights, then activates it and produces the activation. You have to do it manually. So here's the thing. You apply to the first layer. So this produces what? Z. Remember in our language of last two days, Monday, it was Z. When the node Z is bias plus wait times input, that Z gets activated, you need to apply the activation function to get the output from the first layer. Now, once you have the output from the first layer, one of the things you do is you may throw in some dropouts. How do you drop out? You just reject some of the inputs you do is you may throw in some dropouts you can how do you drop out you just reject some of the inputs you say forget it right then what do you do you set those to zero then what do you do you go to the next layer you repeat that process the input output of the first layer goes and becomes the input to the second layer producing its output again its dropout again its output and finally you produce the output from the third layer now what do i do with the output from the third layer what do i expect if my third layer is just one node one neuron its output is one but one of the things you have to be careful with neurons is, with tensors is, 1 may be a number. It may be an array of size 1, vector of size 1. It may be a two-dimensional matrix of size 1. It may be a three-dimensional matrix of size 1. You don't know it is a tensor of size one right inside. So what you need to do is you want to convert it back into a number, right, into a single vector, one dimension. So this one says don't care how many rows are there, but one column. And of course, we know that unless you send a mini batch of data the output column is just one right so this keeps possibility open that you may be sending not just one data point but a batch of the data and so remember that the first dimension that rows belongs to the size of the mini batch right right? So suppose you send the number 5, 7, 3 together, they will go as a column vector. So how many rows are there in that data? Three rows are there, right? So that is why you see that for a tensor, the first dimension, which is the row, is always the size of the mini batch, right? It contains different records there, right? is always the size of the mini batch. Right? It contains different records there. So one analogy that I often use is, see, if you think of all the data points, imagine that this data, whatever dimension, in this particular case is two dimensional data, but imagine that's an n dimensional data, in this particular case it's two dimensional data, but imagine that's an n dimensional data point, n dimensional data vector data. But consider each data as a page. So what is your mini batch? Mini batch is these pages stacked together, right? So these are your rows, right? So one data, two data, three data, four data four data five data six data so your mini batch size here is six isn't it so that is where the first dimension is your specifies the data itself it's the mini batch size that is and if your mini batch size is one then of course you just get one row of data. That is what is meant by that. So this is lovely. So we give the forward pass. Now you say forward is fine, but where is the backward? Where is that whole hard part of, this was very simple, just multiplications and activations. What about the backward part? Because that's where we had to compute the gradient. Do you remember that on Monday, when we used NumPy and scikit-learn, we did the entire mathematics by hand. We computed the gradient for the backward part before we took this step. But what about this? Where is the backwards? Who would like to answer that? Why is there no backward? PyTorch takes care of it. Exactly because PyTorch does auto differentiation, auto grads, and the backward step was just computing the gradients so you don't need to do it it does it so that is the heavy lifting actually after a little while once you become familiar with this you'll realize that this is peanuts right this part of code is just declaring what the structure of it is and the forward pass is still peanuts nothing special right you you do weight multiplication z compute z activate it well drop out if you drop drop out a few of the results some of those notes you values you just zero it out then feed it to the next layer again z followed by activation and so forth this is the forward pass the harder part is you don't have to worry about the function and it's gradient or anything you don't have to do calculus. Python does the calculus for you, and that is it's that is the main and not Python sorry by touch does it and TensorFlow does it, these are. frameworks, so people often say that the reason you use byTorch or the reason you use a TensorFlow is because they run on the GPU. They look at the hardware consideration, but actually that is not the only reason. You need an auto differentiation. You need an autograd framework, automatic gradient framework. Otherwise you're screwed. You have to do everything by hand as we did two days ago for the case of the old faithful geyser. We did the forward and the backward, both by hand. That is a crucial element. Now you can say, well, why is it true only for neural networks? Can I not create auto differentiating computing libraries outside without worrying about GPU and so forth? auto differentiating computing libraries outside without worrying about GPU and so forth. And I invite you to find such libraries. There's some really good efforts and libraries that have come up that gives you, that only focuses on the auto grad part, automatic differentiation part. So the homework is to find such libraries and post it to slack are we together guys that's that and so now does this code look self-evident there is nothing else to it let us recap this code and then we'll take a break. We are creating a simple feedforward network in which this is the declaration of the architecture, the layers, isn't it? You're declaring this is the architecture. Then you're using the architecture to do the forward passes. Forward passes at each moment, the input to each layer is multiplied by the weights and biases are added to it to create the z then the z is activated isn't it you apply the activation of the z do you guys remember guys or should i go back and review the theory with you let let me bring back the theory just for the for the fun of it so we remember it ah lookaja Ayyanar? Ah, look at this. Raja Ayyanar? it's all there in front of us let's see what we learned in theory, does it make sense now I talked about. Raja Ayyanar? activation function right Z is w dot express be right so first you take the input of each layer at each neuron multiplied by the weights to get z and you add a bias to get z and then what do you do you activate the z apply activation or non-linear distortion on the z right common distortion there we talked about the sigmoid and we talked of reloop and so on and so forth and once you have done that then compute the gradients happens automatically. And then this is your learning step, right? Which in the case of neural network is a bit more complicated. It is the learning step. Somehow, if you can magically compute this gradients and the system does it through back propagation, you're done, right? Is this all I taught last time? I think this is what I said, right? So do you see all of these things come alive now? Right? In code, this is all it is. This is all it is. So now comes this is it, this is what you see. And the end result, literally you see this inner loop, this inner loop. Result is the forward pass, compute the loss, compute the gradients, take a step, and you're done. Four lines of code does the inner loop of machine learning. So all right, guys, any questions before we take a break how does the you can end up when you're when you're creating the architecture how does that exactly work oh all it does is that it just says i'm creating a layer with these many neurons that's all oh nothing else nothing special and it connects the yeah yeah it connects it that is it see that connection you are doing here when you're wiring the forward pass you're creating each of the layer but the wiring is what you do in the forward pass do you notice that you are the one doing the wiring to each layer you feed the to get the z activated and you take the result what happens look at 59 the output of the first and just ignore the dropout lines because they are noisy at this moment you can ignore it so the 59 becomes the input to 61 because we this is a convention people keep calling it X. But you're taking the output of the first layer, FC0, fully connected layer zero, and feeding it to the fully connected layer one. So you are doing it. This forward is where you wire those layers together. And here you just create those layers. This is like literally just instantiating those layers. Yeah, you just stack them together but there's nothing connecting them the connecting part happens in your forward right you're taking the output of one and feeding it to this that is it guys you see how simple the whole idea is but you have to break it down like you have to unpack it and see it step by step But you have to break it down, like you have to unpack it and see it step by step. So it will be. Kyle, have you posted it to the course page? Yes, yeah, okay. Let's go to the course page. And I apologize for some reason. I seem to be having different versions of this a project on different machines i don't usually work on windows this is a windows machine and it's a bit of a mess i will clean up the mess and clean the project out so that you guys have access to all the files so during the break um we'll help you uh download the necessary files for this yes for this lab yeah reach out to kyle she can help you thank you kyle for that yep so let's take a little bit of a uh it's 8 22 we'll round it off to 8 25. let's take a 15 minute break would 8 40 be reasonable Would 840 be reasonable? 18 minutes? Or make it 20? Well, all right, 840. Let's regroup at 840. Because then we'll do the universal approximator. We can pause the recording. All right. One of the things we covered is the universal approximation theorem, which says that you can approximate any relationship with a neural network. Remember the purpose in machine learning in predictive models is not to know the true underlying function the generative function that produced the data because that is unknown if that were known there would be no need to do inference model building now with that being absent what is the best that we can do we can build models that approximate that underlying reality to the best of our knowledge. So given an F which we don't know, we try to build a G that at least from the evidence of the data, we can say very closely mimics F. So that is that. That is called model build. The famous statement of Box, which says that all models are wrong, but some are useful. Namely, you'll never know whether your G was the F. But if it is producing equivalent result, it is good. It is useful. Now, again, as a recap, we said that if you take a reasonable activation function and a reasonable network topology, network architecture, then it will approximate whatever function that it is that you are trying to approximate. It will mimic it quite well. It will do a pretty good job of it. Let us see if that is true. So what we will do is take some crazy functions and see. We will go from some easy to hard ones and see what happens. Asif, can you share your screen? Oh, indeed. I'm not. OK. Yeah, I shared my screen during the break. All right. Is that better? Yes. We can see your Slack. Oh, goodness. That is not bitter. Well, this one, let's try a look. Attempt two. What about now? Yeah, we can see a Jupiter. So there is a directory where you call a universal approximator. There's a notebook. We will use a neural architecture not very different from what we built, almost identical to what we built. We are going to use that same neural architecture, simple neural net, and see whether we can approximate a bunch of functions. So let's take, this is it. So I've created a class called the universal approximator. We'll see it. It just uses internally, it's just a wrapper around the neural net that we create, simple neural net. But what we will do is we'll create some data. Let's go create some data. Sigmoid, like, so what, let's create one data set that looks like this you see that this is a highly non-linear data set for example a linear regression method wouldn't do it a polynomial also wouldn't do a good job polynomial regression it may be a reasonable approximation why would a a small degree polynomial let's say second degree or third degree point i will not do a good job can somebody answer that second degree or third degree polynomial not do a good job can somebody answer that oh it will overfit right no because it's a bit of mathematics see transcendental function sigmoid is a transcendental function by its very definition a transcendental cannot be represented by a polynomial of finite degree oh if you try to do it in terms of polynomials, you'll end up with a polynomial with infinitely many terms. That's a very definition of a transcendental function. So sine, cosine, sigmoid, tan, all of these are transcendental functions. So I deliberately took a hard function that linear polynomial regression methods would fail at or not do as good at. We take this and I generate some data. So here it is, this data. You give it this function. And what this universal approximator does is it first generates the data set and then says to the neural network, OK, go learn from it, go learn from this data set and see if you can, and can learn this data. So we do that. And this code here is very simple, approximator. And we are training it for only one epoch, and we are seeing how good it does. So when you do that, the number of steps are huge. We create lots of data points. You see that it starts with a certain loss, and the loss keeps decreasing. The correlation between Y and Y hat, between the ground truth and prediction is, oh goodness, this is five digits of nine. Very high degree of approximation. So we took this function and we asked the neural network to learn it. Obviously, I did not put noise into it because if you want to see that networks can approximate functions, let's try out with clean data. I did that. And it seems to be, you can see that this is not a perfect, can you see the subtle differences between the two? The neural approximation and the actual function? If you look carefully, there are little imperfections to this, and this is still going up, whereas this one, the actual function is more or less saturating. It is reaching its asymptote, whereas the function on the right is still rising up. The approximation is still rising up. Well, you can say that was too easy. Let's try something hard. Here is a function. I deliberately cooked up a function that is a polynomial and a sign. So now it's a mix of polynomial and transcendental. What about this weird function? How quickly can it learn? If you look at the loss, it learns it pretty, pretty quickly. So let's see what it is. This is the actual function and even with this very simple neural that we built three layered almost nothing in it what do you think of this approximation guys or for prediction purposes for practical purposes would that would you consider it a useful model it's pretty similar right it gets the job done, especially when you put a throw noise into the mix. It would do just fine because real life data comes with noise. You say, well, you know, this is still too simple. Let's go harder. So we will make this function. It's called this, it's the famous sync function or a version of the sync function sync function those of you who how many of you are from a digital signal processing background a communication theory background or are used to for syncs i know what it is yes syncs there quite often so this is a sync function and this is an approximation to a sync function it has imperfections. Look at the tip of that. On the extreme left, it doesn't seem to get it right. The shape is sort of approximate, but reasonably good. It gets it right. So your homework, guys, is to complicate it. Build a more robust neural network. See if you can approximate it more closely. You can say, well well that is still too easy what about this weird function now how many of you would say you can even think in your mind what this function looks like sine of sine of sine of sine right with some constants thrown in between multiplying factors thrown in between this This looks complicated, isn't it? Would you agree? So what does this function look like? It looks like this, right? And when you try to approximate this with the neural architecture, this is how far you get in how many epochs? You get there in one epochch so guess guys guess what will happen if you run it for five six epochs cycle through the data more i'll leave that as an exercise for you and here is the exercise guys make the approximation much much better than what i did with one epoch. How will you do it? Run it for more epochs and take the neural architecture and add more to it, right? Add more layers, add more nodes, do whatever it takes to make this neural approximation look much closer to the actual function. This is your homework, guys, and I've written it here. Try out different activation functions, different learning rates. Play with the structure of the neural network itself. And of course, play with the different number of epochs. I didn't mention it here. One of you can put it as a Slack note. Do that, guys, and do that. Now, I'll show you the code behind it. It's not complicated at all. Universal approximator by now, you should be finding it very easy. X, Y, Y hat. Okay, you can forget about the slots and so forth. This is the prediction. So this is just a high performance way. Those of you who are Python junkies would realize that this creates a more efficient way of storing data. So universal approximator. Once again, I've given all the typing and some comments, so you know what it is. What do I need in the universal approximator i need a function remember to it if you go back and look at it i need a generating function from which i would generate the data right for example this function and you take the function as an argument this is one of the lovely things you can do in python in a very natural way that makes you love Python from a mathematical perspective. You notice that, sorry, not here, universal approximator. I give it a function, literally a function, to the approximator as a constructor argument. And you can see that I'm giving it as a constructor argument and you can see that i'm giving it as a function you see function as a callable input is a float output is a float so one dimensional at this moment the range of the data so when you when you use this as a generative function to generate data what are the boundaries of the input the rest of it is straightforward if you know your numpy in this raw data space i generate hundred thousand data points it's hard work you can play around with it then i can find the min max and i scale it by the min max like why because the person may have specified a stop this is worth mentioning by the way neural networks they work well with data that has been normalized you can't give unnormalized data to neural nets they don't do well with it because activations will lead to saturation a very high input value will produce a big value of z a big value of z for a for a for example a sigmoid function will do what it will throw it into the asymptote the saturation regions because it throws it into the saturation regions it is useless right so you should always scale the data scaling the data or normalizing the data standardizing the data a key thing, a key step you shouldn't miss. And you see me doing it here. After that, it's just a normal NumPy mechanics and creating the test and train data, splitting the data into test and train. Remember to shuffle? Yeah, I shuffled it also, doing that. And then creating two data loaders. First two data sets, one for training, one for test. Do you see first two data sets one for training one for test do you see two data sets for training and test and then two data loaders one for training data loader one for test data loader training data loaders is what we use to train now comes the network do you notice that i've created exactly the same network actually i've added yeah 128, 128, 64, 64, 16, 1, right? So I invite you to make this network into a more complicated network. But observe something else. I have used a different syntax for creating this network. In the last one, do you notice that look at the constructor of this network? I just declared the layers like this. Do you see this, guys? I declared the layers like this. Do you see this guys? I declared the layers like this and then I needed a forward step to stitch them together. Do you see me stitching them together? Signal of one feeding into the other and so on and so forth. But there is an alternative syntax I suppose borrowed from the Kira style now research is like this direct because why you can put a break point in this you can see the intermediate step stages but a less transparent a little more opaque but a easier way of creating the network is like this in one sentence you can create the network and there is no forward you don't have to do the forward step at all it is implicit right the sequential class will do that forward step based on the way by just looking at the structure of this now here i am being particular i've given a name to each layer but people sometimes most often don't even do that they don't write it so carefully if you see examples of sequential on the internet on the tutorials they don't give it a name but it is good practice to give it a name because when you're debugging or when you're evaluating and stopping the training process and looking at intermediate states it helps to have human understandable names to the layers rather than just you know a very cryptic programmatic names now you notice that there is no when you write it like this you don't need to write a forward function in one sentence you're literally constructing the just like just this constructor is enough in one line you created a feed forward network. So this syntax is fairly common when you know you're not going to look into the intermediate, you're not a researcher, you're going to do some work. Now the training part is again a no brainer. So there is no drop off and drop outs. You can add that also, I didn't, I was just being lazy. You can do that, yeah yeah so why not do that play around with it right so take that as a homework after that the by now the two loops must be no brainers to you right the first outer loop goes over the epochs the inner loop goes over the mini batches of the data set isn't it of the training data set right so this is the mini batches the x and the y in the mini batch and i is basically the index of the mini patch which item it is so by now these four lines are famous for lines are still exactly the same guys. This is the initialization zero grad is okay, but our main four lines of programming are still the same learning are still the same. Right. Nothing changed. I just wrapped everything inside a model, and then I've created an evaluate function that compares and tells you gives you all the predictions evaluate model it will give you a list of predictions just some niceties to make it look nice pandas etc now it is worth knowing in a complex model what is the correlation between prediction and reality this is the correlation it computes the Pearson correlation. When you do the NP, numpy dot correlation coefficient, statistically is the Pearson correlation. Plotting by now is easy for you. You're quite familiar with how to do the plots. And this is some code that is written right here. Yeah, the Pearson correlation of that. That is it. If you're used to the neural net, there is absolutely nothing new by now. We are repeating itself. The only new information is that here is a simpler syntax to create neural nets. And even simpler would be that I didn't even name the layers. And you find those examples quite a bit on the internet. It's quick, it's dirty. In my view, it's dirty and sloppy. Even if I do this, I always tend to name the layers. So that is what was happening. And the only interesting thing here is that this universal predict approximator takes a function. So what you should do guys is try to fool this thing. See if this universal approximation theorem is really true. Think of some crazy functions. I should have given that also as a homework. Cook up your own crazy functions. Do side-by-side comparison. Imagine your own functions and plug it in and see what happens are we together guys right so that is your homework for today from the lab now typically what happens is that we are making progress in the lab section if you were here the last hour of the lab you would be actually doing it right here this is your classwork right but since you guys are all at home we'll call it a homework but you guys are all busy people i invite you to do it right now i will be here do it play around with it run this code of kate is here kyle is here dennis is here three tas are here teaching assistants are here, Kyle is here, Dennis is here, three TAs are here, teaching assistants are here. We are all here to support you, but do some things right now in the next one hour. But we are done with the lab part of it. So what did we learn today? We learned to create basic neural networks. We learned to do regression. We learned to do classic i mean oh i didn't do a classification example uh there is an example with c4 actually let me do it because you have a quiz with c4 so let me teach that also to you data sets this is an example of classification, we'll come to it. So what is the CIFAR dataset? Remember, we went to the website, we saw that if you have 10 classes and 60,000 data points, all these classes are some 10 different things. I believe they're just 10 animals. Researchers use this CIFAR-10, CIFAR-100 a lot to see the goodness of their bottle so i've created a c4 net simple c4 net i'll walk you guys through it what is it you won't understand it now actually i won't walk over it because it contains something called convolutional layers i haven't taught you convolutional layers but just think a different neural architecture, which isn't just densely connected nodes. It uses, it is inspired by studying a cat's brain, this convolution. But the rest of the theory, if you just ignore that it's a different architecture, it's the same. And you can see how well it predicts and mistakes it makes out of 16, it made two mistakes. It has accuracy of 87.5. Now the beautiful thing is that on that dataset, we created a class. If you go and look at the class, once again, you'll see no magic in that class. It is right here in datasets. Okay, let's... data sets. Okay, let's. So guys, I wrote it the way that you could inspect things that are happening. By now the init, stacking up the layers, I hope it looks pretty obvious. Even though you don't understand pooling and convolution, at least the linear layer makes sense isn't it and just think of these as some slightly weird kind of layers we haven't learned about and the forward is exactly the same you take the output of one and feed it as the input of the second layer get the output here feed it to the third this to the third and so forth right So this is an example of that. You could do different architectures. I mean, you can change the values and so on and so forth. It doesn't matter. And then the classifier part, because we are talking of image data, there's some image transformations that become relevant. So it turns out that there is a Python library called torch vision which makes these data sets built into the library itself when you run it it gets downloaded to your machines and trans create transforms or what when you take an image you want to make sure that all the images are the same size because machine learning when you give it training data all the images are the same size. Because machine learning, when you give it training data, all the training data must be vectors of the same length or the tensors of the same shape. It's important to do that. That is what it does. Just in case those images are not okay, it will do it. The other thing it does is it normalizes the data. It makes sure that the image mean and mean, et cetera. These are like making sure that all the bright areas or the colors, et cetera, you have standardized all of them. When we do computer vision and convolutional neural nets, this will become far more. I'll go over this very, very slowly and carefully, but at this moment, you can sort of ignore that. Just remember that we have created a classifier for images. Now, in a classifier though, there's only one thing worth noting. What should be when the output of the last layer comes in, a classifier does what? Does it produce a number or does it produce a probability? Probability. Probability, exactly. And so when you run it, you have to in the main loop somewhere, y hat, etc. The training loop, which is where is the training loop in our code. We must be careful to yeah training so here's the thing we take a classifier simple rate learning rate and what you have to do is put a soft max n to it it predicts which of the class probabilities it has and we'll come to that more carefully i have not done i'm just rushing through this because i'm going to do the classifiers much more carefully in due course of time right in the in the subsequent lectures so now this homework you can do with the cifar without knowing the underlying structure of a convolutional neural net. I've created a homework in such a way. You're playing with the epochs. What happens if you increase the number of epochs? What happens if you do minor tweaks to the neural network? You know, I've taken three layers. You can play around with those layers. So you can discuss with that. Now, obviously here, the nature of learning is a cyclic. Unfortunately, the lab is moving ahead of the theory when it comes to class image classification we will get to image neural networks after quite some time but you can still do the homework by ignoring the complexities there so this is is the CIFAR dataset. So remember, dataset comes from standard. CIFAR-S10 is a standard dataset. TorchVision gives it to you, and it gives you a way to do the transformations, and it gives you some utilities. But the neural architecture is what you create. You can play around with it. So that is it, guys. I want you to do this c for last but play around with the universal approximator the linear regression and so forth uh feed the universal approximator your very own strange function see what happens all right guys so let's stop the recording I see what happens. All right, guys, so let's stop the recording.