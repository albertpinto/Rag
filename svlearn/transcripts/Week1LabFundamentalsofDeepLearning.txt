 All right guys, so let's start today's session. I hope all of you are here and some may be joining in a bit. Well, first of all, guys, I have been sending you emails and I'll try to send emails. Though, first I'll announce things in this announcement section of the course portal I mentioned last time that it is important to keep track of the portal and updates to the portal I don't know if you folks are getting those updates on your cell phone and on your iPads and so forth I hope you are getting that the alternative is of course to log in here and see the updates I might occasionally forget to send emails but the updates here will be there as you can see there are three announcements first is the survey and weeks little quiz are over due when the YouTube videos became available I posted them so if you look at this you have the announcements the videos are there in the course website then we also have other announcements if you look around you'll see that the first session today evening that of course is is history now so there will be announcements on the portal every day other than that there's a social forum I haven't seen any activity there guys you'll get a lot more out of this workshop if you obviously engage with it a bit more the homework start from today so it would really help you to engage now here's a suggestion I this is collective learning so as you solve the problem and you do it a share your findings with each other see what things you tried and not tried discuss it on the social forum and an engaging social forum is very helpful trust me and learning the material people come up with very interesting findings as they go along the workshop and then part of the social learning you'll notice is that in every section I try to put a wiki here so for example for quizzes and interview questions you're most welcome to contribute your own questions you come across an idea a topic we didn't ask that question you can add those questions in the in the wiki here likewise for the hands-on lab you can contribute your own suggestions on how to make the lab better you want to add a few puzzles on the datasets that we are doing feel free to do that you can even put tips on how to run this you know some of you will get stuck and maybe I don't use Mac if you are using Mac I use a one two so I may not be able to help you but some of you if you find solutions for each other you can help each other by contributing you to the wiki so do that now today I have uploaded the week one lab and homework please start by downloading it onto your machine and unzipping it I believe on Windows Nisarg is mentioning that you have to unzip it twice one unzip leads to a tar file in a second and then finally unzips it on on Linux of course it is a simple tar XVF command that will in one shot unzip it so I try that guys first have this ready now the way I'm going to do this workshop is first I'll keep it simple. I'll keep two pieces separately. We will first make all of this work on your local machine. So that you have a local development environment and a sense of how to do development on your local machines. Once we have done that. After that, After that, we will then move on to the cloud. We'll do it in Colab and we'll do it in Jupyter Notebooks in the cloud. First, we'll do it in Jupyter Notebooks on your machine. So these are two separate things. And if time permits, we will not only set up Colab and Jupyter Notebooks in the cloud, we will also bring up this project into the Jupyter notebook and the code I will leave one of these as a group activity for you I will not tell how to do it because I hope that will that will cultivate or foster some amount of collaboration maybe I'll explain one or maybe if we don't get time I won't explain either and I'll expect that we all collectively figure it out of course I'll be there to support the findings so if you let us start with first downloading it let me know if anybody has not yet downloaded this zip file in unzipped it if you download and unzip it you should notice that you will end up with a directory called ml400 which is the ID I didn't identifier for this workshop I'll wait a minute for everyone to be able to download this file can I please get some confirmations anyone confirming that they have successfully downloaded and unzipped it i'll have done that wonderful so our next step would be uh and this is something that many of you have already done if you're coming through my previous workshops but we'll just sort of go through the motions again uh what you do is you go to the website unaccounted.org it might be a good opportunity to upgrade because python 3.8 is out 3.85 if you're still on an older version of to upgrade because Python 3.8 is out, 3.85. If you're still on an older version of Python, 3.6, 3.7, it is worth upgrading. Some functionalities have really improved gradually. And we will actually be using the features of the latest Python. So you'll see that we write rather idiomatic Python. So you'll see that we write rather idiomatic Python. Asif, do we need to uninstall our older Anaconda or? You see Anaconda is just a directory. I would say that just if you just copy it over elsewhere to something else and then download Anaconda, the latest Anaconda again and install it, run through the install process, you'll be fine so you have a directory called anaconda3 it's like if I remember right you work on Mac isn't it no windows you're on windows so you must be having a directory called anaconda3 in your circ just rename it to something else you can uninstall it if you wish then you'll have a clean install if you have a good internet connection by all means just go ahead and do that I think you'll follow through occasionally one or two places the code may fail I'll tell you where it will fail if you're no older version but you don't have to do it If you have anaconda fairly recently as in 2020 you installed it. You should be fine Will we lose our original packages which we install If we reinstall it See generally you can upgrade anaconda, but in my opinion Upgrades are usually not very clean in my opinion upgrades are usually not very clean right you can just do update of anaconda and that will take care of things all your package will stay my experience has always been that keep replacing it with new installations every once in a while because it's just a directory you rename the directory to a backup directory and reinstall it so guys here we go if you go to the anaconda.com website and our org website i would say dot org you will see a download link for the individual edition you click on the download link and it will ask you windows mac and linux which of the three operating systems you prefer as you notice it says that it is Python 3.8 it's a very easy installer for each of them it's a graphical installer for Linux obviously Linux the culture is not to use graphic installers too much it's just a simple script that you can run through so just run through that script and you'll be done is there a way I seem to check what Python version you have on yes it's very easy just say Python then space hyphen hyphen this is the command you would give let me see now I'm doing it from a teaching laptop which is Windows which I don't use for any other purpose but let's see if it has one. Do you notice that, oh goodness. This is an ancient version of it. But I'm connecting from this to my Linux machine which has. Let's see what the Linux machine has So, Asif, there is four and five and team addition and individual edition. Go with the individual edition. Okay. So I have a different page. I googled it and got. Okay. Okay. So usually going through anaconda.org and I suppose they're trying to also commercialize it if you talk start anaconda.com I got to do yeah it will take you to anaconda.com click on the download button it should take you here and all you need to do is install it guys I'm going a bit slow because I know in the audience there are a few people who do not know Python so for that I have a announcement this Saturday in the afternoon we will have a Python session it will happen right after the quiz the quiz will happen at noon Saturday noon and right after that quiz the quiz should take about half an hour to review and then from 1230 onwards there will be Python session for those of you who are interested on Saturday once again if you are interested please do mention it in the social forum at this moment I have received only one person who said he would be attending if you are interested in attending is there anybody else who would like to attend that ask if I could attend yes sure you're welcome anybody else yes me too okay alright guys so remember 1230 on Saturday and 12 o'clock is the quiz so come at noon every Saturday noon we have a session come to that and after that we'll do this after the way sorry go ahead and say do I change the name of the directory or do I change the whole directory's name usually i rename the old directory and install a clean one but nisarg if you have installed it recently then it's fine i think i believe you were there in the summer class i have 3.6 oh that's ancient you'll get to 3.8 so i'll send you guys a notification of an announcement of this but Saturday noon generally Saturday noon a week e4 help sessions we review the quiz we do the remediation session and after that if time permits as time permits those of you who need individual help with your labs you can get that individual help now once you install anaconda then what you do at that particular moment is you you go into the directory actually i might as well do the same thing as you guys are doing so guys how many of you are looking at a screen like this? Like you're able to bring up your Jupyter Notebook, you're able to navigate to the directory. Anybody at all? Asif, we've been posting the chat wall has been there. No, I didn't hear that. In the chat room, we've been posting you all. And does it look like most of you are? Yes, all of you are. So I can continue from here. So I'll give you a navigation of the way the projects will work. Every week I'll give you some starter code. The code would be for our walkthrough and then in every of the notebooks you'll find some homework waiting for you and you and those home books are very easy they're simple practice and extensions of whatever it is we cover today. Now today is sort of a basic lab we are getting started and things like that. Gradually, this workshop will pick up speed. So do brace for it. Keep up with it. If you don't keep up with it, you may start falling behind. So, but today we'll go a bit slow. So once you are here, in Python, you have something called a requirements file. If you click on this requirements file, it will tell you what are all the libraries that we will need now most of these libraries you can install using just there's a pip install command maybe I should mention it right here itself you have to give this command because if I'm still not there yet. How do we get I'm done downloading the Anaconda. Yeah. I'm your menu bring up Anaconda navigator. And then start Jupiter notebook. Now for those of you who are more familiar with this of course you can just give the jupiter notebook command at this moment do go through this route if you bring up an account navigator you'll be looking at a screen like this see if you can come to this um so this is this is inside the downloaded um anaconda did you install that anaconda that you downloaded no no not yet that's what i'm you have to install that so i have it's a dot sh so i just have to run this uh script that's right that's it i think you're working on a mac or you're working on uh ubuntu oh you are on ubuntu so then it will be very easy just run that sh file ubuntu oh you are on ubuntu so then it will be very easy just run that sh file by the way of all the operating systems um ai is just easiest on ubuntu it is next is the next easiest are other flavors of linux then comes Mac and usually Windows support is a little bit flaky guys and so you might be in for a lot of pain if you are running some things will work some things won't usually what doesn't work is the fact that your code doesn't use the graphic libraries the GPUs to get very good work from GPUs make sure that you have a machine that has a NVIDIA card and is running Ubuntu then you won't have any issues alright, can we make progress? Can I move forward from here? Rafiq, can I move ahead now? Yes, you can. So let's look at this. This is your requirements file, as I mentioned. Requirement file, its purpose is at some point, give a command like this, pip install. I'll just do even more big. You can take it it down pip install minus our requirements.txt it's from the command line open a command line and once python and conda has been installed and you give this command it will install everything in this file right these are the things we will need one way or the other for the first homework now one good news is while you're doing it locally usually and i'll show you how to create a jupyter notebook in google cloud there you can choose to create a compute instance, which is fully configured. You don't have to do anything at all. And that's the nice thing about it. But for doing it on your laptop, and it is good to start on your laptop, so you have some feel for it. You have to do everything manually. And we are going through the process of doing it manually. Premjeet, how far along are you? Pramjit, how far along are you? I'm good, Asif. I have an Anaconda environment on my Mac already. Already, excellent. So once we are here, now let me give you an understanding of the other things. When you, this particular thing, you can read it. A couple of things that I would suggest is, how do you author Markdown? Whenever you're authoring Markdown, people often say, I have to learn yet another language. Markdown has its own syntax and I have to pick up the syntax. Markdown is a very simple language. It has become a defective standard amongst programmers. It's like a five minutes learning curve. However, there is an excellent and open-source environment for it. It is this, and I'll just show what it looks like. Let me see if I have it in this machine here type over do you notice that on my machine now a window has popped up it's an application called I pour and then I can go and write anything I want for example I'll say and you can do all of those things that you like for example in the beginning if you don't know you can do it and now you can write this as you can see you can do that and you can create bullets and so on and so forth. And it gives you support for all of those things. You can introduce horizontal lines and many, many things in the beginning. If you don't remember the syntax for it can say item one, one, two, and then you can save it as a file and it will do that for you. It's a very good environment in my view for writing markdown besides just writing it in plain text. So that is what I was going to mention about it. It is TYPORA, T-Y-P-O-R-A. And in this project, you will notice that I have a file here called authoring markdown. These are all the very basics. One of the things, if you want to know how I use it, I use it like this. I use Typefora, the theme that I use is pixel. I turn on the focus mode. It helps you really concentrate on the part that you're writing, turn on the outline so you see the bigger picture. And there is also a very good markdown support in sublime text. Those of you who are using sublime text, it's also there in Atom editor and I'm sure it's there in just about every other editor. Eclipse has a support for it and so forth. I'm sure Visual Studio Code would have a support for it but I haven't checked so that's something worth looking at the next is the hardware considerations we covered last time I wouldn't go into that now now let me explain that the directory structure here guys this text directory contains a few sample text files these are sort of the famous classics like for, the United States Declaration of Independence, the Lincoln Gettysburg Address, then Shakespeare's Sonnets, Charles Dickens' Tale of Two Cities, India, When It Became Free, The Twist With Destiny's Speech. So if you can click on it, you will come across the text for that. We are going to use this text for today's lab at some point as we make progress with the NLP. We'll get introduced to a topic called natural language processing. Today when we do natural language processing we'll do very lightweight AI. It will just be getting introduced to the topic but it's a good day to start. the topic but but it's a good day to start other than that there is a directory for handling data but this is empty ignore it there are two important directories one is notebooks notebooks is for Jupiter notebooks and as we learn is our library in other words what I have done is I have taken some of the complexity out and put it in the library here. You can go and read this, not all of it, but read whatever you can. I'll tell you what is worth reading as part of the homework. And when you do that, let's say that you go into, let's go into what? A transfer. And if you just click on that, you will come across source code. I would say that when you come across source code like this, in the beginning, it may look very intimidating. Read it, glance at it, after a little while it will become familiar. I do not expect you to make much head and tail out of it yet. At this moment, focus only on the notebooks. But these are the codes that I have put there, this Python code, to make your life easier, to make it easy for you to navigate through this workshop. So we will focus on the notebooks first. are the notebooks now when we run our notebook one fact that will be there is that we need to include our SV learn in the path before we run it and so you'll see everywhere in the beginning I'll be putting the SV learn thing there now if you are running in a Jupyter environment or a collab environment where you don't you may not always have access to the shell then you can run the script what this script will do is just a one-liner the purpose of this script is to make sure that in your environment all the necessary libraries are installed all it does is it installs the requirements so when you run it what will happen is and I'll show you what happens. You go into a notebook. So guys, this is saying and navigating to a notebook opening a notebook many words for it. And a notebook is made up of two kinds of cells, you notice here to fundamental things. these are the fundamental units these units are called cells cells of a notebook a notebook is essentially one page it's a file that ends with the extension I PI notebook I P Y and B any file that ends with this extension is a Jupiter notebook now Jupiter notebook is comprised of many cells in this particular case we have three cells. One cell of text, the text is always in markdown language, which is why I emphasize learning markdown. Do you notice that this is a hash mark means it's a heading. After that, it's just plain text. It will respect your line breaks as paragraph breaks, new paragraphs and so forth. So this is text cell. This is code cell, and this is of course an empty cell, we can get rid of it. So two cells are there, code and this. Now when you have a code cell, Jupyter Notebook allows you to do some sort of magic. Whenever you see this exclamation mark, think of it as one of the magic commands it just exclamation makes you escape and give a command in the underlying machines shell. Sajeevan G. Or if you're sitting on a bundle. You can give this command directly from the command line. But if you want to give the same command from inside a Jupyter Notebook. what you do is you prefix it with an exclamation mark and then you run this command. Let us see what happens. So what happens when we run this? It becomes nice looking text here. And what happens when we run this cell? Look at this. This cell ran. cell ran and what it is saying that on this machine by the way this machine is not the laptop I'm connecting it to this machine called meta which is my Ubuntu server and there all of these things are installed which is of course true because I work on that machine things are installed there so I invite you to run this command in your notebook if If you have successfully opened it in Jupyter, please go and run this notebook. Now you can run this notebook in many ways, guys. And this is becoming familiar with Jupyter notebook. You will see that there's a kernel here. Kernel is the backend engine that runs your notebook. It's sort of like a client server model. Your Jupyter notebook is ultimately just a HTML client. It's a thin client, but it communicates in the backend with a server, Jupyter server. And each notebook is considered a kernel. At the backend, the thing that manages this notebook is the kernel. So you can do all sorts of things. You can restart clear outputs. For example, if I restart and clear output, let's see what happens. You saw that output disappear. You can say run all, right? You can just say restart and run all, and so on and so forth. So you can do all sorts of things, reconnect to the notebook if your connection gets disconnected this is particularly true if your kernel is elsewhere like for example in my case my machine is on windows i'm doing this thing on windows but the server is obviously on a unix machine a vented machine so you can do that so anyone if you could confirm that they successfully ran this fight I do wonderful it worked right out of I hope they were no surprise yeah excellent so now playing the boring install yes wonderful so guys now I'll start with something with the main thing see Jupyter notebook is sort of like an ID it's a development environment if you go and read my notes which I hope you did about the hardware in the installation I suggest that you install the Jupyter extensions also when you install the Jupyter extensions on your machine, a lot of facilities, a lot of features become available, which normally are not available, like the ability to generate table of contents. Do you see this here? You can generate, you can see the table of contents. So when your notebook becomes very long, it's very hard to keep scrolling up and down. You can just quickly go to the table of contents and see it. You also get a lot of extras when you install that snippets. So you have snippets, you have examples, but I have not fully installed it here on this machine. You can do highlight text, you can do all sorts of things. You can prettify your code, you can make sure that it looks nice. And there are many, many things you get along with sorts of things. You can prettify your code, you can make sure that it looks nice. And there are many, many things you get along with just getting this. You also get the ability to introduce LaTeX. So suppose I'm here, let's try this as an example to illustrate what I mean. Suppose you want to write a mathematical expression and let us say that you don't know how to do that. A lot of people don't know how to do that a lot of people don't know so you can say well how would I for example write an equation here we go you notice that it wrote the latex syntax for equation right equation let us say this is equation quadratic I'll give it a name quadratic equation and we can say y is equal to what is it 3 3x square plus 2x plus 1. Let's see what happens. Do you notice that you've got beautifully mathematically formatted equation here? So these are facilities you get through that. Likewise, you can have these widgets. You can embed some widgets into the code, into this thing. And there are many ways of doing widgets into this. I won't mention it, but I'll talk about widgets, whatever widgets. There's a separate notebook that illustrates that point. widgets into this I won't mention it but I'll talk about widgets whatever just there's a separate notebook that illustrates that point so this is becoming familiar with the a Jupiter notebook it's something that takes some time guys but nothing is hard and the way to do that is to start with the very basics and every once in a while you'll notice something useful somewhere you'll come across something that you'll start something useful. Somewhere, you'll come across something that you'll start finding useful. Like for example, for this, suppose you want to write some Python code. You'll notice that there are a lot of examples already here. So for example, how do you go and do a list comprehension, which is something very Python specific. people who come from c c plus plus java background they have no idea what a list comprehension is so it is this and we'll talk about it in the python class it just says that from minus 10 to 10 right for all the numbers so that would be uh 21 numbers you produce the square of them let's see what happens sure enough you see the square of those numbers right and this is again python specific syntax when you are learning python you may not remember a lot of these things but you can quickly look up the snippets and use it to do likewise you can use this markdown to insert you know Things like that insert local We do in search of much remote feature and so forth. So for example here right here suppose you want to do and again I'm just randomly moving around. Let's say that you want to Insert a remote image. All you have to do is is well this is a bad place after the equation let's say here we go then obviously this image doesn't quite exist but if you go and bring a real image let us go and get a real image for that. And there are many sites for free images. We will use images a lot in this workshop for deep learning. So get familiar with this and Flash is a great site to get image images. So let's say zebra. This looks like a perfectly good zebra let's copy the image address and once we have copied the image address let's Let's add it to, where were we? We don't need this, we don't need this, we don't need this, we don't need this. We were somewhere here, instantiating. Yes, we were here. So we can go here and we can put this URL. Once again, if you're familiar with HTML syntax and markdown, etc. So sometimes you may say, well, I don't need to be Spoon fed. I can do these things on my own. But when you are entering this field. A lot of people who come into this field. They come from a deep you know back end database background database housing or they come from a systems programming or for background, data warehousing, or they come from systems programming or for embedded systems and so on and so forth. So they may not be familiar with Markdown and HTML so much. So you notice that with one click of a snippet, we are able to bring a zebra into our story. So these are the snippets aspect of it. You can introduce latex, you can introduce even this as you write code, for example, you want to plot something and you forget how to do a plot. You can go to the basic plots. For example, you feel like making a 3D plot and you have forgotten the syntax for it. Let's go and do that. Here we go. Now, if you look at this data, it's a very simple data. It just takes X and Y values and it creates a by now if you look at this you would realize that it is creating something like well you'll see what it creates it's very simple and it is creating sine X square plus a Y square it looks up particular shape with ups and downs sorry this and you can run this. Yeah. Oops, NP. I forgot to import NP. Import. Let's try that now. But it needs matplotlib. As you can see, not all this, I'm sorry. I'm sorry. Hopefully this should solve a life. There we go. So do you notice that guys you got it but the thing is that by having the snippet you can quickly see or get an example and then you can iterate over it maybe your data range is different your function is different but here is a way to quickly see it use this snippets today I've given you a homework which will require you to use that actually is it today or next time it will require you to do 3D data visualization. So that is about notebooks. Now in notebooks. There is one feature that is quite useful if you want to make the notebooks interactive in which you take values from the user, you can actually do that. Alright guys, so here we go what can this do this helps you you can install this and it will in my case of course everything is pre-installed but i wanted to show you what it does you import it and suppose you want to have a function f function x and you want to create a slider do you notice that you have a slider now you can use the slider to capture the value x what the user enters likewise in your notebook you can have boolean you know true false you can You can have a text, the user can enter a text. You can play, and these are just examples. You can play from here. Do you notice this? It's a play button. You can play from certain value. And this is very good when you want to run a few epochs, or you can start with certain values during your deep learning sessions. These things I'm introducing you to obviously you may wonder why, but become familiar with it, you'll need it in due course of time. Likewise, you have a date picker, you can pick dates. These are standard UI components, people who know UI in every language, they look forward to these components in HTML, in JavaScript slash, you know, jQuery slash, I don't know, Angular, etc. Then in Qt and whatnot. This is something actually you might like, and most of you, especially those of you who have been doing ML 100, 200, you know that we paid some attention to formatting our data frames data tables this is something different it gives you interactivity in your data frame so let me show you why and it is something that I like very much actually this is called the cube grid surprisingly most people are not aware of it so once you do this let's see what happens here is some data some random data this is the iris data set what am i doing can one of you tell and obviously those of you guys who are new to python at this moment i apologize but i'll explain what it does this line loads a data set called iris iris is sort of like the kind of like the Hello World of data science. One biologist, one fine day, walked into a meadow where irises, iris flowers are growing. And he picked up, I believe, three species of iris, and he picked 50 samples of each. And he brought those 50 samples, so a total 150 samples of irises, iris flowers, and he measured carefully the length, the width, the petal length, petal width, sepal length and sepal width of each of those iris flowers and tabulated them by the species they belong to. So that dataset is the iris dataset. It has five columns, petal length, petal width, sepal length, sepal width, and then of course the species of the iris. And those of you who are familiar with iris would know, iris is one of the most beautiful flowers and it comes in a tremendous variety of shapes and sizes. Different species of iris look quite different from each other. They all look beautiful but they all can look quite different from each other. So this dataset is interesting because in machine learning we try to build models to see if the machine can learn how to distinguish between one species and another. Quite often you'll see very scholarly research papers and they would explain the algorithm and they'll show how well it works on the iris data set so this is the iris data set we load it into something called a data frame a data frame is nothing but like a spreadsheet representation of your data and then you take the data and then you you you give us basic statistical summary of it describe will give you descriptive statistics if you remember the descriptive statistics from your school days, it's your mean, median, standard deviation, and the quantiles min, max, and 25th, 50th quantile and so forth. These are the headings. And here is a table. If you look at the dataset itself, just do data frame, this again is very familiar. It has, again, again as i said 150 rows and three species target value has value 0 1 2 but now see what happens if i try to run it through this oh why did my grid not show up it should have have showed up. Okay, something is off. Fix this code. It should have showed up. Maybe because of the remote or something. But what what will show up here is a beautiful the same data frame here, but with the ability to play around with filter it and do things the way you see in rich html or jquery or angela based components and i suspect it is backed by something like that it comes out very interactive so these are the interactive elements of that you can embed in your jupiter notebooks i'm emphasizing jupiter notebooks quite a bit and by the way these are taken from a particular article here you can go here maybe we can see it working there, one second. You can do widgets, the date picker, color picker tabs. Yes, do you notice that you can do pretty fancy stuff, interactive stuff with your Pandas data frame the moment you wrap it up with this widget? Are you guys able to see this visualization here? I'm not getting any Yeah. Asif, what is this article put that length in there oh yes it is very much there in your code it's right here at the very top read this article in the notebook itself so whenever I take usually you'll see that the notebooks come with a lot of references to articles to read so do read that and you'll have fun with that so that is about widgets now gets let's get a more real we will use a framework in deep neural networks called by torch they are at this moment many competing frameworks this Tiano cafe tensorflow and then there is a pi torch of all of these at this moment the mind share is taken by tensorflow and pi torch the way it started out first there was tensorflow one it was very low level it was you had to describe a whole graph and how the execution graph would be found onto the pushed onto the gpu the graphic unit the graphic and compute engine and a lot of people found it very hard to deal with and debug it didn't look like normal code it looked like very clumsy so people in the open source world they created a project called keras keras really put a layer of simplicity and rationality on top of TensorFlow and became a runaway success. Everybody wanted to use Keras. And Keras was also a layer, I believe, on Kaffe and other things, but primarily on TensorFlow. Then Google ended up taking their main Keras developers and making Keras the front end to their TensorFlow. So the TensorFlow 2.0 has Keras as its front end. Also, because TensorFlow 1.0 was getting problematic, then Facebook came out with PyTorch. The PyTorch is a very, very intuitive data science or a deep learning library. People who are familiar with NumPy, NumPy library to be erased and matrices, they just, there is no learning curve at all. If you have worked with NumPy and scikit-learn, and those of you who have been with me doing ML 100, 200, you all have. You realize all of a sudden that you actually, there is very little new to learn. You already hit the ground running. There is something to learn, but from day one, you can become productive. So that is PyTorch. PyTorch has been gaining a lot of momentum. At this moment, the way it stands is that the community used to be predominantly tensorflow but now more and more it became pytorch pytorch has essentially taken over at this moment it is at 50 50 but the momentum is with pytorch in the research community partly because when you write code in pytorch you'll realize that it's very intuitive with the tensorflow the the world is like this if you can write that code in keras, it will be even simpler than PyTorch. It's very easy. But the moment you want to do anything beyond just the copy-paste or, you know, the basic cookie-cutter stuff, then Keras doesn't take you very far. You have to go down to the underlying TensorFlow libraries, layers, and those layers are frankly a pain in the neck. So I used to be obviously predominantly TensorFlow, but in recent years, like everyone else who likes to write their own neural architectures or play with things, I have moved to PyTorch. As we go through this workshop, actually the previous incarnation of this workshop or the precursor to this workshop was in TensorFlow. This one will be in PyTorch. So I would like to introduce you to PyTorch as a library. And I hope you'll agree with me that if you know the standard numerical library, NumPy, it'll be very easy. Now, those of you who don't don't despair remember we have the starter sessions on saturday you'll become experts at it in two weeks like two sessions two saturdays and you'll be very smooth with it it is easier than it looks but going forward let me show you what i mean by that now most of you are familiar this except for except for the import torch. I hope this import is almost like a necessary song you all sing in the beginning of each of your notebooks. By Jupyter notebooks, isn't it? These lines that I've highlighted, I trust you guys are all very, very familiar with. Would anybody like to agree with that? Yeah, I matplotlib. So what does it do? This is the numerical library in numpy. Matplotlib is the plotting library and really well done. I would say one of the things that you realize in data science, the data visualization libraries are just absolutely wonderful. Absolutely wonderful wonderful you can do a lot of visualizations with just a couple of lines of code and it isn't that the libraries are there you have a problem choosing between many excellent libraries many many excellent libraries it's it's sort of there is not enough time to learn all these wonderful visualization libraries. People have really gone out and put a lot of effort. In the world of R, of course, you know, ggplot is very, very respectable. It's based on the grammar of graphics. ggplot and d3js in the world of JavaScript are both influenced by a philosophy called the grammar of graphics, very influential philosophy that philosophy has also influenced python world in the vega and the vega light framework based on which we'll use altair but the old visualization framework in python is matplotlib it is the simplest is the one most often used, till people become more conversant with powerful libraries. So take this as a baseline, just as in R language, if you just give the plot command, it comes built into R. The plots don't look very pretty, they don't look amazing, but they get the job done. In the same way, Matplotlib comes under that category. Now, Matplotlib has been putting in a lot of effort these days to be compatible with the richer libraries. So, one of the things that people haven't yet realized that actually you can write Matplotlib code, but you can tie in one of these richer libraries like Bokeh and so forth, or C-Bond, and your thing, your same code will get rendered more powerfully using this more powerful visualization backends. It's just a fact I'm dropping now. We will see illustrations of it as we make progress in this course. So let's try to understand this course what it is. This is a magic. So you see this person takes something. This is a magic command. It basically says that when I plot something, I shouldn't have to say a plot.show. Assume that any plot, any plotting, the moment a plot comes into existence, you render it in line, in the page itself, right? And not in a window, not somewhere else. Literally in the Jupyter notebook itself you render it so that explains these three lines the one new line that we encounter is the very first line import torch that imports the pie torch library one quick question some of the import torch is just giving an error for me maybe today I missed something in running today some of the requirements for text also didn't run through fully for me that is the reason that's a reason Ram ki why you're getting that so what we will do that needs to succeed right because that will install libraries and so i come to the saturday session uh we'll sit on one-on-one and fix your environment okay perfect thank you yes excellent all right guys so i'll just give a few illustrations uh here is a standard NumPy code. If you look at this code, I hope you all will agree, that looks very easy. You create a linear space of numbers from minus 2 pi to pi, and you create how many of those numbers? You create 100 of those numbers. This is the beginning, this is the end, and how many numbers you want. So it will create an array of 100 numbers going from minus 2 pi to pi Then I'm writing Y as a function of X. I Deliberately wanted to take some complex function This function is a sine wave in X But with an exponential decay built in you notice put an exponential decay. Yeah decay built in you notice i put an exponential decay here right so if i have to write so let us write the mathematical formula for that it is begin sorry equation and end equation so now can somebody tell me how i would write this, I would just copy this and remove the NP here. This is Let's try that now. And all you're doing is you notice that people make mathematics are used to in this funny syntax. And let's see. Oh, no, I made a mistake. This is it. Or if you want to make it look more traditional, you can say like this. there we go do you see this equation guys what I have done is I've taken a simple sine wave and I put in a decay so that it decays down why did I do it no but no particular rhyme or reason I can change this equation you can make it whatever I just wanted to take some equation of X so I took this now let's run this if I plot this right oh NP is not defined let's run this so this equation comes and now let us get introduced to pi torch we will compare this I will just decrease the fonts a little bit look at this guys this equation this is the the standard code for writing it in numpy that you're familiar with and see how we write it in PyTorch can you tell what the difference is all we did is we replace the numpy NP with torch. Can you see that guys? And amongst the more marvelous things is the fact that matplotlib works just fine with torch objects. So torch objects are called tensors. Tensors is a mathematical term. They are a generalization of matrix to higher dimensions. We'll talk about tensors, the concept of tensors we'll cover next time. But just think of like an array is one-dimensional, a matrix is two-dimensional. Now how would you generalize matrix to three dimensions? Add a z-axis to it for numbers. When you were to do that it becomes a tensor. And tensors are of arbitrarily high dimensions. They can be a point, a number is a tensor, and all the way to any number of dimensions you can have. So it's a generalization, right? Now in NumPy also, you could do that sort of thing. So one question that comes is, when NumPy exists, why would you create a library that pretty much mimics its API? Would somebody like to take a stab? Why in the world would you create a library like this? Extra features. And what are those extra features? What are the big things that NumPy doesn't have? And some GPU GPU acceleration GPU acceleration is an important feature but then you know we could have put in effort to retrofit numpy with GPU acceleration by the way the effort is happening there is an effort to make that happen It doesn't support tensor. It can be retrofit somehow to do that. See that you could extend it, right? Why create one more open source library? Actually the reason is very interesting. It has to do with the fact that we want to express or we want one thing in deep neural networks or two things, just two things we need to do deep neural networks. It's a relief actually when you think about it that all these complicated textbooks and research papers, they can all be boiled down to two essential operations. One is matrix addition and multiplication, which is very easy. You know how to multiply an array with another array, right? In one way or the other, we can all do that. So matrix multiplication. And the other is differentiation of matrices, differentiation of functions. So what happens is when you describe a Y in terms of X, is when you describe Y in terms of X, it would be nice if automatically the framework not only understood the moment you told Y as a function of X, it also explained to you immediately and said, all right, now I know what dy dx also is. Wouldn't that be wonderful? So you don't have to explicitly compute it. So that is called autograd. The generalization of differentiation is gradient. So you people call these libraries having the ability of automatic gradient or put it differently or or simply automatic differentiation that is a huge plus with torch by torch and when i use the word torch it should mean pi torch the other aspect of course is the torch is optimized to run on gpus it will run on cpu if you don't have a good gpu it will run just fine on your cpu it will just take probably 10 times as long right or maybe 100 times as long sometimes but it does run so when you do the same computation with numpy what happens is the computation doesn't benefit from the cp from the gpus because numpy only runs in the c. The CPUs are general purpose engines. They're not really optimized for large matrix multiplications. By larger, I really mean large. I believe in the session before on Tuesday, I mentioned that some of the latest transformers and these neural network models and CNNs like Inception, we are talking about parameter space that is in hundreds of millions or even a billion. Ridiculously large matrices we are multiplying. So to be able to multiply those giant matrices, you need dedicated video cards with humongous amounts of memory. So some of you, I don't know if you have kept track with it, Nvidia has just announced the RTX 3090. I'm for example, waiting for it to hit the market. The 3090 has, I believe 24 GB of video sitting next to the GPU, the graphic processing unit, very close to the GPU so that it has a direct part to the GPU. It doesn't have to go to the computer's memory. By the time you go to the computer's memory it's already too late and too slow. So that's the benefit of using TensorFlow. Either TensorFlow or PyTorch. These are libraries that are created with GPU in mind. PyTorch's ability to do automatic differentiation or automatic gradients is huge. Much of neural networks that we are going to learn they have two steps the forward step is just matrix multiplication and so called backward step which is a propagation or a differentiation a wave of derivatives or gradients propagating back back towards the inputs input zone right from input to output if you think of it as a long pipeline in the forward direction of the pipeline you have multiplications going forward in the backward directions you have the gradients flowing back and we will see that so anyway suffice is to say that that there's a good reason to have a separate library that looks very close to NumPy why is it deliberately made to look like NumPy because everybody in this world is more or less familiar with NumPy by the way even if you come with our background you would say well bad luck for me i don't i come from r i don't know numpy but actually you do because below both r multi r's library and numpy is underlying it is almost always the same uh fortran library fortran and c libraries those libraries are blast basic linear algebra system and so forth. So those libraries have not changed and nobody is foolish enough to write everything from scratch. They just put layers on top of it number is a layer on top of it. Sajeevan G. And so if you are familiar with our it becomes a no brainer to quickly become familiar with numpy. And therefore familiar with Torch. It's just that the syntactic difference, the language differences. Once you get used to the language difference, it becomes easy. Alright guys, we're coming up on a break in five minutes. So I would like to finish this part. Likewise, a bell curve. You may say, well, you know what, that was perhaps too easy an example. It isn't easy. I wouldn't exactly call this function easy, but let's try something else. What about you take a bell curve? Bell curves are everywhere in machine learning. Here is the code for a bell curve. There's a denominator. Maybe I should write the equation for the bell curve also. Might as well. Those of you who may I should have done that perhaps Can anybody would anybody like to remind me the equation of a bell curve. Equation I Eat the power of x squared. This over this this over one. Yeah, OK, too. I. 2 pi. 2 pi and SQR and sqrt squared. And then this would be, of course, the exponentiation of it, e to the power. Let me just use exp, exponentiation of what? Minus, well, obviously I'm giving the simplest version of a bell curve here, minus frac inside it, x power 2 over 2. Let's try a lock and see what happens. 2 over 2. Let's try a lock and see what happens. Oh, this would quite, it is correct, but it looks sort of ugly. So I will make it 1. Let's look at this. All right, guys. Here I've taken sigma is equal to zero. The mean is zero. I mean, the standard deviation is one. And what is the mean here? Mu? Zero. Centered at zero. And one standard deviation, white. A standardized bell curve. So, oh, in this equation, I forgot to take the square root. But all right. NP, you can in this equation, I forgot to take the square root, but all right. NP, you can say NP SQRD for them. Standard deviation one, mean zero now. Mean zero and standard deviation one. Yeah, that is right. So guys, in this, actually I've forgotten to take the square root. I'll leave it there because we're coming up on the break and I'll leave this as an exercise for you to fix in the break so this is the numpy code and what is the PyTorch code do you notice the PyTorch code does it look exactly the same days yeah that is Yeah. That is it. So these things work very similarly, right? But then not always, it's not always true. So for example, the function syncX, it's a famous function that you use in signal processing, sign X over X. So if you write the NumPy version of it, you will realize that there is no equivalent of it in tensorflow, but then there's no harm. All you have to do is take a tensor, convert it back to numpy. So how do you convert a tensor back to numpy? You just call the dot numpy method to it. And it will make it into a numpy and then you compute the value and then you convert it back to a tensor. So if you look at this line and try to sort of unpack it, what we did, we created a XX tensor in this inner part. Let's look at the inner part of it. This one, we have converted it to numpy. Then what did we do? We use the NumPy library to find the sync of it, sine X over X of it, and then we have a NumPy. And then all we need to do is convert that NumPy array back to a tensor. And then we call the tensor method on it, function on it, constructor, and it will create a tensor back. So we have a XX tensor and YY tensor. Once again, you can feed it directly into your matplotlib and it will do that. So here we go. This brings us to our first lab. This is your turn. Just imagine, create a function of your own that you like and plot it out and write the numpy and pyTorch code for it. Pick your favorite function. You can take it in one variable, two variable, whatever you like, right? And create this, anyways. This is your first lab to do that. And so with that, I'll take a 15 minute break. We let's regroup, it's 8.30 in my clock. Let us regroup at 8.45. In the meanwhile, sort of review it and see guys, if you can run this code, can you create any function of your own? Or try to take something complex and see if you can write the numpy and the PyTorch equivalent of it. So you will realize that learning PyTorch is a no brainer. It's very easy. If you know the rest of basic numpy, you know it. And numpy itself is just a set of very simple functions, np. all your mathematics, high school algebra functions, trigonometry and algebra functions on numbers as simple as that any questions guys before I open one minute for questions before we take a break anybody would like to ask a question alright, in that case I will stop the recording and I'll stop the live stream. Okay. Good. Are you guys seeing my screen? Yes. Okay, wonderful. So let's get back to where we were we were reviewing the white torch and the statement that I was making is it is something new for all of us but if we put in a bit of effort it is not as scary compared to other as other frameworks go by torch comes as a pleasant surprise. You can pick it up very, very quickly. So with that, I just make sure that I don't hear my phone echoes. So that's that. Now let's go and do something useful with it. I'll just do or cover two more topics today. On Monday, I talked about using some trained models. You know, I spoke that some of these models are ginormous, and it takes a lot of effort to train them. You need enormous computing resources. You need a lot of time. And finally, these models get trained, the GPT-2s, GPT-3s, the BERTs and the Excel Nets. These are not something you train on your own machine usually. So what you instead do is you take this, people have shared the trained models, the big guys, they have shared it into the open community. And you take this people have shared the trained models the big guys they have shared it into the open community and you take those models and you either use them directly or you just tweak them you do a final layer training so what you do is it's been trained for one problem your problem is different so you chop off the head you take the headless version of it attack your own head you're specific to your problem and then you train just the last few layers last layer on the last couple of layers and that training you can do on reasonable hardware and use it so that is called fine-tuning people often use the word fine-tuning bird or something like that you often hear the phrase that is what is meant so today what we will do is take not but we will take the image processing models the computer vision models and i will show you how we can use it to recognize animals. So towards that, let's go into you go into this directory pre-trained, you will see this notebook ImageNet pre-trained. So let me explain what that means. There is a ImageNet standard library. It's a library of a vast amount of pictures of things, animals, not Stanford maintains something called a word net vocabulary of things and nouns and things basically dogs and whatnot and there are images gathered here for each of or most of those things a vast number of those things or words their images so the problem is given a picture you have to tell what is it is it a dog is it a cat is it a duck is it a house right what is it and it has to be one of the finitely many things so when you take an image and you recognize it as one of the many things the target variable in the way that we look at it in machine learning is a is it a real valued or is it categorical anybody category category so image net is a collection of images and if our task is to find out what is each image of is it of a cat or dog it's a classification problem because the target variable is a set of classes set of identifications or types it's a classification problem and so we take this notebook is called pre-trained i call it just to emphasize that we will not do the training path and those of you who have been doing workshops with me you'll be surprised you'll say how can you have a model that is making an inference which you haven't trained don't we first take the data visualize it clean it and then um the data visualize it clean it and then I train the model and after training the model we look at model performance and then we go and use the model to make predictions and the beautiful thing is that somebody has already done that hard work for us somebody has cleaned the data somebody has pre-processed has trained this model has verified the accuracy of these models and these are I will give you a little bit of a history of these models these are the models that have world they have broken world records successive successively so these are the models that have made history in this field and what are we doing we are just literally taking the model and directly using it for inference even on a purely integral computer, for example. It will work just fine on your laptop. So to make your life easier, I have wrapped it up because at this moment, not all of you are very familiar with Python and so forth. So I've taken away the complexities of it. And it is in this class, ImageNet Recognizer. You can go and read the class. So I'll give away the complexities of it and it is in this class ImageNet Recognizer. You can go and read the class. So I'll give you an idea where that class is, ImageNet Recognizer. If you go, remember all of these classes are in SV library. So then if we go and to where we go, transfer. ImageNet, do you see this image net class library a pack sort of module in this do you see the image net recognizer class in Python and in Java and C++ there is a concept called object oriented programming which means that you should bundle up your code in proper, well-defined classes. I won't go into that, we'll cover it over the weekend, but this is your ImageNet Recognizer class, and the code is straightforward, but at this moment it won't make sense because we haven't covered this theory, which we'll do in successive weeks but our goal today is just to get started so we will get started here we import all of these libraries once we what are the libraries we import the pandas the numpy matplotlib all of this usual stuff the torch and now PyTorch comes with a special library for computer vision. It is called torch vision and in torch vision are these pre-built models, pre-trained models, you can just directly import it. So when you run this notebook, couple of warnings, run it on a machine where you have a lot of space because when you run this thing the first time around okay so I have to give it import says I should just say it in process also so guys make this correction in this I forgot to put this first sentence in forces when you do that in my case it ran in what less a second? The reason is all those big models have been downloaded. When you run it on your machine, it won't be that quick. It will take quite some time to run. There are words like ResNet, ResNet, small ResNet, big ResNet, VGG 11 and 19. These are different generations of the VGG,ormous model for image classification and image tasks. It took a very, very long time to get trained on a huge amount of hardware and finally got trained. So they have shared this model. We can use it directly. ResNet is the one that is interesting and we'll talk about it. I believe the history and I might give the dates a little bit wrong Alex net surprised the world by breaking the image classification record in 2014 that is when people realize many people say that deep learning while it was a subject that people were working on for a long time, it has a long history going back into the 80s. But the business world, the industrial world took it seriously, sort of when the AlexNet came about onto the scene. In 2014, it broke the benchmark record in the most impressive manner. After that, successive architectures have come. Each of these are neural network architectures. After that came ResNet and BGG. Both of them actually from Microsoft. I believe it must be different teams, I believe, or one year after the other. I forget the exact history. These were, again, big ideas. ResNet introduced the concept of short circuits. different teams i believe or one year after the other i forget the exact history these were again big ideas resnet introduced the concept of short circuits or residual connections a big idea in the world of deep neural networks it has a lot of implication it made possible creating really deep networks really deep networks became possible because of residual connections and the ResNet architecture brought it about right away broke records. ResNet 18 and then ResNet 152 is of course as you can imagine 152 layers deep, really deep neural net. VGG again winning architecture and then its latest version I believe is VGG 19 it's built in so that's the history of it and dense net is standard dense net I believe it has some residuals and so forth so these are the architectures guys these are the sort of architectures each one of which takes an army of AI researchers vast quantities of server resources, hardware resources and a huge amount of time to train and build. So it is really good that these are now available free of cost for you and I to use and we are going to use that. So how much does it take you can see it just takes a few lines of code to do that so what we will do is because these these architectures are trained we will use it easily first let's look at the lines of code here do what am i doing I'm just instantiating this class that I have created to take away some of the complexity and please do go read that class if you are familiar with Python or have some background in machine learning those of you who took ML 100 200 should go and read that code once you become familiar with PyTorch it will look a lot easier so you instantiate this object and then you ask it to tell how many models has it built in. And you realize that it has all these famous architectures built in. Then, and I've not used all of them, some of them. So then I picked a few of these. And then I say, these are pre-treated models. Let us say how well these models do if I show them some image. So now the question is, let's go get an image. So here, here's the URL of two images. One of them is a duck and the other one is, I believe, or no, it's a duck. I shouldn't say tree. I apologize. Duck. I should say duck please correct it in your notebooks. should say duck please correct it in your notebooks so as you can see it will render a duck but if I change it to here URL I make it to dog for him I can choose which of the two I want to do then you'll see a picture of let's see hopefully a dog somewhere coming up yeah ah really cute looking dog a golden retriever i suppose many of you know that i own a golden retriever looks very much like this yes so uh you take this image and let's start with the golden retriever and now let's go to the model and here's the thing guys we are not training this model is pre trained nothing has to be done just just directly go ahead and use it and it's amazing see this model has not been trained on this picture or on the picture of the time it has been trained on different pictures but let's see how well it generalizes and works of this we will try each of these models and see what happens. Now for each model, we'll ask it to make five guesses. The best guess, second best guess, and so forth. Let's see what it comes out with. Oh, I think I have not read some part of the code. I have to go and run it from the beginning. Let me run all of this. yeah I have to go and run it from the beginning yes how do you import SP learn the oh so the way to do that is just literally in the very first line do you notice that you explicitly give the path to it see so we have to get we have to give our path yeah your you'll have to modify it that's it thank you for bringing that up so just go modify to whatever your place it's where you install this you unzip it right give the path all the way to the deep learning workshop directory because as sv learn is sitting in this directory all right so do we uh we don't we include everything after c drive right whichever drive we have yeah that's right start with that so in windows it will be c colon blah blah blah blah and then finally slash deep learning workshop also we include the c colon as well yes yes i windows i would imagine you have to see so here we go so this is it the duck uh the dog i believe and then let us run this uh model ah look at this it is look at this guys the first model which is actually I believe the rest net or the Alex net which one is the first let's go and see first is rest net 18 a very small model and that very small model is already able to tell that it's a golden retriever with 98.9% probability and then it says that there is a small probability that it might be either a Afghan hound or a cocker spaniel let us go and see what a cocker spaniel looks like see if it is making sense at all or not so I'm going to go and google a cocker spaniel and this is how a copper spaniel looks like. Would you guys think that it looks somewhat like a golden retriever? Look at this. There's some similarity to it. So you imagine that it sort of makes sense that it did that. What about the Afghan hound? What in the world is an Afghan hound? Let's go find that out. Well, that is a third guess. It is pretty hairy, I suppose which is why the the AI is thinking that it might be an Afghan how do you see guys how it is reasoning you can see it thing if you look at this picture of an Afghan how you would see some similarity to a golden retriever isn't it and so this seems to be working and the fourth and fifth I would and then here's a surprising thing it says it might even be a tennis ball can you guess why it is guessing it might be a tennis ball fuzzy yeah because dogs often play with tennis balls and many pictures of dogs are have a tennis ball somewhere in there either in their mouth or next to them but this is the simplest model now look at this the next best model the bigger version of ResNet gets tennis ball is a second probability but it says ninety nine point four person let's go and look at the state of the other the best model look at this inception is saying that for 99.997% probability it is a golden retriever I suppose at this moment and the next probability comes coca spaniel is at 0.0009% I hope you guys would consider this that if you have to approximate it to our three decimal places you would say that golden retriever is pretty much a certainty and others are practically zero you see that guys now let's try a look with the duck and see how well it does the duck it's a mallard I didn't know exactly the duck it's a mallard I didn't know exactly the biological difference between a duck or a mallard but I'll call it a duck let's try and look with this and by the way do you guys see how instantly it did the recognition in the blink of an eye I'll do it again see how fast it works and I'll just shorten the screen a little bit so that you can see track I'm going to go here and I'm going to first clear the output there is no output here and I'm going to run it ready there we go you notice instantly there is a scheme all the five models make their prediction and then what you see is that they are all saying that it's a Drake oh goodness that is what it is when I was looking on the internet I look for that but I got the picture of a Drake and this is it ninety nine point nine nine nine six eight percent probability what is the second best probabilities here plunger I don't know why it came up with that lake shore with the probability so is it a lake shore guys does it look like the lake shore it's sitting on yeah yeah if you take the duck away what you are seeing is a lake shore so this is how the deep learning works and isn't it amazing that today we take this level of extreme accuracy for granted. This is what this deep learning subject is about that's why it's changing the world. Now we are in the world in which you could be driving around in a car and it is looking through looking at the scene in front of it while you're going 60 miles an hour and it is doing recognition and segmentation of images it's dividing the scene into objects and recognizing each of the object at full speed that is a state of the art so when we dream of self-driven cars that's what we are asking for we are asking that the machine should be able to do that and it is able to do that so here we go I've just taken all the guesses of the different models just for you to compare like for example Drake you can see that Increase the font size, right? Hang on. A little bit smaller, maybe? Yeah. Let's look at this. Maybe a little bit smaller, yeah. Is this visible, guys, now? Yes. this visible guys now yes yeah yeah so i hope you all agree that these are extremely like very very impressive identifications so the homework for you here guys is i forgot to write the homework is to go and pick your own images from the internet insert the url and discuss so may i request you guys to do one thing each one of you pick one image from the internet, feed it into this code, run it, and in the social forum, discuss, post your image, say this was the image and these are the results I got. Could you please do that, all of you? it will be interesting you know instructive for all of us to see if we get 30 different objects we can see where the ai is strong and where where it is weak so there are areas that it is weak at and i invite you to go find those areas and see where it is strong yet so that's that that is for pre-trained. Now we talked about transfer learning, you know, using other people's work. And I hope this was an impressive example of that. So Asif, one thing I'm not able to understand is how is it, what is it trained on? Is it trained on Google, all Google images? ImageNet, the entire ImageNet library. So what is ImageNet library? Hang on, let's go there. So what happens is for research purposes, researchers have created with great effort data sets. You know, in the world of machine learning, the hardest part is gathering data. It is the algorithm is one part of it, it's the exciting part of it, exciting part of it but the dull part the boring part is preparing data so look at this this image net is an image of 14 million images 14 million images have been created and you can explore this image net structure as a cloud map download it and so forth now you need permission I do have permission for that but you can get it challenge so every year do you notice that there is a challenge to do this in 2017 after 2017 do you notice that there are no more image net challenges which algorithm will do better there is a reason for it I don't think they have done it because the algorithms have become so good that they are achieving their perfect accuracy now this problem is too easy way too easy for the state-of-the-art algorithms but if you go back to 2010 let's go back to 2010 and you will realize i don't know what the state ofof-the-art was but the state-of-the-art wasn't that good you can go back and look at the accuracy we have a September overview of results here it is large-scale image net recognition at that time knowledge let's see what the numbers were done this year's challenge leave categories teams so you see that the teams are all impressive teams the who's who of big research groups in this field and winners was Urbana-Champaign I'm proud to say I'm an alumni from Urbana-Champaign ah nice and you see that flat cost with prediction and computation well in this case they said how well you can do so you can see that some of the hard categories the the predictions are only 92%, they are like this tree, 86%. It was already getting better, but, oh, these are error rates or maybe these are error rates. These are not, otherwise it wouldn't make sense. Easy categories is 0.12 error rate, but in hard categories very very high error rates but today if you look at the real the results in 2017 and thereafter we are near perfection so you got that this egg yeah and you'll get more of it as we see we haven't gone into the theory I'm asking you to do the labs before you learn the theory, because it's important to get started. So, likewise, there is another data set, which is a bit easier data set, it is called the CIFAR data set. this is the code for it and the code is not hard but at this moment is just barely a couple of hundred points of code half of it is just comments um you can play with this but let me go to the notebook and show you it in action so you can go to c410 notebook and i'll just walk through it here you take this C for first of all obviously you have to once again add it to the path I made it easier for you just go create the c4 classifier you can look at its architecture actually a back the c4 data set with a very very simple neural net as neural nets go guys it's a very simple neural method. It has one, two Convulation layers and two linear layers and one output layer. In the world of neural architectures, this is almost a joke. Still, let us see how well it does. So this is your example of creating your first classifier using a neural net. But once again, because we are playing with it we have no idea what compilation means or linear means at this moment just play with it so what do we do in machine learning we train a model and here the new thing we do is we actually train it we don't take a pre-trained model we train it and then we evaluate its performance so there are 10 objects here. The 10 objects are ship, car, basically car, ship, plane, dog, etc. And you have to identify one of those 10 objects. You can look up into the classifier. It will tell you what the labels are. I should have printed it out. These are the labels. In fact, here in in the code somewhere the labels should be there yeah you have to identify it to be a plain car bird cat it's a treasure so therefore guys is it a problem in regression or classification classification so we will classify we train it for one epoch one epoch means just one times we cycle through the data and no more at this moment and then when we evaluate its performance in one cycle let's see how well it does this time when you do it let's see I'll show you the whole code in action here it is do you notice that it is busy downloading this model this will happen in your case also it is getting the cipher the cipher a data set c for 10 data set there's also a c500 data set which is much bigger you can have fun with that let it go through so at this moment is downloading then it will be ready with it there it is it's extracting it and it is saying that this is a simple continent and I invite you to go change this code a little bit Let's train this model And now it is training it is running through the air box at the different steps to the air points. Oh it finished training Now let us evaluate its performance Let's see. Oh, here are the things. So when you evaluate its performance, let me walk you through this code. This is easy, right? You train it for an epoch. Now what you do is you take a batch of data, a small mini batch of data from the test. Usually when you train a neural network on a data, training data it is called, you can't take some examples and ask it to tell you to identify those because it might have memorized it it might have over fit to the data if it over fits over if it becomes somewhat like not learning but memorizing the answers so you can't evaluate a model on the training data you should evaluate a model on the test data so we are picking up test data some test data we take one batch of test data one batch in this case is about 16 images we use the classifier to make predictions on those images and you notice there guys I'm saying classifier device why because it makes predictions much faster on the GPU so what this code will do is if on your machine it finds a GPU when you run this notebook it will automatically go and grab it and run it in a fast way if it doesn't find a good GPU it won't go there now bad news for those of you who are running it on Mac, even though you have very good graphic cards on your MacBook Pro, it will ignore it because deep learning is not supported on Macs at this moment. Asim, line 3 is giving an error. It's saying no module name types. Which line? This one? it's saying no module name touch of types which like this one yeah the SV learn data sets one line two oh yeah so yeah you're looking at this classic see if I can I fight yes I'm trying to import c410 classifiers, simple c4net from SVDN datasets and it's giving me Oh, right here. It means that you haven't run this line. You have to make sure that this works correctly for you. No, I ran that line. It's giving problem. It's saying no module named torch.types. Oh, then your torch installation has not succeeded but it's like touch worked on the other one they made in it did you install touch vision yeah I did something fish here we'll have to debug what's happening when you mention how do we need to import touch and import touch vision here you don't need to if you want you can because this class cipher 10 classifier under the covers does go and import those you don't need to do that so so then i don't know why it is not failing out on me but yeah we'll figure out what what what is happening on your machine is anybody else having problems guys yeah you do oh okay i installed sv learn but now i'm getting an no module named sv learn dot transfer which is strange. Okay, so we'll need to sit and see what's happening on your machine. Just give me, maybe stay back after this class and we'll do that. We have some time. So then one of the things you do, and this is something I wanted to mention. See, guys, we trained it for an epoch. We evaluated it. This is the evaluation. We make some some predictions and then we count how many predictions were right and how many were wrong so here is it uh this is a bit of python code it says that i gave you a cat what did you predict it to be so the way to interpret it is cat was predicted as cat ship as ship good but one ship was predicted as car so it got confused between a ship and a car one ship was predicted as car so it got confused between a ship in a car this looks right this looks right this looks right this looks right right Oh cat got confused as a dog cats won't like that car was fine plane truck dog horse truck got again confused as a car and a ship got confused as a cat now that is a blunder so what is the accuracy It made four mistakes out of 16. So your accuracy is 75%. So guys, how can we make it better? It's a question worth asking. And this is one of your homeworks. You have to try it out. The way to do that, but I'll give you an answer to this by a hint. I just run it for one epoch ever it saw every piece of data only once what happens if I show it the piece of data not once but twice let's say let me run it here and see what happens you can see that it's running through its steps yes and by the way guys this thing will run a lot slower if you don't have a GPU. Make sure you have. And now what happens? Inference. Oh, you notice that the number of errors came down? It became 5 out of 16. So accuracy has gone up. No, it's gone down. It's actually gone. Well, it's a random process. So the lesson is actually the opposite of what I want you guys to that because I have reasonably good hardware I'm going to run it for 10 epochs and let's see what happens if you're running for 10 epochs it cycles to the data 10 times and it's a vast quantity of data remember And it's a vast quantity of data, remember. So do you notice that the loss is coming down? It started out with the loss of, well, it actually started out with a huge loss, but within a thousand steps, it came down to 1.2. And then it is continuously decreasing. The loss, what does the word loss means think of it as the amount of mistakes it is making out of those millions and millions of images tens of millions of images how often it is getting it wrong and it will actually it's not how often it's more complicated it's cross entropy we'll learn the concept of cross entropy next time there we go we finish this model let's try a lot evaluate there we go oh sorry I started the training again all right we'll wait a little bit but in the meanwhile let me talk about this while it's training see guys when you train a model as you can see it takes time to train a model right in this case i've given a ridiculously simple neural net but two convolution layers two dense layers and an output layer right in the world of modern architectures this is almost laughable but what i want to show you is two things. The first is that training a neural network takes time. You can see that even on a pretty powerful hardware and the hardware that you're looking at in my machine is actually it's it costs tens of thousands of dollars. It's a full, powerful, deep learning workstation. And still, it takes time to run. But when it runs, now we run this. There we go. It still comes out with six errors. So I'll let you play with this and see what you can make out of it. How you can reduce these errors. You have to figure out the depth set at 62% accuracy. And it will vary because you're taking random samples and doing it. So when you take a model that takes a lot of time to train, especially if it has taken a month or weeks to train, you don't want to throw it away. You want to save it. So the first thing you do is you save the model. This is what you do. In the lab, you build models, the best model that you can, and then you save it. And then what do you do? You go to production with it. So we are going to save it. Saving it is easy, you just save it to a file. Here I saved it to this file. Now what happens? What will it say? What does it mean to save the model? A neural network is made up of a lot of weights, what I call weights, or parameters. And it will store the value of all those parameters. Even for the simple neural network, if you look at the number of parameters, it's actually huge then when you take your model to production so here it is you're done with the development you're not talking about it you have given it to a different team that team is taking it to production and usually the people who take your model to production do not know artificial intelligence their job is to blindly just use whatever model you give them and they will use to make predictions they load it up and they'll use it to artificial intelligence. Their job is to blindly just use whatever model you give them and they will use to make predictions. They load it up and then use it to make predictions. So they will do this. They will load the model at inference time. They'll put up maybe load it into their micro service. Your flash application, your fast API, your Tomcat, your whatever and these models can be loaded in tomcat and your electric models are very portable across languages you can do that there's a onyx format so you can then load it so now guys i have a set of homeworks for you the homeworks are the following you read the source code of c510 this source code i'm saying just read it now the c510 source code is not that hard the first is the neural net this is where we build the neural net you won't understand it guys at this moment i haven't explained that here but start by just reading it see if you can get a bit of a sense of what it is doing here it is using a base class if I classify that I've created which is doing most of the heavy lifting here you actually there isn't much code if you put in a bit of effort you'll understand it the main here is exactly what you find in your Jupiter notebook so it is not that easy to I mean it is not that hard, but it will take you time to read this class, especially since you don't know the theory yet. Try to make some progress and then play with the number of epochs. What happens if you increase the number of epochs? See what happens. Does it improve accuracy? How many epochs does it take? Then what happens if you change the learning rate? The constructor of the CIFAR has a parameter called the learning rate. Keep the learning rate between zero and one. Learning rate is never more than one. So between zero, what happens if you make it 0.1, 0.01? Take it in powers of 10 or inverse powers of 10 see what it does to your accuracy of your module what happens if you change the mini batch size so if you look at this a neural net the way I've constructed it you can actually give it different sizes you notice that this is in the base class so I should go back to the base class yes so it's a little bit of a code that you will have to gradually get used to the base classifier so this is something read with caution in the beginning right it may take you a little bit of time to get your heads around it takes a neural network is a mini batch size learning rate but the way you would do it is you would just go to the code here where you say where did we construct the classifier? Right here. You want to give it a different learning rate. You can say learning rate is equal to 0.1. Or 0.1. Or 0.1. Let's say that what happens if you give it a huge learning rate? Train this model. train this model you notice that it's going from much bigger loss to it's making slow progress let it make progress while we continue discussing the rest of the things so play around with it guys these are called the hyperparameters of the module and usually when you train a neural network even when the architecture is known there are are a lot of hyper parameters that you have to search and find the value of. Are we together? So that's it. And lastly, this is challenging. Do it only if you're very comfortable with Python and have some exposure to PyTorch. Go and tweak the underlying neural net. There is a class called Simple CIFARnet. I made it very simple trying to add more layers bigger bigger layers and so forth and see if that improves the accuracy of your model. Does it do better? Makes sense right? And now this is for image processing. I want to show you now some things to do in the space of natural language processing. In the natural language processing, actually I've kept it very basic at this moment. There are only two things that you should focus on. And I'll talk about that. about that one is well don't read this quote sorry I take it back go away at this moment forget about this code go back to the notebooks and it'll be free films first of all there are many NLP libraries the libraries that are very popular these days is NL TK it It's written in Python, it's very Pythonic, it's easy to understand, it's complex. It's slow, it's very, very slow because it's written in Python. It makes NLTK manageable and simple. Always start with text block. It's very easy to use. And vocabulary is simply the vocabulary. You can ask for any word. It's a dictionary. You can ask it to give you the meaning, the synonyms, the antonyms of a word. It'll give it to you. Now the industrial strength libraries, the ones that you actually use in production. So most people, they tend to use NLTK and you see a lot of NLTK code on the Internet and that's all right, tutorials and so forth. But actually what you use in production is not NLTK. It's very slow. You use these two libraries, spaCy and Gensync. These are libraries that are industrial strength and they are very opinionated. They have only one way of doing things, but they do usually do it right. And Spacey in particular has a very good integration with the transformers because it integrates with the state-of-the-art transformers this giant pre-trained models you literally get high performance efficiency with whatever project you're doing in a matter of a few lines of code so here i'm just introducing uh the text block this is your hello world of getting started with uh nlp so you run these libraries you you do that. I took this quote. This is from the author, Charles Dickens, a British author. His book, A Tale of Two Cities starts with this beginning. It's a famous beginning, you must have, it's become a cliche. And you must have seen it at many, many places. It was the best of times places it was the best of times and so forth and this is one of the last paragraphs in the book it's also a memorable paragraph when you know the protagonist is sacrificing his life to save the husband of a girl he used to love and so forth. So then these are the last few lines. It is a far, far better thing I do than I've ever done and so forth. And so what we will do is we will look at this. How many sentences are there? Unbelievably, this entire paragraph is one sentence in Charles Dickens' book. And this is another sentence. So we will ask this library we will give this library this text and ask it to just tell us the first 10 words and identify what they are so as you can imagine it is able to do it it is a proposition was the these are all symbols times it sector so these symbols you can look up there in the dictionary the worst is a adjective and so forth it will tell you that now you can ask it to give you the noun phrases or verb phrases or adjective phrases or whatever it is and then it is trying to do that there is a typo here like it has interpreted as now the rest of it it seems to have gotten right darkness a present period noisy authorities well it has included the adjective also now the superlative degree seems to be doing pretty good if you ask it to do sentiment analysis is it positive or negative again guys it's a what no-brainer it's absolutely a no-brainer these days it is saying that the first paragraph is essentially neutral would you agree that it is neutrally every positive sentence is cancelled by a negative sentence do you see that best of times the worst of times age of wisdom age of foolishness belief incredulity light darkness hope despair right which is why I chose this just to show that if how well the sentiment analysis looks so the polarity it is saying that this sentence is neither positive nor negative it has close to zero polarity would you guys agree with that that it's correct for this text seems no yes seems correct is it a subjective sentence subjectivity is low it was the best of times not very subjective what is subjectivity subjectivity is opinion isn't it? Yeah, lack of... I mean, in other words, it's one perspective. One perspective of it. One person's perspective of it. Now, you look at the second sentence, though. It is a far, far better thing that I do. Do you see the subjectivity here? Than I have ever done it is a far far better risk that I go to than I have ever known one would imagine that this is definitely subjective let us look at it polarity it is a positive statement well it's a beautiful story a person is being bulletin head is being chopped off and he is thinking these thoughts positive sentiment and subjectivity it's highly subjective statement so guys play around with it feed it your own text this is something for you to do today feed it your own text and see how it works with the point I wanted to make today or the purpose of the first week is you can do a lot of practical things without even before you have learned deep learning just enough you can be productive the libraries are excellent and you can start marching forward with it bear with me I have another 15 minutes and I show you some more magic language detection we ask this thing to tell what language it is and it seems to say this has been written in english now here is something for you to do go translate it into some other language we ask you to translate it into now how many of you in the audience know Hindi me sir so those of you who know Hindi read it and tell me whether this looks like a reasonably good translation okay but not for like in the first line it says where means he, right? Second line onward, it is yeah means this. Yeah. Yeah. Yeah. is not right, sir. is not correct. Yeah. That is not correct because it's a literal translation. Yes, sir. So, and then we will do transformers and other things. So this exercise, which we have done with a very easy library, which is TextBlock, yes sir so and then we will do transformers and other things so this exercise which we have done with a very easy library which is text block we will repeat with some of the state-of-the-art transformers all right and we will compare the results but even as a baseline result it's not that bad is it would you say it's terrible I would say it's pretty good isn't it yeah it's not that bad is it would you say it's terrible I would say it's pretty good isn't it yeah this is for something where we haven't even used the state-of-the-art neural neural architectures this is a very easy library text blob and we have used it which uses a simple it does use neural network with a simpler one and then in the coming weeks we are going to improve upon that and see where it takes us but something to get started with we look at the tokens we ask it what are the sentences in this text and very clearly it says there are two sentences one sentence here here to here and another sentence it is here which to me looks correct you ask it for the words and right away breaks it up into the words. And you can play around with it. So this was a one library text blog. I would suggest that if you're starting with a natural language processing text blob is your friend. it will help you gain confidence on day one just looking at this code guys do how many of you feel that yes a natural language processing is so easy that even we can get started right away and be productive even when we don't know much it's sure yes go ahead pradeep So I am doing one assignment for college where they asked to do the same thing using metapy And the functions and the everything tokenizer everything looks looks very much similar. Yeah. Yeah, most apis are similar Yeah, because I mean see nlp has only so many ideas you tokenize you clean your removes you do stemming limitization you remove stop words that's right yeah how far can you and then you start doing your real work after that text classification and so sentiment and this and that all right so this is that the reason i, so this is that. The reason I mentioned it here, I didn't bring in Spacey, et cetera. It's a little bit more complicated. Every week we'll try to introduce ourselves to one more library as we make progress. But I hope today we have introduced ourselves to quite a bit of things. I would like to take the time to introduce a couple of more things, just to show you the magic of this thing here we are going to find keywords and we are going to use either gensim or something called rake two part and there are many by the way many libraries but gensim is pretty powerful so i have text if you look at the directory you will find five different files shakespeare's song these are by the way some of my favorites so you are seeing a very biased selection here if you don't like that I ask for your forgiveness Shakespeare's sonnets long ago when I used to have black hair and I was a teenager I was absolutely in love with Shakespeare's sonnets I would print it, I would post it on my wall, I would look at it and so forth. So, well, they are there. The other is the US Declaration of Independence, a profound document. It's a democracy, the largest democracy being born on this document, certainly worth it. Tale of Two Cities, we just went through it. Gettysburg Address. Those of you who have been, who know the history of the Civil War, of course, it hardly needs to be explained. And when India came out of colonialism, after almost 200 years of oppressive rule, the speech that the Prime Minister of India made at the midnight is the Trust with Destiny. name the midnight is the Christmas destiny so these are the five our text I chose and I want you to do this guys change this value first of all make it your directory change these values to your stuff and ask this library to find the keywords in it and the two libraries are either J sim or rake r-a-k-e you can give it the two words now here I've run it with this this is a huge amount of sonnets the sonnet and I will go straight to the end and what does it say? Let me see. What does it say at the end? The last sonnet is Somewhere here. Obviously, there's a copyright notice also here. Yeah, this is it the last of the sonnets But anyway It's a little bit archaic language, but it found these many keywords Those of you who know Shakespeare would immediately recognize these keywords thy thou etc now if you look at this you observe something this thing has been trained possibly on modern English so it is picking up thy and thou as keywords and death and d as keywords and shall as keywords well americans don't use the word shell so it popped out as keywords are there really keywords or should you put it in stop words and remove it right because in the in the shakespearean time the word for word was thou actually uh i remember even now when I read some of the older British books, up to almost 1950, I would imagine, 1940 or 1930, it was still common to call your sweetheart Thou instead of You. your sweetheart, thou, instead of you. You was more impersonal, thou and thee was much more sweet or personal. Obviously those words have gone out of usage, but in something so beautiful as a point, a poetry, they shouldn't show up. But anyway, your mileage will vary. So go play around with these keywords, but it's amazing, isn't it it that it picks out the keywords in a text and the last one is something very interesting it is the beginning we will develop it more it's actually one of the projects we are trying to do in my day job also suppose you get you get a piece of text you ask this, how readable is it like Is it something that a kindergartener can read. Is it something that a 10 year old can read sixth grader fifth grader can read. Is it something that High schooler can read. Does it need college degree or does it practically need a PhD. Right. So there are libraries that do that in particular, there are two generations of libraries. One are the statistical libraries. For many, many years, since 1940, people have been creating all sorts of tests. For example, this flesh reading ease test. It's been there, I believe, since 1940. And it all tells how much education you need to be able to understand a text. So I invite you to go and figure it out. Here, I took Lincoln's address. Lincoln's address, when you do a score of, it turns out that a high schooler can understand. Now, Kate, would you agree with that? Yes. It sort of does that but what happens if we try the US Declaration of Independence that could be a tricky thing let's see or what happens if we try Shakespeare will be tried Shakespeare let's try something else suppose we put it here in contrast and see what happens if we try Shakespeare will be tried Shakespeare. Let's try something else Suppose we put it here in contrast and see what happens. I'll have to read run this thing from the beginning Oh something went wrong text is not fun Something went wrong. Text is not found. Text that has no attribute. Okay, I'll tell you what the result is and you should try it out so guys let me tell you accidentally I didn't comment it out please do this right away in your code go to your code and I'll post an update and with that thing removed when you go NLP readability you see this code readability dot PI in this comment out the last one two three four the last four lines here guys can you see my screen yeah right comment it out guys. Kate, would you mind posting these things in the forum? I'm taking some screenshots. I'm kind of getting a bit behind. Yeah, so the directory. I'll try to get what I can in the forum. Yeah, that's right. All we need to do is comment out the forum and I'll post a new version of the code if needed for this. When you comment it out, you realize that the readability, it's the US Declaration of Independence is much harder to read than the Gettysburg Address. And when you feed it Shakespeare sonnet, it becomes extremely hard to read. I believe it says that you need 100 or 200 years of education to understand Shakespeare. Perhaps that's one reason why Shakespeare is not popular these days. So play around with it guys and by the way once you comment it out or play around with it I'm almost done showing you the same as if it stayed in work even after commenting oh yeah just certain run the kernel oh restart and run the kernel it will work for you then because it's still holding on to the old pre you know a compiled Python code so guys that's there there are a lot of things we didn't do auto machine learning should we keep it for next time because we are out of time now so auto automated machine learning is something I'll just give you a taste of it. Remember, I said that in a model you can have a lot of hyperparameters to learn. So, how do you not have to learn all that? So, let's do this. I want to do it properly. I don't want to do it just like this. Let's keep it for next time. are running out of time these are libraries that do automated machine learning let this be there is one more thing that I can squeeze in quickly I told you that for visualization matplotlib is a baseline library there's seaborn there's book a there's a bigger I mean they're beautiful libraries that people can use those of you who are familiar with gg plot would be pleasantly surprised. We have a lot. Altair is actually, it's based on the grammar of graphic. And the way it is based on the grammar of graphic is that there is a JavaScript equivalent of the grammar of graphic. It's called D3, D3JS. Very popular library for visualization. But Vega takes it further one step further it creates a very structured approach to creating visualization and now they have even simplified that with the Vega light they're coming out with so Altair is based on Vega and Vega light and I wanted to show you some basic examples of using Altair and in the interest of positive time I will not like run it right here just assume that it is run because we have only two minutes so just look at this suppose you want to create bar charts right the way you interpret so these are the inputs enable this is it so now look at this this is the data this is just your data frame now look at this and how in one line you create this beautiful bar chart comparing the year 31 32 you see that so the chart you give it data, you ask it to draw bars, and code it by saying column here, but because in the data there are two years, it will automatically draw two columns, or two different charts. X is yield, you see the X is yield in the data. The barley, you're looking at how much crop harvest was there, and Y is the variety of that eel what particular variety of barley was produced and how much was it produced and color is the site where was it produced so if you think about it this is very very rich visualization there are four dimensions to the data the year is one dimension site where you're looking at the harvest the variety of the barley and then finally the measure is the quantity right is the yield by the way you can interchange x and y i invite you to do that and see it but i hope you see how you can use structured libraries like altair and do very powerful data visualizations. And what is not apparent to you is that you see that these are interactive visualizations. Here, I didn't add a tooltip, but actually you can. And here you can export it as SVG, PNG and compile it to Vega. You can actually look at the Vega compiled code. You can even open it in Vega. You can actually look at the Vega compiled code. You can even open it in Vega editor. And look at this. One line of Python code wrote a ton of JavaScript and data for you, JavaScript for you. So this is it. It's very good. Vega is a great library, by the way. Use it. And based on that is Altair. The second is this is a famous dataset, CARS. Anybody remembers the CARS dataset, the auto dataset from our ML100 mileage? Yes. that's it so horsepower versus miles per gallon the more the horsepower in your car the miles per gallon goes down yeah and unfortunately I can speak from better experience my car has 600 horsepower and it barely gives 13 miles miles a gallon so there we go so once again anyway the point is that you can see that this is created with just a couple of lines of code once you become familiar with this code you realize it's very powerful and but you notice that these are interactive libraries I am'm switching between colors. I am, you know, these are, these are not just images. These are interactive live visualizations. That's the power of Vegas. This is a positive and negative graph chart with negative thing in it. Right. And again, you can export it to PNG, so on and so forth if you compile bigger code so i'll stop with that guys this is a tool of i hope the things that we will do in the coming months we today got started with the lab with the purpose of getting a hands-on experience the nature of diving in at the deep end is that of course we don't know the theory, we are going to learn the theory next time. So from next week we'll start slowly. We'll go back to the foundations, ask what is a neural net and we'll carefully and slowly build up the theory. But while we are carefully and slowly build up the theory, on different track, we will actually move ahead and keep developing our expertise with the state of the art models. So for example, next week lab will not only do the basics, we will also do a little bit of the automated machine learning and so on and so forth. So guys, today's lab should have been intimidating for you, for those of you who have entered it. The purpose was that I wanted to give you a flavor of what can be done. Assume that you won't understand all of this, but just seeing the code, just being able to play with it, it gives you a chance to become familiar with it. Maybe borrow it for some job for something that you're doing in your workplace or make something out of it if you can but don't get intimidated you know we will cover all of these things very very slowly the next session next week will start from the very very basics it starts from what is a perceptron what is a neuron and what is a perceptron? What is a neuron? And what is a neural network? We'll start from there. Are we together? So the lab, the homeworks guys, please do do the homework. I'm going to release another quiz today, tonight, not today, tomorrow evening. I'll try to do it on Saturday. We'll discuss the solutions to both homework, you know, week zero quiz and the week one quiz. And the week one quiz will be on all these things, these buzzwords that we talked about, transfer learning, automated machine learning, explainable AI and so forth. Kate, go ahead. Yeah, I noticed it's a, you know, probably need the homework all listed in one spot. I guess we'll use the chat. I'm still more used to Slack channels for that, but also referring to the notebooks, you know, with the directory structure based from the root where everyone's going to have it, the deep learning. The name of the notebook and to say to look in that notebook at the bottom where there'll be homework stuff to look at. There's one place that kind of lists their stuff, the bottoms of these various notebooks in these locations to look for homework assignments. Exactly. Is it written up nicely, but they're in the very bottom of various notebook. My hope is that to find the homework. She left to read the notebooks. Right. Telling people the order they are, you know, which ones to look at. Oh, yes, yes. If you people the order they or you know which ones to look at oh yes yes that would be wonderful it's supposed to turn on to our will I'm using the wood slack but let's oppose it in our discussion group in a social forum okay I'll do some take some time to do that tomorrow so guys are now I'm going to stop the recording and let's open it up to question You guys have all been unusually quiet. Редактор субтитров А.Семкин Корректор А.Егорова