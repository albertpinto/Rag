 So this is our first session on NLP. Now we are going to talk about the project that we will do in broad strokes. This is the outline. This is the NLP project. Are you folks able to see my screen? Yes. Yeah. So the business statement is, and I'll give you a write-up about this. So it feels like a business problem. It is like this. You have a corpus. Well, okay. You have documents, lots of documents. Well, okay, you have documents, lots of documents. Now, when we use the word documents in NLP, we don't really mean paper documents or something. You just mean a file, roughly speaking, think of it as a file. That's a very rough way of looking at it. A document is a file, right? It could be a few paragraphs, it could be a file, it could be whatever. It could be what you extract from a url and so forth right now what you will get is this you uh you will take artic these documents will show up as possibly articles from possibly articles from simple Wikipedia. It's a simple Wikipedia. It will be an article from the main Wikipedia, the Wikipedia that you are familiar with. By the way, the simple Wikipedia is a Wikipedia address towards children children so those of you who have children and don't know about simple wikipedia it's an excellent resource to go and learn things it's a very clean nice wikipedia where knowledge is described in simple language that children can understand okay so we'll take articles from here and then we will also get YouTube videos. So you will get URLs for all of this. You'll get a whole list of URLs that you will gather. Your problem would be this. In a page, you'll create a web page, a single page application. Page. Application. You'll create a web page, a single page application, page application, which will be written in your standard HTML, JavaScript. This is the bare minimum and of course, some basic CSS, but you don't need to worry about it. It doesn't have to look pretty. But what this will contain is it will look like this. You will give it a input. You will choose to either give it a URL, point it to a URL, you can give it or you can just give it a text box. Or you can just give it a text box. Are we together? And the moment you either give a URL, or if a text is provided, it's very simple. So in the beginning, you may start with just taking the text as is and not the URL. But I'll give you the whole statement of the problem. First thing that you have to do is step number one x get the plain text of content. What does that mean? A, if it is given in text box, means you're done. You have the plain text. Isn't that? B, if it is a URL, URL to a plain text file. Oh, by the way, the URLs will also contain Gutenberg articles. The fourth one is Gutenberg. Did I spell it right? Gutenberg. Gutenberg is a global repository of free books. Gutenberg is a global repository of free books. Gutenberg book. So it could be a plain text file, URL is pointing to a plain text file, in which you just download and get the text. You don't need to save the text internally unless you want to. Just extract the text. And then what you need to do is if it is, on the other hand, HTML, and this is aspirational, these two are necessary. Let me just put this as necessary. These two should be there. Optional. If it is HTML, extract text. Right? How can you do that? Very easy. Either use or Scrappy, or you could use, that is in Python, or you could use JSU for Java, or you could use Apache Ticker. All of these are great means to just extract the plain text out of an HTML, the text content. So do that. And D, use, there is a YouTube transcript API that will give you the text transcript. A text transcript of any YouTube. Are we together? You can get the free transcript out of this. So you can use it. It's very simple and I'll give you the sample code. None of this by the way is hard. So what have you done? Step one is just to get the plain text version of the content. Are we together? That brings us to step two. Step two, read it. I call a microservice. So you call a rest microservice such that input is text. Input. A text input goes in and out comes a few things. Out comes a detection of subjects. So this is a classification subject detection. So you'll get a list of about, let's say, 10 subjects. You'll have to determine which of the subjects it belongs to. You'll have to do a positive negative sentiment, sentiment right analysis. Are we together? You'll have to do Are we together? You'll have to do named entity recognition. So, or entities, locations and organizations and so forth. You'll have to do that. You will also have to take all the nouns in the text that are there, and the verbs. You'll have to create separate lists of the nouns and the verbs. And lastly, what you have to find given this text you have to summarize the text the text into let's say hundred words are we together you'll have to summarize the text in 200 words are we and, you'll have to generate the next paragraph. Next paragraph. So imagine that this is one, two, three paragraphs of text. Can you then continue it and generate the next paragraph so guys what is this each of these tasks is simple actually it's not hard but when you do it you'll get a pretty good practice in basic nlp tasks and you'll do it over four weeks it's not that you'll do it over four weeks. It's not that you'll do everything in one day, right? Or in one week. Does this make sense, guys? So, Asif, for the step before the first step, right? The single-page application creation, do we need to learn CSS or should we be providing the code for that? Make the ugliest page. CSS only if you want to beautify it. Sorry, can you repeat that? I'm saying that you need CSS only if you want to beautify it. Okay. You can just make the ugliest possible page. I don't even know how to make a page. I'll give you some sample code. code. It's very easy. HTML is not that hard. But see, these are skills. See, here's the thing, guys. We work in our day job for big companies. If you do work for big companies, big companies will always do one thing. They'll find out your area of strength, and then they'll pigeon you into a job that utilizes your area of strength so that you become a delta function you become super good at one thing but you lose breath but if you ever want to do a company of your own a startup of your own you need to have breath and so in this next few months you you'll learn a little bit of everything. And each of these is a very shallow learning pool. It's not deep pools of knowledge. These are very shallow. HTML and that much. How much does it pick up? Anybody would like to who has had experience picking up HTML quickly. Would you like to speak up? How long does it take to pick up basic HTML just to render a form or some or something like that so about an hour or two about an hour or two that's it not more than a day yes so you know you will learn this Nisargha these are useful tools. I will give you guys some code using React. For those of you who are a little bit more motivated, I will give you, we will do some visualizations, some interesting visualizations. There are lovely visualization libraries using Vega and Vega and so forth, right? These are layers built on top of D3. They make data visualizations extremely efficient, right? It's a new world and it's really worth learning about it. See, imagine being a one man army and being able to create an entire start startups technical stack in a month on your own. I'm just taking you through that process. Like this is something you do with me, but hopefully the next new idea that you have, you already have a template and you'll do it on your own. Right? Natural language processing is pretty hot. And while we are not doing some creative, absolutely groundbreaking work, it will feel to you groundbreaking because for you, this is new. So that is step number two. We will call it. So then, yeah, go ahead. Question on step one. So the corpus of knowledge. Yeah. I didn't get clarity when I looked at the text we said, so is there a corpus that you have access to which we pull from or your suggestion? That is true. So what we will give you is the training part, training the models. This is it training the models. So here, there are certain words that become important. We use the word corpus and its plural is corpora. Corpora, think of it as a universe of documents to learn from on a given task. So we will use quite a few corpora. And as we do the different parts, I will give you the detailed instructions which corpora to train on. Also, you will have access to a lot of transfer learning pre-trained transformers that that have already been trained on some well-known well-known corpora everything so we will do that we will use a language model model so these concepts we i will clarify in detail next time. But today, just to get you guys started, language models are models that help you predict the next sentence and so on and so forth. So there are language models that we will use. Then there are word embeddings, word vector embeddings. We'll either create embeddings occasionally. So two things we'll do. We will learn an embedding as part of our work. So when we are training BERT, in the process of training BERT, along the way we'll train an embedding. Or we will use a pre-existing universal embedding like Word2Vec and so on and so forth. And we'll use specific embeddings for domains. For example, there is a specific embedding, word embedding for the medical space or biospace and things like that. So when we deal with diseases and so forth, you'll deal with that, right? So slowly let's make progress with that. So you will deal with that. So that is that, and then there is a notion of vocabulary. Vocabulary is the set of all permissible words in our language. So what happens is that you deliberately restrict the number of words in the English language can be five million and growing but you may not want to take such a large vocabulary. You may want to take a vocabulary of size N such that you have the word one and word n followed by the n plus one word is other. Anything that you don't find in your vocabulary, you just declare it to be other. So that way you deal with smaller vocabularies and you deal with that. So our job will be, let's take simple things. Sentiment analysis. Example. sentiment analysis example so you have to rate it on a scale of zero to four let us say whether something is good or bad or just positive or negative given a text what is the sentiment being expressed so what will happen is you'll get a copper or a document set, which is made up of training data, which will look like the x vector and the label. The x would be some sentence, this food sucks, let's say. And then there will be a rating called zero, let's just say, very negative rating, right? Rocks, something like that, and a thing for, and so you get the idea, right? Your X and Y, you'll get the sentences and their labels. And so you can train now a classifier for sentiment analysis. So you will get multiple of them. We'll use Yelp review, we'll use movie reviews, we'll use many other review databases to do sentiment analysis. Are we together? And in this whole project there are other aspects that we will do. We will do an aspect of chatbot question answer okay question answering and so forth so there will be some optional aspects of the project but the core aspect is very simple guys you will take text and the the non-machine learning part is actually not that hard but it is worth learning about, right? Because it's part of the journey, that's how deep learning or machine learning doesn't exist in a vacuum. It exists in a fabric of a bigger software project and we learn to do that. So anyway, you will train your model, then you will store your model, store it as some form, right? Let's say that you store it as, there are many forms, there are many ways to store the models. Standard. Step four. Excuse me? That's step four? That is, yeah, actually I'll call it part of this itself. Training the model and save the model somewhere. Now comes step four, right? What do you do? Load it into dockerized, it into a dockerized rest microservice. And you have a choice of your language. You can do it using Python, Java, R. Most people don't write these things in this. The one thing that you can do, but you don't expect support from me is Node.js. You can do it directly in Node.js, but I would strongly suggest to stick with the top the first three like micro you'll realize why because the support for ability to load pre-trained model with uh for pytorch in javascript is a little bit weak so node.js is a bit of a struggle so you will write a rest microservice i'll give you guys guys, I'll give you the code and we will in the coming weeks, we'll walk through the code systematically. I'll explain the skeletal code and your job is to go complete it. And I will, in the code, I will put a lot of fill in the blanks. All you have to do is think about it and fill in the blanks and as you fill in the blanks, gradually a product will emerge. Are we together? So now you do a dockerized REST microservice, deploy it in Kubernetes Engine of Google. Are we together and once you have deployed it then do what then create your last step is to create a step 5 create a performance scalability, and reliability profile. Because it's no use having a startup with a wonderful application that crashes on the second request. This is also in the modern world with all the excellent tooling, this is easier than you think. But you learn to make sure that your application is scalable. So scalability, how do you ensure? Unless you have screwed up in your code, you don't have to do anything. Kubernetes takes care of that. It takes care of scaling it out. Performance just means that you don't do something weird in your code that screws up performance and if you have, you remove it. Reliability just means that it doesn't die at the request, but throws an exception and dies. It's reasonably good code. We will learn to do that. You will do this and then finally step 6, create a narrative. A narrative, right? A storyline, a data story. Story and a startup pitch. Each team will make a startup pitch to get funding. will make a startup pitch to get funding. So you will create some marketing material together. And towards the end of it, sometime around Christmas, I mean, right as we move along, we'll start having presentations of these pitches. And we'll record it all. And we'll share it with each other right we will do presentations so guys this is an end to end do you see that this is an end-to-end journey we will learn a lot but the flavor of the work that we do in part two i hope you see that it's by by construction by design It is different from part one. Could some, would somebody like to voice what is the main difference from part one and part two? Application and project based? Yeah. It's hands on. It's very hands on, you learn NLP. You see, we will still do theory. Remember, Mondays are theories I will go deeply into transformers I'll go deeply into even the classic natural language processing and so on and so forth right but now it is all about doing projects so this Wednesday what I will do is I will come to you with a business specification and I will give you little bits of starter code on many areas, little areas. And you all make progress, guys. I will be with you, helping you. Now, the only way we can do a lot of learning, you can get the most out of this is if you all commit hours to it. If you can't. So, see, let us say that, guys, if you can put 15 hours out of this is if you all commit hours to it. If you can't. So see, let us say that guys, if you can put 15 hours a week into it, you can do this entire project alone. Now let's start dividing it. If you can put seven hours a week into it, what do you need? You need at least one partner. If you can put five hours a week to doing the practical, you need two partners. five hours a week to doing the practical you need two partners if you can put only three to four hours a week into it you need three partners three to four partners do you see how it goes guys so pick the number of partners based on how many hours that you can commit to but but you know as a group conquer it it to but but you know as a group conquer it right conquer it as a group and treat it treat this projects as a sort of kegel competition try to come up with the best possible models you'll i'll give you a lot of flexibility when i explain to you the transformers the various approaches i will not tell you that use specifically this. I will give you a certain degree of latitude. And I'll let you learn some real world experience. You will learn, for example, that it is not the shiniest and the latest toys that get you to good results. It is often just plain hard work, cleaning the data, preparing it, and pre-processing, and so on and so forth. And sometimes you can get excellent results with humble tools. And these are worthwhile life lessons to learn. You will realize also, if I may give you some hints, that the quality of your results is directly proportional to the number of hours you put into it. You folks do this well and then of course later on in January when you're looking for jobs and career moves or internally whether inside your own company you're trying to convince your boss to give you AI projects or doing internal mobility or looking for some other jobs outside or whatever your goals may be, you will realize that the projects that you have done will give you confidence because you'll be fluent. Right? See, the only cure of nervousness is a mastery of a subject master it and you'll get all the doors will open of course that's a that's a given so this is that guys would you guys like to ask me any questions on this i think one question i have asif is just the the new stuff which is included in the product that is the html part the kubernetes and microservice part uh how much time should we spend on it and when do we start working on that understanding that aspect let me put it this way the non-machine learning parts will take time it will take 25 percent of the time 75% of the time will be AI and once again guys it's a decision point see I can focus this course all the practical work I can do just on training the model that is what most of the books do you know just train the model and save the model and you have no idea what happens to that model after you've trained it or how is it used in production it is my belief and it could be wrong it depends upon what your priorities are that we should learn the whole ai pipeline the whole process end-to-end process of making ai useful in real life so amongst all of of you guys, we can take a vote. If you guys feel that we shouldn't do the end to end process, we should only limit ourselves to the specific AI part, then raise your hand. Anil, your hand is raised. So unless, those of you who believe we should not do anything except NLP raise your hand Anil I believe he has just stepped out so his hand has been raised for a while anybody else so can I assume that all of you want to go through the whole exercise end-to-end exercise any other things i think i think we just need direction that is what this course is about at the end of it you'll come out confident you remember how At the end of it, you'll come out confident. You remember how I took you guys through the 100 datasets? Yeah, but I think that as well, Asif, in a certain aspect, at least in that, we didn't have to deal with microservices. You didn't do the end-to-end process, but it was a big problem to analyze. Yeah. So if we know what resources we need to use and then how much time to spend on it. And when to work on it. We'll get detailed instructions. Yeah, I think that is important. We'll get detailed instructions. Very detailed instructions. Okay. So you will get instructions to, this entire exercise can be very, very enriching and a memorable event in your life. Or it could be, you know, a disaster. It all depends upon how much effort you put into it. So I would say that aim to succeed, form your teams accordingly, look at yourself in the mirror, see how many weeks you can actually give in a given, how many hours you can give in a given week. If you know that you can give a lot of hours, then you can have lesser number of people in your team. If you feel that you need more help, because you'll be busy, pick up more team members. But collectively, as a team, plan to put 15 to 20 hours of coding into it. Now you realize that 15 to 20 hours is no joke. After a full day's job, if you're holding on to a full-time job, you're looking at quite a significant commitment if you're going solo. If you are, some of you have put your job aside deliberately to focus on this workshop. For those of you, then 15 to 20 hours is not a big deal. You should be able to put into it, besides the theory. Let's say that you put in five to 10 hours a week reviewing the theory, then you can put in 15, 20 hours in the lab in the programming part of it. But have that commitment, and I will release the details. Any other questions, any feedback, anything, any comments? Asif, about the project commitment, I'm not sure how much time I will be able to spend but but if I form a team let's say if I become part of the team I'm afraid that I may become burden on others. Don't think like that guys see here's a thing I have a healthy team spirit we are all adults we all professions we can all get very busy so in any team people will be able to put different amounts of effort that should be perfectly fine guys and don't don't look down on a team member who is not pulling his weight because you know people have different levels of commitment when you pick a team member be aware that they mean they may be much busier than you are, and they may be able to put a lot less time than you do. But trust to their spirit of learning. They may not contribute so much with the number of hours, but they may contribute by, for example, queuing the code, reviewing the code, helping set up things, contribute in other ways, helping make the presentations. If you notice, there is an end-to-end aspect to it you know there are aspects which are programming related the other aspect is just setting up kubernetes in the cloud right which just means that in the gaps between meetings you could be setting up a kubernetes cluster in the gcp cloud right and by the way guys be careful don't reserve yourself a massive cluster in the cloud and cloud. And by the way, guys, be careful. Don't reserve yourself a massive cluster in the cloud and rake up large bills. For this project, to take this application to production, you need very nominal amounts of resources so that by end of the month, by end of the project, each member, each one of you should not have spent more than like 30, 40, or maybe 50, $60 across the two, three months on GCP cost. Another reason to have a team, because then you can spread the cost amongst yourself. So I wouldn't worry about it. And I would strongly urge you guys, you see if if if you have a team of three people and you feel you find that you're pulling a lot of the weight all the better think of it as an opportunity to learn more right because this project is a learning opportunity and the more you do on your own the more weight you pull the, the more you are learning. So don't obviously form judgments on others. Don't blame people. Take it in a very healthy spirit, guys, and I'm sure we'll do well. Rafiq, you can join our team if... And that is the common concern. I was also thinking that if I can't put many hours, I feel like being better, but I think together, it can be accomplished. Dr. G R Narsimha Rao, You guys together, it can be achieved, and you have to trust me that I have Dr. G R Narsimha Rao, Now, Dr. G R Narsimha Rao, close to 25 years of leading projects almost right starting with my work with NASA, the Project Horizon and so forth. So, you know, over the years you learn a lot of things when you work on large scale projects. And let's put it this way, I don't tend to fail at projects that I need. Think of this, that I'm leading a project, you guys are all joining into it and we'll all have a very successful set of outcomes. I will be there all step of the way. There'll be a lot of code that I will be contributing. So it isn't that you're writing code in the vacuum or that you're directionless. You'll get very detailed directions in writing and you will see that in the code when you check out the code structure when i give you the code the labs they will specify in comments what is it that you need to do right so you are not doing it from scratch you're filling in the blacks all right All right. Okay. You're just filling in the blanks guys and gradually as you fill in the blanks you'll see a emerging product like you'll see an emerging product take shape. So what are the things you can do between now and Wednesday? You could do this. Immediately go and purchase the books, guys. I cannot... Books are our friends always, right? We are surrounded with books. Get yourself this book immediately. This is the PyTorch part of it. And for the traditional, the non-D, the aspect of it also, go get this book. Right. And this book is a very light reading. Go and finish this. Now, I would like to do one more thing. I'll show you a website that you can start reading right away, even before you go and get any book. Are you looking at this page? Yes. So just go to Spacey. You see Spacey here? Yes. Right. Get started. How do you get started? All you have to do is, of course, pip install spaCy. And do you see these basic features and pipelines and so forth? Examples and so forth? Start reading this. It's a very simple thing. In fact, if you are really good at learning from the web, you don't even need the book. The book doesn't contain that much more than what is there on the website itself. Are we together? So start reading this. These are very simple examples. Each one of them is just two lines of code. Do you see this? Just two lines of code. And these are runnable examples. If you run it, it'll launch a docker container on binder and you'll see the results takes a while for the first one to run right so just get started here it's a very well documented a library go get started with it and make sure that you are reasonably familiar with it when we meet on Wednesday. So today I would like to just end early because today was just to shape the part two. So your NLP, your image processing, your anomaly detection and time series, all the four projects will be along the same structure. And this will be a structure. So, sir, this five weeks, almost six weeks will be all in NP, right, sir? Yes, it depends on how fast you guys are moving. If you guys are very committed, we might even finish it in four weeks, but maximum six weeks, because we have a lot of other things to cover and next will be probably the computer region right sir yeah it will either be computer vision or it will be anomaly detection fraud and anomaly detection and then we'll come to Computer Vision and then we'll also do our time series. This next one will be sometime in January. Is that correct, sir? No, no, no, no, no. Six weeks from now, I'm hoping that come early December, we are getting into Computer Vision. Okay. Especially if we move fast, if we all work with all our energy into it. And guys, I will be supporting this project throughout the week now. So we can use one more thing. By the way, this structure that we have established Monday theory, Wednesday lab, guided lab, and then some extra help on Saturday and a quiz on Saturday review and Sunday a research paper. Does this work with you? Would you guys like to change something or add something to it? I think I don't. I'm not that comfortable with the Wednesday timeframe, Asif, to be honest. That is too big a crowd, Sheen. I know. I know. But you just asked, just ask right what doesn't work i just told you that but if everybody agrees to change it to thursday i'll agree to that so you have to convince everyone else thank you wednesday yes yeah this is perfect is where i am right now in terms of this is the first time i've done a program with you. Like the flow of this right this. Little introduction to theory, followed by lab and the quiz discussions are useful and the Sunday paper reading kind of gives a little broader perspective in terms of what else is coming in the space so. Big concept. Thanks. Sidd, can you hear me? Go ahead. big concert nice yes it can you go ahead yeah if we can stick to the timing that will be great you know seven to ten nice up sharp at ten because you know I have quite a few calls a line up that yeah we all have to get into India meetings these days yes I'll try to finish my time most days that's a good feedback. Anything else, guys? Asif, also if Saturday can be used for lab session. I'll try. Lab help is good. Saturday is a bit sort of a, it's the aspect of human frailty. What happens is that my day job is pretty intense. Like for example, I'll finish with you guys and at 10.30 I have to get into the India meetings. Like all of you these days are getting into. So I'll get into India meetings that will continue. Then in my mornings, once again, the meeting starts. So what happens is come Friday evening, I get completely tired. So Saturday, I'm just sort of recovering. So I do the quiz and I hope to do more of the lab. When I have the energy, I'll obviously stay back and help you more with the lab. Otherwise, we'll either do it on Sunday or we'll figure some way out to give more time to the labs. I help with the labs. Any other feedback, guys? Any other change that we want to make to the format of the class? Speak openly, guys. It's a collective thing. We are all on a long journey. We'll all be working very hard. This is a fun project. Think of it this way. It's just a project for which you are not being paid. Paradoxically, you're paying to do this project. Hopefully, the last time you work and you pay instead of work and get paid. But it has to be fun for all of us. Treat it as a project and as a worthy project to do in which you learn a lot. And bring your own data if you want to do something in NLP on your own by all means bring your data Thank you.