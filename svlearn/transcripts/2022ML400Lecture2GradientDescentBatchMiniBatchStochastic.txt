 All right folks, so last time we learned a little bit about automated machine learning, one of the things that is the cutting edge of what we are learning, of what deep neural networks are doing in a deep learning topic. I forgot to mention one small point. I talked about neural architecture search. I talked about bias and optimization. One of the things that happens in this space that also is worth mentioning is something called meta-learning. What is meta-learning? Let's say that you have a model, M1, that is making a prediction, Y hat 1. And the prediction is, let's say that you're trying to tell whether it's a cat or a dog, right? Or maybe a cow or a duck, you're trying to distinguish that because we always... Now, suppose you make another model M2, and it also makes a prediction Y2. Now what you can do in this situation sometimes is you don't take just the average of the predictions or something like that. Sometimes what you do is you take the input and you feed it into a yet another learner, a model M3, you stack it and then you say, okay, what's the prediction here now from this model? So people have tried many, many approaches by which to wire up learners together to get good predictions. This sort of thing is quite common, actually, as ensemble models. And we talked about that in the comprehensive intro to data science, to machine learning. We talked about random forest and gradient boosting, so it's bagging and boosting. So stacking is another alternative. So people do things like that to improve the learners. At this particular moment, we won't talk. So what I would like to do is go back to the topic gradient descent and continue from there, our scope for today are these topics one today. We will continue discussion on. gradient descent. continued. gradient descent continued to, and we will talk a little bit about, and then we'll get into something called back propagation. This is the main topic for today. But when we do the back propagation, we'll need a little bit of calculus, review of differential calculus, and we'll learn in particular something called the chain rule. It's something quite simple. And even if you have forgotten it entirely, which is quite likely, it will come to you quite easily. So do not be worried. We will all be there. All right. So we'll learn a little bit about that. We'll learn about something called softmax function. And why do we need that? It keeps occurring as a last layer in neural networks quite often. We'll talk about that. We'll again go back and look at some simple loss functions. Simple loss functions. We will look into the effect of learning rate. Remember that when you do gradient descent your basic thing about gradient descent was without the subscript, it is the w next is minus alpha. gradient of the loss like the derivative of the loss with respect to w, so this is the learning rate how fast we are learning effective learning rate on the optimization process of the of coming to the solution we will study that quite a bit if time permits i will, so one more talking. We'll talk about something called mini, sort of batch gradient descent, stochastic gradient descent, Stochastic gradient descent. Stochastic and mini batch. A new way we'll learn is the mini batch gradient descent. This will be important topics and so we'll cover all of these topics. These are not hard topics. These are all fairly small topics, except for this one. This is the main topic for today. But before that, I'll cover all the smaller topics. And if time permits, we'll do the bias variance trade-off. Bias variance trade-off. Now, to remind you, what is gradient descent? Gradient descent is an efficient way to find the minima of a loss function or any function. And the way you do that is, or the way to think about it is that if you consider a function, especially a loss function, but more generally any function, so long as they're continuous and differentiable, one of the interesting things is if you think of a loss of function as a landscape, and that is a very good intuition to have about loss functions. Functions are generally surfaces in n-dimensional space. So suppose you have a n-dimensional space. I often use the word that somewhere in there, there may be, you know, often, for example, for linear regression, it is like this. And somewhere in here is the minima around which the contour lines are there. If you remember that from your introduction to machine learning, we talked about this, that there is an optimal point. And the way to come to the optimal point is to keep coming, falling down this gradient surface, which would take you from here to here in the contour, in the hypothesis space. So remember the axis of these are the hypothesis parameters these are the w1 let's say w2 and this is the loss the y the y-axis here is the loss the odd sort of the vertical axis is the loss and we have shown only two axes w1 w2 in general there are many many parameters As you notice in neural networks, especially, there are thousands, if not millions of parameters. And so you're doing a gradient descent in a very high dimensional space. To do the gradient is just to find the path of steepest descent. So a couple of things to do. If you look at this surface, this last surface, always think of it as a surface. Geometrical way of looking at things is always much more intuitive, much more efficient. So think of it like that. It's a surface and how would you come down? Common sense says the fastest way to come down is to tumble down that hill, right? To reach the bottom, to reach the valley here this is the point of optimal or minimal loss point that you can get to right so we'll learn a little bit about this now this is true for linear regression linear regression is a situation where you have a convex optimization. So linear regression has a convex loss surface. Why do I say that? What does this word mean? What is convex? A surface is convex. If you connect any two points, basically the intuition is right. It just, there are no bends in. There's no sort of, there is nothing like this. This is not a convex surface, not a convex surface. Whereas a convex surface is such that if you join any two points with a straight line, well, my line doesn't hardly look straight, then the surface tends to remain on one side. It doesn't intersect. For example, here, if I go from here to here, you have this intersection point where the curve or the surface intersects the segment. When the surface intersects the segment, It is non-convex. Whereas if it doesn't ever intersect, it is a convex. So one of the one of the good results is that for linear regression, it beautifully the last surface is as simple as it could be. It is the shape of a bowl in a higher dimensional space. It sort of looks like this bowl. There is only one minima here, the valley, the bottom of the bowl. So if you're anywhere here, think of it as a marble or a stone, what will this stone do? It will sort of slide down to the bottom of the bowl. If it is taking somewhere here and you give it a little nudge, it will just come down to the bottom of the bowl and that is gradient descent or in simple terms stumbling down the hill right now it so happens that for more complicated situations the large surface is not necessarily convex in fact for neural networks we know for a fact that the lost surface is not convex. Now, when loss surfaces are not convex, the whole question is, how do you find the minima? Because there may be many minima, like here you see, there is one minima A, there is one minima B. Now, how do you know when your learning stops, that you're not stuck at a local minimum rather than have reached a global minimum. Now this is a problem that puzzled people for a very long time and they came up with many ways of trying to solve it. They thought that the whole lost landscape would be cluttered with lots and lots of local minimas and learning would be very hard. Many people even argued that maybe that's the main problem with neuro... and there was a time when neural networks were not doing well about 20 years ago and people thought some of it had to do with the fact that the loss service was not convex. Today we know that that is not true. And in fact, we will go through a demonstration that beautifully shows this. What happens is if you have a good loss of if you have a good way to optimize and gradient descent with some degree of momentum, as in physically it happens, what happens if you come across a little pothole in the hill, because you have momentum, you still continue to tumble down right and that was one realization the other realization was that minimas or local minimas are not as pathologically prevalent as one would expect you have a lot of saddle points and things like that, but you don't have, I mean, there are lots of local minima, but they're not as many as you would imagine. It's not, the lost landscape is not infested with just lots and lots of local minima where learning gets, it can be, sometimes it can be, but generally it's not. If your neural architecture is good good it won't be stuck in such a situation so we will learn a little bit about that i'll show it to you with an example but before i do that i would like to give you the idea of a new concept called batch gradient descent stochastic and many batch gradient descent, stochastic and mini-batch gradient descent, these three things. So let me first finish that topic because it is important. Batch, and stochastic gradient descent. See, what happens is we always say that you have to compute the loss. What is loss? Loss is, let's say, prediction. This is the prediction minus the reality for a given point. Let us say that you're looking at regression loss. Regression loss is a quadratic loss. Remember, the regression loss is a quadratic loss over n. So you're computing the loss from or the error in computation. And of course, I've dropped all the regularization terms and extra considerations. So in a very simplified world, it is the sum squared error, right? And so you're trying to do a least squares optimization here, right? Now, this loss function, of course, is a function of all the parameters. This is there. Now, the question that is, is that what is n? When you do the gradient, when you find the gradient of L, and you are trying to optimize the, learn the next value of w, some w, and I will not put the things. In reality, what happens is the W is associated as the edge between two nodes, two edges, two sort of neurons in the neural network belonging to a certain layer. And so there's a lot of indices that come in. But just to keep things simple, ignore the indices for the time being is equal to, I will just write it until there means the next one. So you can see that we are decorating it with lots and lots of things. Learning rate. But this point, to the extent that it's the gradient of the loss, one question is, this is one step of learning. This is the learning rate. So this is just recapping. And at this moment, we're just recapping. Now, remember this expression in simple, for linear regression in the notation of our previous workshop used to be, suppose you have an equation, y is equal to beta naught plus beta i xi. Then our equations used to be that any particular xi, next step would be beta i minus alpha, gradient of the loss with respect to beta i. In other words, it would be this, wi. So we could just write it. Because we are writing the subscript notation, it will become just the wij of the layer l. So this used to be beta i, right? If you remember for linear regression, for linear regression, this used to be an equation. All that happens is the parameters now, they need an address. So suppose you have a neural network, right? This is the layer L minus one, this is the layer L. And here is a node I, right? And this is the node J. Then this is the address of, and it's very backwards. The way you give the notation is that you give the target node first, address of the target node, address of the source node, and you speak of the target, the layer that you refer to, L index, and this refers to the L. So let me mention this in big notation here. I, J of layer l what it stands for is This is i-th node in the ellipt layer. So this is the target of the edge. And j is, you can think of it as a source node to the edge in the L minus 1 layer. So the visualization is, once again, I'll make a visualization here. And there are many, many layers. We'll just focus on the L minus one layer. And then let us say you have the L-th layer. Layer. Layer. L-th layer. This is, let's say, the I-th node. And suppose, so not I-th, this is the J-th node. And you're going, you're looking at the I-th node, I. you're looking at the ith node i and let's say that this is the jth node so this edge is w i j l and it takes a little bit of getting used to you might like intuitively you say hey why is it not j i why is it i j and the reason is it's just a mathematical convenience when you sort of grind through the matrices and so forth it is more convenient to write it like this if you wrote it the other way around nothing particularly bad but you'll have to work with transposes of things matrices so it's just a mathematical convenience that we write it like that. And this is not very different from what we are used to in linear regression. But then one question that remains is that when you compute the loss, over how many points are we computing the loss? What are we learning from? So there are two extreme ways of doing it. Let's say that your data set is huge, humongous, it's a million data points. So if you mean this step updating the updating the parameters this is the heart of learning this is in machine learning this is the learning step this is the learning step. This is the learning. Right? So when you take one step of gradient descent learning, what is n? In one step of learning, what is n? if n is equal to all training points training instances then what happens is you have to sum over the loss of errors that you make y i hat minus y i square you are summing over the errors this is the errors over all the points the entire millions of points right that is your total loss yes and so you have to wait your system may take a long time to add up all of these errors, and then you take the gradient of that, and then you take one step. So the step happens after quite some time of waiting, especially when you have millions of data points. I hope that that looks obvious. The other thing you could do on the other extreme, if n is equal to one, so wait a lot for each giant step to happen giant step compared to what the other extreme is you say you know what i'm going to take loss from each point learn from each point we learn from only one point data point data datum and take a learning step and do a step right so then what happens each point changes the you need to update the weight you look at this one point it says ah your loss was too high right you you got it you overshot the mark so you say all right let me change the weights in such a way that the predicted value is not so big but the next point comes next data points you learn from and it tells you that hey you greatly undershot the mark now so then you say all right all right let me fetch the weights in such a way that the loss the y hat increases right and so what happens is that because all data points have noise in them, you know, data comes like data is not perfect. If you're trying to do, imagine that you're trying to learn linear regression, something, you realize that one data point may ask you to make the line more steep. Another data point here, let's say a data point here may ask you to make the line more steep another data point here let's say a data point here may ask you to make the line less steep do you see that the different data points are teaching you different things they're trying to move the slope the intercepts etc in such a way to favor themselves but the point the point is all these data instances they not only have signal they also have noise well that is all right now the advantage of learning this way is advantage each step is very quick each step is very quick isn't it because you're learning from only one instance of data and then you go to the next instance of data and so forth right so these are two extremes this thing when you take all data points there is a name for it it is called batch gradient all data points there is a name for it it is called batch gradient descent batch gradient descent on the other hand when you do it with just one each point at a time it is called stochastic gradient descent. And how it manifests itself is, let's say that in the contoured surface, suppose you're going from here to here in batch gradient descent. Then for stochastic gradient descent, you would be going like this. And actually, you'll never quite hit the minima because every point, the next point that is informing has a bit of noise. So it will keep shaking. What it will mean is that your line will keep vibrating along the perfect solution. It will just keep vibrating. It won't exactly go and sit on that. So these are the advantages and disadvantages of stochastic gradient descent. Each step is small, so you can see the effect immediately. the effect immediately but the downside is that because data comes with noise you'll never really converge to the optimal solution you'll keep zigzagging your way around it right or in the case of this straight like if you're trying to fit a line to this data for example your solution will keep vibrating the line will keep vibrating so this is the stochastic gradient descent. So now you say, well, each of them has a advantage and disadvantage. In batch gradient descent, you take one giant step, but it takes a long time, right? And also there's some computational aspect. You can't parallelize it. You can't parallelize learning. You can't do distribution, distributed computing and many things. When you take n is equal to one, you're very quick, but you zigzag around the solution. You take a very drunken man's walk. I call it a drunken man's walk on the lost landscape towards the optimal solution so these are the two extremes now so let me highlight the two words that we learned. These are the two things we learned. So now you ask yourself, batch is slow. You have to wait a lot to see one bit of progress. And stochastic is fast you quickly keep seeing updates but it doesn't quite tend to converge and set the solution it keeps zigzagging and vibrating there so what should we do it turns out that if you do sort of a compromise between the two that is the that is the most common practice these days and And that works very much. So what you do is you take a batch size. Let the batch size be, let us say, you take it to be 16 data points in training data. points in training data. So suppose, so how many batches can you make? You take this entire size N and you break it up into little sizes. Each part, each of these slices is called a mini batch. That is the more correct term, mini batch. Now, each of this mini batch, number of mini batches that you will have in the total data set is, so assuming that two, these are disjoint sets, mini batches, how many mini batches would you have? You would have N divided by B. If B is your batch size, isn't it? Number of mini batches, N is equal to this. So in other words, if it is 16 and you have 160 data points, how many mini batches will you have? 10, isn't it? 160 divided by 16 is 10. Does that make sense, to you any questions before i continue anyone no so let's make progress beyond that what is the advantage of that it's it turns out that when you do gradient descent on that you you get something that is halfway so you sort of you take a path which is somewhere between a drunken man's walk and a nice direct path to the minima right so this is the path that you will take and so this is considered pretty good you end up in the solution and you tend to stay there now when you learn through the data you might say when do I stop or how many how do i iterate through it how do we iterate do we iterate through the data through the data so what you do is you know that so we have a concept of our epoch one epoch is one round of learning from all the data points, all the training data. later so let's take the situations the three cases when you have batch gradient descent batch gradient descent then the size what is the batch size b is equal to n itself so how many steps are there so if you run through in one step, the number of steps is n divided by b, and that is equal to 1. Means in one step of learning, you run through the entire data set by definition. That's how batch learning is. So one step in batch gradient descent, batch gradient descent, one step of learning is sort of a giant step of learning, is equal to one epoch, isn't it? In stochastic gradient descent, on the other extreme, stochastic gradient descent, batch size is equal to one. So number of steps is equal to n over 1 is equal to n right because each step is learning from one data point isn't it so there are are n steps per epoch it's an obvious statement isn't it epoch and so this is these two things and then the in between the happy medium right so in in sort of uh in this business of gradient descent and learning you can think mini batch as the sort of the goldilocks zone right it's the it's the best way to do it so you do mini batch gradient descent there batch size is whatever b is number of steps is equal to n over b so n is equal to, so there are n steps for epoch, n steps for epoch, right? Little n, little n steps for epoch. Or maybe I should have used M as a different word. So there are N steps for learning. Now the question is, what is a good batch size? It's tough to tell. It depends on your data. It depends on your problem. It depends on your hardware. How much memory you have in your hardware, in your graphic, in your math co-processors or these GPUs or tensor processing units, right? How much memory you have. And the cost of a video card rises practically exponentially with the amount of memory the gpu has right so for example a 48 gb gpu or a like a 40 or 80 gb gpu can easily cost you about twenty thousand,000. Just think about it. Whereas 80 GB of main memory would cost you what? Two, $300 today, right? But 80 GB on the GPU would cost you easily $20,000. A GPU that contains that, which would be a 180 GB. You can look up the cost. I believe it's somewhere in the range of $20,000 or 40 GB is in the range of $10,000. So these are prohibitively expensive memory. So one of the limiting factors that you face is you want to be careful with the batch size. You don't want to run out of memory and so on and so forth, right? So generally batch sizes between four and 32 are common. Now, it also turns out that batch sizes have an effect on the learning. They have somewhat of a regulatory effect on the learning. As you can see, how much you zigzag your way to the optimal solution depends on the batch size. So we say that the optimal batch size is sort of the hyper parameter of your learning. You have to judiciously pick it based on your hardware based on your problem based on your data are we together but generally this is the goldilocks the happy medium the happy solution which is which has the best of both of these you have relatively fast learning and relatively a straight enough path to the minima. Right. So this is the concept of batch sizes or mini batches. People often call it not mini batch size. They'll often call it the batch size. But when they when they take a bad size like 4 8 16 32 etc what they are the approach they are taking is the mini batch approach to gradient descent it's quite common now there is one any questions guys is this i hope uh fairly straightforward any uh anyone needs further further clarifications on this no okay so you just randomize the points when we select please do that yes what you do is you never trust the data because see if all the data let's say that you just look at the basic case of linear regression itself if the data was so ordered that this set of points were before this set of points it would be crazy learning right because the first set of point will try to tilt the slope up. And the second set of point would tend to push the slope down and it would just keep oscillating. So what you always do, it's a very good point you raised. Whenever you get data, don't trust it. Don't just assume that it's randomized data. One of the first things you should do is for every epoch, as you go through an epoch of learning from the data, just shuffle it shuffle it randomize it and you should start with randomizing the data