 Hello and welcome to the Support Vectors video series, AI and a Cup of Coffee. My name is Vanu Peelimai. I'm the VP of Revenue Generation for Support Vectors. Now, unless you've been living under a rock, you've heard mention of an emerging technology called artificial intelligence. At this point, just under 80% of companies worldwide are either actively working on an AI strategy and implementation, or they're researching AI and trying to figure out what kind of things it can do for them. Support Vectors is a 100% AI-focused lab that delivers AI strategy, implementation, and training to our customers. In this video series, which will be released every other Monday, starting today, we'll learn from a true expert in the field of machine learning, data science, and AI. His name is Asif Kumar, and he's the CEO and founder of Support Vectors. He's also a 30-plus year veteran of the technology space and has architected and been the driving force behind a number of very large, very successful AI ML products. Now, this series is meant to be, it's meant to acquaint those in the public who are not aware of what AI is with its capabilities. It's also meant to give those who might be working in the space a bit of a sounding board for them to express and share their ideas and thoughts via the comment section. Now, if there are any questions that you'd like to ask Asif directly and maybe have us answer on the show, please reach out to info at supportvectors.com and in the subject line add questions for Asif now in this first video we'll be introduced to Asif himself and his background and then he and I will explore the history and evolution of AI. Now, this is being presented as a conversation amongst friends, which, you know, we obviously are. It just so happens that one of those friends is an AI expert and the other one knows very little about it. So hopefully, through these conversations, we can give you, the audience, the information that you're looking for. All right. Well, without any further ado, here we go. AI and a cup of coffee. I hope you guys enjoy. I want to thank you for inviting me to this talk. I come from India, as my accent should give away. Many, many years ago, when I was very young, right after college, I finished my engineering from one of the IITs, and I came to US to do my doctoral studies and got involved with research, and I stayed back in this country. I worked at many places for a small stint. I worked at NASA and National Center for Computing Apps. Then I worked with a company called civil systems that doesn't exist anymore we used to make a crm software it got acquired by Oracle then I worked in Oracle doing data mining machine learning in one of their databases s, multi-dimensional analysis database. After that, I got very interested in applying AI to new domains. And so I joined a startup as the chief architect and the VP. We built that startup, Evolve, up to do what I thought was, what we felt was pioneering work in studying employee workplaces and happiness factors and attrition and so on and so forth. That work was recognized by the White House, the United States presidential, and it became surprisingly successful. As all successful startups go, its fate was to get acquired. It got acquired by a big giant, Cornerstone and Demand, where my mandate was to lead the machine learning AI division and essentially see how AI could be used to transform the learning experience in the workplace, the workforce training. We did that and we had some pretty good results and that we did I was there for many years eight years and after that I started support vectors now while I was doing all of this engineering I did have a dual life of starts through in graduate school I used to teach and I would love teaching, as many graduate students do, their teaching assistants and instructors and so on and so forth. And the students liked it, so I wanted to continue doing that. So along with my engineering career, I also continued to teach engineering. I did that at University of California Berkeley Extension. Then later on, I founded Support Vectors initially as an AI training lab. And now I'm full-time on it. And we do AI strategy. We do AI implementations and AI training. This is right here in Silicon Valley, very close to the Tesla headquarters. And we have been fortunate to have some of the very, very bright engineers from Silicon Valley streamed through this place over the years. Over 1,200 engineers have been through this. And they are all, a lot of them are obviously doing very, very good work. Some went on to found new startups of their own, successful startups. Some went on to work for Fang. Some came from Fang to get further trained in AI and so on and so forth so that's been our trajectory yeah and that's been it's it's awesome you know as now being a part of the team it's you know to feel the energy and the things that we're trying to do and the message that we're trying to put out around surrounding AI and stuff like that that's you know it's been amazing for the period of time that I've been here thus far and look forward, obviously, to a lot more growth moving forward. This particular video series, Asif, as you know, we've discussed it, is about awareness of AI, you know, and talking to people and, you know, kind of, I'm a novice when it comes to AI. You know, I do sit in some of the trainings and I, you know, kind of, I'm a, I'm a novice when it comes to AI, you know, I do sit in some of the, of the trainings and I, you know, I get lost and things like that, but I like to hear the conversations that are happening. And so this is set up as a, you know, as kind of a, a weekly or bi-weekly conversation between an expert yourself and a novice myself and you know and allowing some of the newer things that are happening in AI to drive you know drive us a little bit in our in our conversation today's today's particular episode though you know is going to be around the beginning right like where did AI come from what you know how did did it evolve? Where is it going? You know, and that type of stuff. And this is, and I want to make something clear to the people that might be listening or watching. You know, this is according to Asif Kumar, who has had a very strong career, you know, in the very beginning of things, you know, in the very beginning of AI and machine learning and stuff like that, who has had a history in building and building successful softwares and AI softwares and things like that. So with that being the case, Asif, talk to us about the beginning. Where did AI come from? Why is it here? What's the evolution of it? How have we arrived here? of it? How have we arrived here? AI, like many of the transformation technologies that we see today, one can say that it does have many fathers. It has been enriched from the traditions of statistics, from mathematical physics, computer science from even and many practical domains like geology medicine and so forth so it's a little hard to tell where specifically the contributions came but we can talk to the history of it the notion that we we should have artificial intelligence goes way way back I suppose it's at the core of human nature ever since we have been on Earth we have wondered can we create things creatures and endow them with intelligence in just about every civilization in every culture you see narratives going back hundreds of years or thousands of years that speak to this. For example, if you look at the Arabian Nights and the story of Aladdin and the magic lamp, it was about rubbing a magic lamp and out of it would come the superhuman character that could do anything you want and it and it would understand you it would exhibit qualities of intelligence likewise if you look at the uh for example until if you look at the hebrew tradition from what i understand there is a there's a concept of golem which is with clay, you can build the likeness of a human being. And under sufficiently specific conditions, certain individuals could breathe intelligence into that. Then it could do whatever you asked it to do. And the interesting thing is that it would do with superhuman ability what you asked it to do but it came with attendant risks it's a dangerous creature to bring into existence and so even before we had artificial intelligence this entire debate whether such a thing would be a force for the good or the evil was already around we have the story of frankenstein yeah right and and so forth. But in practical terms, while these stories have imbued, you look at, you know, the Wizard of Oz and the Tin Man. So these stories have been around for a very, very long time. They are part of all cultures. In practical terms, people have been, and genius have been trying to create this. If you look at Charles Babbage and his so called analytical engine, he was trying to create an artificial intelligence, it was not his goal to create a better abacus to do arithmetic smarter. It was to create or just and what today we would just call a calculator. His aim was to create an intelligent machine. And I believe right in that generation, and if my history is right, perhaps, closely associated with him, were people like Ada Lovelace, and so forth, who were busy creating or thinking up languages and constructs that would go into artificial intelligence. This is way before any of these machines came about. If you look at Alan Turing, the great mathematician who would break the Enigma code and his project and can be rightly attributed as a creator of the first practical machine. The so-called Turing machine is a computer today, the modern day computer. His goal was not, once again, just to break the Enigma code. It wasn't just to create a big calculator or tabulator. His goal or his aspiration was to create artificial intelligence. Now, while his aspirations have been there, it is clear that the things holding it back have been two things, computing resources, computing power. In the 1950s, there was a program in which they sat down very seriously. They had a conference in which they sat down and they said, all right, let's go and create artificial intelligence. And there was a lot of euphoria at that time. They thought they could do it in a few years. Minsky, I believe, believed that in five to eight years, we will have intelligences far superior to human beings. But as they peel the onion of engineering, they realize that they were very thorny there were core problems out there for which you needed far more computing power far more data right and frankly far more breakthroughs we didn't have the mathematical breakthroughs the algorithmic breakthroughs at that time in the 1980s or late 70s and 80s, once again, there was a renaissance. People began to look very seriously at Geoffrey Hinton and so forth that started creating neural networks. Those were simple neural networks. But if you go back and look at what they were creating, quite remarkably, the first uses they made of the neural network they created was a language model. That is a remarkable thing because today, what a language model is, everybody in the world seems to know. It is all about chat, GPT, and large language models. Well, those language models were not big, obviously. They were small circuits and small code with a few neurons, a layer of small neurons. But they were still trying to create a very specific language model. So today, you could say since then, many things have happened since the 80s. First, computing power, we have been blessed in a way with a successful reign of Moore's's law and the reign of Moore's law has not been over despite everyone's skepticism the Moore's law is still going strong in one form or the other the computing power accessible to us is doubling in very short intervals of 18 months, two years, give or take. And obviously the price of computing has been going down. So with all of this computing becoming available, now we can build fairly complicated algorithms and churn, do the computations with that. A few years ago, we wouldn't have thought of with impunity, multiplying matrices that were billion by billion or something like that, very large matrices or things like that, dealing with weights and biases that were extremely large. We don't do billion by billion, but like creating a neural network with billions of parameters, many, many layers, and still doing fairly large matrix inversions, like a thousand by thousand or something like that, or 10,000 or whatever the large numbers are. Today, we just take it for granted, those numbers don't even look very big to us. 1000 by 1000 matrix you want to multiply with, it's a piece of cake, essentially. So computing power has evolved. Along the way, data has become more accessible. If you were to pick up a textbook, or even a so called data mining or machine learning textbook from a few years ago, just a couple of decades ago, almost all the homeworks I remember in my grad school days, the homeworks in machine learning would deal with a data sets that used to be like 1000 instances of data. And that was already getting maybe 10,000 and you're pushing the limit. Today, we deal with data sets, which are in billions. And we don't think much about it. So the data has become we live in the world of big data. Big data came with the web tour with the social engagement, social interaction, when there was a flattening. Everybody was both a consumer and a creator of data. And human beings are a gregarious species. We talk, we opine, we discuss. And so through all of that, vast quantities of data emerged, the social data emerged. Not only that, the IoT, the Internet of Things and the industrial, the computers getting embedded into just about all machinery with their sensors and actuators meant yet another torrent of data becoming accessible. For example, when an airplane flies coast to coast in the United States, in one flight, it generates a few terabytes of data, a single flight. So we are, and so many flights keep buzzing all over the united states every time all the time so one can just imagine how much data is being generated you look at a particle accelerator atom smashing experiments and it generates vast treasure troughs of data with gems and discoveries buried in there so data has become plentiful with it computing power has become plentiful. With it, computing power has become plentiful. And there has been fundamental generational breakthroughs in machine learning, in artificial intelligence. So it is almost a happy coming together. Yeah, kind of confluence. We have many, many forces, each of which was a stumbling block we didn't have enough data a few decades ago we didn't have enough computing power a few tickets and when we look back some of the crucial breakthroughs in the algorithmic space in the mathematical space that is needed to empower this we did not have all we had was a big dream that we should have artificial intelligence, that it should be possible. But today, we have an opposite situation. People are amazed. Even researchers are completely taken by surprise at the tremendous power that some of these new AI models are exhibiting. So it's been a very, very long journey and suddenly pieces are falling in place today. Sure. Yeah. So one of the questions that I would, you know, that I'd ask is what, you know, you mentioned that it's kind of human nature to, you know, to push in this direction, to, you know, see these, you know, artificial, we'll call them machines or things like we talked about Gollum and stuff like that in the Hebrew tradition and stuff, where we take these not human things and try to put intelligence into them, right? And what role would you say fiction, right? F fiction has played like so you you brought up Frankenstein you know the the you know and that that type of thing you know is is you know we seem to have an idea and then we put it onto paper we put it into a movie and then that kind of fosters things what is the role do you think that those types of that that type of you know thing has played in in the development of what we have today because we had a movie right a little while back called AI with Will Smith and you know there was there was a movie called AI and you know and that people are kind of freaking out now about it and stuff what role do you think that plays or do you think there's always been this technical actual approach to ai that might have been more the inspiration for the movie rather than the movie for the you know for the for the thing i would say that see two two aspects first of all the narratives the storytelling has not only been way ahead of the science and the technology, they have been nourishing the development of science and technology. So Alan Turing and the generation that were very keen on building these computers, they were already deeply influenced by the possibilities of AI, if we could create it. So it has always been the case, as I said, that the human aspiration to have AI or to even understand its sociological implications, its risks and its possibilities has been generations ahead of what we could actually do. If you think about it, and this is very close, near me is Tesla. Tesla started out by being super confident that in a couple of years, they would have self-driven cars. AI would take over and drive the car fully, fully self-driven cars. From what I understand, they even took bookings for it. And people paid real money for that. that it takes it took a while to realize that it's actually a much harder problem than we had thought and it harks back to the early days throughout AI's history we have aspired to do things things have seemed very possible and then as you peel the onion it turns out sometimes that you can do it it's very it is very possible and that those are moments of celebration. And then there are times when you realize that you can't. You hit, you find a tough core to crack in there. And it takes a bit longer, but it does eventually get cracked. So if you were to ask, would self-driven cars be a reality? Possibly in our lifetimes. It may not be on the very compacted timeframe that, for example, Tesla imagined. It may not be on the very compacted timeframe that, for example, Tesla imagined, but it will certainly, I would say, fairly plausibly be within our lifetimes, that some approximation to self-driven cars would be here. And so I feel that these stories, especially science fiction, and I'm a science fiction buff, I feel that narratives nourish and they are the nourishment often for the scientists and the engineers, for their minds and their imaginations. They have a very significant role to play. And in the case of AI, they're generally far ahead. Yeah, awesome. Yeah, that's absolutely true. And where do you think for now, like, with regard to AI and the things where we are today, and how we've arrived at where we are today? You know, what? At some point, we had the AI come out, and now we have the computing power. We have the mathematical breakthroughs. We have that kind of confluence of things that puts us into this position to actually have actual AI. What is the power of it today, right now, as of May 12, 2023? you know, as of, you know, as of May 12th, 2023, you know, are we at the, are we at the max of what we know today? Or is there stuff that that's probably out there, you know, more, more things that are kind of in the background that, no, you know, this thing is done, but you know, it just not, it hasn't hit mainstream or anything like that, you know. That's actually an excellent question. See, quite often we have to use a Dickinsonian phrase, the best of times in the worst of times. We have had rapid breakthroughs in progress. One of the core ideas, transformers came in the December of 2017, graph neural networks came. There are many, many breakthroughs. I'm just taking two as an example. 2014 was a big year when really some of the newer algorithms came into our own. Way before that, in the 1990s, the kernel machines, the kernel methods were a big, big breakthrough. Then came the ensemble methods. So the breakthroughs have been accumulating. There is, however, a feeling that, two sense of feeling. If you look at the zeitgeist has a sense of euphoria, a sense of irrational exuberance about what AI can do and how it will transform the world. Is it going to transform the world with what we have currently done? There is absolutely no doubt about it. We are the cusp of the transformation, but that is applied AI, the applications, the novel applications of the fundamental ideas, and so on and so forth. And that is going to take off. It is hard to even predict what the world will look like in two years. It's changing so fast. It may be the biggest revolution of our lifetime. We thought computers were the biggest thing. Then came the internet and we thought internet is the biggest revolution. Came the social media and the big data and we thought big data is the biggest evolution. Today, we are in the midst of AI revolution. And now we realize that the scale of this and the transformations that it will bring in the coming years in the very imminent coming years would could be could dwarf the scale of the industrial revolution itself yeah on the other hand if you talk to very serious researchers if you talk for example to jeffrey hinton if you talk to the likes of Noam Chomsky, who study, who have given a whole lifetime studying linguistics, and ask them, what is their opinion of these large language models? It's a study in contrast of what they have to say. Chomsky has persuasive arguments to say that, no, we are not there yet, by a long shot, right, in generating true AI. Jeffrey Hinton points out that backpropagation, which was discovered in some form earlier in the 50s, but really rediscovered with him and his groups and applied to actual neural networks in a practical way. So you could take, if you have to take a milestone at which it became really practical and used you could take his work and his team's work he point and it is the main engine driving the so-called neural networks that in the forward direction it makes a prediction it makes mistakes from the the way it learns from this prediction says it looks it propagates something called the error gradients, like what knobs you need to turn in the big machinery, the parameters you need to modify in order to make lesser errors. So that process is called, you do it using gradients. They have to back propagate sort of a wave that has to go back throughout the network and all the weights and parameters have to readjust to make lesser mistake and learn from the errors. So that's the learning part in machine learning. So he believes that while it has been a very effective tool, one crucial objection that he has is that biological systems don't use back propagation to the best, you know know because there is no forward and backward propagation of signal right to the best of our knowledge our nerves can have a signal transduction in the forward direction only right and so uh he has been vexed with this problem for a very very long time recently this is Jeffrey Hinton yeah And then he came up with a pretty remarkable paper, which was at the big conference in this field last November, December, in which he presented another algorithm, forward-forward algorithm, which manages to teach a neural network just using the forward direction propagation itself. It turns out that it was lost somewhat in the din of the big news of chat GPT. At that moment moment everybody was fascinated even now people are obviously it's a remarkable applied thing we are we all have a shiny new toy to play with and so his talk was slightly uh I would I would say um overlooked he made a pretty significant uh in my view a breakthrough so they're very serious scientists not just him they're very serious scientists not just him they're very serious scientists who are basically asking this question do we really understand how neural networks work we know the basics we know attention how attend the basic these are concepts used here attentions and the back propagations and so on and so forth broadly we know but what we don't know so forth. Broadly, we know, but what we don't know are the specific dynamics inside a neural network and what makes it learn things the way it is. There's an intense amount of research in trying to make head and tail of it. And that is the despair part of it. I believe Sam, the CEO of OpenAI made a statement recently, that while chat GPT and GPT-4 are remarkable things, it may be the end of the line for the current generation technology that went into building it. In other words, they have squeezed the lemon as much as they could. And we need new breakthroughs. And you sort of hear these quiet voices, serious voices saying this. So there is a different current, a different thinking amongst the researchers that we desperately need a breakthrough in understanding how these things work. So both currents are there. And these are two different perspectives. From a very applied perspective, we are at the beginning, at the cusp of great transformations yeah so that's that yeah that's amazing like some of the some of the things that you see is possible today you know like you know just last year for me you know just well since some of them just you know 10 minutes ago you're you're waking up and oh wow they can do that now you know and those and those things are just, are absolutely amazing. And the thing that technology is bringing, things that technology is bringing to bear, you know, in business and, you know, and in our personal lives, it actually really is, it's completely, you know, taking, you know, giving everybody kind of this left turn, if you would, you know, that they're all kind of taking right now. And AI happens to, is absolutely right smack in the middle of all of it. And it's part of the conversations that I have daily now, which is, you know, why do we do this if 10 minutes later that technology is going to be old, you know, or what's happening is going to be old. And so those are some of the conversations that are, you know, that are out there right now. But to kind of shift our focus to something that really does speak to a novice such as myself, what's your take on the fear that some people have? Some of the major players in AI, some of the fears that they have around artificial intelligence and some of the fears that they have around artificial intelligence and some of the things that could happen? Those fears are very legitimate. Let's put it this way. Whenever a powerful tool comes about, let's say nuclear technology gets created, it has a potential for tremendous good, and it has a potential for tremendous harm in the hands of bad actors. So generally, we do have enough time, governments come together, cool heads prevail, and treaties are signed, governance rules are created to handle it well so today for example we have had now close to 60 70 years or 80 years of relative peace in the world some have argued is because we have managed nuclear technology amongst the many many reasons better governance better cooperation between the governments and so forth and I would say United States has quite a role to play in that in creating a stable world they have really managed to could the right salt treaty and this and that to manage that technology which which can which unmanaged could have had devastating consequences it could have wiped life from the face of the earth likewise if you look at stem cell research when it came about it was quickly obvious that you could create designer babies you could create super soldiers and God knows what else you could create right and you could create all sorts of Chimera half human hive animal things like that and with crisper all of that do the possibilities remain yes but today you have the governments all came together they put governance there in place so that and there are no bad actors occasionally I heard once there was a story that some scientists some researcher in some country was a china somewhere created sort of misbehaved and broke the rule or the treaty and created some child or something like that a fixed child some something relatively small and the whole world frowned upon it including the government that country's government i forget which country so there's pretty good governance when there is good governance we see the positive side of it today without I mean nuclear medicine is is foundational we go and get MRIs done we do we go get positron emission tomographies and we get radiation therapy and so on and so forth the nuclear energy is supplying a lot of the power. It's one of the cleanest forms of power. And we have essentially managed the nuclear question, the potential of nuclear in a positive way. Likewise, we are using genetics and the possibilities of genetics engineering in a very positive way, right? Mostly positive way, I would say. The same needs to happen with AI. We have upon us a tool that has the potential for tremendous good and tremendous evil. Now, what today we have is unbelievably more powerful than what we had a decade ago. But just look at the technology that existed a decade ago. Those were the personalized recommender systems and things like that. And yet yet they were used to manipulate government democracies today it is it even has to look at it with relative hands to see globally there is a huge shift towards the let's say a little bit more medieval way of thinking uh everywhere a little bit more like reactionary or closing the doors. egalitarian thinking is and people are far more afraid. Throughout the world, if you look at, for example, in the US, if you look at the actual crime rate, it has been in steady decline for many, many decades. If you look at the people's perception of crime, in the imagination, crime has been growing crazily, and everybody is fortifying their homes with video cameras, the inside of their homes, the outside of their homes, their doors have very high tech locks now. And it has been so the perception people have angst about safety and security. Where is that coming from? It's because the information propagation and these news medias, they have figured out that they're money-making institutions. They will feed you any news that you would like to hear and will come back for more with so that they can advertise, show you more advertisements and make advertising revenues. So the AI has been at their disposal. And likewise, human beings have become addicted to the smartphones, to the social media. So what this has led to are a whole set of detrimental effects. For example, these houses which control those AIs, those social media systems and those other recommended systems and sales systems, etc., they have accumulated unprecedented wealth at an unprecedented rate. It's never been there. It's directly, one would say, to a large extent because of the use of AI. At the same time, most people around the world, they have benefited from that, but at the same time they have gotten far more addicted to and being controlled now right somebody asked me a question yesterday when i was giving my a lecture in the class they asked can ai be used for evil and you know something like skynet and controllers in the future and i had to tell the person that the future is long past for a decade now we have been manipulated and controlled by ai in the modern civilization in the contemporary civilization and that is using yesterday's technology can you can we imagine what harm it can do unless we manage it? What does large language models, this reinforcement learning with human feedback and all of these things that are emerging, what it can do if we don't put governance in place? So the great need here is there was a petition filed, repeatedly multiple petitions filed by various people saying, let's stop AI. That is not likely to happen there is a historical parallel the leudites during the Industrial Revolution in England they went about breaking machinery they did have a good point because if you look at the Industrial Revolution in England children were being chained to machines to hang to those and they were they were eating, sleeping there. Yeah. It was barbaric. The people who owned the means of production were, there was mercilessly profiteering at the expense of the common man. Then, and that was before there was a countervailing movement, a social movement to bring about a more egalitarian, a more just thing. And to the great credit of Europe and the Western world, it did put frameworks in place. Today we have the benefits of industrialisation, and one would argue that to the first approximation, it is a force for the good rather than a disaster. In the same way, but at that time when things were pretty bad the leudites came and they were after a genuine or mythical figure called general lud right which no one had seen apparently they went about breaking machines saying these are things for the evil did they have a point they absolutely had a, they wanted to stop the Industrial Revolution till this exploitation stopped. But that's not the right approach. You can't stop it. But what you can do is aggressively bring about reformation, reforms, and laws and frameworks to manage it. What I am seeing with AI is there are two opposite approaches. On the one hand, people are saying, oh, AI is for evil, let's stop. People are not going to stop. The good people may stop, the evil will continue to build it. And so what will happen is the evil will become more powerful at using it. The evil agents, the bad actors, you don't want that. So progress, scientific progress is hard to hard to stop but what you can do is gallop ahead really get serious at this moment the governments of the world need to get serious into creating the legal frameworks the law enforcement and reform everything in view of our ai world that has come upon us now yeah we We cannot have antiquated laws continue to govern this AI driven world anymore. We need to get very, very serious and reformulate things and bring about checks and balances. And that is strictly needed. If we don't, AI will destroy the world. Yeah. That's such an interesting thing, thing you know the that how you how you say it can be had for evil it can be had for good you know and and that it's kind of a the evolution of ai sounds like a continued evolution of the world right like of the history of the world you know it's just kind of where the world is going to go you know and it's always been heading in that direction right and there have been these key points in history the industrial revolution and those types of things and now we're just at this next one right with ai and you know and what what that can do and stuff like that and it's going to be a balancing act to keep it to where because like you said as of today the bad actors probably have access to it right the the bad actors probably have access to it and you know and so they're going to develop their things to try to you know to try to take advantage to try to you know steal and those types of things and that the counter to that has to be like you said a really hard gallop out in front of it to go you know by the by governments by you know by uh you know by municipalities and things like that it's it's an interesting thing because i'm i'm i'm generally a small government guy you know i'm i believe more like a small government but with the proliferation and with AI being put out there and and these really strong you have to have a very powerful mechanism to to battle that you know and where that mechanism is you know at this point it's kind of like the obvious thing would be for government to do it you know and so so we won't we won't go too far into those into that piece but you know but that is a very interesting thing and you know also if I think that as of you know for a for a first round of of this conversation you know the hopefully this you know our video series here I think this is this has been awesome and um you know really thank you for your time um and you know in our next you know we'll have we'll have another one in a week or two um where we'll talk a bit more about about ai and and some of the things that are happening right now you mentioned forward forward i know that's something that you had that you had a big interest in and you kind of worked some things about so maybe that's something that we'll we about in a future episode and stuff like that. Yes, I would love to. Yeah, great job. Thank you so much, Asif. Thank you.