 There is a concept called receiver operator characteristic curve, and I'm going to explain the receiver operator characteristic curve now. I don't know if you guys remotely can see me. Yeah, we can see you. Nice. So the topic is ROC, receiver operator characteristic. OC, Receiver Operator Characteristic, ROC curve. What is this? So for that, we have to step back a few years and look at it from a signal processing perspective in the old days what would happen is when you try to send digital signal over the wire it would go it wouldn't go as fiber optics it would go as electrical signals you would have high voltage or no voltage right higher low voltage so typically in my days it used to be plus five volts i don't know what it is or zero volts or, or maybe minus five volts. But let's take zero and plus five volts. If you received a five volt potential, you would consider it one. Otherwise, you would consider it zero. Are we together? And signal would come at a certain frequency so you would have to keep reading your zeros and ones so imagine a channel you're sending the signal you're sending either a high voltage or a low voltage in other words you're sending a zero or one what happens is by the time it is received here, the voltages, for a variety of reasons, they have become something between 0 and 5. Are we together? There are no more 5 volts or 0 volts. All sorts of reasons. It has degraded. Voltage has decreased. And now you have to infer, was it a 1 or a 0? So, in other words words imagine that y goes in and out of the box a y hat comes out right so you have to essentially you're sitting here and predicting what did you receive right up to a threshold you can say up to a certain threshold you will consider it to be one below a certain threshold let's say you can say up to 0.35 up to this otherwise I'll consider it zero zero right something the other, you have to decide. And based on whichever decision you made, right, you would have now your false positives. Do you see the same problem? You have the same confusion matrix, right? It is a 0 or a 1, and it is 0 hat or 1 hat. You are predicting, right? Right? So you have your confusion matrix and the threshold controls your metrics, like basically your true positive, false positive, etc, etc, are controlled by that. One easy way to not have false positive is to keep the threshold very high unless the voltage is 0.95 you consider it zero but then you start having a lot of false negatives right because a lot of truths become bigger once begin to go down as zero so you have a problem and so that is why in that context, this concept of a receiver operator characteristic curve. It says if you just randomly guess, it is like this. If you have something that is a bit better than that, and this is the false positive, true positive and here positive is literally positive voltage or one right and it is controlled by your threshold for different values of the threshold you'll have different false positive rate and different true positive rates are you seeing that and that is where the roc word came from and roc area and the roc curve came from very interesting isn't it right it's as simple as that right you you set a threshold and you do that now i'm tempted to say i would like to do Now, I'm tempted to say I would like to do linear discriminant analysis today, but not. Is there any other smaller topic I can do? So what I would like to do is I would like to, we have a little bit more time before we call it today. I would like you guys to ask questions. Do you have any questions on this topic? Okay, no, there's one last topic. Sorry. See, the thing is, we are predicting a probability, right? Given a P, we are doing a probability of cherry, given the data and given a certain parameters, sorry, certain parameter vector. You have built a model, given the input, it will produce a probability. But how do we decide what the classifier is expecting are words like cherry or blueberry? Isn't it? So this probability needs to be translated into this. How do you do that? You need to do what? You need to pick a threshold. And you can say if p is less than threshold, let's say less than equal to less than threshold, it is blueberry. Else, I mean, obviously the condition is p is greater than equal to threshold. It is cherry. Right? And it is the threshold, the value you select for the threshold that controls how like that your roc curve like it basically draws the rsc curve because it controls a true paul it is it controls the positivity negativity and all of that so let me ask this question suppose let's take a few use cases you want to screen people for a serious medical condition something like a malignant tumor right if it is a malignant tumor and you are screening people for it, you have a machine learning model that screens people for malignant tumor, where would you, if you have a probability of having the tumor, your model comes out with a certain probability, where would you like to put your threshold? To catch the cancer. your model comes out with a certain probability. Where would you like to put your threshold? To catch the cancer. To catch the cancer. Like at what point do you want to, a screening test should say the person needs to be looked at, examined more carefully. You put the threshold a little lower. Little lower, isn't it? In fact, you would put the threshold a little lower. Little lower, isn't it? In fact, you would put the threshold very low, even a 10% chance that the person has malignancy is scary enough, needs further testing, isn't it? Now, if you have been, if it is the final test, so the only people you get are people who are suspected of having cancer and you're going to do some very very serious operation let's say that will do permanent damage to the person but at least if it succeeds the person will live you are about to do that kind of a surgery at that moment where would you like to put the threshold before you take the person in for surgery? A lot higher. Very high right because there's way too much at stake if you're wrong. Likewise let's take another example suppose you I suppose all of you are moms and dads by now, and most of you are not all actually. Some of you are kids. I shouldn't say all. And we are middle class, most of us. So let's say that you have a finite amount of money in the bank for your children's education. Then comes a friend who is in dire need, or somebody, and says, can I please borrow money for one month? I will return it to you. And I need a few hundred thousand dollars, it's a crisis. For you, the problem is, you would like to loan the money to your friend, but in terms of priority of who should use the money, the money should be there so that your family, your own children can use it for education. That trumps frankly, right? But the children will get educated many years later. So the money is lying there, then your bank, let's say. So if you can get the best of both the worlds, give it to your friend, help him, help her, and get it back and then later on use it for your kids that's the best of both them so the question that you're trying to determine is should you give the money to your friend or not and the prop you're asking this question what is the probability that he'll return it now comes the question where would you put the threshold where would you put the threshold now that's a twist that reminds me of uh so such as saying it depends upon how much you love your kids reminds Reminds me of a saying by the Indian poet Tulsidas. One of his sayings that I remember, he used to say, means, if your son is good, if your children are good, son, your daughter, if your children are good, then why accumulate money? You don't need them. If on the other hand, your children turn out bad, once again, why accumulate money? They'll squander it, right? So anyway, leaving that aside, assuming that you love your kids and you're not philosophical, where would you put your threshold? Depends how much you care about your friend. Yeah, you would generally put it very high, right? Because if your friend doesn't return, you have your family, your family will be in a deep soup and you'll be reset. So you would like high probability, you would like to help your friend, but you would like a high probability that his assurances will be kept that he will return or she will return the money right so i mean that's the way people think now imagine that you're a banker you want to give a loan where would you put a threshold that your loan your banks of course have infinite money huge number approximately you want to decide should you give a loan to a person and the only deciding factor in loans is whether the person will eventually repair or not where would you where would you put the threshold why low I think at least from the recent economic thing the guy who got the I think, at least from the recent economic thing, the guy who got the Nobel Prize, he said that the chance of people who you kind of feel that never will pay back was like 10 times higher than they were giving back as opposed to... No, no, that is about social biases, right? But suppose you knew objectively, you could put an objective probability that about how likely is a person to return your money, then what would you do? Where would you put it? I think medium, so that you can give them more money. And very likely at the end, even bank will lose some money, but overall, they'll gain the money. So collateralized lending, I'll put it very low yeah yeah so what happens actually is without collateral or without these things even then the experience of the industry this is and the reason I brought this example is this is where it gets complicated see for a bank you want to put the threshold very low because most of the money a lot of these lending people make not from the rich the rich unfortunately pay back the money and they don't hold the loan for long even if they take a 30-year loan they will pay it off in a few years most of the money is made by people who cannot return the principal but forever keep paying the the interest not only that who miss payments and you charge them punitive punitive and criminal amounts of late fees right in fact this was uh our senator uh what's her name warren elizabeth Elizabeth Warren. She wrote a book that I love very much. Actually, our past president has spoiled everything. He called her Pocahontas and it's just terrible. It just sticks to your mind. But Elizabeth Warren was a really amazing scholar and researched this topic and she was looking into banking loans. So once she sat at a table where she was making the point that the poor people are not able to afford to repay the loan. You need to not charge such punitive damages and this and that. And a lot of people were debating it. And then apparently it was a long boardroom and there was this quiet old man sitting at the head of the table quietly listening to all of that and then he spoke and then of course everybody went silent he says we simply cannot do it because most of our profit comes from the poor people from the interest and much more so from the punitive damages we hope that they default and when they default we charge them lots of penalties have you noticed that your penalty for uh late payment has gone up on the occasional trip time you make a trip to india or something and you miss your payment it becomes terrible right not only that uh most of these teaser rates credit cards will give you teaser rates they don't have collateral they'll give you teaser rates these are don't have collateral. They'll give you teaser rates. Teaser rates will say 3% or 4% or whatever it is for two years. But in the fine print, there is a statement saying that if you miss a single payment, if you're just late for it, immediately it shoots up to ridiculous values like 35%. So the entire system is gamed in such a way that you squeeze from the people whose probability of returning is not zero, but it is very low. They stay trapped. Student loans, too. Say that again, Kate, please. Student loans. It's a racket she's trying to address, too. Yes, yes. That is right. The student loan, I would say interest rate is fairly low here the racket is universities are i mean convincing people to take out massive loans isn't it and giving substandard education not what the not what the price they charge and people are saddled with debt for life so anyway the point i was making is this saddled with debt for life. So anyway, the point I was making is this threshold that we set, don't just assume it's always 50%. Where the threshold is, you have to do another curve. You have to plot something, let's say accuracy, against different values of the threshold and see where is it that you get it right. And also, many real- world economic and other factors kick in yeah real life consideration kicks in cancer you cannot take chance you have to have your threshold very low in a screening test because what the worst will happen you will scare a person and say we need to be we need to look at something go for further tests the further test will prove that nothing is wrong with this person this person will at the end of it go through a bit of rough days and then be fine again on the other hand if you miss a person with cancer or early stage cancer it becomes late stage cancer and you lose the person forever i mean the person dies so um that's how you value or evaluate where to put threshold. You have to look at the real business situation and decide. It's very, very important to do that. Are we together guys? So that is it. With that, I would like to, today I kept it a little shorter because we covered a lot of territory. Actually, I was going to do the linear disc the discriminant analysis itself but i would rather keep it for a separate tuesday session it will be more digestible if we keep a topic for it but i am open to doing it right today itself so i want some level of voting uh one of you kate could you please see how many votes we are getting for doing it right now instead of raising their hands and raising their hands in zoom yeah and anybody here who wants us to do it right now one do not see any hands raised yet okay i see two hands and on zoom any hands guys for having just finishing off the topic i'll keep you here for just two hours i see one hand raised one hand okay so three it's a minority guys i think it's better to hijack the tuesday uh paper reading and instead use it for lda yes how many is there anybody who absolutely cannot make it to Tuesday? If you can, let's split it up, guys. We covered a lot of territory. Let's review what we learned and take it from there. So let's see what we learned. We learned quite a bit today. We met out of the camera. Oh, I am out of the camera. sorry. Better? Yeah. Yeah. So actually, if you look today was a heavyweight concepts. We learned about the concept of, let's see. Yes. We learned today, we start, so we reviewed a lot of what we learned today we started so we reviewed a lot of what we learned last time then we learned how to consider one hypothesis superior to another we say look at the reality under which hypothesis the reality is more likely to happen right so Ram saysattle is a rainy place it rains three days and one day it doesn't and shiam says seattle is a desert so which of the two hypothesis is more likely to produce the data, three day rain and one day not. You realize that it is Ram's hypothesis. It is actually, Ram says it's 90% chance it will rain every day and Shyam says it's 10% chance it will rain every day. And so it turns out that Ram is correct more than like more than 10 times. Right? Even Ram's like, yeah, Shams is not 10%, 20%. Shams is 20%. So the one hypothesis superior to another with respect to the data, it says that this data is more likely under this hypothesis that is it that defines the concept of hypothesis the concept of a hypothesis is the joint probability of the data happening given a hypothesis so likelihood doesn't make sense in the abstract you can't say what is the likelihood that it will rain today. That is not likelihood, that is probability. To be more precise, that is probability. Because we are not taking any hypothesis under consideration. Likelihood only makes sense when there is a hypothesis under consideration. Are we together how likely is that given that hypothesis how likely is this observation to happen that is how you think about that's the distinction between likelihood and probability though in colloquial language in normal language people tend to mix the two up but now that you guys as data scientists you should never mix the two up so we looked at it and we said in linear regression something in logistic regression this is our equation uh which is our equation this is our equation since you can't see the mouse this is our equation so we need need to pick that set of, so now they are not Ram and Shyam. They are infinitely many people, each with a different hypothesis. In other words, there's an infinite family of hypothesis. You can pick any point in this three-dimensional beta naught, beta one, beta two plane, and each plane in the hypothesis world is a particular hypothesis. It's a particular model. And so given the data set, you have to ask the data favors which model, which of these hypotheses, which hypothesis is more likely to have produced this data. So you create the likelihood function, which is the joint probability of seeing the evidence under the hypothesis. And then you ask which hypothesis, the beta star is that optimal hypothesis, the optimal parameters that maximizes the likelihood function. And that's why they said the maximum likelihood estimation. We went on a tangent talking about maximum a posteriori, starting with the fact that there's a prior belief, then there is a likelihood of under that belief of seeing the data, that belief producing the data that has actually happened and multiplying the two together to get up to a proportionality constant, getting the a posteriori belief. So we will deal with that when we do the math of data science. By the way, the registration for math of data science is opening. Those of you who are interested, please send your name to Kyle or Kate or Harini, any of them. Please do that. Now, here's a caveat. I don't know. These are pandemic times. We may not have enough enrollment, or we may have too much enrollment. Before the pandemic, that was one class that used to get overfilled because there's a capacity limit. I don't allow more than 30 people into the room or into the session. It becomes the educational experience degrades. So should there be a situation that there won't be enough seat at this moment it doesn't look likely but who knows next year who knows but uh so if you want to reserve your place let let the TAs know that's all you have to do let the TAs know and which day are you doing it to see but to be decided we will take a vote on what people like best. Sometime in 2022, right? Definitely. So 2022, no more classes in 2020, 2021. All the classes are for 2022. So I'll be opening a formal registrations. If you feel like registering early, please do register early. There'll be some incentive to register early, or you can register when the time comes. But you must let us know and be aware that math of data science class is overdue and it is likely if economy recovers, it's likely to fill up fast. What would be covered in math for data science? In math of data science we will do multivariate calculus, we'll do vector like linear algebra, a lot of linear algebra and then we'll do a lot of probability from a Bayesian perspective. So we'll do Bayesian machine learning and Markov chain Monte Carlo and things like that. And those probability, linear algebra, I'm missing out on one more major area. The calculus probability. So you'll do a lot of multivariate calculus. You'll do a lot of probability or you'll do a lot of linear algebra. Basically, you will do a lot of the foundations that you'll need for deep learning along with it sounds great and of course after that many of the math that is hard here so generally people say that you know they take the machine learning, but then they gain real confidence in the topic after they do the math class. Because I make the math easy. I'll take real world examples and make the math easy. I think some of you have sat through the class. Would you like to give your feedback on it? Sachin, I think you have taken it before, isn't it? SACHIN TAMBWAKER- Yeah. What did you feel was the value of that class I think I took it simultaneously you did that Tuesdays and Thursdays right right right here it was a little bit of skew for me like a slip but I think the math was ridiculous so and I had to touch up the math but I think things were making sense so it was like what you did in linear you had covered it in the prior months itself right yeah it was like it was going a little bit backward for me but i guess most of the other people came who had done this one and then done the follow-up because yeah it made perfect sense yeah after doing this this course math is makes more sense for you. Kate, you also did it, isn't it? Would you like to share? Yes, it was very valuable. And I think it is important to, it's very good to be reviewed on that before the deep learning. So I'm wondering if it should just be planned to be concurrent with or? Yeah, I would, see here, unfortunately, i might have to make it concurrent because um deep learning is a long sequence i'm breaking it up actually into three four different courses so for that to finish in six months we have to move fast uh four courses which means that i will have to run the math along with the fundamentals of deep learning, which will feed directly into each other. One will feed directly into the other. Anyway, so that is it. So from that, we learned about the likelihood. We realized that to maximize likelihood is the same as to minimize the negative likelihood. Then comes a numerical problem. Multiplying probabilities, they all become zero when you have a lot of data. You don't want to do that. Instead, you want to have some sort of additive process. So it turns out log comes to the rescue because log converts multiplication to addition. It's a good thing. But is it legitimate to use log? It turns out it's legitimate to use log because logs is a monotonically increasing function right so it is perfectly legitimate we can use log and so we have a happy situation log will convert your multiplication to addition and it is legitimate to use it because it's a monotonically, monotonic function. And so all is well. And so when you apply negative log to the likelihood, that's why it's called negative log likelihood. And it is the loss function then becomes, taking the positive and negative cases, it becomes this, this thing, it becomes this thing. Then we have a little we have a little trick deliberately we set it y i value we stick in front because it's a mathematical convenience but not just that it turns out if you do this this term is well understood in information theory and many other areas and information these are deeper aspects of it feeds deeply into machine learning this is called cross entropy loss these are cross entropy terms and that is why because it's a sum over cross entropy terms this loss function is often called the cross entropy loss otherwise it's a long word negative log likelihood function right instead? Instead of saying that, it's just called a cross entropy loss, right? And so this is the final expression for the loss function. So this is it. Now we have a loss function for classification with the regularization. And we have a loss function for regression with regularization. We have a loss function for classification. And how do I regularize this, guys? What would I need to do? Just add the same constraint surface, you know? Circular, ridge regression. Yeah, this is important. Let me write it as a separate topic. The moment you write the loss function like this what happens is that the rest of the equation it is still a linear loss function i invite you to plot it out and see what it all comes out to be but basically the same reasoning applies this is circular constraint is a ridge regularization. L2 norm. Remember, this is the Euclidean, many words that I can use to create recollection. On the other hand, if it is this, what is this? Lassu. Lassu. And which norm is it? LASU. LASU. And which norm is it? L1 norm, right? Manhattan. And you can do all sorts of mixes in between, add different kinds of norms, but those things you can again go and add to the loss function. So that is that. Now we learned more. After the cross entropy loss, we realized that something very interesting. How come we talk about likelihood functions here in classifiers and we didn't talk in regression? The answer is actually we do. The reason when we did regression, I used a hand-waving argument that if you square the residual errors, it's a good idea. It becomes positive. It treats the outliers, big mistakes seriously, and so forth. You can do a more rigorous treatment using the maximum likelihood estimation argument. If you assume that errors are normally distributed, which we know to be true in most situations, then you can change it to something else anything that. R. Vijay Mohanaraman, Ph.D.: looks reasonable but under the normal distribution of bell curve distribution hypothesis of errors what happens is when you write the likelihood function. R. Vijay Mohanaraman, Ph.D.: Over the residuals it turns out that it leads you directly to through a little bit of very simple mathematics. The product of all of that, and when you take the negative log likelihood, you find that you're essentially left with the same thing. There's a constant term plus one over one over two sigma squared and the sum squared error. All of these constants don't matter in loss. So ultimately you realize that you recover the sum squared loss as a path for estimation. Are we together, guys? Great. Now, there is something more which I haven't taught you, which is in the math of data science. Actually, I did some hand waving here. I did some hand waving here. If you do it a little bit more carefully and use the biation sort of a perspective on it, you will realize that this loss function within a biation treatment will not only lead you to the sum squared loss, it will actually lead you to a sum squared loss plus regularization term. Remember that constrained surface? It comes out very naturally out of a biotin treatment. That will keep with the math for data science because enough math here.