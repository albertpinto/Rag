 All right, folks. So today is our first lab exercise. What we will assume is that you have a laptop here with you. We'll go through some basic steps today. First, we will make sure that you have the whole python the latest python installed if you have an older version of python now is a great time we'll go through the process and install the latest python environment we will install pytorch in your environment after we have installed these two things, we will download the project from the website, a course website. There is a little lab one as a zip file called lab one. We will download and open it up. And today what I will do is we will do some things very basic. We'll make sure that our background is in place. We remember something called numpy. We understand the basics of what a tensor is, what a multidimensional array is. And we'll do a few exercises. And then things that we learned in the lab. For example learned about linear regression we will do it we learned about gradient descent i'll show you how to do it and so on and so forth we will also learn about two new topics today one is uh explainable ai and one is otter. This is actually from, I wish I could have covered it on Monday, but we ran out of time. So I'll take some time now before we get into the labs. I'll take the first half an hour to explain what these two things are. All right. We will also have a quiz at the end of this session today. Quiz one, right? I wish you all better luck this time. we will also have a quiz at the end of this session today quiz one right i wish you all better luck this time and let's see remember with the quizzes do not be disappointed if you um get worried if you get a perfect zero it means that you're falling behind but if you get something like like a third or half the questions right in the beginning that is all right because you have just learned the topic the point is to get a reality check go back and review it right go back and watch the video and review the notes and review the lab notebooks and then again take the test once you understand it better right and and then again take the test once you understand it better. And progressively you'll get better and better at this quizzes. Likewise, we will give you some homeworks. Today's homework is simple, but in future those homeworks would be lapsed in themselves. The homeworks I invite you to do it as a group if you want to. Form your study group, do it together so that you don't feel discouraged. Remember that we are all there, the whole teaching faculty is here. We will support you through this. And again, there is a lot of volunteerism here. So anyone of you who are repeating the course, you're welcome to act as a step in and help each other out, help the new people out, please do step in. So with those words, I will, before we continue, I would like to talk about two topics. One, and so this is back to theory for some time, for half an hour. See, when we do machine learning, especially when we do predictive models, right, or supervised learning, as it is called, in which some input goes out and some inference, some prediction comes out, we have two phases. You train the model, and once you train the model, And once you train the model, then you sort of use that model to make inferences. You train the model with some label data, training data, but then you use it for inferences. When you use it for inferences, one of the fundamental questions that comes is, why did the machine come up with this prediction? Can you trust that particular prediction? Kyle, I think you have a screen. Oh, so one second. Give me one minute, guys. I think I have not turned on the monitor here. Oh, you did that, okay. You did that, okay. Thank you for remembering that. Yes, okay. So, I clearly am getting, so let me bring up my notebook and I will write it up again. Give me a second. Yes. These are the notes for last time. All right. So suppose you make a model which goes like y is equal to a plus bx, right? This model is very interpretable. All you're doing is there is an explanation of why you make a prediction. Sorry, there's something weird happening with the screen. Refresh. I don't know how to refresh it. Yes, much better. See, when you have data that is like this, and you make a simple model like this. This is a model of linear regression. A linear regression model is very explainable. You're seeing that there is a constant term. And actually, let me write it in the notation of our course. I can say it is W0. This is the bias term, plus w1 x, right, the first feature. Now, our w1 x, this is a straight line. Anybody, if you say that at a given x, Why did you predict y? This is y hat. Why did you say, let's say y hat is equal to 12. You can explain what the model was, how the model fits the data. So these sort of models are considered explainable models, very easily explainable models. Now, it turns out that while these models are very explainable, they are not all that powerful when it comes to very complicated situations, because as you realize, complicated situations are highly nonlinear. So for example, you may have a relationship that is something like this and a linear model wouldn't fit it. So you start using more complicated models. And if you have taken my previous courses, you know, you'll be, you'll do it. You'll be doing all sorts of very interesting models. You would be doing ensemble methods. Like random forest. And gradient boosting. XG boost. You would be doing kernel methods, like support vector machines, support vector machines. By the way, that's where the name of this particular our class comes from, support vectors. that's where the name of this particular our class comes from support vectors right i will so support vector machines you can use neighborhood methods and there are many many methods that you could use but the point with these things is these are very hard to explain. How do you explain to a business person why your random forest or XJBoost is predicting a certain value? So what happens is that you lose interpretability. A very simple interpretability is gone. There is more interpretability in simple models like decision tree, if you remember, decision trees, they give you much more interpretable model, but they suffer from problems. For example, a decision tree tends to have overfitting issues. You solve that by going to ensemble methods to random forest, or doing support vector machines and then there are many there there's a whole variety of algorithms out there that you could be using and what comes or what happens is a very interesting observation that the more complex you make the model the more powerful that you have let me just use the word powerful in a sort of hand-waving sense or common sense, business sense, or greater accuracy, greater predictive accuracy, predictive accuracy. And by the way, accuracy in a more general sense, not just classifier accuracy, but let's say regression, there's a mean squared error is, a mean squared loss is, error is low. Then what we notice is that simplicity, and then the other, the more, so on this side are the simple algorithms. It turns out that these are very complex algorithms. And as you go from simple to complex you tend to get a lot of predictive power but what you lose is interpretability so if this is the axis which is inter pretty ability if you look atability, then you will find that simple models like linear regression, which is here, they're highly interpretable, linear regression. So in this region are things like that and decision trees. decision trees, then as you go to more and more complex models, what happens is that you start getting very low interpretability. For very hard xg boost and by the time you get to neural networks are really complicated neural networks you are in trouble you get a situation like this highly highly deep neural networks deep neural networks you get neural networks, you get extreme power, but you don't get much interpretability. Because what do you explain? You say that, you know, I have this box, which is made up of layers and layers and layers of notes. And this box tells you that this is the prediction and you ask why and why is this real why why does it matter see let me give you a real situation there was a company that used to do something like a predictive hiring or tell you which candidates in a job to for recruiting you should look at from all the resumes that you get, right? So it would apply a neural network to do it. The problem was, and when they tested it out, they said that it works and this and that, they took the product to market. But when people use use that they observed and the company got sued because in u.s there are discrimination laws the protected classes you cannot discriminate based on age based on gender based on race and so on and so forth and so they were sued because it was claimed that this thing is violating the discrimination laws. It is preferentially picking one race over another, or one gender over another or something. So now the question is, how do you prove that it is not? In defense, the company claimed, look at our model. There is no way. We did not hardwire any bias into the model. Right. But that is not a proof that the bottle is not biased, because you may have taught the model with bias data. Right? You may have preferentially given it a lot of data in which you have, for example, let us just say that males tend to do better than get more higher than women do. Women have a higher rejection rate. If you feed such data, then what will the machine learn? We learn from evidence. We all learn from data. A good machine will intelligently conclude that well that's how it should be and so you have introduced bias into it right and that was indeed the case now the problem is it's extremely difficult to find bias in data it's very. We don't realize because frankly, the society that we live in today inherently has biases, discrimination, and see, there are two aspects to it. There is an aspiration. If you look at any country's constitution and its bill of rights and so on and so forth, especially of the United States, it is just absolutely superb there's great aspirations towards equality right racial equality and fairness gender equality and fairness and all sorts of laws to protect against ageism and so forth so the the aspiration is there to bring that about. There is also the reality. Reality is we have reached there only in half measures. Isn't it? It's a work in progress. The society is still a work in progress towards those idealized goals. And so when you gather real life data, you tend to pick up biases biases and you have to know what biases there are in data you cannot just say my model is so good see i have just a bunch of neurons and therefore it has no bias it must explain what it learned uh an architecture a neural architecture which is inherently unbiased learn something and it needs to prove that it doesn't have bias built into it. Are we together, guys? Right? There was another important case. I believe it was Amazon, which came out with a facial recognition technology. I think or something they called it. And the law enforcement community of the United States went all gaga over it, right? And they started using it to pick up. And then a researcher, I believe at Harvard or MIT, I forget, Columbia, I don't know. She did it. I mean, actually, I should remember that. She did amazing work. Joy Goulwini. It's hard to say her name. didn't i mean actually i should remember that she's she did amazing work hmm okay yes so let's call her joe joy joy joy so joel did an amazing piece of research a very simple experiment she took the faces of the black caucus in the congress in the cap Caucus in the Congress, in the Capitol Hill, all the Black congressmen and senators, and fed their faces into the recognitor, their pictures, to see what comes out. And guess what they were recognized as? They were recognized to be murderers and rapists and all sorts of criminals. This obviously did not humor the congress very much and they started investigating why this is happening and then if you really think why it happened well obviously amazon wasn't trying to do that create a biased system nobody does but if you think about it as software developers, you go to any of these software development campus, what do you find? The fact of life is mostly in software you find Caucasians, Southeast Asians and Asians. They're dominant in this area. So imagine those developers, they're trying to train a model and they need a picture database. What are they likely to do? They are likely to take pictures from the employee database. I'm just guessing. I don't know what happened. You take pictures from the employee database. So you will get very, very low samples of data, right, that belongs to it. And then you take pictures of some crime databases or whatever it is, and there you do see a disproportionate amount of incarceration of African-American people. And then suddenly it looks as though all blacks, I mean, the point is that what the machine will learn is that black means some sort of a criminal or something like that. It will identify it. So something like that must have happened. I don't know what really happened. I'm just sort of simplifying and making a guess. Most likely, they must have had a more deeper reason why things went awry. But it speaks to the fact that biases in neural networks can tear you apart right tear society apart it's very very dangerous to these days there is an irrational confidence in neural network models these are not infallible machines they are very fallible because most of the time the data that goes into them are tremendously biased data. It's extraordinarily hard to create unbiased data, especially when you look at societal aspects. Another story is told in this context, and I don't know whether it is true or not, but it has been told so many times that it is worth telling so the story goes that one fine day department of defense they looked at silicon valley and said these guys are up to all sorts of creative work let's do one thing can they create a machine a model that can tell in a theater of war whether a machine whether a vehicle is a military vehicle or is it a civilian vehicle why do they need it because you know when when you go out into the field in a in a battle zone you don't want to hit civilians right but you want to give any military vehicle pretty close scrutiny. So that's a pretty legitimate task. So they came to some Silicon Valley blocks, got hold of a startup and said, can you do that? And the startup says, in our sleep, right? We can do that. And so all we need is a lot of pictures of military vehicles and a lot of pictures of civilian vehicles, right? Because we need to train, we can show these examples to our neural network and train it. And by the way, we'll do a similar exercise today with pictures, but for animals. So they train the network, it worked fabulously in the lab. right and so the military came and they demonstrated see how well it works they they felt proud as punch then the military said all right we'll take it to the what we will do is we don't trust you we have brought another box of images this time you didn't train your network on this but now you tell us with whether these are military or civilian vehicles right and the neural network make perfect predictions near perfect predictions right so military was very impressed they took it up to the field but when they deployed that model in real life it was a disaster right so and then you scratch your head but why is it something that worked in the lab failed in real life the answer turned out to be quite can you guess what the answer could be what could be the answer why is it that something works fabulously in the lab and fails in the field by the way it's a very common thing as you know when you are in in pharmaceutical research it happens all the time drugs seem to work miracles in the lab and don't work in the field the environment yeah it's close yeah morning evening like yeah when you do evening lighting yes that's what it is. See, what happens is you can imagine what the military did. They asked their soldiers, gather pictures in order, gather pictures of military vehicles. Now, when do soldiers see military vehicles besides their own vehicle? In the morning, you know, before they have gone out into their tour of duty, they have, you know, gone. So all the military vehicles are parked in the base camp wherever it is the base military base and so it's very easy they all just go about with their cell phone taking pictures right and posting it happily and when do they see civilian vehicles when they're out in the field right in broad daylight this they can go taking snaps of civilian vehicles. And in the evening also, again, when they come back to base, it's usually low light conditions. In the daytime, it's high light conditions. And so what the neural network caught on to is it's very simple to classify. Just look at the amount of ambient lighting. Are you seeing that? And so that's how it was making prediction. So what it shows is that you may use the most sophisticated algorithm, but data will have subtle biases and those biases become obvious in hindsight. They don't become obvious right away. So what is the way out? For quite some time, people used to say that forget about interpretability. Do you need power or not? Do you need powerful algorithms or not? For quite some time, it flew, except now that we are beginning to discover what damage these powerful algorithms can do, we don't believe so anymore. It's a requirement, legal requirement often, that the models explain their inferences. So how do models explain their inferences? It turns out that it is a growing area of artificial intelligence, a very crucial area of AI. We are going to cover it in this course and one of our sessions will be devoted to interpretable AI. So the way it works is that, so let's say that you have a deep neural network. We have a way to tell, so suppose there's a deep neural network and we have a dog, right? How does a dog look? How does a dog look? Well, this is my dog. Let's say, right? So it may, and it's with its cute ears and so forth. So the AI may come and say, hey, I call it a dog because look at its face. This is the spot that I focused on. Right. Because it's this, I know it's a dog and not an elephant, for example. Right. If you're writing a classifier between a dog and an elephant, it might say, look at this. An elephant would have a trunk but this face looks so dog-like right so this is interpretability this is you you bring back inter pretty well that's quite a long word ability interpretability i hope i spelled it right. You create, what you do is you literally create a sort of neural network that are a reverse process. You ask it to explain points in the data that made it make the decision. Now, not all points are important. So for example, if there's a green grass here, obviously a green grass, clearly the AI learned to ignore it, isn't it? And it should say that it did not make a decision based on that. So the ability to do that is this big field of XAI or explainable AI. This is one big area that we will cover about, cover this at some point. The other interesting thing, topic that has emerged in today's contemporary neural networks is, look at this. We built, if you remember in TensorFlow last time, we were building a neural networks, right? Do you remember guys, we are playing with Tensor Playground. So we could, to solve a problem, we could do many layers, in one layer, many nodes, two layer, three, four layers. How do you decide how many layers? How do you decide how many nodes? How do you decide how many nodes? Even in that simple architecture, that was in our hands. All that the neural network could do is once you create your neural architecture of those nodes, develop the neural network, then you could train it. Do we remember that guys? From last time, right? So the one thing that remains in our hands and that the neural network doesn't learn you have to tell it is what is the structure of the neural network how many nodes per layer and so forth even in the simple case now as we discover more and more complicated neural networks for example convolutional neural networks and other neural networks, for example, convolutional neural networks and other neural networks, what happens is that the number of these, so these things are called hyperparameters, number of layers, the number of nodes in each layer, these are the hyperparameters. And one question is, what is the right hyperparameter that will give you the best predictive model? Because each change, if you add an extra layer, it's a different model that you're training. If you add more nodes to a layer, you again have a different model. Its accuracy will be different, isn't it? So what do you do? How do you decide how many nodes to have in each layer? How many layers to have in the neural network? Isn't it? So do we want to go back and look at that TensorFlow playground? Just for a minute to recap what I'm talking about. Let's do that. TensorFlow playground. Playground. Playground, yes. Yes, let's look at this problem. We created it with so many nodes. Why so many nodes? So if you remember right, we solved it with this. This led to a loss of 0.1, pretty much very low loss. It's a good model. But what happens if I decrease the number of hidden layers and decrease the number of neurons and I do this? You realize that this doesn't seem to have a very good chance of succeeding does it this clearly has a high loss and it won't succeed so how do you know which neural architecture to use there are some heuristics one thing that you could do is simply go about adding lots and lots of layers right and say well here i go but every time you make your neural architecture complex you're adding to the computational cost and you're also adding to the likelihood that you'll overfit the model you'll overfit the data sorry right your model will actually not be as good it will have remember the bias variance trade-off you'll start having variance problems unless you bring in tremendous amount of data that will sort of dampen down or suppress the overfitting right remember more data helps you regularize the model so that's what you do so between these now it's a pain for simple architectures like a fully connected feed forward network as we are dealing with it is okay you can experiment and play and do it but still it's a waste of time isn't there should be a way to discover these hyper parameters how many layers are best how many you know neurons per layer good. Wouldn't that be nice? Right? So there is an emerging field of neural network that is called automated machine learning. And this is achieving amazing, amazing, very impressive results. And automated machine learning is basically saying not only learn to classify the data, but first discover what is the best neural architecture? What is the best neural architecture that will solve this problem? People also call it as automated AI, but I will use the word machine learning because this word is much more standard in the industry and in Kenya. So what it says is that whenever there are lots of hyperparameters, what is the best learning rate? What is the best batch size? What is the best number of layers that you want to have? What is the best number of nodes in the layer? It's a good dropout rate and so on and so forth. There are many, many hyper parameters in the model. And you're saying, first discover the best architecture, which combination gives you the best architecture, and then also learn the best other things like learning rates, et cetera, and do it. So that is why there are topics in it called neural architecture search. Neural architecture, and just to think about it is amazing. What you're doing is you're creating a network whose job is to discover the best network, the best solver. Yeah, go ahead. What does it mean to architecture? It means number of layers and number of nodes how does your network look yeah not the parameters parameters are the weights that that you will learn hyper parameters is how many layers in your network what does your network look like like going back to this picture, where are we? We were there, the neural architecture search, where is it called? Give me a moment, I think. Yeah, so here, should it look like this? So should it look like this, Dhwani, or should it look like this? Or should it look like this? Dowani, or should it look like this? Or should it look like this? Do you see these are different networks. So each one of them is a neural architecture. We call it neural architecture, right? And so the question arises, which is the best neural architecture? Isn't it? Now, broadening the scope to most of machine learning. If you remember, neural networks are not the only way to solve a problem. You have linear regression, you have polynomial regression, you have random forest, decision trees, support vector machines, and so many, many algorithms that you learned about. Which of them best solves this problem? That also, the search for the best, and each of them has hyperparameters built in, isn't it? Polynomial regression, for example, what degree of polynomial should I use? That gives you the bias variance trade-offs. Should I use random forest? If I do, what should be the number of trees? And so on, how many number of estimators do I take? All of them have hyperparameters. So what happened, what used to happen is, it used to be a very tedious process. Our teams would divide and conquer. You take a bunch of data scientists and you say, you do linear regression, you do decision tree, you do random forest, you do this and solve the same problem. And then we'll compare which one works best. And each one of them would try to come to make the best model using that particular algorithm, do all the hyper parameter tunings and then come up with the best model. And then they would compare notes and pick the best. It often happens actually, this is the way most of the Kaggle competitions are won. They sort of divide, a team comes together, divides and conquer, quickly runs with it. But then has emerged this new field which is called automated machine learning, which can do this architecture search. And in, especially in neural networks, it's very important because neural architectures can be bizarrely big. They can have quite literally billions of neurons in it. This looks like baby compared to what you have in real world neural networks, right? So how do you decide on the parameters? How were those things discovered? So you need a technology that helps you do that and that technology is the world of automated machine learning. It contains topics, bias and optimization. So I mentioned it this time and there are other things in it. I mentioned it here because this may be, it may turn out that we may not have time to cover it in too much detail, automated machine learning, but you should know that these things exist. I will incorporate at least half a session on each of these topics so that you're introduced to it. Each of these topics actually are deep topics, right? And in a follow up, like when you go to the subsequent courses in the series, you will do it in greater depth. But i'm just going to introduce you to those topics in this, and you should know, and if you are interested, go read about it for the typing become aware of it, because this is important today. These are very important topics today. Now with that bit of today, I'll give you guys a very quick break of five, 10 minutes. If you want to grab your coffee, there's fresh Starbucks coffee here and snacks. And then after five minutes, we will continue and change, we'll change pace and move on to the shift and move to labs. Right? Pause, yes. See, I mentioned that when you build predictive models, supervised learning, what do you have to do? You have a pretty long journey. You have to first create a good architecture, isn't it? You have to decide how many neurons, et cetera, there will be, what will it look like. Once you have done that, then you have to train the network with lots and lots of data. and after you train you have a trained model given the train model now you can use it for inference it so turns out that models today the models that work for non like tabular data like for example if data is in table form as in rows and columns in a database then they are in a way much easier to handle but real life data is mostly unstructured data data comes to us as text data comes to us as pictures videos audio waveforms isn't it these are highly unstructured things they come to us as for example the social graph right facebook graph has what a three four billion human beings linked to each other linkedin all of these are giant social graphs right so molecular structures each molecule is a graph connecting the atoms and if you think well why why just grab why think of it as graph think of a protein a protein has gazillions of atoms and so it is a complex graph of And so it is a complex graph of atoms, the molecule, the protein molecule. So think of the DNA. It is a graph. So all of these structures, they come, the data presents itself, not necessarily as tables and columns. They present themselves in different ways. When you build neural architectures, there's a complex theory. And in fact, in this course, you will learn about it. You will learn about, you'll see that for convolutional networks, people used to predominantly use something, I mean, sorry, for images, people used to predominantly use convolutional networks. And now transformers are taking over, visual transformers are taking over. Now, these networks that actually work convolutional, besides the simple ones that you can create by hand, the ones that actually work, for example, if you look at a inception or one of these big networks they take more computing power than you and i have access to right so unless we are researchers who are willing to invest in a ten thousand dollar machine it would be hard for us to train those networks in fact that may not be enough to train. For example, a modern transformer takes thousands of machines running for many months before those models get trained. But you could ask this question. Suppose I've trained a model to, let us say, recognize animals, right? Can I use the model to just simply classify between a dog and an elephant, right? Would it be possible? I can use it in a slightly different area. And would it work? Or maybe use it in the same area. My use case falls within the general category with which it has been trained. If you're lucky, what can you do? You can just download the trained model, isn't it? The pre-trained model, you can get it and you could start using the pre-trained model. Use it for inference. That is actually very very, very successful approach. These days, using pre-trained models is something under-emphasized when people learn deep learning. They feel that their job is to go sit and create an architecture. But one of the things I want you to learn is that sometimes you don't have to do that part of the work. You just need to search and find the best architecture that is out there, which is the closest to solving your problem. May not solve your problem, but close to solving your problem, right? Because if you get that, then two things can happen. Either it matches your problem, in which case you just use it, or it doesn't match, but it's close. And then you do something called, you solve the last mile problem. It is mostly trained. It has all sorts of intelligences built in. And now you're doing the last mile training to distinguish or to, let's say it's a classifier problem. One of the projects you will do is you will go around in the neighborhood and take pictures of weeping below. You know the tree weeping below, right? And of the California pepper tree. Both of these are very common here in our neighborhood. So you will start from first principles and that's one of your, and you will create your own data set of those pictures. Then you will use, you will create a classifier that given a new picture of a tree, it tells whether it's a pepper tree or it's a weeping below, or it is neither. All right. So now if you think about it, how would you create a neural architecture for it? One is to create it from scratch. The other is say, you know what? Let me find a model that recognizes all sorts of things, trees, horses, dogs, et cetera. It is trained to just recognize a generic tree right and knows that it is different from a dog or a bus or a house or something like that let's take that model and now do a last mile training so that it very carefully distinguishes between a pepper tree and a weeping willow are we together so what did we? We took a model which is already learned and we transferred it to our problem. That's the language people use. And that is called transfer learning. Transfer learning is taking a pre-trained model and just doing the fine tuning, the last bit of things. So typically what you do is you have a big neural network, all the weights are pre-tuned, then you just shake up the, you just relax or open up for final training the last couple of layers. You say that these things can change, right? Open up a few layers, or maybe you can open up all of the whole network. Sometimes just opening up the last few layers is more than enough. And then you feed in your data, your little bit of data, because you won't have any data set. What will happen is you'll have maybe 100 or so pepper trees and 100 or so weeping willow pictures. And by the time you'll get tired of taking pictures. And yet, with that small data set you will be able to train your model that you downloaded to very accurately distinguish between pepper tree and weeping willow. Right, this is actually one of the project for this course project for this course that you will do in computer vision. one of the project for this course a project for this course that you will do in computer vision and it's not hard will help you uh as you make progress with this so what so that is what we are going to that is transfer learning now in the spirit of transfer learning we need let's i'll give you guys an example a trained model that we can use and get our things done so first of all let me introduce to a famous data set it is called the c4 data set right can you make that window uh large this is different size yeah okay so the secret data set, and I can make it even larger fonts. Is that better? Yeah, that's good. So if you look at this dataset, it's comprised of 80 million tiny images. So this is one of the things you and I will get bored after taking a hundred pictures. So it is quite an effort from the researchers to collect so many, many pictures. They have taken the pictures of objects, they have shrunk it down to a standard size of 32 by 32 pixels. So 32 by 32 pictures is, you can say, well, that's unimpressive. These days, modern cameras take mega, you know, what, 20 megapixels, 40 megapixel pictures and so forth. It turns out, and this is one of the very interesting facts, the neural networks today can, they don't need such high resolution pictures most of the time. They need it in some situations, medical situations, when you're looking at MRI images, x-rays, and so forth. But generally, smaller images with lesser number of pictures are enough. Because it turns out that both the human eye and the computer networks, neural networks, are able to distinguish between things even if it is just 32 pixels by 32 pictures i invite you to look at this can you tell aeroplanes do they look to you like aeroplanes isn't it automobiles you can tell looking at it that these are automobiles these are birds horses so this data set comes in various forms. The CIFAR 10, which is what we will use for our learning today, consists of 60,000 pictures. Right. And for each of the class, like there are 10 classes, what are those 10 classes? A truck, ship, horse, frog, dog, cat, cat bird automobile and so on and so forth right they can each of them have thousand images right and there is a separate uh so this data is split into like test batch is divided into five training batches and one test batch. Means 50,000 points are, 50,000 pictures are for training the model, 10,000 pictures are for validating that your model is correct. So this is how you use this. So this is something good. CIFAR is something you should now put in some effort to read about it and see what it is. You will often use CIFAR. People whenever they create a new algorithm and want to publish a research paper, they'll often run it against CIFAR. There are simpler data sets, image, like for example handwriting recognition and so forth, you will encounter them when you do the homework. So with this in place, what are we going to do today? Let's start into the labs. So first things first, I will go through a very quick primer on NumPy. I'll assume that you guys know NumPy. Is that a fair assumption? Most of you. Nonetheless, I'll go that you guys know numpy. Is that a fair assumption? Most of you. Nonetheless, I'll go through it. So what is numpy? Asif, could we also tell them where they could find these notebooks? This one, could you upload it to the course page? Okay, yeah, let's do that. What you do, if you go to the course page, well, I'm looking at it as admin, so I'm seeing more. Let me change my identity for a moment. Switch roles to manager, guest, student. Okay. Now what do I see? Quiz. Oh, you have exposed all the quizzes, is it? No, no, I haven't. You have it. Okay, only one. This, I think, is probably the old course. Oh, I'm looking at the old course. You're right. So did I deep learning foundations? Indeed. Oh, goodness, I have uploaded the latest file to the wrong place. I have to fix that. All right. So if you look at this and you go to labs and homework, session recordings after that. So I need to take this away. Yeah, I'll do that. So could you move this file from there to here so here are the here are all the files you'll find i haven't put the numpy file in the file so just add it whatever you don't see me doing kaya please keep it so this is a section where you'll find all the things and you will download we'll go through that exercise today in a few moments so what is numpy numpy is a a way to do fast computation see python comes built with an array right it's it's the list python and array are interchangeable words. Then you ask this question, why would you bother using a library for arrays? The reason is interesting. See when you do machine learning, you're doing numerical computations and lots and lots of them. When you do lots and lots of computations, you need to have optimizations at two places. First, your software must be really optimized. Be able to do matrix multiplication extremely fast or tensor multiplication, multidimensional matrices, tensors, tensor multiplication extremely fast. And obviously, you need good hardware right now python is literally a few hundred times to a thousand times slower than languages that are dedicated to math it turns out that most of the mathematical routines were written in Fortran. So when I was your age, Fortran was dominant. It is still dominant. People tend to think it's gone, it's not. In research communities, it is still very much used. For example, your ocean current simulations, your weather simulations are still, and nuclear simulations are still Python. I'm sorry, still Fortran. So Fortran is an extremely fast language. Compared to it, people used to worry that when people said, let's write these computations in C, numerical computations in C, there was actually a worry in those days in the community that won't it be too slow, right? Today, we consider C to be a very fast language, but actually Fortran is even today faster, right? So when you look at these two languages and libraries written on it, these libraries have been created over 30 years, right? 30 years or 40 years. They have been in evolution for a very, very long time, even more, maybe some 50 years they have been in evolution for a very very long time even more maybe some 50 years they have been evolving now mathematical libraries are very very hard to get right software business software you can get right in a year or two right you can read out bugs or so forth but some of these mathematical routines are extremely hard to eliminate the corner cases i'll give you an example if you have to find the average of two numbers, how would you do that? So suppose you have x and y, you would say x plus y over two, isn't it? Right? But it turns out that if you were to do that, it wouldn't be correct, surprisingly. Why? can you guess why x plus y wouldn't be correct over two see it is subtle it escaped people for many many years so is it because of the float float number it is the size of it because if whether it is integer or float or whatever it is the computer doesn't have infinite precision or or there is no such thing as infinity in a computer underflow issue right come again underflow issue right both of that overflow issue actually but okay i'm coming to that in a moment it should be x by 2 plus y by 2. yes in a moment i'll come to it it's a good guess but yeah in a moment i'll come here so um you re for every number the computer allocates so many number, the computer allocates so many bytes, right? And you have to fit that number in so many bytes. What it means is there is always a max limit to each data type, whether it is integer or float or long or double, there is always a limit. Because there is a limit to these, if a number, if your variables X and y happen to be close to those limits even one of them is close to the limit what will happen is when you add x plus y you'll overflow so the number will basically become something that is meaningless it is not really x plus y right so you have an overflow problem. So what you do for that situation is when you have that, you need to do one of two things. Now the opposite, so the people have tried many things, some implementation, like somebody said, X by two plus Y by two. But what if X is too small and pretty much close to the smallest that you can have then x by two can have sort of underflow issues so there are always this peculiar little dynamics that are there so there are many many ways of doing it usually x by 2 plus y by 2 is considered reasonably safe but you can look at the literature how much discussion people have done how to do it correctly and there is a correct way of doing it i believe the last i remember is it is x plus first you find the difference between y and x y minus x and take half the difference and then you say x plus half the difference is the middle of it is the average of it right you find the smaller of the X and Y, and then you add half the difference, right? So that's the correct way of doing it. So the point is, I don't know what the latest state-of-the-art way is, but the point is, even in something so simple as finding the average, there are subtleties involved, right? And these subtleties can, and this is the things that mathematicians are trained to look for, so they'll catch it. This, but there are many subtle issues in the code, in numerical computing that can trip you. So nobody in his right mind creates numerical libraries from scratch. So these libraries in Fortran call base blast and so forth, Linpack, LaPack, Atlas, they have gone through 30-40 years of maturity. So people build on those libraries. They're super fast. They're battle tested. Today we use it everywhere. The whole scientific and research community uses those so when python comes along or any new language comes along they just layer on top of it so for example matlab used to sit upon linpack labpack and so forth this fortran libraries there were good usable layers now python is a simple language it is far easier to learn python than fortran and c language it is far easier to learn python than fortran and c and most young generation has learned python so it's a way the approach that people take is you take a general purpose easy language and you create language bindings to the underlying fortran and c are we together you make it simpler and you you you expose a very pythonic interface to it pythonic library to it so such a library is numpy and it is extremely fast when you do any array or vector or matrix computations with it it's a blazingly fast and you don't want to ever do matrix operations with the traditional pythons built in lists and arrays that's the thing so we'll take an example it's also more intuitive so if I can it can intuitive. Vipul Khosla, Ph.D.: Oh goodness, so there is something on this machine that is not installed sorry I made the mistake of running this, but I will. I'll tell you guys what all things to install in a moment. This laptop I've just set up. Yeah, go ahead. Somebody. Yeah, in Python, actually, the overflow ender for issue is already taken care. We don't need to explicitly do that. In other languages, we do need to do that. But in Python, it's OK. They have taken care of it. Very, very interesting. Nice ways we do need to do that but in python it's okay they have taken care of it very very good interesting nice about python python is a well thought out language nice i didn't know that actually i learned something so uh let's look at the list so suppose you create two lists length and width and suppose you want to find the area so suppose you go you have so imagine that you're a land surveyor you go to five plots of land for each plot of land you measure its length and for each plot of land your method measures width and suppose you want to find the area of each plot of land what would you do you multiply each length by its width corresponding width simple problem so how would you do it in normal python you need to do the best that you can do is you can do it using a list comp list comprehension right if you are familiar with python code you would say that you would do it like that you can do it in other ways also, but this is perhaps the. easiest way that you can do it now look at it, it takes a little while to grasp what you have done for every element, so you have zip zip means for every first corresponding elements think of a zipper. the tooth are matched. So for every element in this list and in this list, do what? Call the first one x, call the second one y, and then multiply the two. And when you do that, you'll get the area which is here. Now, you would agree that it is worth noting that this is a bit harder to read than if you had done something like this. Wouldn't it be nice if you could have been able to do this, right? But Python won't allow you to do that. You can uncomment this and see what happens. If you try to uncomment this and run it, it will, ah, well, okay, I need to define length here. Right. It says can't multiply sequences, blah, blah, blah. So Python will protest. You cannot do that. I'll put a hash mark again next to it. But it would have been nice to be able to do that. Likewise, if you consider the knee, we need to find the perimeter of it. This is the formula, right? So you may be tempted to do something like this. But when you do that, you get, do you see what you get? The two lists get concatenated, then you get twice. Right. You get two times each of the lists get concatenated. This is not something that you expected. So in other words, normal Python list doesn't behave the way mathematicians intuitively think. Right. What you instead have to do is once again do this. Right. Now look at NumPy. is once again do this. Right? Now, look at NumPy. So NumPy is not only faster and battle-tested, it's actually more intuitive. We are going to do, we are going to create equivalent lists using NumPy. So NumPy length and NumPy width. You can convert any list, Python list, into a NumPy just doing np.array. Right? So NumPy is a library, I would exhort you, if you're not familiar with it, spend a lot of time becoming familiar with it. If you are to be a data scientist, you have to recognize this, the way you recognize your staple diet. You know, you have to be, this should be as familiar to you as apples and bananas. Get familiar with the functions in NumPy. Now, NumPy library has over 200 functions. You don't have to become familiar with all of them, but even about 10, 15. So get a cheat sheet for NumPy. That cheat sheet will give you most things. For example, sine, cosine, everything that you learned in your high school mathematics is there as a function. So you can just use it. Now let's look at this. Once again, we're trying to find the perimeter. Now look at it. If you want the area, you're just multiplying the two together. Do you see how intuitive it is? And if you want to find the perimeter, you can do that. You can do it in such a way. So the observations are, observe how the code feels more native to numerical computations of math, the way you would write math expressions. We are not doing element-wise, actually there's a typo here element wise operation instead we are doing vectorized computation directly on the vectors numpy arrays so what happens is not only is it more easy to understand we say that when we work with this and write it in this intuitive way we are are actually doing vectorized computation. What it means is these computations are pushed down to the underlying Fortran and C libraries. Are we together? And those libraries are blazingly fast. So they are actually done by the BLAST and LINPACK layers underneath it. So when the data sets are large, these vectorized operations are orders of magnitude faster than the element-wise operation in the Python interpreter. You don't want to do it in the Python interpreter, it's very slow. So now you could do some operations, for example, let's look at the area array that we created. We created this area here. let's work with that if you want to find the first element, you can say you know this is, you can index into it like an array but here's something intuitive can you say if you see area greater than 30 it will tell you which of these elements. match that condition or not isn Isn't that quite intuitive? Right? And if you want to come up with those elements, which are the plots of land, which are big, you can do it like this. And there are many intuitive things you can do. You should play around with it. Interestingly, NumPy also deals with non-homogeneous arrays. Use it carefully and with caution, all right? numpy also deals with non-homogeneous arrays. Use it carefully and with caution, all right? So for example, suppose you create an array, which is mix of numbers and booleans, true, false, then you should know what to expect. When you add them up, for example, true will be forced into a one, false will be forced into a zero, false will be forced into a 0. Right? And so you will get something like this. How do you do two-dimensional arrays? Quite simple. Nothing very different. You can create a two-dimensional array by giving each of the rows. When you give each of the rows, this is what you get. You can ask for the... And you first create it as a pi you create it like this and then give it make it a numpy array and you could have directly created it as a numpy array you can ask it to tell its shape declare its shape and it will tell you what is its shape and right uh where is it numpy print print okay so some of the prints have disappeared here the shape is uh here this is the shape two rows five columns is that correct the shape of this two rows five columns of this array and if you want to know what is the printed dimensions of the first one from zero to this. So things like that you can you can play around and print objects so you can do all sorts of operations, pretty much the same thing you could do with normal Python, you can do. Right. And now, NumPy statistics. It turns out that NumPumpy can do all sorts of statistical measures. Suppose you create the data, the dimensions thing, which is length and width. So the length and width are specified here. You can do things like that. Mean, median, correlation between the two, standard deviation, sum. All of these basic statistical operations come with it. You could do numerical array methods, you know, subtract. For example, x minus y and numpy dot subtract, they are the same thing. You can do that. So you could very intuitively take the dot product. You can say x dot y. So those are the nice, you can say x.y. So those are the nice things you can do. You can build, like if you use matplotlib to quickly, matplotlib is aware of NumPy. The point is you can pass it NumPy data naturally. And so for example, you can give it a histogram data and it will plot it for you. So there are more examples. You can plot some functions. This is an example of what NumPy contains, sine, cosine, et cetera. You can plot those. So NumPy is something I assume you are familiar with. And I hope you are waiting for me to continue beyond this we will post it to the course page in case you would like to have that the next one i would show is so now we come to pytorch see first one of the most popular libraries was tensorflow One of the most popular libraries was TensorFlow. That came out, TensorFlow 1.0. And a lot of us used to use TensorFlow 1.0 and it was rather non intuitive, hard to deal with. So then came a project called Keras, which calls itself Neural Networks for Humans, right? And the punchline there comes from the fact that TensorFlow is so hard to write that people wrote a proper layer over TensorFlow to make it easier, library to make it easier. Then TensorFlow 2.0 adopted Keras as the front end, right? It took a while. In between came the PyTorch library from Facebook. TensorFlow came from Google, PyTorch came from the Facebook, and it became a runaway success in research communities and widely adopted. Today, market share is more or less divided between Torch and TensorFlow. We will use PyTorch because we don't want to... TensorFlow is too low level, but even TensorFlow 2.0, I will give you as a separate example, but we'll use PyTorch as our primary language because you can see what is happening. You can debug, you can put breakpoints and see much more clearly how your network is getting trained and so on and so forth right so it is useful we'll do that now i want to why by torch the basic thing that it works with is something called tensor now if you remember ml100, the ML 200, the previous classes of machine learning, we used a library called scikit-learn. Most of the scikit-learn worked with NumPy, isn't it? NumPy libraries are great, but today the neural network as a field has become so complicated. So needs such powerful hardware. Actually, there are two places where the most of the expensive hardware goes these days. One is for that task of bit mining, which is the most useless thing to do. But anyway, people go about doing bit mining and they, it's an environmental disaster in my view. Okay, that, but the other thing people use it for is to train deep neural networks. So you can't do it on the CPU, the Intel CPUs or your AMD CPUs are not meant, they're general purpose computing units. So there are companies which make math co-processors effectively. It turns out that the video card that people use for gaming, it has a lot of math co-processing units built in. It does vector and matrix multiplications for that. And so it was an easy thing to say, let's repurpose it for deep learning. And that's what has happened. So people have gone further and further. It started by using the GPUs, the graphic cards, but then those graphic cards for the ai market they started putting dedicated tensor tensor multiplication primitives right into the silicon and that is what the latest generation so for example if you get nvidia 3090 or 3080 they all have tensor units built into them, dedicated silicon to do AI work. Then now, just now, NVIDIA has released the H100, which goes even further. Now what they're doing is they are optimized for one of these pre-trained units, like, you know, the transformers. They are optimized for transformer architectures, right? So it just shows the evolution, how fast AI is moving and how fast the hardware companies are catching up. So in simple terms, Torch, for our practical purposes, is a NumPy replacement or equivalent. Not a replacement. It's a complement that is GPU aware, that can work on GPUs very well in an optimal way. So the community that built Torch, obviously the developers of Torch, they did one thing which is very nice. They made the Torch API mirror NumPy API almost exactly right so anything that you're familiar with numpy you can call on torch py torch so today let's start by taking baby steps with py torch now just we'll walk through and then i'll make you guys do it it means that we have to set up your environment we'll do it in a moment. So consider some simple operation. Suppose you take a function like this. How would you write it in this math expression? Y is equal to this. How would you write it in numpy? First of all, you'll create lots of data points between minus pi and just some range of data, some by x range right let's go create 100 data points then for each data point each value of x you would compute a y does that look familiar guys you would compute the the same expression np dot exponential and p dot absolute x sine y we are just computing that value. And then you would plot it, three lines. You would go plot it. So guys, ponder over this and tell me if it looks hard to you. I hope it looks very, very straightforward if you're familiar with NumPy. Can we, anyone would like further explanation explanation or anyone is who is completely new to this. So now, let's see how does it look. If I were to do it using by torch instead. Look at this. Do you see any difference. Any difference? All I did is instead of np.linspace, I put torch.linspace, torch.x and so forth. And this is it. And the best part is, look at this. Matplotlib worked just fine with tensors. It is a huge boon actually to be able to work so fluently with all the existing libraries interchangeably between numpy and tensor it's a it's really a boon similarly you can do for a bell curve right so here is a pytorch version of the same thing you can do it so i won't go into more the point is that torch can live in the GPU, not just in the CPU. But not everything is supported. So suppose you take a more complicated function. Here is a NumPy function called SyncX. SyncX, which is sine X over X. NumPy version is this. All you have to say is np.sync. The last I checked, and maybe things have changed a torch doesn't have a touch dot sync you cannot call right so what you have to do is you have to call numpy itself inside it but you can make it work interchangeably and you'll get the same curve, right? So now this is your lab guys. You will at homework, create practice touch mathematical operations, play around with it, see how it works, create some matrices, make some plots. It's your first thing. So this is about PyTorch. Now, before we go into, so I'm going to walk you through and then help you set up the environment. Any questions so far, guys? And again, we are taking baby steps at this moment. Great. One more thing, guys. This is the website of PyTorch. This is the PyTorch website, right? I invite you to become over time, intimately familiar with it. It's a very active community of people who are developing PyTorch. New things keep happening all the time. You see that PyTorch 1.11 has come out, Dodge Data, many new things keep happening. Even I have to keep catching up with it, right? So I would have created my own library to do something. One year later, I come and see, oh, now they have also created it. So now I can throw away my library and use theirs. So this happens all the time. Become familiar now, and we will use it to do the installation in a moment. But by touch.org you should bookmark it definitely bookmark it. Please, Kaiser. Now that we have done that let's go and do transfer learning. Let's take the simplest case. Can we take a model? So I'll sort of read this out. It's useless to read it out, but I'll read it out for just in case you're not sitting and staring at the screen. There exists a very rich library of pre-trained models that provide remarkable predictive performance. Quite often they can be used as is. At other times they can be used to train only a small subset of the parameters such as the last layer or with small modifications. Since training of some of these models is computationally prohibitive, having them trained on well-known datasets available to us represents a huge time and computation saver. In this notebook, we will learn how to use the pre-trained models that have been trained on the massive ImageNet dataset. That's another huge dataset of pictures. In this simple exercise, we will not perform any modification to the model or any partial retraining. In this exercise, given an image to a few of the pre-trained models, and we will take, we give an image to a few of the models, and we see how well they perform in identifying the objects. This is thus a classification task, where the image is, where the input is an image and the output is a label such as parent right the labels comprise of this stanford's word net data sets the labels the labels are the standard data sets of so a lot of these standard data sets exist you'll become familiar with it so there's a bit of a warning for this make sure that you have enough disk space on your machine why is that when it downloads this industry trained models these models are ginormous sometimes they are one gig size half a gig size so just think of a neural network that has so many many parameters that's what you get and these are like, these are all great models will come to it. One of the things is when you download it, I'll help you do it, you need to point to the directory where code that you downloaded is. So So, now the way this lab is organized is, I've kept the main code in actual Python files and in Jupyter Notebook, and this is considered the best practice. In Jupyter Notebooks, you call those functions that you have written so that your Jupyter Notebook remains a clean notebook. It doesn't get cluttered with a lot of code. Right. So we have we have I hope the name says it all. We have an ImageNet recognizer. It will identify any picture that is there in the ImageNet. Then this will download a lot of models. So when you download the models, what will happen is, let me give you the idea of the models. AlexNet, each of these by the way is has been a landmark in computer vision, and in this field of deep learning. All of these names will look to you rather unfamiliar, but just consider these as pre-trained neural architectures. Are we together? These are pre-trained neural architectures. And by the way, a couple of years ago when I was giving this course, this wasn't there. This is a new addition to the system. So what we will do is that for each of these models, they're different sizes. So suppose you use AlexNet, ConfNet, DenseNet, or any one of them, they come in different sizes, small, medium, large. And you can see all of these different sizes of those models. And by the way, training of each of these has taken a lot of time. So it's good to just download it. When you download this model, here, as you can see, when you download it, these are large models. Do you see they're 44 MB? 500 MB. VGG 11 is 507 MB. Next one is even bigger. It sort of keeps getting on like this. Inception is 104 MB, right? So we ended up getting, and we just picked only a few models. I didn't take the transformer model, which also I should take. Vision transformer, I should add it to the list and see how well it performs. I leave that, maybe that's an exercise for you. In this list, we don't have the vision transformer. Add vision transformer here and see how it affects the accuracy. Please take this down as a homework. Now, when you do this, by the way, you have to download it only once. Once it is there on your machine, it will remain on your machine. Next time, you don't have to download. First time time you have to wait for it to download now on my machine for reasons it is it isn't quite working this is a laptop i just set up this environment there is some firewall that's preventing it from being re-downloaded or something like that is happening so we'll ignore this part now what happens is happens is I will, you can give it, what we do is you give it some image and you say, what is it? Give the top five guesses. The image that we gave in this particular case was, actually, this is not, when you look at the place, you see these two images we gave. This is the duck. If you go to this website, you'll find a duck. Oh, no, a dog. You find a dog, right? And I invite you to run it on your machine. On my machine, it's having a bit of a problem on this laptop. I need to find out why. Windows, I'm not very familiar with. I apologize. I'm mostly a Linux person. So for me, it's a learning exercise to make these things work in Windows. Let me just see. Do you see this dog? Actually, my dog looks so very similar to this dog. So I chose this one. Now, where's that card? The other one is a duck. I hope we recognize it as a duck. It's a mallard duck. And when you run this, you will be surprised, or maybe not surprised now that you have learned or heard so much about this very complicated neural networks, you'll be surprised how accurately each of these models identify it as a duck and a dog. So run it, we'll now do this exercise of running it but in a moment so this is an example guys wherever possible if you can download the models if a model exists on the internet a standard model use it by and large that is the approach today people in industry are increasingly using pre-existing models and doing fine tuning of it, the last mile training of it. This approach is called, what's it called? Transfer learning. This is transfer learning. You're transferring a model which was trained on one data set and now you're training it on your other smaller data set because the problems are somewhat similar it won't work if you do something entirely different for example you can't take an image classification model like this vgg net and start doing word classification you know give it a text and say tell me is it about science or is it about politics right it will do terribly i mean even if you could somehow squeeze it to do that i don't know but it would do terribly it's not meant to be used like that i don't know how you would make those words into images but okay one way or the other it wouldn't work that's the idea of transfer learning but now that you did transfer learning let us let us actually build a model that's real. So before I do that, let me show you the Python code that went into transfer learning. Where is the code? Oh, by the way, this same transfer learning is running in PyCharm. So what is PyCharm? This ID that you look at, it is PyCharm. In the community, the dominant IDs for Python work are PyCharm and some people are beginning to use VS Code because it's free. And then there is some people use Eclipse for it, but PyCharm and IntelliJ also, but IntelliJ when you use, you're actually using PyCharm underneath it, built into it. These are the dominant, IntelliJ slash PyCharm is it built into it. These are the dominant IntelliJ slash PyCharm is the dominant one. It has a community edition, which is more than enough for you to do your labs. And I'll show you how to download it today. Download PyCharm. So please take this as a homework. Download PyCharm and become familiar with it. Use it. Use the community edition. By the way, if you are a student in a university, then it is usually university will give you a free license to it. If you use a university email. If not, then you can go to the PyCharm website and claim that you are a university student, if your university doesn't have free, and they'll give you a steep discount. It is worth getting PyCharm professional if you want to do a lot of development. On the other hand, the PyCharm community, which is absolutely free, is good enough. So we will walk through this code. I'll start from the top. How did, remember in the, in the Jupyter Notebook we called ImageNetRecognizer. Do we remember that? We instantiated this class. What is this class about? It uses, by default, if you don't give it a pre-trained model, it will just use a ResNet-152, which is a small model by today's standards. Otherwise, it will take whichever model you give it. Then, what happens is that you need to create some transformations. Right? What are those transformations? Make sure that it's the right size and this and that. You will see that method, I've created it, create transformation, and then create labels and eval. At this moment, your exercise is to spend a lot of time trying to absorb this code. I'll walk you through. The main methods to look at is, first of all, classify an image. So given an image object, you take an image and you transform it by putting it through the composition. So this will resize and make sure it becomes 32 by 32 pixels right once you have done that you need to uh put it that whenever you feed it into a model it is not expecting just one data point it's expecting a batch of points so when you just give it one you just what you're doing is, you are basically creating a third axis, which has just one element, right? So that's that. You take this model. So this is all the PyTorch details. You have to gradually become familiar with it. And if it looks strange, don't worry. You become quite familiar. It's a pattern. It's not that every time you write code, will look different almost every time it looks the same. Right you're unscrupulous and I put little comments here now create a batch of a single image and then you put it through the pre trained model when you do the model you'll get a result. Right now, when you get the result you need to tell what is it, so this is a little bit bit of a code that says you know you hear you return the result, the result goes in here, what do you do with that you're seeing. parameters result, it is saying find the Max the most likely element right, so it will say the index of the most probable element is so what happens is it comes up with lots and lots of predictions it will say probability that it is a horse is this probability that it's a truck is this right probability that it's a house is this and then somewhere in there is a statement item in that matrix that says probability of a dog is this. And let's say that you fed in a dog. You want to know which row it is. You go to that row, and obviously you can get that particular row. Now, what you do is there is a function in machine learning called softmax. Softmax is something I may have introduced you to. Otherwise, in the next theory session, I'll introduce you to it. It basically, it's a mathematically rigorous way of taking a whole bunch of numbers and finding out the best, converting it to a probability and telling that, right? So what really happens is when you put it through these models, right? You get certain, the outputs are activations. Remember we said that the output of the neurons are the activations. So you can just imagine that there is a neuron that says, how likely is it that it's a dog? Right. The second one says how strongly it believes that it's a dog. Second word is how much house light up, how much truck lit up. So you have lots of these, think of them as bulbs of different brightness so what you need to do is you need a function first of all that converts all of those numbers into probabilities right probability so that it all goes as probabilities they all add up to one, right? And then it picks the biggest probability item, right? It attaches probabilities. And once you have probabilities, what can you do? You can go to the results, right? And you can like fill it up with those percentages, most likely. So here we are taking the top, I don't know how many results we are taking, percentage index. So this is the most likely. It will tell you what is the most likely item. This will give you the top-end guesses. This is the code. Now, when you look at this code, guys, you may say, oh, goodness, I have to learn Torch, PyTorch, right, which is a fact. The main exercise for this week is do your setup homework is and become familiar with pytorch go to the pytorch website and follow the tutorials they are very very well written tutorials right now to the extent that this is a fast moving course we wouldn't we wouldn't have the luxury of doing all of that slowly you need to move a little faster so it becomes an exercise for you to go catch up all of these are straightforward things if you study the tutorials for even three hours total you'll already be familiar this all will look very easy but you can at this moment just look at the function names it will tell you give me the top n top 10 guesses or so on and so forth so now look at this thing create labels so this is something image name you can ignore that it reads the labels this is the internal details of preparing the model and then what i did is i took an image which is a dog on my machine let's go and verify that i have a dog in my machine temp i have a directory called tam temp do you see i have a picture of a dog Do you see I have a picture of a dog? So I'm going to feed this dog into the model. Now, can you, any one of your dog lovers, can you tell which species of dog it is? It's a Labrador Retriever. That's right. So now let's see how well the model is predicted. Sonal, did you guess it? Nice. Good. How many of you don't have dogs? You don't have? Dhwani, you have a dog? You do have a dog. Everybody has a dog, except Dennis. So Dennis doesn't have one. You don't have one. Yeah, you said that okay no dogs now only cats. One old cat. Nice. California is the most dog friendly state, most people have dogs in this state than another so this code if i run this image through this and i ask it to make prediction so here's the thing the same code image net it will tell what models are there and then you say go classify this image and tell the most likely thing in the prediction so what happens this is what it comes out with first it tabulates all those just like in the jupiter notebook you saw the same thing here for some reason the jupiter notebook is at this moment failing out on me on this machine so it says that the most probable is the input is most like an image of Labrador retriever, right? With a probability of 80.69%. And then it goes on to say that, well, you know what? It could also have been a golden retriever. Now, those of you who are familiar with golden retriever, you know that they're close cousins, right? They look rather alike. And then there are other ones, I'll let you decide, but then it says it could be a tennis ball, right? Or a soccer ball, I mean, much lower probabilities, less than one person probabilities, right? So this is a neural network model in action are we together and this is resnet 152 so i will give you a task guys in this code by default you remember that by default what is the model that i took you know in the constructor that by default what is the model that i took you know in the constructor you you can give it a pre-trained model isn't it if you don't give it anything then it becomes resonate 152. resnet 152 by now is considered a baby model right and yet it's doing well try with all the other models that i mentioned here not all of them but pick a few of them in each category. Pick a slightly bigger model in each category. Pass it as arguments to, in this argument here, in the constructor, either here or in your Jupyter notebook, here, in the Jupyter notebook, somewhere here, wherever we do, okay, okay so network now where's my not linear regression we weren't on this the where is the transfer learning module one second there are too many files open c4 and c4 10 transfer learning linear regression no one two three no image net yeah imagine it so here it is go in there and in the constructor when you run it pre pre-trained models are this. Oh, here we are taking a sample image and you are making it ImageNet. You see this ImageNet model? You're doing it. So what you do is you feed more models. Actually, I've done it already. For each of these five models, I've taken these many models. I've taken these models. We have tried it. Now try it with more models. For example, try it with Vision Transformer. See how well it works. Those are the state of the art models. You'll have fun. Are we together? So this is your homework. Now, transfer learning, we are getting to a break, should be your first bet, guys. Just take it, use it if you can. Now, we are not doing any pre-training here. You may say all that is good, but what about creating our own neural networks? Won't we get the pleasure of creating our own neural networks? our own neural networks won't we get the pleasure of creating our own neural networks let's do that after the break we'll create our own neural network let's take a 10 10 minute break and come back and build our own neural networks we'll quickly walk through a linear model and after that we'll end this day with making sure that you all have a full setup. Otherwise we'll do an extra session tomorrow evening, in which we will make sure that your environments are properly set up. Are we together? We can do it, but we'll do it only if you fail to. There's a sort of like clinic hours. We'll start at something like eight or 9 PM, a couple of hours, and do a help you, help you set things up. So 10 minutes break, guys, and be back. Bit of time. So first of all, go and make sure you download this. The things that are visible as a student, let me see visibility as a student. I'm still seeing the same. Are we? Are you guys still seeing the same? Okay, how about this? I'll put it on Slack because... I'm getting the new one. You're getting the new one? Yeah. It says 18.5. Yeah. Try it again. I refreshed it. You did refresh it and still it's not... It says 18.5. Yeah. Try it again. I refreshed it. You did refresh it, and still it's not helping you. It still showed the older timestamp. Oh. Like that was updated. Timestamp is older. OK. It might be. Why would it do that? Hard to Navigation. Let me see. Gray Stigler and It's not supposed to be the September 9, 2020 No, now you should say 18 slash 5. see look uh let's say 18 left right now it's okay now there may be a bug in this moodle software because some people are getting redirected to the older version of this i suspect for some reason so i have to disable the older version entirely most likely see i see a time stamp of 18 5 22. authoring markdown tip md is that what you added hardware considerations yes all of those things are there in that those are new one right there's a new one yes yeah there's some old and some new so so yes that is that and i think it's okay it's okay now okay so obviously i'm seeing a lot more than you guys are seeing so switch road let me see it as a student and see what what happens what what happens to my normal role okay now what shows okay yeah it does show correctly yeah it shows correctly for me as well okay so we will sit together i'll make it happen for you uh one way or the other dennis could you please help him yeah see what's happening on his machine Dennis, could you please help him? Yeah. See what's happening on his machine. All right, guys. So we'll start from the basics. First thing we do is we go to this website called anaconda.org. If you have done this, if all of you have done this, let me know. But if you haven't, or if your anaconda is more than a couple of years old, a year old, it is high time you updated your Anaconda. What is Anaconda? It gives you the full Python environment, and it includes all the data science, standard data science libraries built in. So NumPy, Scikit-learn, Skipy, all the standard libraries are included in this. So please go and download this. Right. Once you download it, go through the whole installation process, make sure you install it. download it go through the whole installation process make sure you install it when you go through the installation make sure you add it to the path of your machine but any one of you who doesn't have anaconda speak up otherwise we'll move ahead yes you can reach out to me i can give you the installation instructions okay so we will move ahead at this moment. Is there anyone who raised their hands and said how many people? Nobody remotely. Nobody remotely. Okay, so we assume that everybody has it, isn't it? Sonal, you also have it. You did the previous course. You have it, right? Yes. Okay, okay so wonderful so once you have that the next thing we do is we go to this by torch the dark website oh this python is to talk hang on let me why did this all become dark colored this one is okay we go to pytorch pytorch.org if you see this you're in the right place what you would do and this by the way folks in the course of this workshop you should become very good friends with this website. You will need it a lot. A lot of good work is being done, really good work. And things that would cause multi-million dollar efforts are being contributed free to the open community. So it is certainly worth keeping track of it. So how would you do this? There are many versions. You can install it locally. You can install it in any one of the clouds. For example, in the cloud platform, how would you do this? Through an image through containers but today through whichever cloud is your favorite cloud you can use it right but what we will do though is we will keep it local for now right and when we keep it local we will take the latest version which is quite good actually now what is the difference between latest the stable then preview and the lts stable is something that we know works preview this is the nightly builds so obviously you'll be at the bleeding edge lts is long-term support if you're doing enterprise work or something, sometimes people want to stick to a version for which there is support, right? That won't be obsoleted and so on and so forth. So this is it. A PICU operating system, usually when you visit it, all these things should have gotten highlighted. highlighted. Right? Now, generally, conda, Python, etc, a pick CUDA 11.3. Pick this one. Right? And once you have picked it, do you notice that it gives you a command? Right? What will you do with this command? Copy it and then go to your anaconda, fire up anaconda, navigator, something called anaconda navigator. When you fire it up, you should see something like this come up. When something like this comes up, you open a terminal. And when you do that, a terminal will open up. And in the terminal, just paste paste that command. Right? You see, I've just pasted the command in the terminal. When you paste that command in the terminal and hit Enter, it will take a little while, and then it will try to install it. So now in my case, it says all requested packages already installed. In your case, it won't say that it will install it. Now if you have older versions of PyDodge or older versions of Anaconda, which is likely if you haven't been recently updating, please update it now. Now is the time to update it. Are we together? Then, it would be a wise thing at this particular moment to go and install PyCharm also. Where would you go for install PyCharm also. Where would you go for the PyCharm setup? And these things, folks, work closely with our teaching assistants. They'll help you carefully. I'm going a little bit faster. You can go to the PyCharm website. Do you notice that you can download it, the community version, the free built-in, built-on open source version? That is generally good enough. But if you happen to be a student, you can get it free. Or if you don't mind, or if your company pays for it, usually companies pay for it, for the the software so you can download the professional version right when you have it in the professional version then the next thing you can do is you should do at this particular moment is you should launch jupiter when you launch this jupiter a web browser will open up. But where will it go? Before it goes anywhere, what you need to do is download that zip file, lab1zip, and unzip it in some directory. Then when you visit that directory, let me show you the structure of that directory. Suppose, where did I desktop now packages, give me a moment. It is in user user and github documents github i'll show it to you on my local machine okay here's lab one no not lab one github so when you do that you will find that it will basically inside it you'll find a directory called deep learning workshop. Do you find a directory called deep learning workshop? All of you. Sorry, as if I lost you there. Where would I find this deep learning directory just unzip the lab one from the website course web portal here from the course web portal where is the course web portal gone um here download here labs and Yeah, one second. Do you see week one labs? You should see. Yes. So download this. It is a TGP file. Uncompress this in some location. That is your next step. Let me know when you have done that. I'll wait a bit. Are you done, Vani? Yeah, I am actually in a hotel in a hotel where the uh the rest of the internet is not very fast so oh okay okay i got it you got it okay and a bit we'll wait a bit And remember guys, if you're falling behind, or if you are not missing we will have additional sessions and tomorrow you can have a clinic session in which we'll help you get there yeah i'm able to download it so once you unzip it do you see the directory called deep learning workshop i'm pretty sure it was it wasn't no it isn't there is there ml 400 and inside that deep learning workshop no it uh it opens to uh dm directly to the deep learning um folder oh it opens directly to the deep learning folder. Oh, it opens directly into the deep learning folder itself. Okay. Then that is fine. You directly see notebooks as we learn. Okay, guys. So my bad. I unzipped it in such a way. So lab one is your project. That entire directory, what you should do is remember the location first. Now, this is our optional step for today. If you have PyCharm, load that directory as your project. Create a new project. Just say open project and open the directory as a PyCharm project. This I'll leave it as optional for you because this will take time. And I'll keep it for tomorrow. Why use an editor? See, often people argue that they can write Python in their favourite editor, whatever it is, Vi or Sublime Text or whatever it is. Generally, yes, you can. But IDs exist for a reason. They give you a very structured environment and a lot of support when you're coding. And you realize that support when you're refactoring code or debugging and so forth. So it is worth, pick your ID, integrated development environment. Is it VS Code? Is it PyCharm? Is it Eclipse? IntelliJ? Whatever it is, pick one. But don't stay just with the editor. It'll be pretty hard for you but for now that directory if you look at the directory you will notice that there are two sub directories inside it one is sv learn do you guys see the sv learn directory this is the directory of code python code python of code, Python code, Python. Right. You will see a lot of Python code here. Most of it you don't need today. You will look only at the ones we care about. In fact, we didn't go to the universal approximator also today. We went to very basic ones. Right. Oh. Yeah. In your case, it will just be lab one. Yeah, in your case it will just be lab one. Right, the sub topic will say just lab one. So go with that. And what I will do is I might put another version of lab one cleaned out version in which I've trimmed down and taken out many things right so you can read the code the image net code that we wrote that we just ran it is here this is the code that you will read but even if you can't get this far today leave it for tomorrow and do this now go to your uh go to your anaconda where is the anaconda your anaconda was here when you go to your anaconda launch jupiter When you go to your Anaconda, launch Jupyter. Let me know when we have all launched a Jupyter notebook. It's under notebook slash pre-train. Yes. I mean, you're looking for the Jupyter code, right? Yeah. Yeah. That's right. So what we do is we open this. Once we open this, I will take you through the process. Linear regression, image and documents comprehensive. No, no, I'll take you there. Let's go step by step. Let's not jump ahead. We'll get there. Let's make sure that we are. We are able to wherever you open in your case it will say lab one right lab one inside lab one. You should see a directory. So you should see something like this let me know if you're seeing something like this you are seeing it right yes you will also see a requirements file this is something this is optional but i would suggest you do that and to do that what you can do is you see that there is a okay no ignore the setup file for now uh you if you go into this file you will find all the libraries that we need now there are two ways of installing one is you can one by one install all of this the other is you can go to your um your shell uh where is the shell god your shell uh where is the shell god there is a notebook called install libraries yes uh there is yeah we'll go there yes that's right i have a library called install libraries which it's under notebooks and you can install libraries yes but you can go here and it will do this for you literally this is the command it will do why is this file here it's ordered it is essential to install the relevant libraries let me edit it and well okay this is these things are not needed is these things are not needed i think i put the image just for fun width is equal to just to recognize this 600 let's say there we go so we need to run this code when you run this code it will install all the libraries on your machine so go to this install libraries directory yeah i forgot you could do it i was going to make you do it from the command line but it's nice that it's so that you show a lot more libraries yeah that's the whole point It will install it on your machine. No, no, no. It will install from the requirements.txt, right? So the requirements.txt that you have, when you open it, it doesn't match what we have. What? It has fewer libraries in there. In there. It's all right. Let's start start with those what are the ones that you have clearly i have a sort of i think i have screwed up a little bit. Certainly, I've screwed up. So let's do one thing. I'll post the requirements.txt to Slack. Let's use that. How about that? All right. You also need to import OS and import sys. Yes. One second. By the way, we have touch pi torch installed for today right so it's enough, but let's do one thing. Let's make sure that we have all the other libraries installed. users So I have a requirements.txt here. Let me do that. Where is slack? I will put a file here. We don't need it for today, but let me fix it. Let's install everything today. Why has it become so small? I have no idea. All right, let's try this and hopefully what I'm pasting here makes sense. Guys, I posted on Slack a file called requirements.txt. Put it into your root directory of the project, lab one directory. Once you have done that. Do we have to install torch again? No, it won't install it. It will just verify that it's there. That's all. All right. It will never reinstall things. And once you have done that, then you can come and we need to set library path within the image net pre train, I think it would help set the path that if we use that code. I'm sorry, say that again. In the ImageNet free train notebook, Yes. you have kind of hard coded your own directory. That is right. That is a step I'm just about to come to. Hold on. I haven't spoken about that. So what we need to do is we need to, every time we do this, we will have to point it out. We'll have to do this in every notebook for now, right? So, but I'm coming to that. You have nice code in the set library path code. You just copy that and it extracts the right. Yeah, except that it doesn't seem to work on Windows. That's the thing, that code is great for Linux, it doesn't work on Windows. I realized the hard way that it doesn't work for Windows. And many people are here on Windows. So, where's the setup dot? Install libraries. So guys, after that, run this install libraries. I'm going to run it also. It's still getting the same message that the libraries are missing. Would you please share your screen? I will share mine and let's help you through with that. So here is default to user installation. Normal site package is not writeable. Oh, you are having permission issue. Requirements already satisfied. Okay, defaulting to this. Going down, requirements, this is fine. Please keep going down, as in scroll down, please. Just keep scrolling down. Yeah, this is the end. You're fine, so why are you unhappy everything is there oh I don't know for some reason just a second ago it was saying that the files are missing yeah I I think it were right when I kind of raise alarm but that's when it happened the background I'm in multiple windows sorry that's all right but it's good to know that it's it's's set up see guys setup is always a bit of a pain uh but it's important we set up the environment properly once we have set up the environment now there is one thing that is a bit of a pain and you'll have to do again and again especially if you are on linux machines this you have to set the path to the sv learn directory wherever you install lab one you will have to do that so let me go and pick which was the image net pre-train is what we use right so today let's go here in this one of the first things you notice i have done this guys i'll open this file image net pre-train do you notice that i have hard done this import uh also i think we have a notebook for this as well no it doesn't work on windows the point is okay i'm saying to set this uh library path we have a notebook uh i mean an instructions not really i created that but it doesn't work on everybody's machine you see that right setup library notebook is the one you're referring to that right setup library notebook is the one you're referring to yeah this is set library parts this works on some people's machines and not on other people's machines especially people this code i was very proud that i wrote this but i actually asked the students to use it in the last batch they they didn't have success. All right. So guys, here's the thing. Try your luck out. If you want, run this thing. This is a code I'd written, set library path. Run it once. It may fix your environment. Or what you can do is add import, set current directory, this, that, right? You could just do run, instead of doing, sorry, where am I? ImageNet. I seem to have many of these open. Let me close some of them. We are not getting to uh ask if are you sharing your stream or oh yes now oh sorry i am not let me do so oh i should have so guys there is a file as i've pointed out i wrote a setup library but you may or may not have success with it you can try it out so what i have done is you can either do percentage run give the name of the library or you could do this right which is explicitly give the directory name where lab one is installed on your and that will be unique to your own laptop please do that this is a bit of a pain if you're lucky the alternative is you could just say percentage run and give the name of that particular setup library everywhere in your at the top of your jupyter notebooks it will put that path in this let me know when we have reached this far are we all together here guys can i move forward and once you are there once you have fixed this, run this notebook guys, run it. When you run it for the first time, it's going to do a lot of downloads, right? You notice that the number of downloads it has done on my machine, it will do all of those downloads. Which notebook you are talking about, Asif? ImageNet. So here, name of the notebook is always at the top image net pre-train right this notebook i think you you are sharing a different screen oh good yes um yeah hey i'm really making a lot of mistakes okay i apologize okay is it better this notebook, ImageNet pre-train. And I wish you better luck on my machine, there was a little bit of a problem. So let me walk you guys through this code. Today, you must leave with this thing running on your machine, properly set up and running. So first thing we do is we set this up, guys, this path. In case, in fact, I was not sharing my screen. You must be wondering what I'm talking about. Fix this to your directory, lab1 wherever you install that one once you have done that run this code image net recognizer when you run this you will notice that a lot of our models will get downloaded start getting downloaded this and the next one lots of models will start getting downloaded is that happening for you guys and it's taking a long time isn't it yeah very good you're able to see the data frame itself that is it that's the end so why don't you share your screen would you like to share your screen it's still dark. Your screen is still dark. Is anyone seeing something on the screen? No. No. So, as if in this case, you wanted us to go to ImageNet pre-train and kind of do the run on it again, right? Run all. Just do a run all. Just be aware that when you run it, if your internet is slow, it's going to take a long time the first time because it's going to download all those big models. Come again. How interesting. Did you pause it by any chance? Okay. That's all right. Maybe anybody who has run the notebook successfully into it would like to share the screen i couldn't do it what's happened here uh let's open up your jupiter yeah let's run the first item it's this kind of um this went through yeah the next one yes went through very The next one. Yes, went through. Very good. What about the third? Next one. Yeah, downloading is going through. Wonderful. And oh, this is your screen. Okay. So it went through. Very good. Very good. Let's keep going down. So we take an image. Guys, what do you notice in this image? It's a, what is it? It's a duck, right? And now let's see. It's a mallard duck, in fact. Let's see what the guesses are. Keep going down. And here we see. What are the guesses? Yeah, it is literally something is saying it's a Drake, I believe, is a male duck. Is that what it is? I think. Yeah, that sounds right. So it's a Drake with a very high probability. Let's keep going down. Drake, all of them got it right. Now we can try it with the dog. Yeah, and so this is a nice table. All these results are given as one single table, how well each of the models did. The first guess of all of them is that it's a Drake, right? And you can see the confidence level that they have. Do you see how confident these models are? 99% confident. So this was too easy for them. Now let's try. Let's try it with the dog, dog. The other image, Dhwani could you please switch to the other image in the notebook? Yeah. So the tree Yeah, it just changes to dog URL. URL is equal to dog URL. Let's run this. You don't have to, yeah, this is it. This is your dog. And just run the guesses part. Yes. Rerun. Now the element above it. Did you make it? Did you run the inference part? No, you just open the image and now you have to run it through the model. Yes. Stop here. This element. if you you ran that so now yeah you see the result yeah so guys do you notice that if you give it the image of a dog a golden retriever it seems to be pretty sure it's a golden retriever most of these models are sure that it is a golden retriever so i'll wait here and we won't call it today till all of you have reached this place i haven't you haven't you share your screen and uh how about this i'll walk you through otherwise you sit with a kyle and um and they'll help you one by one uh share your screen let's let's see what's stopping you it says that you can't start sharing while the other participant is sharing really okay let me see if i can change it kyle it's a setting the security setting in that meeting you can go and say people can take for sharing let's do that for this classroom all right yeah so over here run the first element no no change item number one change the path to your path do you see a sys path sys path um the first cell you have sys.path.append you have to add your add the path to lab one right okay and you also have to say import sys i think it's already there in case you have to do so put the directory put your directory so first you say import sys I think you modified it a little bit yes and then I have to also kind of look at where they no no you know you just do lab one just paste this here change that string to this Change that string to this. And change the backslashes to forward slashes. Excellent. Excellent. Now, put this line, write a sentence, import sys. Before this, it should be before the sys.path. Import sys. Import system as sys or import sys? I think it's just import sys. Let's run it okay it ran through now run the next element one by one run the elements and this will cause this massive download. So what is happening is you're downloading pre trained models. So a lot of the people they spend a lot of energy and time and money to train these big models, horrendously expensive to train this model very accurate neural network models and you're downloading some of these publicly available models got it i think this is going to take some time so okay so now the next one will what what will it do it will load the models it will instantiate the models build those models from the you know files that you downloaded and then you notice that we are not training the model we are just exercising it in the next one sample image yeah so this model would have to be changed this path would have to be changed that is commented out ignore it oh yeah that if you want to try for something in your local machine you can try it otherwise deliberately to be safe, I just gave the URL of publicly available pictures from. One is a dog actually I call it tree, you are you probably want to call it that you. Because it's not a tree it's a duck. yeah so or a Greek rather so now everything will go through fine. Yeah, I think I'm not going to waste your time. So this should work now. Sure. Very good. And all right, guys, have we all run through this exercise today? So today's lab was just baby steps guys. Now that environmental setup is always a headache. If we have been through this, after this, things should move fast. Now one more thing you have to run. Did you run the requirements? Did you run the setup notebook? Vanish, did you run the setup notebook you're on mute guys have you all run the setup notebook yeah yes just run that notebook just so that if you go up to the notebooks in the in jupiter don't go externally go into jupiter in your jupiter itself you were there yeah in the documents tab go up go up one directory in the lab notebooks you will see uh install library sorry install like that i did you did that okay so you have your full environment set up for this workshop great now you're all this is by the way the most frustrating part once environment is set up we can make pretty good progress now yeah but we'll end we'll end here today guys thank you so much hi you're welcome did the lab code make sense to all of you when i was walking through the code guys at this moment it should feel strange because you're not familiar with pytorch so the main homework guys is go to the pytororch website and learn PyTorch. Learn the basics of PyTorch. And it always helps to get the textbook, the one that I posted, the PDF Kate posted. It helps to read the textbook because textbooks are generally friendlier than the documentation online because they take more time developing the thought and explaining it. It's a very good textbook and available free actually the authors have made it freely available. So I'll end here today. Is there anyone who needs help? You need help. Why don't you share your screen? I'll help you. Yeah, take your time. Should I share in between? Sure, go ahead Abhishek okay anyone can I'm having issue uh like uh again screen sharing yep yes yes oh what are you up to so yeah uh I'm uh getting this error like yes we learn transfer image net yeah go up a little bit please look at your directory python now what happens is because you have spaces do you notice that google drive has space in it should i double quote it has space in it. Should I double quote it? No, you probably no, no, no, no, it won't. Yeah, maybe I don't know how it works in Windows. I'm not a Windows expert. Try it out. See, you got an exception right there. So run this thing. We have to make this successful. Okay, I can try changing the directory and then try it again. Copy it into a directory which does whose part doesn't have spaces in it. Okay. Try that right now. I want you to go home with this running successfully. Would you like to share now? What is that called? What is that called? Oh, you're not in Zoom anymore. Okay. Yeah, it's in Slack. Or Kyle, could you please repost the Zoom link in Slack? Yes, I'll post it on the website as well. Yes. Okay. Okay, excellent. Kyle, would you like to try helping? Who's in here yeah okay did you join the yeah okay yes let's go to the jupiter notebook yes oh pip if you're using an outdated pip which is possible to if you did intend to build try installing. You know what I would suggest? Get rid of the conda that you have, the conda directory and install a clean conda. I installed it last night. You did? So just check which directory it's picking up pip from. Do you have a Mac, right mac right give the command which pip it will tell you whether it's picking it up from the correct directory or not which pip is this yeah do you see that this is the kind of mini forge three no yeah so for the m1 no yeah so for the m1 oh you have to get it from here yeah how very interesting and it's not if you just try installing a rest compiler actually i wonder which she used to use the same machine as me. Okay yes time to ask her. Did you use mini forge for your thunder? How did you install? Just the install the thunder. Okay so yeah let me try deleting the mini forge yes uninstalling that and then try that a bit because this is the most frustrating part just getting your environment up yeah yeah well the sv learn. learned transfer likes to be very quality. The very first lap. Yes, Dennis, you're smiling. You're happy. Yes, changed absolutely nothing but opened and closed and reopened the notebook and we started the kernel and now it's working. It's working. Yeah. There are many mysteries under the sun sun what's the shakespearean phrase there are many mysteries under on earth and heaven or something like that then you know then you know of then your philosophy has thought of or something like that there's the duck something like that. There's the doc. Sachin, are you doing well? My laptop crashed, so I was kind of coming back. Should I help you? Would you like to sit with Kyle and get it fixed? Yeah, I'm doing the setup. I should be okay. No worries. Okay. But yes, interesting. It was fast enough. Oh, yes, of course, CUDA wouldn't work. You have an M1. Yeah, right. So it doesn't it needs an NVIDIA thing. So do it without CUDA, just do the CPU. That works. Yeah. So yeah, you'll have to be in that new territory figuring out how to um there must be a separate software that you have to use to access the gpu yeah there are m1 accelerators for by torch for PyTorch. Yeah, you showed me the link. So maybe we can copy that. Yes. It's on the website. I'll show it to you. What you have to do is see you when you go to PyTorch.org. Yeah. Yes. See, here's the thing. Do you see computational platform? This one, of course, you're lost. Suppose you said Mac, right? It will tell you Mac binaries don't support blah, blah, blah, install from source if Qt is needed. So you're stuck with just this right and so you go ahead with it then installing on mac uh there is a way someone pointed out they have created special packages mac os version or above somebody has created a special something i don't know this is actually why I installed mini for it yeah but now that's don't yes stay away from it just go to anaconda website and get Arsene, this PyTorch is pretty extensive. So you mentioned that this is something we should read before sometime. So is there a certain sections that you want us to be more familiar with? Yes, a good point, actually. See, if you go to the tutorials, in the tutorial, where it says a guest get started with pytorch you do want to do that which is fine it will be like running the quick start but the ones that you want to focus on are like see this quick start is basic it will tell you these examples and i can walk through these examples but they're very self-descript tree. It is just a quick torch, just saying there is a dataset, take this dataset and we can do some, we can run it through and build a model and this and that. In my view, this quick start is not quite a quick start. It's actually a bit intimidating because we haven't covered this territory. We'll cover this territory a bit slower next time so what you do what you should do is you can go to the introduction to pytorch do you see this introduction to pytorch uh i will post this link on Slack. This is actually a great question you asked. I meant to mention this, that the quick start isn't exactly very confidence building at this moment. So where is this thing going? Why am I not? Yes. Yes. Start with this tutorial this page. Gosh, why am I, give me a moment. My inability to work on Windows shows. So if you go here. There are lots of YouTube youtube videos good ones published by pytorch itself you should watch those and it says follow this now first thing you want to do is deal with torch library itself the torch itself you know how to do matrix multiplications and basic operations on torch you see that if you're familiar with numpy it's very similar right now this is the art of building the first model though you have as if you can share your screen oh i'm not here yes today i'm really um i just posted Today I'm really losing it. And there's a 60-minute Blitz short course. Yes. I mean, on PyTorch website itself. I broke my screen because every time you share the screen. So if I were doing it, I would start with the basics. Like today I learned, I said that learn tensor. So just learn tensor yeah right yeah this is one thing worth learning learn about data sets and data loader this i would say stick with that and also you can put that bits i remember that bed spot archive it's a good one it is posted a good one it is posted right now when you go into this sometimes you know these things are written for people who already know or who have done deep learning using some other framework right so for example all these transforms and these things may not make sense i'll explain it later so don't get intimidated by that but try to try to do these ones the tensors and the data sets and data transforms you already ran these two things learn the basics basically right yeah that is it it is not hard it's just that you have to become familiar with the you know it's a little bit of a chicken and egg situation. The libraries use concepts from deep learning, but we haven't learned all those concepts of deep learning yet. So you have to learn and get what you can out of it. So transforms is to transform the image right so the examples start out with very image specific is the nature of this deep learning most of the easy examples are with images because it's very And you can either read these articles or go to YouTube and watch the videos based on your preference. In fact, next time we will do this, we'll learn how to create neural networks of our own. So if you read it it you get some early you know background but next workshop i will very carefully walk through all of these lines of code not here but you know if you want to get a sense of forward-looking exercise just go to our this this thing and look for linear linear regression and so forth right you'll find or approximator you'll find this approximator here try reading this code here at some point we build a network this is actually a little bit cleaner way of building the network more rigorous way of setting it up, in which we name, give a name to each layer. We'll cover this next time, universal approximator. Remember I said that neural networks are universal approximators. But today we'll stop at pre-training. Can you guys, I wanted you all to take the quiz. If you still have the energy, please go take the quiz go ahead there is a code for gradient let me come and see what your screen. Oh, but why don't you share your screen? I'll stop sharing mine. Let me see what that question is. All right, guys. all right guys so officially we'll we'll call this session over please feel free to drop off i won't teach anything new i'll just be helping you guys over here