 So the topic today is sequence models. What are sequence models? These are models that have the quality that you feed in a sequence, one sequence, they think over it, and after thinking over it, they produce another sequence. So for example, you can feed in, let's take an illustration, you can feed in English text, and you might be expecting French translation to come out. These are the quintessential examples people give of that. Or sometimes you can say, I'll feed in some text and I expect a summary to come out or things like that. Now, the quality of the sequence models is they need to be contextual. Like for example, when you translate a word, the words in a sentence to another language, in another language the sequence of the words is different from the sequence of the words in the original language, isn't it? So for example, I don't know, if you say So, for example, I don't know, if you say, well, unfortunately there's only one language that I can speak other than English well, so let's take a statement. The cow, having enjoyed a lot of carrots, jumped over the moon in delight. I'm just concocting a sentence. Now, when you say the cow having eaten a lot of carrots jumped over the moon in delight or something like that, you would say, when you write it in Hindi, I'll let you do it in your own mind, you will see that the word sequences are different. It is not a literal word-to-word translation and then laying it out. That would not make sense in French or in any other language that you are familiar with. Try to translate the sentence into that language. You'll realize that it doesn't work. So the question comes, how do you therefore deal with these situations? If it was simple word to word translation, it would be very easy. You may probably not even need a neural network. You can just look up a dictionary, right? And just do a translation. So when people tried to do that, the first thing that came about was something called a recurrent neural network. They're very fascinating architectures. They have inherently an autoregressive quality that we will talk about in a little bit. Now, when you have the technology of recurrent neural networks, they were very popular for quite some time. A lot of applications everywhere, even today they're very, very popular for a lot of use cases. You could do forecasting, for example, a sequence could be the weather data, the temperature data for the past few hours, days, whatever it is. And you're trying to predict the upcoming temperature in the next few days, right? As another sequence, I give you the sequence of past temperature data and I ask you to predict the temperature in the coming days, not just tomorrow, but a whole week or 10 days or something like that. So for these things, these recurrent neural networks, we're doing very well. Now, the way the recurrent neural networks work, I will explain today in the first hour. When we are doing the recurrent neural networks, we'll do it in pieces. I will cover the base recurrent neural network. Then there are two improvements upon the recurrent neural network. They are called the LSTM and GRU. These are popular architectures. They take the idea a little bit further and I'll explain how they carry the idea forward. Once we have done that, we will then look at the limitations of these recurrent neural networks and LSTMs and GRUs. So when I use the word recurrent neural networks today, take it in a much more broad sense. Take it to include the simple recurrent neural networks, which we'll talk about today, as well as these things lstm and gru now if you look at the literature of deep learning you'll find the word lstm and the word gru they are pervasive they're just about everywhere right and it speaks to the fact that for a lot of time a lot of problems could be solved using these recurrent architectures. Therefore, it is very important that we learn about these architectures properly. We also learn about the limitations. Why is it, where is it that they don't work? Then after that, after that hour of conversation, we'll get into a new topic called attention. It turns out that the way to remove some of the limitations of recurrent neural networks is using the concept of attention. It turns out attention is a very old concept. It was, I believe the first paper on attention was 2014 right about the time when recurrent neural networks are taking off. So they had a parallel development and they showed that if you couple attention to recurrent neural networks, you remove some of the limitations of the recurrent neural network. Then came another breakthrough, which was a landmark breakthrough. That breakthrough came in a paper that was submitted by Google to the archives in December 2017 and really got to be talked about in early 2018. That paper starts with a very provocative name, title. It says, attention is all you need and that itself is thought-provoking what would they mean when they say attention is all you need what they showed is that you don't need recurrent neural networks at all to deal with a lot of sequence model problems you can solve it just using an attention mechanism or the self-attention mechanism. So we will do that. It's a very clever architecture they create in which they make the recurrent neural networks redundant and for this sort of sequence models and you just get away just by using the attention mechanism. That particular part is called the transformer architecture. Transformers are dominant. In yesterday's lab, for example, we saw how important transformers are, how powerful they are. You could probably see that for a variety of tasks, you can just take this pre-trained transformers, do transfer learning, apply it to your context, and usually it works very well or works well with a little bit of fine-tuning and so forth. So today I'll be shaping the discussions gradually towards transformers. But before I go to transformers, I would like to take a little bit more history part and it is still important to cover recurrent neural networks. They are still quite useful and prevalent. Then we'll talk about attention and then we'll talk about transformers. Now today when I do the transformer, I will do the classic paper of 2017, December, attention is all you need, we'll cover that paper in detail. But the specific implementations, for example, that we were using yesterday, BERT and this and that, those things, that many, many implementations, it's almost like there's an explosion of implementations of transformers. We will cover on Sunday in the research paper in the paper reading section we will cover BERT which was a very influential implementation of the transformer. BERT and GPT-2 are two very big implementations. Then there are other implementations too, for example, Distilbert, Robertow, and so on and so forth. There are many, many implementations and they all have their pluses and minuses. Sunday, time permitting, we'll look at the tradeoffs and aspects of it, also BART and this and that. But let's focus on the concepts today. So to summarize, today we'll cover three topics. We'll cover recurrent neural networks which includes LSTMs and GRUs. We'll cover attention and then we'll cover transformers. In particular we will do the paper attention is all you need. Are we clear guys about the scope now? Are we clear guys about the scope now? So if that is clear, let me go there and let me do a few mathematical preliminaries before I proceed. start by first taking a page. And that gets the pen closer to me. So first I would like to use or sort of introduce two concepts. One is Softmax. Some of you may be familiar with it, but some of you may not. You may have seen it and used it sort of in code, but may not see or get to the bottom of the mathematical implications of it. So we will study what softmax is. And we'll also look at another concept, which I will call the dot product. Now, the dot product is something that you have, of course, learned in your school, in college days, but we'll look at it from a like sort of it will be a review and I'll point out a couple of features that to us is very relevant. So what is softmax? The word softmax when we use in neural networks or in machine learning it's actually a misnomer what it should be called is I don't know arc soft arc max max or arg well it's a soft argmax is probably the better way of putting it. This little piece which explains what it is, is usually omitted. And many, many people, I believe, have complained about it that I wish we did not have this misleading notation. But the idea is very simple. Suppose you have a bunch of numbers. I will use the word energies. And I'll illustrate it with this concept. Suppose you have some neural networks and you give it some input and they are all producing at the end of it, what they are doing is, let us say that this neural network will tell you how like a predict, how much, how strongly it is voting in favor of some, a cow let's say right and this is doing the same thing for a duck and this is doing the same thing for a horse and this is doing the same thing for what should we take we have already taken cow duck horse, horse. Let's take some bird, right? A cow, duck, horse. So what happens is that, let's say that there's some code that is here and it is producing and each of these is coming out with certain strength. And so let's say that this number for cow is, I will just take a random number, let's say two, that's positive or negative. Let's say the duck is minus one, horse is 0.5, and a bird is, let us say 0.7, right? And so you need to ask yourself together, given the fact that each of these independent nodes, they are only focused on what they are looking for cow, duck, horse, bird, and they are producing what in the what in this world, we in this world of deep learning we call the energies. These are these energies. What does classification look for? It is looking for a label, isn't it? What you need is a label. Oh, yeah. The answer should be cow because this is big. Are we making sense guys? And what we want ideally is we want probably we want these energies to be converted to probabilities. Probabilities go from zero to one, right? If you look at the probability of it not being, and what you want is the probability of cow plus the probability of a duck, cow plus probability of a duck, plus the probability of a horse, plus the probability of a bird, what should it all add up to? One. One. Exactly. It's one of these four, you can't say none of the above. Right? So in this classification problem you set it. And this is the sanity check, they should all add up to one. So now the question is how do you take these numbers and you convert them to probabilities? There are many ways that you could do that, but one way that you could do, if I say, is that see first we need to get positive values. You can just square it or do something or the other, but one easy way that you could do is first exponentiate each of these numbers. So e to the 2 is for cow, e to the minus 1 is for duck, e to the 0.5 is for the horse. Right, well bird does not look like a cow certainly, so I'll make it minus three let us say, huh, e to the minus three for bird. Are we together? Now, when you do that, when you exponentiate numbers, what will the numbers look like? Will they be all, will you still have negative numbers left? What is E to the negative number? It's just a small number between 0 and 1. This will be a number beyond 1, like it will be e square will be approximately 9, I believe. And this will be 1 over 27, that will be 3%, very small. So all of these, they add up to numbers greater than 0, greater than equal to 0. That part is clear? And now what we need to do is how do we convert it to a probability? We can do it using a trick by saying, let's do one thing. Let us take each of these values and divide it by the total of all of this, E2 plus E to the minus 1 plus E to the plus 0.5 plus E to the minus 3. So in other words, you sum up these energies in the bottom. When you sum it up, what will happen? Each of these will become a proportion of the whole, isn't it? Each value here will become a proportion of the whole. Are we together, guys? Yes. It will become a, and we can do that. We can, like maybe in the break, or depends upon how much time we have, it would be illustrious to do this in a Jupyter notebook and see how this works. So what happens is not only that, because it's a proportion, it will now take values between zero and one. And so we accomplished our task, we converted these values into probabilities. these values into probabilities, right? P cow, P duck, P horse, P bird, right? They become that, these things. Once you divide it by the total, they become probabilities. So this thing, this thing is called, this is, and this is where the confusion comes, this exponentiation. So in other other words the probability of a cow is the energy of the cow whatever the energy of the cow was produced which in this case was two let us say two divided by some of the energies of each of the instances, right? Does this make sense? The probability of the cow is e to the cow divided by e to the, all the other energies summed up, all other, all energies summed up. That is what we have done here, isn't it? More generally, we can say probability of a class J or class I, let us say, class I is e to the energy for I. So let me just use the word y. Let me call these energies yi, yi hat in some sense. Let me just call it y i so it will be y i divided by sum over e to the y j all possible values of j including the value i this is your expression for the probability am i making sense guys this is how you can convert any bunch of numbers probability. Am I making sense guys? This is how you can convert any bunch of numbers into, you can give it proportionate probabilities based on their size. Together guys? Yes sir. But you may ask this question, well why did I exponentiate it? There are other ways of converting numbers to positive. So that is actually quite interesting. When you play this game, you will realize that E squared, you know, the two energy, the probability of cow will be approximately, or as far as I remember, when you actually do this, you'll find that this is greater than 90%. Probability of the next biggest thing horse will actually be somewhere close to and if one of you have a calculator you can quickly do this. Probability of a horse will be small. Probability of a duck duck very very small and probability of a bird will be approximately zero right so it amplifies the answer what it does is given a cow's result which is two given a duck's result which is minus one the horse result which is 0.5 and and a bird result, bird energy, which is minus 3. What it does is that when you softmax it, you notice that this here, this blows up. It becomes huge. This becomes small. This becomes a little bit there. And this is practically zero right so it makes the big value stand out are we together guys right so now that it stands out now comes the question what do you want to do when you use this for classification so for classification you want to do you want to pick the guy with the biggest probability isn't it the class with the biggest probability so you want to pick that argument class. Class, what is it? That maximizes this function, right? Maximizes the this thing, yi. So you want to find that i. What is it? i that maximizes this thing. e to the y i divided by summation of e to the y j. Now, do you see how we write this mathematical expression? We're saying which thing is it, which index is it? Let's say i is equal to 0, i is equal to 1 for duck, i is equal to 2 for this, i is equal to 3 for that. What is it? Or maybe i is equal to just literally cow, duck. Let me just use it like this. i is equal to cow here, i is equal to duck, i. Which value of i maximizes this thing? What would be your answer here? It would be? Which class maximizes it here? Cow. Cow, right? Obviously the cow maximizes it for you. So you say that I want to find that class which maximizes this function, which is a probability associated with it based on the energies. And that argmax of this has a misnomer name. It is softmax. People call it the softmax function. Softmax. So what the softmax does is for all the like when you give it a vector of numbers like here we give it a vector of numbers like 2 minus 1 or 0.5 actually let me spell it out 2 minus 1 what else did I give 0.5 minus 3 what will do? It will single out this index. So it will say this index, which happens to belong to a cow. So it will say cow, right? Zero. Asif, how did single it out? It would just have a higher value, right? Among all the- Yes, yes. So it will pick the highest value, highest probability think it won't actually automatically pick it right like we'll have to write some code to pick it out right um the answer to that is yes and no based on which library you're looking at generally what happens is when you apply the softmax depending upon how the library is implemented it will take you this far and then you will have to say like for example uh if you say torch in pytorch dot max right dot max of already something that has gone through a softmax so let's say that the softmax has come out uh this what it will return you is two things it will return you the value and the index right so it will be isn't it kind of argmax of softmax it is actually arg softmax argmax of softmax and that is what makes the thing see you don't use the word softmax. The soft exponentiation does nothing but just exponentiates it. Right? It just exponentiates it and makes it into probabilities. Then you pick the largest one. When you pick the largest one, you get the cow and the index of the cow. That's why it's a misnomer. That's why it's a misnomer. That's why it's a misnomer. It's very hard to, and many people have written libraries, right, and this is where mathematicians get a little bit irritated. If you look at, for example, scipy.special. So for example, if you want to do this in code, all you have to do is import skip from scipy import softmax. So now when you give to softmax, if you do softmax, let me bring it up, softmax this array to minus one, 0.5, minus three, this array, it will actually return you an array of probabilities, 0.9. I'm just taking a guess, I don't know what it is. You guys have to do it. All you have to do is write this one line code and you'll figure it out in Jupyter what it is. So I'll just say something, something, something, something. Now you need to go pick this number. Sorry, let me write it there. 0.9 something. So then what you have to do is you have to pick this. Am I together? And PyTorch takes the same attitude. What it does is when you do the softmax, it will produce the energies. I mean, it will produce the probabilities. And now you'll have to do torch dot max to find out, OK, which what is the value what is the index right so it will be like cow is the value index happens to be zero so is there a softmax in torch yeah yeah yeah torch dot i'm talking about the softest torch dot softmax It does exactly the same thing as cypi, numpy, etc. do. So PyTorch has taken a lot of pains to be compatible with well-known scientific computing libraries. So guys, so let's summarize what we learned. Softmax is a bit of a misnomer, but it just helps you create a from energies or from energies or simply think of numbers numbers as list or array or tensor whatever you want to call it. It produces or tensor, whatever you want to call it, it produces, maybe not, let me just use the word vector, because it's a one-dimensional vector, it produces probabilities using this expression, using this thing. Probability of i is equal to e to the y i over summation over e to the y j for all values of j. Using this formula, it will produce another array of probabilities. And then you can pick the best one. And its quality is that it makes the big guy really stand out. Do you see this? This cow here is big. And compared to it, this duck and these horse probabilities, they look vanishingly small. So it shines a light on the big value. That's one metaphor I can use. shines a strong light, accent light on the biggest value. That is the intuition behind the softmax. In a whole list of numbers, it will make the big one stand out really well. So far so good guys. One question, Asif. If we just take a look at this four values, we already know the number two is the largest among all. So logically, one would say, why do we need to run the software? You can just pick it. Yeah, that's a very good question, actually. Thanks for asking. See, what happens is that when you do classification, and people not only want to know which is the bigger, sometimes they want to know the probabilities. They want it as probabilities. The reason they want it is sometimes they may pick two answers if they are big enough. For example, they may have a cutoff. They may pick two answers if they are big enough. For example, they may have a cutoff. They may say, if the probability of something happening is more than 10% or 20%, I want to take each of those answers as seriously. So for example, imagine that you are doing a test, a medical test. It is testing for many diseases. Suppose two of the probabilities, one is for some form of cancer and one is for another form of cancer, both of them they show probabilities in excess of let us say 10%. One shows a probability of 25% and another shows a probability of 10%. And then the other 30, 40 diseases, they show very, very little small probabilities. The rest 100 diseases show very small probabilities. But the fact that two of them are amplified relative to others, it is cause for you to be alarmed, isn't it? You would say, well, let's go and do more tests just to be sure. Do you get that? So you don't want to just pick the biggest one. You want to have a relative sense of proportion, which probabilities give you. All right, yes, got it. And it gives you a way to do cutoffs. If you remember in the SK Learn, we had the scikit-learn, we used to get the prediction, right? And we used to also get the predict proba. You remember probability? Predict the probability of it being a cow or duck or horse or something. So quite often, actually, you not only care for what you are predicting it and a thing to be, but you also are caring about how strongly do you believe in that? So I'll give you a thing actually from today itself in my work. We were looking at some text. Given the text, we had to identify which or are we talking about productivity tools or something like that. So then a question comes, we notice that when the probability, so suppose it predicts that it is a personal development, right? And let's say that the probability that it comes up with is 65% or 70%. By then you're pretty sure. And let's say that the second best is around 6%. And then it goes downhill after that. Other things are much less probable. You're reasonably sure that this text that you're looking at is about personal development or one of these things that people keep getting as trainings in workplaces, productivity, etc. So then on the other hand, if you get another piece of text, and it talks about, let's say, two subjects, let's not name, maybe, okay. Let's say that it's a little bit about team management, and emotional intelligence or something like that. But they both develop 30, like 35% and 30% probability. The highest one is let's say, our team management. The second highest one just a little bit behind is let's say at 30 percent you realize that the game has changed now you're not so sure it could possibly be that one is not winning over the other by a huge margin so what your right approach should be that you ascribe this thing. And in our case, it was valid to do that. You ascribe this text to both the subjects. You say that it contributes to both the subjects. So when it, there is enough information in it to belong to both the subjects. Asif. Yeah, go ahead. I have one question. So you're talking about probabilities over here which are summing to one, right? Yes. Can we only use it when we know there are fixed number of classes? Oh yes, yes, yes, of course. Remember classification presumes a fixed number of classes always. You must establish a number of classes a priori. Okay, but then you give an example of disease. So let's say if we don't know what kind of disease is it, so will still it be useful to use it in that case? See here's the thing. There is such a thing as an ICD-9 code. And I think there's ICD-11 code or something. There's a world standard international code for diseases which has itemized exhaustively all the diseases we know about including uncertainties like we don't know what it is. Are we together? Yeah. So it does exist and it's a pretty exhaustive list. If you ever go to a doctor and you get a physician and you get a, you know, he'll hand out a blood test thing for you. Now for ordinary blood tests like, you know, annual checkup, it will probably not say anything. But if you do have a specific chronic illness, if you look carefully on that blood test form, the lab work form, you'll see these ICD codes. It says that we are doing this special test. And the justification for that is this patient has these diseases. Which we are monitoring, managing. So that's how it goes. But if you are doing classification, you need to be exhaustive in what classes are there. What people do quite often is that they have one placeholder class for none of the above. So suppose you're looking at a cow and a So suppose you're looking at a cow and a duck, but you expect some zebras to crop in to the picture. Zebras are there and, you know, I don't know, birds are there and for all you know, buses and trucks and houses are there. And you want a classifier in which the only thing you care is, is there a cow, is there a duck and others are irrelevant so you might have a three the three classes cow duck irrelevant do you see how you can deal with it in the irrelevant everything else will fall okay yeah so that could be one way that you would deal with it so guys uh this was i hope a simple exercise It is a preliminary to the topics that we'll deal with today. Was this easy? Now can I move on to the next one? The next thing we'll talk about is again quite simple, but we are building up the ground for something important. Let me use a different color here now, dot product. There's a few who took ML 200 with me. Remember the magical powers of the dot product. Remember the kernels and all of the things we talked about and all the tricks you can do. So dot products are actually quite interesting things. And a lot of machine learning can be reformulated, believe it or not, as in terms of dot products of things. Right, and that's quite an interesting thought and it turns out that when we today the things that we are going to deal with, the transformer etc., they are very very much in there. So what does dot product do? Suppose you have a vector in some feature space, right? So let me use another color for this vector now. Suppose you have a vector here, A, right? And you have another vector, B, and you have another vector, C, another vector, D. have another vector c, another vector d. If you did the dot product of a dot b, which I also write, if you notice, I use this notation, this a dot b. And what you will notice is that a.b, a.c, a.d, you will observe something very interesting. This will be a positive number. This will be a negative number. So what it means is that when you take the dot product, it tells you how aligned the vector be, some other reference, some vector is with respect to a reference vector. So suppose you treat A as a reference vector now you take any vector let's say it is x i x vector when you do a dot x right what you're telling the the result here will tell you how aligned x is to a are we together and this becomes even more pronounced if I take the dot product and I also divide it by the magnitudes of these. This becomes the so-called cosine similarity. Cosine similarity. This is literally, this is the angle theta. Then cosine theta is this between the x vector and a let's say is the reference and in particular when two vectors are perpendicular to each other what happens is that their what will happen to their dot product cosine of 2 what is the cosine of 90 degrees zero zero right so that is why i said this is zero close to zero and when the the the dot product or when the cosine so here's the thing suppose i were to write cosines here implicitly cosine then this would be close to approximately plus one, somewhere near that. A little bit, maybe 0.9 or something like that. This guy would lead to zero approximately. This would be approximately minus one, close to minus one. Let's say 0.85 or something like that right so the values will go from minus one to plus one based on how aligned another vector is to a reference vector are we together always think of cosine as a measure of alignment between two things if two things are very well aligned they will have a good cosine otherwise they will are a good dot product positive dot product if the two are not aligned if they are perpendicular they'll tend to have zero and if they are anti-aligned right you would say that then it would be again a big number but with a negative sign so far so good guys with this idea of transform, sorry, cosines and dot products. Now we are building up, there's only one last piece of observation I'll make before we launch into what we are going to do. So let me use this other color now to this. So there is an observation in random vectors in high dimensional spaces, tend to be surprisingly, and this will surprise you, perpendicular to each other. How is that possible? So let me give you an idea. So suppose you are doing a two-dimensional plane. So suppose I have a vector x and I have a vector y. I take a random vector somewhere, y. The chances are maybe you can just pick a number somewhere or the other, this, right? This and this. Maybe I'll just take some number y. There's some certain angle. So let's do that. You can write X made up of two components, some random number. And let's take unit vectors for simplicity. Let us take unit vectors for simplicity so that we don't have to distinguish between the cosine and the dot product. So now what happens is, suppose I take a number, some number, very small. You can pick a number between minus 1 and 1 or something like that, then or like unique vector small vectors and then some value here so if you pick values here let us say that you pick what should i pick 0.5 right and here you ended up picking up zero or maybe you ended up picking up up picking up zero or maybe you ended up picking up minus 0.2 then you have y and then again you pick up some value so minus 0.3 and 0.7 right something like that i'm randomly picking these two values and now see and obviously uh here i'm sort of contriving it. What will happen is when you do x dot y, you'll see that it is these two things multiplied.15 plus, let us say, 0.14. So obviously here I'm contriving it to make it look perpendicular. So anyway, it is some number. Maybe let's not be so clever okay you can pick whatever number you want it will be something but now when you take multiple dimensions so suppose you have x vector made out of 100 components right what is the average value that each of those components may have right you will realize that if you have to have unit vectors, you'll have to do one over 10 approximately, one over a hundred, let's say that one over a hundred, one over a hundred. The average in each of the columns will be when you pick a vector one over a hundred and so on and so forth, right? Now what will happen is if you take a unit vector, so let us say that by chance a unit vector is aligned along this axis and the other vector is along some other axis. Actually, the better way to motivate it is think like this. If you take a vector which is in this plane, in the horizontal plane, now you take any other vector, guys, what is the likelihood that that vector will fall in the same plane? Relatively low, right? 1 by 3. Right. So you expect that the other vector may go, for example, like this, or it may go like this correct isn't it and so if you look at it the angle that you subtend between these they already begin to look sort of uh not close to zero they seem to be extending a pretty big angle it's very unlikely that it will be exactly the opposite in the other direction of the plane it It will just be off the plane. When it is off the plane, it will be almost nearly orthogonal. In three dimensions, already you can see the effect. But when you have many, many dimensions, so imagine that these are all the dimensions, right? So if in all of these dimensions, if one vector is like this, and the other vector is like this, what you will gradually begin to see is that they are orthogonal to each other. So we can do this with a little bit of Python code. It's fun to actually see that this works. Now, I can give a more mathematically rigorous answer, but let's stay with the hand-waving arguments here. So the conclusion we are seeing is in higher dimensional space, most pairs of vectors, pairs of random vectors, vectors vectors will tend to be almost orthogonal. So now look at this. Most, I use the word most, not always. And I just say tend to. There will still be a situation by randomness that two vectors may just be aligned, almost aligned. But it is far more likely that they will be orthogonal to each other. So far so good, guys? So from this, we have three facts. First is we understand what softmax is and why it should have been called arc softmax. The second thing we have is we understand dot products, what they do. They show you the alignment between two vectors. And the third observation, which is a bit startling because you haven't thought about it. Usually you don't notice it, but it is true that in higher dimensional spaces you take two random vectors and they'll tend to be perpendicular to each other or nearly perpendicular to each other. So this is food for thought. Think about this on your own. And maybe when we are doing the next lab I will show it to you but today in the interest of time i like to move forward so we will take these three facts with us and launch into today's very interesting topic of transformers but before that we'll do rm so let me write it down three things we learned was softmax number one the number two that we learned was a dot product that it measures alignment, right, measures alignment. Number three is that random pairs of vectors in high dimension dim, and then since it is machine learning, we can put it, let me just use the word high dimensional spaces, tend to be orthogonal, i.e. x, y random values will tend to be zero. So these are our three takeaways from this mathematical preliminaries for today. Asif, is that an assumption, the third one, or it can be mathematically proved? Oh, it can be very rigorously proved. Okay. And the argument is there, but it will take us a little bit of time. The argument is, like to prove it rigorously, it is actually a theorem, and it's a little bit involved. So stay with hand-waving arguments. That's good. What is the theorem called? Well, it is literally, it doesn't have a name but it just says that random vectors and high dimensions are very likely to be orthogonal. All right. Saturday, remind me if you get time, right. Those of you who love the mathematics of it, I'll give you guys a rigorous proof. Okay. So, Asif, so the softmax, so is that the same concept as like distillation? Like the Geoffrey Hinton paper like in like 2000, like earlier initial paper which talks about like knowledge distillation. So is it like the same or similar concept? Actually, it's been a while since I read that paper. So I'm a little bit hesitant to the 2006 paper you're referring to, right? Oh, yes. Yeah. So, no, it's's been a while i'd have to go back and look at it good question okay yeah so that one i don't remember actually so i'll have to look whether he's saying the same thing it is possible i don't know so um all right so now we come to the sequence models. So here I'm eating up a lot of things, which we will do in great detail in the coming months. So I'm sort of hopping through the highlights of a big field here. So the way you do sequence models is this. Imagine that you have a thinker. Think about a thinker. Thinker who has, and this is my intuition. So you won't find this in textbooks. It's my just idiosyncratic way of thinking about it. Who has a thought, it who has a thought in her mind and what the thinker tries to do is you say something to the thinker and it tries to distillate or get the essence of it and hold on to it some abstract form of it. So suppose you say the cow after eating the carrots, it's a silly statement, I suppose my way of thinking itself is a little like this, so this gets into the same genre, the cow after eating a lot of carrots a lot of carrots i jumped over the moon so i will even modify it a little bit. Was a Pyrrhic was happy and it jumped over the it's delight. Crazy sentence. But I'm concocting this sentence just to point it out. So what are we talking about? Isn't it? The cow is up to all sorts of things. It's eating carrots, it's feeling happy, it's jumping over the moon in delight and so forth. So this is a thought vector. So now let's imagine how a thinker is responding. You said the cow so just think how a thinker if it is a machine what would it do in order to hold the information that you have uh in in its mind so first of all you give it let's say the cow huh you say the you fitted the word let me just write it like this You say that you feed it the word. Let me just write it like this. You feed it the word, the I'll just write some part of the sentence. The cow after eating a lot of carrots. So think about this thinker who I will just replicate. So what happens is you feed it this word the, right? Now what this thinker can do is to say, hmm, okay. It's holding something in its mind, right? So let us say that what it is holding in its mind is H1. Right? Now you say cow. The next word is cow. Now it needs to think something, but whatever it thinks, the next sort of a thought that it has, which captures what it has heard so far, must include not just the the, but also i mean not just the cow the second statement let's say one two three four five six seven eight it must not only hold or create the thought based on cow but it that thought that it comes out with would you agree that it comes out with, would you agree that it must include the also? Right? Likewise, now, so let me call it H2 after getting the second input. Now you give it the. It will produce a bigger thought, H3, but you would realize that if the thought that the thinker is thinking only responds to the word after it would be a rather meaningless thought it would be far more relevant if it was this thought represented the essence of the cow after somehow and this represented the cow and this represented the cow. And this represented the, right? And likewise, you can keep going on. I'll just draw this. So the next thought that you produce, it somehow takes the previous thought and it alters it. You know, it sort of adds something to it. Do you realize that? The thought is in some sense gradually forming, a more complex thought is gradually forming in the mind of the thinker. If the thinker were a person, this is how it would work. Just see how you listen to people and you'll realize that it is somewhat along these lines, isn't it? So now you have the coming in and whatever the hidden state was, what was it? H5 goes in and the response that it produces, the thought that it thinks, which represents all that has gone in, would be like, for example, this should represent the cow after eating a lot. It should contain this much, the cow after eating a lot. Somehow that much of thought must be captured. The essence should be there in the thought of the thinker. Am I making sense guys? I'm saying something very simple that if your job is to somehow hold whatever you are told as a thought in your mind then you have to pay attention to what has been said so far and the next word that you hear and you have to process it all in your mind to create a sort of a representation of that sentence. Am I making sense, guys? Yes. Something very obvious. So now what happens is at the end of it, when you get the last word, and so suppose here it is the delight, and then followed by a full stop, right? When it finally gets, and so now here, whatever final thought comes out, it should somehow encode the entire thought, right? The entire thing that it has heard, it should somehow be able to represent it right so one one very obvious way that you can think of is what it will do is it will literally memorize whatever it has heard and the thought here is nothing but the entire sentence exactly as it is, isn't it? So one easy way for you to just listen and just literally remember it as it is, right? And that would be okay because that's just a recording, but here comes the interesting magic here. What you do is you ask the machine, so suppose you're dealing with machines or or just think of a thinker you ask the thinker that see i i don't care whether you can literally regurgitate what you heard what we what i want you to do is understand what you heard can you focus on your thought should Can you focus on your thought should understand in some sense, what is it that you heard? Now understanding is different from just parroting or just being able to literally memorizing the sentence or holding it in the mind. Understanding means you got the essence of what was being said. And so if you really understood it and if you could speak in two languages, for example. Now I can ask you, well, why don't you now say that thing in French? Do you see the difference? You're saying if you really understood rather than just memorized, can you reproduce that in French? And then the translation into French will emerge not by a word-to-word translation from the initial text, but it will be derived from your understanding of the text. Isn't it? And that's how you do translation. Imagine a translator. What do they do? They hear a sentence and then they understand that sentence, what was said, and then they translate that into a different language and obviously when they translate the words the words are not literally in the same sequence but they make sense in the other language are we together guys yes sir so that is the crucial difference we are saying when you hold that thought Yes, sir. So that is the crucial difference. We are saying when you hold that thought, that thought should represent your understanding of what you have received so far. And the word that people use is multiple. I have seen people use the thought vector. I like to use the word that what finally here is that it is a thought vector. Vector is simply because obviously it's information, it's a data structure, it is numbers. So it will ultimately be some numbers because in machine learning everything is numbers right but somehow this thought vector should be an understanding of the input sequence this is important we are not saying just literally reproduce the input statement, but understand it. So how do you make it understand it? The way you do that is, and this is classic machine learning, you don't give it enough memory to just memorize the whole sentence. You give it very limited memory. The size of this vector is limited. Let us say that it is 1024 nodes, neural network nodes, right? So you have a neural network. So what happens is that every time a new word comes, it goes and updates the weights associated with all of these. Are we together? Right? The output, sorry, activations, A1, A2, A3. So the activation result that you get, output, is your thought vector. It is your h i right when input i goes in what happens is it goes through this neural network let's say it has one zero two four nodes and then it produces these activations those activations as a vector is your hidden thought now you say well how would it know suppose you're using some activation function uh maybe relo or or I don't know, TanH, whatever, doesn't matter. The important thing is you need to know what the weights are, W1, et cetera, et cetera, for all of these, right, for an input word. Ultimately, what the weights are. So what will happen is as you keep on, so suppose you it has certain weights you don't know what they are you put in the first word it creates one thought vector now you comes to another word h1 so it will become like this h1 goes to h2 goes to h3 goes to h final do you see that guys because what you're doing is you're passing it word by word and you're keeping track of the activation with one difference. What are you doing? You're not just feeding it the input. You're taking this activation of the previous. So before the next word comes, so let's say that when input I goes in, into this neural network, you not only feed the input, you also feed the thought so far, right? The thought vector so far, generated so far. And so this plus this produces the next thought vector. The word people often use in literature is, I have seen, they usually call context vectors, context vector, and some people like me call it a thought vector, a thought vector or just context or thought. It is the thought behind the sentence. Are we together? Or another way to think of it is, it is the essence or understanding of the sequence. And now, when I generalize from word to sentence, sentence and words to sequence, I now could also be talking about any time series data. So for example, you may be feeding in the temperature data across different hours of the day for a whole year. And now it should have some understanding of the seasonality so that if you say go predict the temperatures, the noontime temperatures for the next three months, it should be able to produce something that approximates what will happen, right? Or what is there? Are we together here so far? And the interesting thing to know is that, see, what is happening is if you really think about this neural net here, I'm writing it and so it has all of these nodes inside it. There are two things that go into it. One is in the beginning of course, it will be a first word, W1, right? And there is no hidden part here. So you can pass it just a placeholder H0 thought, blank thought. Then these two inputs going into the network produces the thought that comes out of studying or learning the word one. Now there is another thing. Sometimes this neural network, not only you do this, you may just have an output one. You may ask for some output also, right, from the neural network that predicts something or whatever. So far, is it a positive sentiment, negative sentiment, whatever it is, you can pick some output. So now, in our case, we don't focus on the output very much. This one, I will not focus on today. So now how do we generate H2? What will happen is it is the same box now. You have taken this. Actually, let me put it this way here. So people sometimes write it like this. H0, they both go in to produce H1. So the same thing, how do you do for word two? The same box now, what I need to do is feed it, let me write it, H1 and word two. And what will it produce? H2 in the same network. And now you have H2. So you take H2 and word three and you will get, therefore, H3. The H stands for the hidden state, typically. So you get this result, these activations. And so you can keep going on till you get the word, h final minus one and the word final which is the terminal character let us say and it will produce the let me use a different color just to make sure that you realize that we are feeding it all into the same network let me do this but i hope this idea is clear now guys f h f minus one word final it will produce what will it produce it will produce the h final do you see that guys and this is a remarkable thing you're not taking a many many neural networks because you can't. Sentences are of arbitrary length. What you're doing is you're taking just that same neural networks, but you're feeding it the input and the output from the previous sequence, you know, the previous, the sequence so far. That's why it's recurrent. And that is the root of the word recurrent neural net architecture. It's a recurrent neural net architecture. Gosh, my spelling is terrible today. Architecture. So this particular form of architecture for neural nets is called a recurrent neural net architecture, RNN. So, Asif. Go ahead. This architecture will only stop once we are out of the words yes the moment you hit the last the full stop you're done so it's not really anything related to reducing loss function no no no at this moment all you're doing is you have just come up with the thought vector you haven't done anything so the training part is still there now we'll come to the training part in a moment oh okay so what you call is you call this the encoder part of our encoder decoder decoder so now because i'm jumping along you can use rns for many things right for example if you really cared for the output then it could have been the sentiment of this of the sentence so far and whatnot but I'll ignore it because what we are concerned so in your mind a frame that the problem you're solving is machine translation because it will help you understand the situation better. Translation, right? From English to, now pick your language. Can be Spanish, French, et cetera, et cetera. So far so good guys, right? So the way we think about it is we unroll it. You unroll this diagram this diagram and you think of it not as even though it is the same neural net you tend to draw it like this h naught w1 produces h1 which gets fed into the same neural network, but it produces H2, right? And it keeps going on till you have H final minus one, word final, which is your stop word, right? A full stop or whatever it is. Are we together? No more inputs. And when you don't have any more inputs, whatever output you get, the final state is your thought vector. This is your final is a thought vector capturing hopefully the entire sentence or your temperature data or stock market data whatever it is hang on guys hold on for a moment let me finish this thought hold your questions now comes the question that okay what about decoding it this is the encoder part right so this part here so far is called the encoder and I'll take questions in a moment guys and please just be patient encoder what about decoding it so you need then a decoder let me put decoder another separate color just for fun you need a decoder you need a decoder. What the decoder does is it takes the thought vector, H final, and its job is very interesting. In the beginning, you just put up, you know, you just feed it some placeholder word, which is just the start. You know, you may have a token called start, saying the start of the output, start producing output. And what this should produce is the translation of the sentence. For example, I will just put something in Hindi, and please forgive me if you don't understand Hindi, guide. And my spelling is atrocious so most likely i'll spell it wrong so this vector goes in you give it the start token and it produces one output right this is your output one this is your uh just input and now what happens is actually you don't feed it any input forget about this input thing you just give it it this, you do step one, it produces this. Now it produces, let me say the decoder, I'll just create the decoder step. So those were encoder, is it okay if I use the word decoder? So D1, right? You treat this as D0. And you now ask this question if I feed this into this network this this thing the next time I trigger it what is it going to produce so then it will produce an output o2 let's say chan by the way this guy means cow and Chan means moon. And let's say that you get D2 and then K. Something like that. I'm just putting some Hindi words here. It will start producing different words. But the problem is, how do you train this encoder decoder? So you know that these are all neural networks, how do you train it? So training is actually very straightforward. It is the same back propagation, the same loss function. So what happens is that it produced, let's say that this network was not trained at all. So this thought vector will be absolutely useless isn't it it will be some random values so you ask it to produce a word what it will do is how will it produce a word it will produce let's say that your final vocabulary hindi vocabulary has, let's say, that the, as, should we say 10k words? Roughly speaking, you can choose how many words you want to start with. So what will it do? The details are, this guy, this box, decoder, it is feeding it into for output it is feeding it into a softmax with how many values there nk words right so this will be word one hindi word one right hw1 hindi word two h Hindi word 3, and so forth. Now what will happen when you feed it into softmax, you'll get your energies. Remember, you'll get the energy outputs. That's what we talked about in softmax, isn't it? Yeah. Right. And so out of these, one of them will have the highest probability. So a wrong one, let's say, comes out with a high probability. And the right one, let's say that the cow, the guy is sitting here, the Hindi for cow is sitting here. And this poor little cow comes out with a probability is equal to 0.01, very probability what can you do now your data says that your label data says that your first word should have been guy right and cow cow in hindi basically a guy but uh but something else came out let's say uh said let's say that a donkey came out as having the highest probability and this is a mistake. We don't want donkeys, we want cow. So how do we do that? Now can we create a loss function? What can we do? We can say that this probability of the cow, if you take the negative log of the probability of the cow that you predicted, is pretty low. Isn't it, guys? This turned out to be pretty low. Whatever it is, this is your loss. Because if this probability was one of the cow, what is log of one? Zero. Zero. So there is no loss isn't it the loss would be 0 log of 1 let me just write it down if prediction was perfect log P cow is equal to one log p cow would be zero i no loss right you can't do better than no loss on the other hand in this situation but for let's take an example but for p is equal to 0.01 and let me cheat let me take it to the base 10. It is actually to the base e but I'll cheat right because I'm not I can't mentally compute log to the base e cheating so using log 10 right should be and i'll just put an should be e so but i'll just cheat so what is it this is equal to 10 to the minus 2. so what is minus log to? So what is minus log 10 to the minus 2? Can you guys tell me what is it? This is equal to minus of minus 2 is equal to 2. Pretty significant loss? It's a positive number. So in other words, because I made a wrong prediction, I have a significant amount of loss of error measure. And so for the next word and the next word and the next word, and so you can accumulate all the loss. And now once we have the loss, right? So this is your standard, let's say, here I used this way of doing it is of course, the cross entropy loss that we are used to from ML 200. And you could try out different log measures, it doesn't matter what log you took. But the important point is that suppose you have a log loss, what can you do now? With this loss, you can do gradient descent and start updating all the weights right because ultimately there is just only two networks here this guy and this guy because these the rest of them are just copies of this right i have just unrolled it out you have to just look at the weights here and there am i making sense guys there's an encoder network and a decoder network. And I can do the using laws, using gradient descent on laws, back prop and update weights in what? In encoder and decoder. Obviously, you have to feed it a lot of sentences, lots of data because each sentence is one data instance. So you'll have to give it a lot of label data. This sentence, the translation is this. This sentence, the translation is this. So at each mini batch of sentences that you give, now you can, or even just one sentence at a time, if you do stochastic, you can now start computing loss and start doing gradient back propagation and gradient descents. Am I making sense, guys? So at the end of it, all these complications later, what do you really have? You have the encoder to which you're giving it a sequence. And then that creates a thought vector which goes into the decoder, which produces a translation. And you notice that I'm not using the same number. This is five and this could be one, two, three, four, five, six, seven, right? Because a different number of words might come out in a different language. So this is what you're doing, but each of these is nothing but neural net. And this is neural net one encoder this is neural net decoder so they are just filled with weights trainable weights and trainable weights and biases is right same here isn't it and because they just filled with weights and trainable weights and biases what it means is that so long as so number one you compute the loss and the same loop of machine learning kicks in from there how do we do that we do a backward remember in python you do a backward it computes the back prop the gradients back prop compute gradients and then with respect to these weights and biases and number three And then with respect to these weights and biases and number three, update. What is the delta rule for update? Again, any particular weight will get updated to the previous value of the weight minus alpha gradient of the loss with respect to the weight i. The same machine learning that we are familiar with will take over. Are we together guys? This is the RNN architecture, it's very simple. Now comes the question that where does it work and where does it not work? It turns out that, and this has to go back to the Turing machine and how we think about it. Think like this, if the thought vector is limited, for example, you have 128 nodes and their weights there, your thought vector is only of a finite size. Think of it as a person with a limited memory or understanding. What happens if you give it some simple input? It will do a pretty good job in translating it. Isn't it, guys? These are three words you give a sentence. How are you? And it will say, translate it into another language pretty well. But gradually, as you make your input longer and longer, what happens is that the word that comes in the beginning, W1 and W final, see gradually these things are there in the memory first, then you extend it and extend it. Soon this place gets overwhelmed so what happens is that the the understanding gets biased words recent words. Are we together? The thing that it heard last, it is much more able to remember or understand, but the understanding that it had of the sentence, the long sentence, the words in the beginning, they begin to get diluted. Are we right? So let us illustrate that with our initial sentence that we took. And I deliberately took a long sentence. The cow, after eating a lot of carrots, was happy and it jumped over the moon in its delight. So what happens is by the time it reaches this, it begins to forget what were what were we talking about right so uh there's a there's a lovely story uh you know that uh finding nemo for children and i believe there's a character it is called dora or dory just keep swimming yes she keeps him and she has a very short memory and there is a beautiful sort of point, day in which all her friends, they are preparing to give her a surprise party I suppose and she has no clue that it is a birdie. She's entirely forgotten it. Right, so she's seeing all of this puzzling activity but can't understand it. So it's a little bit like that. These recurrent neural networks, they have a small memory or small understanding. They are like Dory. And if you say things too much in the past, a really long sentence, it begins to forget the beginning parts of the sentence. That is one way to understand it. Are we together? So that is the limitation. Gradually it begins to forget and starts making mistakes with longer sequences, whether it is sentences, and I use the word sentence more broadly, it could be time series data, any time series data. If you consider a sentence as also as a time series in words, think of any time series or any sequence, long sequences, it begins to forget the earlier parts of the sentence in its understanding, you know, it begins to fade out of of the sentence in its understanding, you know, it begins to fade out of the amount of understanding it has. Does that make sense guys? Does it happen to us also? Somebody tells you a very long and complicated story. We also have a very limited transactional memory. At the end of it, we remember what he said last. Would anyone like to confess to that? Definitely true. Definitely, right? So this happens with machines too. So then the question came Would anyone like to confess to that? Definitely true. Definitely, right? So this happens with machines too. So then the question came that this is your standard RNN. Can you improve upon it? So people tried to- One quick question before we move on. So what you used here to frame the edge and the boxes, that's a conceptual framework in terms of you know there's a thought that is getting built little by little right yeah and those thought is nothing but the activations of the neural network sitting there that box is a neural network it's just the activation the output activations of the neural networks or the hidden states okay so in that sense then these have to be, when we think of the underlying neural network that will model this, you need to have as many layers as you need to be, you know. No, no, no, no, that is the point. See, and let me emphasize that. So I did not do a good job then, hang on. See, take a simple one layer neural net if you want, 128. Something, some amount. I'll just write it as 128. It's typically 256, 512, 1024, whatever. right but let me let me just simplify it but to argue simplify it to simply five it to four right so let us say that you have one two three four right and now what happens is you feed it a word let us say that the word every word can be represented by um let us say that you have a very simple vocabulary a word can be represented by a 10 dimensional vector because you have only 10 10 words in your vocabulary all right so your input All right. So your input is, which is 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, right? This is the word that you are feeding, that any input, this is your input. This input will get to the hidden layer, whatever, your standard dense, whatever. So what happens is, and then it will produce an output so together it will produce an output now think about it this guy can remember or the context of this is limited right what you do is word one comes in word one comes in and by the way the other thing you do is so let me actually simplify it so let's say that this is the word wi and the rest of the notes that are rest of the information that is coming to this is actually coming from the edge hidden state so far that is there and this is the hidden state output so what you do is whatever hidden the same thing you're not making many layers of the neural network just one layer one hidden layer okay yeah you're just taking this and back feeding it this is the recurrent part recurrent recurrent word right refers to the fact that you're taking the output and feeding it back as input along with the true input at each stage so you have therefore one hidden there see you can make it multiple hidden layers but not because the sentences are long or you know sentence, suppose the sentence has 10 words doesn't mean you need a 10 layer hidden. 10 hidden layers, it's not like that. It's the same, the number of hidden layers is independent of the input. It is your architecture, you pick your architecture. Okay, yeah, that's that so in this the problem really is that uh it begins to forget right or does forget its understanding of the earlier stuff right when you give it very log sequences so let me write it down disadvantages um ask sir i have a question. Yes. I'm pretty confused with the input part and how the thought is generated. The question is on similar line how the gentleman just asked. So input is the whole sentence, not word by word, right sir? No, you feed it word by word. That's the whole point you first feed it the word one it comes out with a hidden state output hidden state as h1 and some output over if you care about right that hidden state think of it like this some people draw this diagram like this to emphasize that this also becomes w2 and h1 goes into it to produce h2 and the output 2 if you want the next hidden state which you feed it back into the same guy let me call this guy x is the same x network okay yeah that i was getting confused that is probably h is x is, but it is basically same X. It's the same X. You just unrolled it to explain it or to just understand it, right? Which is why a lot of people without unrolling, the diagram is typically mentioned like this. Okay. And one word at a time, it will keep feeding and keep taking the intermediate basically. Exactly. And so that is the sequential nature of it output. So let me say that again. What you do is you feed it one input at a time in a sequence. You have a sequence of inputs, for example, sequence of words. You can't feed all of them to it at the same time. You have to feed it one at a time. Right? And so that is its limit. So now let's itemize its limitations of this architecture. RNNs are very powerful actually. When they came about there was an interesting thing, the unreasonable effectiveness of RNNs because it could do things. It could actually do translations and do many things and a lot of people were very thrilled with it. It had its limit and people felt that we can keep on improving the RNNs and get a lot of mileage out of it. They kept on trying. It kept getting better and better. So I'll just mention its limitations here. So I'll just mention his limitations here. One more question, sir. So they thought, Victor, that is not exactly sentence or word. It is just basically a vector. Abstract representation. Yeah, abstract representation, probably. So that's that. So now what are the limitations? First is, as you identified, need to feed the sequence one word at a time. Isn't it? As you can clearly see, right? One word at a time. And when the entire sentence goes in, then the output begins to come. Once entire sentence is in, then decoder starts recording again one translated word at a time example in this case one in the word so the entire thing is sequential now why is a problem? It's a problem because if you, we live in the world of GPUs, you know, graphic computing units, the video cards and so forth, the tensor processing units. These are massively parallel machines, right? These are vector processing engines. They can deal with a lot of computations in a parallel way and so if you look at the the computer when we did the computer vision part in the convulation neural net we talked about the entire image going in at one go we were not feeding it pixel by pixel isn't it and not only an entire image in fact a whole mini batch of images. We were doing a forward pass and a backward pass and one step included an entire mini batch of images all in one shot. Right? One forward matrix multiplications, one gradient computation, one update step. Right? Whereas with RNN, the first thing that hits you is that this is tedious. You can't feed it a mini batch of sentences. You have to feed it not only that, even a sentence, you can't just feed the whole of it. You have to feed it one word at a time, until it hits the end of the sentence and then the output will come. So obviously in the natural language processing community, people were very concerned that the translations are very slow relative to the extreme computational performance with images. Language translations are very slow and you can see why. The other problem that we said is the Dory problem. I call it the Dory problem. It tends to forget, tends to forget about the earlier, forget or fade the earlier parts of a long sequence. Right, so there is a British author that used to be there, there was rather, I don't know if you have heard the name of Francis Bacon. Right. So there is a British author that used to be there, there was rather, I don't know if you have heard the name of Francis Bacon. And you know, we as in India, we were ruled by the Brits and we read a lot of those British books and British authors in my generation. I don't think we do that anymore. But Francis Bacon is one of the British authors of the previous century. Actually, I don't know, maybe the 19th century. So he wrote his books. I remember encountering a sentence which started, was it Bacon or was it Maculay? I forget. Either between Bacon or Mac Macula, another writer. It started in one page, it filled the entire page and most of the next page, and that was just one sentence. So you realize that that sentence is extraordinarily long, and when you try to feed that sort of sentences for translation, the recurrent neural networks tend to do a pretty poor job. So then people began to say, can we solve or do something to make these recurrent neural networks better? So what they did is something quite interesting. They came variant of within the same recurrent neural network family they came first the so-called lstm right and i invite you to find the full form of lstm it's very interesting it's sort of a sounds almost like a oxymoron so i'll let you figure it out what it is. Right. And so what it does is... Long short term memory. Yes. So it's an... You see that, right? So, but anyway, Anil, you knew that she shouldn't have spoken up. I wanted people to go search for it, but okay. Long shot. The long shot. You see how contradictory it looks. What it does is it contains basically three components. One to remember, these are called gates. It remembers some things. One to unremember or forget. And one that we are doing update, update the thought vector. And these three interact. What it means is, see, when you hold the context, after some time you can forget about it, you know, that particular little bit of information from the beginning of the sentence, exactly when can you forget about it? There may come a time when you can forget about it. So it is, these, I won't go too much into it because the architecture is a little bit complicated. These are the gates here three gates and when the inputs are the sequences flow through that. All it's a collaboration between the remember forget and update gates that helps you create the thought vector and then produce the output, are we together. the thought vector and then produce the output. Are we together? Am I making sense guys? I wouldn't go too much into detail, but it is essentially the same RNN thinking, a sequence in, a thought out, a context out, right, so encoder, and you would put another one of these, and then this would be a decoder. Right? Translation. Next. So you could, I mean, in this particular case, sequence to sequence model, the thinking is exactly the same. It's just that you can make it a little bit smarter so it can remember things.. Then came another architecture which was simpler, which is more recent, which is GRU. So I'm deliberately not doing it because we'll do it perhaps in more detail later on when we do that for in-depth part, which sort of gets forgets about the forget. It says forget the forget. Let's remember and do with that in the update and that is good enough. The functionality of in some sense forget is subsumed in the update. And so GRU is simpler and faster than LSTM. faster than LSTM. Right? So, that is it. And I invite you to find the full form of GRUE also. So these are the architectures, but see the good thing is that they were evolutionarily improving. They're doing better and better things and then people in parallel there was a new architecture coming about called the attention right and so now i would like to go into the next part so let's say that we'll end here this is end of part one one.