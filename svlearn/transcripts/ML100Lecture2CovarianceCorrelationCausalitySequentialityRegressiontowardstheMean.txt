 All right guys, welcome back to the workshop. Today, we are going to cover quite a bit of territory. It's the first in-depth look at topics in machine learning. So, I hope you are fresh. If you haven't had coffee, this is a good time to have that. So, I'll start by summarizing what we learned last time. Every time I meet you I will summarize what we did. Then I will explain what we want to do? First is we will do a summary of last lecture. This is what we are going to do. We will follow it with a quiz. Oh no. Who is ready for the quiz? So, we will ask some basic questions. This is just a self-test and then we will have a lecture, a theory session and then we'll have a lab session and so this will be our format. In the theory section we'll cover topics like very strange topics covariance words that you may have learned but forgotten correlation, causality and sequencing. We will learn about regression. Today is the day where we will learn about regression a little bit more in depth. We will continue on and I will prepare you for doing the next lab. I have emailed you a lab. Has everybody received it? If you have not received it, raise your hands. Okay. All right. So, this is our agenda for today guys. So what did we do last time? Last time we talked about what data science is. What is it to look at data? What are its facets? We part of it is exploratory data analysis and that looks at data that which is manifest that is just there waiting for you to look at. And there are many many tools over the years that have emerged partly we do it through data visualization. Data visualization used to be in the world, old world, used to a large extent be called reporting or business intelligence. Since you are from Oracle, you probably know, I was one of the old architects for Oracle BI. It came from Siebel, Siebel BI. Yes. So, old history. So, then there are things you can do with SQL approximately. You can do with all sorts of manipulation of data and see it. You can get your top end, you know, if you want to know who are your top most spending customers, right, and things like that. You can see that then that sort of analysis like what is the minimum maximum total aggregations we have been doing it for a long time with data the summarization of data in some sense but looking at data in different ways then we visualize the data a visualization obviously the traditional visualization we think of as what you can do in Excel, scatter plot, bar chart, pie chart and so forth. Now what you will realize is that the world of visualization has moved far ahead. And today we have far more powerful tools for data visualization and libraries for data visualization. In fact, data visualization is a language in itself in some sense. People have formalized it. They talk about the so-called grammar of graphics based on which there are two particular open source projects which are runaway success and dominant in this field. In the JavaScript world, there is D3. Anybody knows about D3? Quite a few know about D3 for data visualization. Then based on the same philosophy, the grammar of graphics, in R and in Python, you have something called ggplot. There are many more libraries that have been created which take an approach that data visualization should not be a haphazard collection of functions that do something and you have to sort of know them to be able to make a plot, which is the situation today to a large extent. These disciplined libraries take the approach that just as words come together to form sentences and paragraphs, you can systematically construct piece by piece a visualization. You can think of it as layers. There is data layer, then it's basic things. What are the axis of your visualization? What are the aesthetic elements, the color elements? And you can keep on layering things on it, transparencies and whatnot. And you can create compositions of very different graphs in one single graph this is reminiscent of Photoshop if you have experience with Photoshop those of you who do Photoshop know that when you create a picture for publication typically you have like 20-30 layers sitting there right those layers are stacked on top of each other I have even seen people go to 50-60 layers right and each layer is adding something to it some some color dimension some highlighting some smudging something right but things to it and obviously it can get silly for example you can one layer you can take a donkey and another layer you can put a crown and now you can move the crown on the donkey's head right or any funny thing you like or you can make a tree grow out right from somebody's hand or something like that so all of those fantastic things if you think about how did they come about they came about because Photoshop takes a disciplined approach to building any particular photo right and these are layers. It also is sort of reflective of a grammar of graphics. So that is a subject we will deal with exploratory data analysis. Now just exploratory data analysis, while it seems to be the mundane part of data science, it is actually not. And as your first lab will show, just looking at the data changes the world. Quite often changes the world. The most remarkable thing is once you have gathered the data once you know what questions to ask scientifically or what data to gather quite often the answer is staring you in the face but there are situations where it is not so obvious where there is a signal but you have to it's hidden you have to find out, right? So we took the example last time of ice cream on the beach. How much ice cream can you sell on the beach? You have data that shows on this day, this much ice cream sold for this temperature, isn't it? Given the temperature, this much sold. So you can do descriptive stats. You can do what's the minimum and maximum that was sold, what's the average amount sold, right? You can scatter plot it and so forth. Those are descriptive stats. Out of that exploration of data comes clues. It helps you build hypothesis, isn't it? It helps you build a hypothesis, possible hypothesis about what's the relationship between the sale of ice cream and temperature. You would not have gotten that intuition unless you did exploratory data analysis, isn't it? Unless you visualized and summarized the data. So I always say the data is like friendship. You have to spend some time to become familiar with the data. It is not about brilliant tools that bypass all that. They don't. The more you become familiar with the tools, the more time you spend on the data itself, exploration itself, and become familiar with the data, not the tools, sorry, the more likely are you to get lots of ideas that will guide your investigation into the machine learning part, into the AI part. Are we together? If you look at the people who win Kaggle competitions, at the end of the day, at any given moment, there are only two, three algorithms that are state of the art for that particular data set. And if you look at the guys who are in the leader board and people who are 100 or 200 ranked, you will realize that they are doing essentially the same thing. They're not doing much different things. The only difference is these people, the winners, they spend a lot of time cleaning and preparing the data, understanding the data, and squeezing the last bit of performance from the data. But the tools are quite often the same. Rarely do people do breakthroughs in algorithms to win Kaggle competitions. It is the known algorithms, but people spend a lot of time on the data. So never, never sort of underestimate the value of exploratory data analysis. So that is one aspect of data science. The other aspect, which is sort of the core of it, is obviously the machine learning part of it, the predictive modeling, the pattern recognition aspects of it. So in in that class of course we talked about this algorithm which we can think of as a black box. Inputs go in and it predicts a number. The number is something, it is a sale of ice cream on the beach. It could be for example how many items, like it could predict a whole variety of things. When is this device going to fail? How many days will it last? Reliability engineering and things like that, right? Median time to failures and so forth. So, you can predict all sorts of things so long as you can represent the output as a number, as a real valued field, it is regression. The inputs do not have to be real valued field. So for example, you may be feeding it cats and dogs and based on any species it might be coming out with a number. That number may be let us say the weight of the species it has some magical way of looking at the picture of that animal and guesstimating the weight it can be done right if you have a standardized picture and so forth. It may or may not be terribly accurate, but it is still a valid regression are we together, but the input was not necessarily a number maybe it was a type it is categorical. So, now we will talk about what types of data do we deal with the they are fundamentally two types of data numbers real numbers which measure something right for example a weight is a measure right and it is sort of, most of us do not want to know our weight, so we can take something else. So, weight is a measure. But, which day of the week it is, is it a measure? Is it a measurable quantity or it is just a type? It's a type, it's a class. Days are days, Wednesdays are Wednesdays. Wednesday is not more or less than Tuesday. It's just a different day. Are we together? So those types of data we call categorical data. Data which whose possible values belong to a finite set of values. Those values are called classes. For example, if you want to predict whether something is a cat, a dog or a horse, then it is a category of animals which has only three values cat, dog, horse. Do you see how this language is developed? A category is made up of classes. That is it. So when you predict, when you look at an image and you recognize that this is a cat, it doesn't mean a specific cat it means that cat is a type of animal and this cat of the category of animals and cat is a class of animals isn't it it has a tail and what not so that is categorical data now within categorical there is a between numbers in categorical sometimes there is a certain bit of ordinality ordering. If there is an implicit order in the data for example, which day of the month it is. Now, the day of the month from 1 to 31st you may say it is categorical it is a finite set is not it. So, if I have to predict of which day of the month well you stop being scared of coronavirus right it is a particular day of the month right but nonetheless there is a ordinality to it. Fifteenth is before eighteenth. The order is there. Right? And three is before fifteen and so forth. So, that is ordinal data. And we will learn how to deal with ordinal data. But for the time being, we won't... Date, for example, is a classic ordinal data. Month of the year. Right? So, even though we treat it as categorical sometimes you you have to ask yourself does it make sense to treat it as numeric right so a predict which month it will be you might come out with 1 3rd February 2020 two third March. So, then you say well it is mostly March. You may bin it to March and so forth. So, you may do something like that and we there is a whole sort of judgment process you will go through to see whether some measurable or some observable you want to treat as categorical or real valued. Real valued, by the way, what are real valued things as opposed to imaginary value I suppose? What are real values? In simple terms a measurable is a real value. The reason mathematicians use this word and they use, you'll see in my notes this peculiar notation r written with a unnecessary bar here. This is a symbol of real number line. Means it could be positive number, negative number, rational number, irrational number, anything decimal, whatever 2, etc. So r-valued is a part of the vocabulary that we will use r-valued so these are the two types now when you make prediction let's say in the case of regression part of the summarization is we had the concept of missing the mark data says on this temperature the sale of ice cream was Y and your model predicts what? It predicts a Y hat. By the way what give the whole answer? That's a correct answer. Anybody would like to rephrase? So, in the case of regression, a straight line is a hypothesis of a relationship between input and output, between the case of regression a straight line is a hypothesis of a relationship between input and output, between the input and the response. It is a hypothesis, it may or may not be true right and which line itself you do not know. So, what determines a line uniquely? A line is uniquely determined by a slope and a intercept. So, the slope and intercept we write in Greek or Latin. Are you sure? I will write it. So, we write it as, let me just review that. Remember, we wrote it as Y is equal to beta beta naught plus beta 1 x. Which is the slope here? Beta 1. Which is the intercept? Beta naught. What are the observables? y and x. So, x and y are Latin or Roman letters and these are Greek. That is why you hear machine learning people speaking Greek, right. No one understands them, right. So, these are concepts that's the way to remember. Now predictions are, so actually this is Y hat, right. Even though we say Y, this is actually Y hat. Your hypothesis is that this is the relationship. Together this makes your hypothesis. Isn't it? It's your hypothesis. Then the real relationship is y is y hat plus some error term. Isn't it? There will always be error. Am I together? Now, there are two kinds of errors when you build a model. One is your model is really very good and then you have values away from it. Like for example, we took our situation which was this and let us review what we did. Suppose you have data which is like this. Can we see this data from the back? Why? This is the data. When you look at this data and you make a hypothesis that, let us make two hypotheses. One hypothesis goes like this and another hypothesis goes like this. Which of the two hypotheses intuitively we feel is the correct one? The green one. And what is the intuition behind it? Yeah, it sort of gets it less wrong for most of the data points, isn't it? So the the error which is or the residual we talked about or let me just use the word r i or which is the same as error term of this is equal to y minus y hat, isn't it, Of every point. Now, we ask this question. Let us say, even for the best line, so till we reach the best line, you realize that till we reach the best hypothesis, we can flex this line. We can reduce the error, right? Or we can choose a better hypothesis. For example, if you insist that your hypothesis should be let us say this, this blue you realize that this hypothesis has really missed the structure of the data isn't it. So this sort of, you can start with the wrong hypothesis. Then you are likely to make a lot of errors. Then even in, then you might have a better hypothesis of a line, but you still have learning to do. You have to use what technique for learning? Gradient descent, you have to tumble down the hill and come to this. So, there are two kinds of errors, the prediction and reality. You realize that in this case, the gap between a prediction, a data and the reality, I mean the prediction gap is pretty big, right. This represents something you would call a reducible error. Means you have taken a model that is just not appropriate. If you choose a better model, a better hypothesis, you will be able to reduce that error. Are we together? So, these are reducible errors and errors and it deals with what sort of models we pick and then train to the best line, let us say if we choose a line model, the best line that will fit the data. There is a learning part in machine learning. Then there is another error which is actually not reducible. So, when you look at this data, look at the green line, we agree that the green line is the best we can do. And yet we have data not sitting upon it, not hugging this line, but you have errors even for the green line. So, if you look at the sum squared error what is the measure of error here sum squared and what is it sum squared error term is equal to anybody would like to tell it is what it is basically the residuals square which is equal to i y minus y hat square, isn't it? And if you plug in this thing here, you realize again a recapitulation that this becomes a quadratic equation y minus beta naught minus beta 1 x square. Now, if you look at this equation y i yi, xi, yi are data. You cannot play around with it. When you are trying to move around your hypothesis, your line, shift your line, you cannot play with this. You can only change beta naught and beta 1. And therefore, I mention a dual space in this context, a space of hypothesis. You realize that for every line in this world, there is a unique slope and intercept. Every line is uniquely identified with a slope and intercept. So, if you look at another space, a hypothesis space, whose axis are beta naught beta 1 slope and intercept, right? Let me just call it slope intercept, you would agree that for each line there is a point here, isn't it? Each line there is a point here and for each such point, each such hypothesis there is a total error. And what is your goal? You want to find the minimum. You want to find that beta naught beta 1 that will minimize the quantity. So you are searching for those argmin, a fancy way of writing it. Oh goodness, does this look scary enough? It does, right? So because you will find it in books, let me just explain what it means. You are searching for those arguments because this equation is in terms of beta naught beta 1. You are looking for those values of this that will minimize this. Is that simpler? That is all it is. You see this notation, but it is nothing but jargon. It is just simple. It is just a convention in the field to say things succinctly and soon you get used to it. You are looking for that value of beta naught beta 1 that will minimize this. And how do we do that? This is a quadratic equation just to recapitulate. What we have is beta naught beta 1, we have and this is your error three dimensional space what do we have? We have an error surface which is quadratic. You remember we talked about the quadratic surface right that a quadratic term has how many bends? Only one isn't it? So, we can have only one bend it is a minima. Now it achieves its minima here some point. This quantity this distance is your minimum amount of error that you are left with. It is your irreducible error is not it? As far as this is concerned you cannot get better than this. So, the question remains are we together? So, what can you do? You just start with any line, let's say red line, and now ask how do I quickly move from this to this. And that journey is very simple. We all know from experience that if you are in a bowl or in a hill, the shortest way to the valley is the one that you don't want to take. You can just tumble down and you'll be at the valley is the one that you don't want to take. You can just stumble down and you'll be at the bottom of the hill into the valley. So there's a fancy word for it. It's a steepest descent, right? And the people often in this community, they more often than not use the word gradient descent, The path of gradient descent. Now, this is some very beautiful mathematics around it and as we develop expertise we will come to it. So, it's gradient descent path or in much more layman's language is just tumbling down the hill. Tumbling down the error hill and you'll come to the point of minimum errors. But you still are left with these errors and the last question is why is it so? Why is it that when we observe data, inherently it comes with errors? This is the irreducible error. So, just to recap last time, why do we have irreducible errors guys? Svesh, do you remember? Oh no, you were not there. So, Patrick. . Why? . Yeah, that is an observation. It is never perfection. What could be the reason for that? Why? The way you try to . Yeah, that's an observation. It's never perfection. What could be the reason for that? What are some of the reasons? . Yes, that is one. In other words, see look at this example of selling ice creams on the beach. The sale of ice cream on a given day doesn't depend just on the temperature, which is what you have looked at. It depends on multiple beach. You know, the sale of ice cream on a given day doesn't depend just on the temperature which is what you have looked at. It depends on multiple factors. For example, is it a weekday or weekend? For the same temperature, you'll sell far more ice creams on a holiday because parents will be bringing their children there. On weekdays, they'll be slaving away in the workplace, right? So, they would not exactly be willing to take kids to the beach. It is much more likely to be. So, how will that show up? You will end up with a lot of readings for similar temperatures or very close temperatures, but a whole band of readings, is not it? That represents whether it is a holiday or it is a work day, things like that. Is it very windy, for example? Is the sea very choppy that day? Because some parents, they're hoping to do surfing, right? Or go sea bathing and so forth. The children want to go into the sea. But if the sea is very choppy and windy, our parents wouldn't want to take them there. So, there are many many factors which your data has not accounted for and that manifests itself as irreducible error. And so, this is one thing you have to know guys that whenever you get data remember that it is a small window on the reality. It is never the whole reality. Are we together? It is a small window. Somebody thought this is essential, temperature is essential and perhaps more essential than other factors. And so gather that data. But whenever you gather data, you pick certain observables out of infinitely many observables and factors that may be there. So for example, when you are looking at the amount of ice cream that you sell on a given day, a completely unrelated factor would be on that particular day whatever the temperature was, average temperature was, how many dolphins or how many penguins jumped into the sea in Antarctica? Now you say what in the world has that to do with it? But you say well how would you know? Who knows? Right? It is just your plausible guess that it is not a factor that matters. Do you see that? You just plausibly guess that it is not a relevant factor and so you did not include it and sometimes what happens is most of the time we pick the factors correctly, but sometimes it can have startling effects. Sometimes a factor is staring us in the face and we do not realize its value and we do not pick it up. Are we together? And in fact, when you do your lab today, the lab work today, actually there was supposed to be six data sets that I wanted to give in lab today. And I was not sure whether three of them I should make homework and make three with solutions or I should give solutions for all six. So, at this, I've given you solutions for three of them. And the other three, I am still thinking whether to leave them as homework for you, fill in the blanks, lab work, or to give it to you. I'm leaning towards just giving it to you, because it's your very first lab. But as we make progress, you will see that I will give you less and less and expect you to do more and more of the lab. But here are your labs that you are going to do today. The first is of Florence Nightingale. We talked about her, isn't it? And her profoundly influential data analysis. During the Crimean War, and I'm told that, I don't know if this figure is right, I'm told that one million people died in the Crimean War of 1853 to 1856. That's when Russia attacked the Ottoman Empire, Turkey, right? And Britain and France came to its defence. And so, Florence Nightingale was not so much concerned with war, but she was concerned with taking care of people, helping them and she realized that these wounded people who come, the soldiers who come and she didn't care which army you belong to, she was taking care of soldiers apparently of whichever army, doesn't matter whether they are Brits or not. So when she was taking care of them, she realized that very few people die of actual wound, we talked about that. A lot of people die of actual wound we talked about that a lot of people die simply by visiting the hospital itself and if that seems far-fetched this is still true in some third-world countries how many of you would be delighted to be hospitalized in a hospital in an Indian hospital for example right you don't want to but you think that that is bad even in US the hospitals are actually germ beds even today. But one of the great work that Florence Nightingale did is she showed the importance of sanitation and that drastically reduced the number of people who were dying in wars. Somebody quipped that the most unlikely reason you will die in a war is a bullet. You are much more likely to die of malnutrition, unsanitary conditions and what not. So, that changed with her visualization. So, she noticed a factor that was staring in the face but nobody was paying attention to. Isn't it? So, that is something important. Likewise, the second data set is of John Snow's Cholera data set, the spread of cholera in a city, London, again in the 1850s. So, these are the data sets that sort of started this field of statistical analysis and data analysis and so forth. People used to believe that you got cholera because the air was bad. When the air became bad you would pick up diseases. Cholera and plague you would get because of bad air. It was the miasma theory and the bad air, the things in the air that made it bad were called the miasmata. But then what John did is he just took, every time somebody would die, he would mark it on a map. Where did the person die of cholera in a particular outbreak in London? And what he observed, and then he would go and interview every person who was sick with cholera to see how did you contact it and so forth. And what he noticed as he gathered data is that the answer was staring you in the face. Nobody had considered it but quite obviously there was a cluster of cholera and the likelihood of your getting cholera was directly related to how far you were from one particular water hand pump. In those days germ theory was not taken seriously, people didn't have the modern understanding that these diseases are caused by germs. So it was still the miasma theory. But just by looking at the data he said whatever it is its here right and so if we could take out this hand pump and so forth it could have a beneficial effect. Then later on they investigated and it turned out as you will see in the notes that actually that hand pump was the culprit. Another culprit was a bunch of companies that used to bring water to London just as in Bangalore today big trucks bring water to the city. So and what they found is that they were getting water from a polluted part of the river. So sewage, imagine sewage flowing into the river, common sense says you shouldn't take water downstream from that isn't it but that was practically what was happening and so that was implicated in the in the disease so you know this is the interesting thing factors you did not consider why did you not consider in hindsight they look like obvious factors isn't it why did you not consider because people have preconceptions people think that soldiers die in war because of wounds, because of battle wounds. Isn't it? They don't realize that there are other causes. looking for other causations. So, those are the ways you miss features that matter and you should always be on the guard when you have a wide error, you should be on the guard that that is happening. But then even if you take care of that, there is still the fact that observables come through measurements and no measuring equipment is always precise and accurate. You take your own temperature 5 times in quick succession with 5 different thermometers they will not all agree with each other. Before the coming in of the atomic clock, now we all get a time from the atomic clock. In any given town it used to be a custom whose time by whose clock. There is a reason why every town had a clock tower, because all the clocks would disagree with each other. So, we needed to all be based on one clock, not because it is accurate, but because it is the reference, isn't it? And no guarantee that that would be the best most accurate clock whatever you tried and that was the concept of the clock tower in cities. So, remember the fact that instrumentation error will also introduce irreducible error into the system, noise into the system. You have to be aware of that. And sometimes there is even deeper reason some things inherently cannot be measured to arbitrary many decimal places. For example temperature, how do you measure temperature? You cannot measure temperature to 20 decimal places why? Anybody? Yes, temperature. Doesn't matter degrees, Kelvins, Fahrenheit. Why can we not measure to 30 decimal places? Even if you, even in principle you can't do it because temperature is the thermodynamic, it is a macroscopic representation of atoms bouncing around statistical mechanics you know. If you look at the mechanics of atoms bouncing around the aggregate effect is temperature isn't it. But there is actually at the atomic level no such thing as temperature nobody can take a thermometer and say this atom is at 100 degrees. That concept is absurd. Do you realize that? So, certain concepts are essentially by definition they emerge and we know that these are not fundamental things at the subatomic level and so on and so forth. But they are practical things and they have limited precision, but they still work right. So those are the sources of irreducible error. So that is a summary guys of last time did I miss anything are we together so far and we need to fix that clock it is telling me we are we should start now right okay. But with that I will ask you guys a few well I think it is a simple enough material I would not have much to quiz you about. Any questions guys anything that we did not understand before we move forward. So, today is here is the interesting thing guys there. Myosinma theory just said that when the air is foul people catch diseases they are things particles in the air the smells in the air and quite often that smells were associated with fecal matter and so forth sewage. So, they would whenever these epidemics happen, the first thing they would be that let us move away from the sewage because it stinks and the illness is coming from all of that garbage and sewage and things like that. But obviously today we know better, we have the germ theory and to the best of our knowledge that is the correct explanation any other questions guys. One is the real oh the categorical things that are not measure measurable, but things that are types Tuesday and Thursday are not measurable, but they are types of a day in the week. A cat and a dog you just look at it and say it is a cat and it is a dog that is it. So, they are the other color blue, green, red. So, these are the categoricals, two fundamental types. Patrick. Sir, how do you define so much of domain experts? Those are usually called domain experts. One of the great lessons we have learnt in the recent years is, see there has always been a way sort of an interesting relationship between people who are data centric and people who are domain gurus, domain experts. Domain experts need some data analysis too, but they think of it as secondary to their experience, to their understanding of the field. On the other hand sometimes data scientist get carried away they think give me the data do not have to tell me about the domain and I will figure it out. Usually both sides get stumped the best combination is of putting data and domain experts together, data scientists and domain experts together. It is sort of a symbiotic relationship. There has to be a give and take, a moving forward together that takes you forward. There is a lot of history of course to all of this. For example, to create these teams in US which team would win which game and that now we know that what is that called curve ball no hard ball there is some TV show right hard ball or something money ball money ball or something. So it is about games or some teams and how do you form teams by looking at all sorts of statistical data. Who to have as a member of your team, who is likely to do well next season. The domain experts used to do it based on all rules and then came a bunch of data science people and they outdid those guys. Today we know that you need both of them to really get good predictions and good understanding of that. It is everywhere like you cannot just be a tool at the same time you cannot ignore the tool and be weak in the tool and just say I know from experience. You need both. Any other questions guys before we move forward? Now, so today we are going to do the lab part guys. Lab I have kept it for a post 9 o'clock a post 9 30 you can also do it at home just to remind you we have three TAs in the class they are here in the evenings right. So, if you in the afternoon or evening if you get stuck just visit us will help you do the labs at the same time you will form small groups guys and now what will happen is I will teach for some time and 8 o'clock one more hour I will teach you after that I will leave you guys to form little groups go to your room and do these labs. I will give you some I have deliberately omitted basic instructions like how do you set up a Jupiter notebook right and how do you set up a Jupiter notebook, right? And how do you set up some of these basic things? Because I want you guys, I will come to your rooms and give you some instructions, but ideally I want you guys to collaboratively find out in your steady group because this will help you form your steady group, right? And I have given you many of the steps but not all the steps deliberately because I have left something for the group effort to happen. So you will do it like that. So that is it. Did all of you receive the notes? Have you all looked at the notes? Look at it for a couple of minutes and then we will ignore it. And I expect that you will start doing it today and you will continue to do it through the week and next time when we come you must have done it are we together right. The reason I want to emphasize theory today is we need to have enough foundations before we do more labs, but gradually as we make progress with this workshops you will see that we will become very practice heavy lab heavy towards the end right, but at this moment we are going to build the foundations. So now guys I will talk to the next topic, I will start the session with something which we are on a journey to regression, but we will take a detour. We will talk about something that your book does not actually talk much about, what is the relationship of correlation, covariance, causality and so forth? So, first people very popularly, this is a very popular thing, everybody seems to use the word, these two are highly correlated. What do we mean by that? What is correlation? Can anybody explain to me mathematically what is correlation? Give me a geometric interpretation for it. What is it? One changes the other changes. Yes, sort of. Do they and we will we will formalize that relationship today. Covariance, correlation we will talk about. What is causality? Causal effect, right? You put water, a pot of water onto the stove and turn it on, the water will boil. So, you can see a causal relationship between your turning on, all of your prior actions, putting the pot there, turning on the fire and hot water. One has caused the other in a very direct sense. Causality implies a sequencing in time. You cannot cause an incident in the past. You can for example, to the best of our knowledge, not go back and kill your grandma. It is a fact because causally causality goes only forward, it does not go backwards. So far so good guys? So causality always has that the cause in a sequence of events must be prior to the effect. And that brings us to the concept of sequentiality. How often does sequentiality affect and causality like are related? So, do you think that if one thing comes before the other, there is a you have a very strong suspicion that one caused the other. It is a very natural human fallacy, isn't it? We tend to do that. An example is people often say like like you remember the example that I took last time. The pilot instructors absolutely shouted at the bad pilots student pilots and they noticed an improvement. What is wrong with that reasoning? Do you remember? It is not enough control. Right, but more fundamentally just because improvement came after the shouting does not mean that shouting caused the improvement. Logically it is as basic as that. It is about as absurd as saying another fact, I came to silicon valley and there was since then the internet revolution. So, I must have caused it, right? It is literally as absurd as that. People often say, I started eating, you know, all sorts of people. These days, by the way, we are in a generation of food fans. Everybody is on a peculiar diet, right? Somebody believes that it must be just protein. Somebody swears by, I don't know, celery sticks, right? So suppose you eat a lot of celery and let's say after a few days, you notice that your boss just gave you a raise. Has the celery made you a more productive employee? It does not go like that, but people make the mistake all the time. Suppose and it is the history of medicine before the discovery of the antibiotics and the modern medicines. For centuries, for thousands of years, doctors still existed. Today, when we look at the medicines they prescribe, they look like absolute nonsense. So, for example, putting a whole lot of leeches to suck your blood does not actually cure you of any disease whatsoever. There is no such thing as body developing an excess of blood and things like that. Yet, it was a very dominant medical practice. Did it work? What do you think? It did. So, there is a causal relationship between sucking your blood and you getting cured of diseases. But there are some other parameters of causality, but it's not. No actually this is the human fallacy. The deepest human sort of bias of fallacy psychologically is we confuse sequence with causality. So here here is how the old practice works and obviously any doctors out here, oh there is one. So, tell me two of them, so you guys will tell me whether you agree with my statement or not. See suppose one of the things about the human body is diseases are self limiting, most of the diseases will cure themselves. Occasionally you get something terrible and you don't get out of it. But more and you get chronic diseases. But usually what are the diseases that you get? Upset tummy, fever, flu, corona or something like that. All of these things, you don't have to do much. If you leave the body alone, it will essentially bounce back. Sure, modern medicines can accelerate the journey out of it, but the chances are very high that you will bounce out of it. If you have an upset tummy or something like that, the kid will bounce out of it, essentially. So the guy goes with, oh my tummy is hurting so much. Doctor can you do something? So what would the doctor do 300 years ago? He said, my dear boy I'll take care of you. Now, it doesn't matter what medicine he gives. He can just give ash. And the person takes ash. In those days they used to be the concept of this mixtures carmated mixtures so the whole concept of a chemist was you would sit with the this thing what is it called pastel and water and go about grinding something I put it in water and you would get a mixture and in my own childhood I've seen when I used to go to the doctor and come back I would come back with two three bottles of colored mixtures. One was for fever, one was for cough and what not. Well at least that was in modern times. I think they were still getting acetaminophen or whatever. But think of the world before that. People were still getting mixtures and then this guy with his tummy, a few days later he's cured. So what does he go about saying? This doctor is just amazing. Isn't it? Because most diseases are self-curing. Any quack will have a high success rate. Do you see that? Any quack would have a very high success rate. And why do people believe, why do people swear by quacks? You can see that in India. Actually my mother is a surgeon and you can see that in the remote parts of India. It's extremely frustrating to be a genuine, you know, well-trained surgeon because people are extolling the virtues of some quack, right, who is very good and you know that the guy is completely clueless. It happens all the time. Now why do people believe in that guy? Communication. Mostly because they are confusing sequence with causality. They went to the doctor, the doctor gave some medicine, this guy was cured. Therefore it must be the medicine he gave that cured it and the correct diagnosis that made it happen. Do you see that? What they don't know is that even if you had not gone to the doctor you would still be cured. Right? So that is the big fallacy that human beings have. Obviously it's very literally entire professions for the longest time. I don't know when you look back at many of these professions like medicine, what exactly were they doing 600 years ago? They knew practically nothing about the human body, right. And yet there were some experimental drugs, you know by experience you knew that this could do this and this could do that but in most of the cases when you go back and look at it you can quietly replace one drug with another, another of their mixtures and the effect would still be the same namely the guy will get cured, right. And a lot of people believe for example and obviously I am no judge, I'm not an expert, I'll let the doctor speak, they are homeopaths. To the best of my knowledge, it's a very peculiar science, the more you dilute, the more powerful the medicine becomes. At some high power of dilution there is not even one atom or molecule of that left a little while and that is supposed to be tremendously potent. I don't know how it works but to me it does it ring as though it may be sequence leading to causality, right? Being confused as causality. What do you think guys? Probably, right? I don't know maybe and nobody has come up with a scientific explanation of why it works. No placebo is not actually and in the paper that I have given you, I have given a reference to Stigler. There is a very interesting study, placebo the you know how placebo came right during the first world war in a in a battle camp one person, so morphine was supposed to come to a battle ground that night and the soldiers were groaning in pain, but the supply lines didn't come through, morphine didn't come and so there were no morphine injections to give to the soldiers. And so this fellow had the brilliant idea and he said let's do one thing. Let's go and give each soldier pure distilled water injections and tell them it's morphine. And most remarkably that night the soldiers slept peacefully. It was a quiet camp and that was the startling discovery of placebo effect. But placebo effect works only for for pain it has never been proved beyond that right there are all of these stories that people say that you tell a guy this medicine will cure you of cancer he gets cured and then so forth but actually there has never been any systematic evidence for that it's only for pain that it works right but it is just sequentiality you know the things of that so anyway that is important that is something to just sequentiality you know the things of that. So anyway that is important that is something to remember sequentiality and causality should not be confused. Last time I asked you guys with a puzzle why is it that children of very tall parents are not as tall and children of very short parents are not as short. Do you remember that? The off springs they regress towards the mean, towards the center. Why do you think that happens? Do you guys want to know the explanation? And sort of is very related to why this algorithm is called regression. But I will let, Glenis would you like to speak? You remember that? Yeah, that's the correct explanation. So now you know you have to go to the T A, right, next evening. So, I'll just re-state that. See what happens is, any effect, like I just told you that y is because of some causal factor, some model, some driving force that is producing a response. But beyond this, there is the irreducible error term. You see that, the error term. So, let us The wonderful weather during your birth, your mother's pregnancy and all of these wonderful things caused you to be this tall. You realize that if you are extraordinarily tall, you are because of certain genetic and environmental factors but also because of a conspiracy, some very odd and unexpected conspiracy of other factors which caused you to just leap forward because it is sort of the error term that you do not understand. Error tends to follow a bell curve. Are we together? Now, the bell curve has extremes. In fact, the tails never end. They keep on going all the way. There is no ending of the tail. It thins and thins and thins and just when you thought now it cannot thin anymore, it still keeps thinning. That is the nature of the bell curve. So, what does it mean? The probability of the error being close to 0 is high, right. Quite often these errors are small, but rarely the errors are outsized. So, suppose you make a giant error in the positive direction, delta E in the positive direction, right. It happens. So, what happens is that your height, let us say your height was supposed to be big. It was actually supposed to be here in the height curve. Most people have height here. You even suppose you are tall. This is your fx. This is the height from your genetics. Tall parents produce tall kids, isn't it? But what happened is, to this we now need to add the error term. So for the offspring on whom the error term took you this far and put you here. Now those advantageous factors that are there in the error term, the positive error term, will they be there when this person becomes the parent? No. What will be there? This will be there, isn't it? So, what is likely to happen? This person will again produce a progeny which is this plus the error term. Now the error term, if you are sitting here, very unlikely that the error term will be this or bigger. It is far more likely that the error term will be less. Isn't it guys? Do you see that? Because error can be anywhere. It is far more likely that it will be here. So if the error is anything on this side, what is likely to happen? This guy would have regressed back in height. Are we getting that? And that is the explanation of why you have regression towards the mean. Do you see that? And what happens is that, that story that I told you about the pilots, let me rephrase that. When certain people, some student pilots, they do extraordinarily bad on a given day, why do you think they do so bad? Are they absolute hopeless people? If they were absolute hopeless people, they wouldn't be there in the Air Force to begin with. Isn't it? But we all have a bad day. Have you noticed that there are certain days when you go to work and there is no mistake that you leave uncommitted? Right? You just blunder your way through the whole day. Right? And everybody wonders, what's wrong with you today? Well, you are the same person, but somehow a combination of adventitious factors is causing you to blunder your way through. Those days are relatively rare. What is likely to happen the next day? Those adventitious factors won't be there. You would perhaps be better slept, other things would kick in, right? The problems you are facing will be more conducive to your abilities and so forth. So you are likely to do better. If you have done particularly bad on a given day, good news is next day you are likely to do better, isn't it? So that is what happens. When you take those people who have done extraordinarily bad shouting at them has no real value because they are likely to do better anyway the next day. And you shout at them and you just come to the lovely conclusion that shouting helps. You might as well have sent them to the movies and you would still come to the lovely conclusion that shouting helps. You might as well have sent them to the movies and you would still come to the same conclusion. Isn't it? So that's the relationship of causality and so forth. So that is regression towards the mean. That paper in your notes I have given two papers guys, reference to to two papers one is Galton's original paper regression towards mediocrity in hereditary traits do read that it is an original paper you do not have to read the whole of it read the introduction and go far enough are we together and then there is a far more delightful and very influential writing by the great statistician and sociologist Stigler and that paper which is regression revisited, regression towards the mean revisited. It is a brilliant, brilliant understanding of how this whole thing confuses us. And I would highly recommend that you read it. The reason to remember it is in data science, do data scientists not make that mistake? This is the most common mistake made by data scientists. It is also the most common mistake made by scientists, all scientists in every discipline. Sequence is not causality. Regression towards the mean is a fact of life which will always happen. You do not have to give explanations to it. So be aware of that. Lay the foundation strong for the field. So So, what did we talk about? Regression towards the mean. So, now let me ask you more questions on the causality. I'll tell you, I'll start with the fact that I hope you guys will really get bugged about and the point is to annoy you so you remember it. It so happens that the population of India since independence and the population of donkeys in China are nearly perfectly correlated. The curves look identical. Now you wouldn't want to believe that one set of couples is taking hint from the other. It's implausible. So why do you think it is there? Are Indian couples somehow causing the donkey population in China to go up or vice versa? So, when you have correlation between two things in the colloquial sense and I haven't defined these terms what does it really mean does it mean that one causes the other? What could mean when you see a perfect correlation between two two things over an axis let's say time axis or something like that what does it really mean? Does it mean that one that they are interrelated or one is causing the other? What are the possible explanations? Very good. So the explanations are interesting. One could actually be causing the other. Are we together? So you study, you put in a lot more hours and the number of A grades that you get in college begins to go up. Number of A grades per semester. Right? Directly correlated with your number of hours of study. Well, one would possibly argue that one is causing the other. Isn't it? It may not be causing the other like in this particular case why is the population of donkeys in China related to the population of India for many years actually I'm told long ago I saw this data it was hilarious actually why do you think it is true can you explain you were on the right track Balaji, so explain that. Yes, so your possibility is what you call a latent variable. So behind the two there is a third variable which is the causation. So with that hint how would you explain this to? See what happened India and China when they did become free at about the same time before that they were colonies they were massively exploited for resources they had family like situations population growth was stagnated isn't it. Now basic population dynamic says that the more the resources available food available the better the population growth of a species. So, both these countries had enough food after independence because both these countries have made despite all our morning and grumbling that nothing is being done, both of these countries have made an astounding amount of progress, just phenomenal amount of progress. In 50-60 years they have pulled themselves up like rapidly. Food hunger is actually not that big an issue in these countries. It is there, it has not vanished, but it is not as big an issue as it used to be. When I was young, I used to go to public places and find places littered with beggars sleeping everywhere in Asian countries. Today it's not a fact. People are wearing pretty good clothes, isn't it? So, what happened? Population grew in consequence. When food is there, population grows. Population of India grew, population of China grew, population of Chinese donkeys grew because they too had food and I am sure the population of everything grew. Cows grew and goats grew and everything grew in these lands. So, there is a very natural explanation why populations are correlated. Do you see that? But, unless you think of the explanation, the whole thing looks absurd and almost insulting, isn't it? To point it out. And that is something you have to know. Sometimes correlation points to an underlying factor causing both of these. And there is a third thing that correlation can point to. Absolutely no relationship whatsoever. So for example, if you every day count the number of penguins jumping into the sea in Antarctica from one particular ice block. I bet, I completely bet there must be the stock price of some company which has a perfect match with that. Right? With all the thousands of companies in the stock exchange around the world, exchanges around the world, you would find a very strong correlation. So, do you think that this penguins are determining the stock price of this company or this company is influencing the penguins, some subliminal messaging onto them. It's not, it's absurd, isn't it? So, sometimes you have to acknowledge that see anything a time trend is a graph. Suppose you make a graph like this over time. The gazillions of things which may happen to have this graph isn't it. And so because they have the graph something similar to this you will say wow what perfect correlation and therefore correlation becomes confused as causation. It is a cliche that children are taught correlation is not causation and yet a mind gravitates to that. It begins to think of correlation as though it is causation. So, you have to know that there are three possibilities. One is no relationship at all. It is completely adventitious, completely accidental. The second is that there is an underlying factor driving both. And the third is one really is causing the other. But without further evidence you can't tell one way or the other, isn't it? You need more evidence, more data before you can make a statement. Exactly. I was going to come to that. So the internet has like the lovely website she mentioned. There are many, many websites, right? And what they do is they find all sorts of absurd correlations in the world, right? They'll find correlation between the number of swans in a lake and something very serious happening in the world. They're just looking at curves and they do quite a good service. So that is, by the way, a thought experiment, a homework for each one of you. By the way, I've created the Slack group. Tonight I'll be adding all of you to it. Engage in that. The first homework for you is that you must find some absolutely ridiculous or interesting. Find some correlation that you wouldn't have thought of and post it there. It can be absolutely frivolous and hilarious or it could be something serious and thought provoking and making you wonder is there really a relationship. So now this correlation and causation business is very interesting. There is a bit of history to it. So I was told this is sort of oral history I was told by once what happened is and I think is accurate to the best of my knowledge. In US they used to be the big tobacco, right. Those great plantations which many years ago used to have slaves and all that, right. But even when that got over, big tobacco was still there, pretty strong. Then gradually scientific evidence began to emerge that smoking might be bad for people, it might lead to lung cancer. In the beginning you could easily dismiss it, there is not enough evidence. Is that correct? When there are just a few points of evidence can we ignore it? Yeah, we should. You need a preponderance of evidence to believe in something, right? Because you should not believe in the extraordinary unless there is a preponderance of evidence. Like for example, there is a thing going around that surprisingly all the corona virus, our favorite little virus, right? Seems to be happening, outbreak seems to be happening, outbreak seems to be happening around the globe around 40 degree latitude. But if you notice the number of points that are there, there are very few points, it is a handful of cities. So therefore is there something really jinxed about 40 degree latitude, something scientific mischief going on there at 40 degrees or it is I believe it is called the Bonafori's law or something that when the data is few you can see all sorts of relationships with them. Perhaps you can notice that none of them have two vowels right or something like that right or none of them start with z or god knows something like that. You can find all sorts of relationships, but a preponderance of evidence or preponderance of data will start breaking those patterns, isn't it? And so you wouldn't get caught up in the patterns. You wouldn't start believing sprucious patterns just because there is not enough evidence. So anyway, as the evidence gathered, it seemed plausible that smoking causes lung cancer and more and more evidence mounted up and that is when the tobacco industry got serious, big tobacco got serious. So there were lawsuits, there were high court things went to high court and big courts in US as they usually do and these are extremely tense things where armies of lawyer come and argue. But it seemed that there was a preponderance of scientific evidence relating, correlating lung cancer with smoking. So the common scientific explanation is smoking is causing lung cancer, isn't it? So they took the whole matter to court long and drawn and then experts were supposed to be brought and obviously the tobacco make sure that they have special scientist whose experiments always show that there is absolutely no relationship between smoking and lung cancer. And those scientist have never been able to show a relationship right and they go publishing it right. So in the same lovely spirit they were getting along till things got out of hand. Very prestigious scientist began to say no there is a relationship. So something had to be done. So, what they decided to do is let us bring in the big guns now. So, one of the fathers of data science of statistical analysis, Sir Ronald Fisher, right, a great guy, they flew him in from London, from England to stand in their defense. And he says, no problem my boy, we will take care of this, right. He marched into the court and then he was asked, do you think there is a correlation between lung cancer and smoking? He said, of course there is and everybody was totally shocked. Wow, big tobacco has finally succumbed and accepted that smoking causes lung cancer. But he says no, absolutely not. There is a correlation but it's not that smoking causes lung cancer. It is lung cancer which makes people smoke which causes smoking and then he projected a story in which the tobacco was the big philanthropist because when you have cancer or even a tendency towards having cancer your body is in a state of unconscious pain which is alleviated by tobacco and so well of course they were doing the philanthropic job the humanitarian job of alleviating so much suffering. This is history. I am raising it up so that once and for all as data scientist as emerging data scientist you get out of the notion that correlation and causation are neighbors or cousins. They are not. There may be a relationship, there may be completely advantageous or there may be underlying cause. Are we together? So that's the relationship. Now we will talk about what is covariance and correlation. We talked a lot about these concepts. I am going to go into the mathematics of it now. Any questions before I go in? So guys I have covered a few topics. I have covered causality. Are you guys able to read it from there? Causality. I have covered sequence. I have covered a little bit about regression towards the mean. These are elementary topics. See guys, in your entire career we'll never talk about these topics again because we'll be dealing with esoteric models, you know, random forest and support vector machines and complicated algorithms. But it's good to lay your foundations correctly in the beginning. So, you'll never really get to do that. So, now I will talk about what is this term correlation. Correlation actually comes from covariance. See, imagine that you have data, you have data like this. What does it show to you? As x increases, does y increase or does y decrease? Increases, isn't it? On the other hand, if I have data, a different data set, let us say like this. So, this purple data set, what would you say? As x increases, does y increase or decrease? So the word you say, in this case, as x increases, y co-increases, co-varies. When x decreases, it co-decreases. When x decreases, it co-decreases. So in other words, whatever x does, whatever variation x does, y co-varies with that for the black dots. Isn't it? Are we together guys? Does it look like common sense? So very simple co-variance is on a stove, you turn on the fire to max. I just did that. I was trying to make roti. My Samhita was not feeling well. So, I immediately became a knight in shining armour and said let me make roti. So, I was making roti because I like cooking. So, as I was making it, as anybody who has made roti knows, there's a very direct covariance between how well cooked the roti is and the temperature. And whether or not or how well it will swell also depends on how you turn on the stove. You do it the right way, it swells up nice. You do not do it the right way, the whole thing is a disaster and it is under cooked. So, that is it, they co vary together. fine so far guys. On the other hand, some things contra vary. For example, if you have you notice that the more ice sorry these are allergies do not worry about corona. So, if you put more ice in a beaker or in a glass, the temperature of water increases with the amount of ice or decreases? Decreases. So, it contravaries, right? It goes opposites. The more the ice, the lower the temperature of the water, isn't it? So, it would have a relationship. Would you agree that this would be much more representative of a relationship? And for approximation, I am taking linear relationships for the time being. I am just looking at the class of linear relationships, isn't it? So, it may co-vary, it may contra-vary or this is the second possibility. And the third possibility just to just for entertainment is a set of points which are, what about these red points? Do they co-vary, do they contra-vary or what do they do? There is no relationship. One varies the other whether it will go up or down has nothing to do with Y's, Y has nothing to do with X. Isn't it guys? So there is an absence of relationship. Right? So now let me bring in a subtle point. A covariance, so now you know the idea of covariance. So by the way people don't use the word contravariance or rarely use it. I have not heard anybody use it except me. They use say negative covariance for reasons that you will see why they just call it a negative covariance right this downward thing and this they will say zero covariance one does not affect the other. So is y is y a function of x genuinely does there exist some function that you do not see? When there is covariance, positive or negative, clearly there is a relationship, a linear relationship. But when there is no covariance, does it mean there is no relationship? Look at the red. There does not seem to be a relationship, is not it? So, one can often get into the fallacy and believe that there is actually no relationship, but that is not always true. Suppose you have data like this. Well, might it here itself since we are projecting all the data here. What do you think of the blue dots? Is there a relationship between X and Y? There is. You know it is a quadratic relationship, it is a parabolic relationship, isn't it? But what is the covariance? Well, you will say it will be zero because on this side it is positive and this side is negative, isn't it? They will tend to cancel each other out. So, remember this thing, an absence of correlation or covariance. Correlation is nothing but a standardized covariance. An absence of correlation or covariance does not mean an absence of relationship. It's a subtle point. Whenever we see absence of covariance, when we see covariance is 0, in our mind this picture comes. We forget that this also is possible. There may be a non-linear relationship. All it means is if there is a relationship between x and y, it is likely non-linear, if at all. It is not a linear relationship. On the other hand, a significant covariance either positive or negative means it is a linear relationship. And that is a subtle point guys, get that. Whenever in data you see an absence of correlation, do not presume that there is no relationship at all. Assume that the relationship is not linear, it is something else. So, now that is all good and intuition and geometric. Let us boil it down somehow to numbers. How would you do that to a formula? So, let us take which one the black one. How in the world would you put this intuition into a formula? One way to do that is look at these red points. You know, I made them around the origin. It was very easy. There is a very simple intuition. If you count, see points in this quadrant, the first and the third quadrant, do you realize that when there is positive relationship they tend to be more here and less points in the opposite quadrant. These quadrants signify lots of points here signify a negative relationship, is not it? A contra relationship, contra variance relationship. So, all you need to do is somehow go and sit in the centre of the data, like for the red data we are sitting in the centre of the data. So, for the black one also, let us go and sit in the centre of the data, go and sit in the centre of gravity. Let me call it the x prime y prime. You go to the center of the gravity. Now, it is clear. You see that in positive correlation, all the data seems to be in the first and third quadrant. If I go and sit in the center of gravity of the purple points here, somewhat like here. Do you see something very interesting? Most of the points tend to be in the second and fourth quadrants. It is a very interesting intuition. So, first of all, let us redefine the points in terms of not x, y, but x x prime y prime. But what is the center? The center will surely be the x bar y bar. You know that is the mean. Center is by definition the average point. So what is the relationship between them? x prime is equal to x minus x bar, y prime is equal to y minus y bar. You can convince yourself that this inequality holds this equality holds right. That is what it is the relationship is x from a point here is x prime plus this quantity x bar is not it the shift that you made. It is basic translation guys. So, would you agree that in these coordinates I can write it? Now, look at it in the primed coordinates. What I can do is, I can just notice that x prime times y prime is positive here and here and it is negative here. So, if I just add up the x prime, y prime, just add them up and see overall do I get a positive quantity or negative quantity. Then what should happen is for the black one I would get an overwhelmingly positive quantity, for the black one I would get an overwhelmingly positive quantity, for the purple one I will get an overwhelmingly negative quantity. All the terms are contributing except for some occasional ones. You notice that there are just a few points in the wrong quadrants. And for the red ones what happens? Equal amounts of positive and negative products will be there. Isn't it? And so, this quantity just staring at it seems to be a nice simple way for us to quantify covariance, isn't it? Right? Well, there are lots of points here, n points. While you are at it, this is sort of nitpicking, but you can divide by n also, if you so wish. Let us just divide by n, why not? Right. And when you do that you are literally looking at the definition of covariance of x y is defined as this. Isn't that easy guys? You see how the intuition of this concept can be developed just by thinking how in the world would I measure this? How would I convert intuition into a measurement? And this is the most natural way you can do that. Do you see? The reason I mention it is that these formulas, unfortunately the books, they just foist it on your head and you have absolutely no idea what hit you. How many of you have had that experience when you look at these equations in the book? So, whenever you see an equation you don't understand, it means you are not looking at it in the right geometric perspective because when you look at it in the right perspective it will be easy. So, now let us expand it out x i minus x i bar because that is the definition of yeah and this is y i minus y i bar right. Oh lovely and taking the average people also call it by a much more fancy name let me just call it fancy name to be precise it is called expectation. Right? So, it just sounds very nice. But anyway, so people often call it, write it as E of X minus XI, Y minus YI for all items. Sorry, XI minus, sorry, I take it back, I screwed up. Do you see how simple it is? It is literally by definition. These two things mean the same thing. This is covariance. So, do we understand covariance guys? Now, here is something. Look at two quantities. I am comparing the weight of an elephant in thousands of pounds and against the age of an elephant in years. Well, age of an elephant in years? Well, age of an elephant in years will go from what approximately 0 to 100, give or take. The weight of an elephant, have you tried weighing an elephant? It is very heavy. It is in thousands of pounds, isn't it? So, you realize that we are doing something peculiar. We are multiplying two numbers. One is vastly big and one is small, right? And that does not seem fair, right? So, if you standardize the value, in other words, you compare apples to apples, what you can do is, you can say that look at this. Let us say that the weight of an elephant, assume that it has some distribution like that. It does not have to be a belt curve, but whatever it is. Let us take that for simplicity. It has a... What can I do? I can actually not only go to the center of the data, I can sort of scale the data, right. So, by the spread, how spread out it is. The weight of an elephant will have like approximately 600-700 pounds spread or maybe a thousand spread between elephants. The weight, the age of an elephant will not have a thousand year spread. It will be much smaller, isn't it? So, suppose I could divide it by the spread. So, what happens is that one data point is like this and another is fat. If you could just squish it in to look more standard, more comparable, then it just somehow feels that it would be a better way to compare. So, to scale that It is called the z score or the z scale score scale whatever is equal to given a value xi minus the mu of mu subtract the mu or the x bar actually we are using the notation x bar. So let me stick to x bar and then divided by by the way you know that xi is an observable what about x bar can you buy x bars in the store or see it you cannot it is a concept. So, what should we do in keeping with our new way of thinking what should we do let Let us make it Greek. We will call it mu of x. It is a convention mu stands for mean. It is the closest thing to mean mu, is not it? And the spread a measure of it this going back to your standard statistics it is called standard deviation how much it deviates from the center. It is a fancy word but all it means is how spread out the data is right. So if I scale by that what happens is that most of the values will be between minus 3 and 3 general observation right. Or certainly between minus 6, 6 even with outliers. Some values will go beyond it, the bulk of the values will be here. Are we together? Because you have made it into a standard bell curve. Most of the mass of the bell curve is right here, right. Even though these bell curves go float away to infinity, very unlikely or very lightweight out there. Bulk weight is here are we together. So now you can say we can do further improvement I can just deal with z of x which is this standardized right and I can have z of y and I can say hey let us do a better comparison, better covariance. One nice thing with this is, this Z's value is dimensionless. So you look at the covariance, you know X is in pounds, the other is in years. Covariance, the unit of covariance becomes pound years, isn't it? Whereas, if you do Z scoring of a quantity it becomes dimensionless because x is in pounds let us say mean will be also in pounds and the variance is also in pounds standard deviation. So pounds over pounds is a dimensionless quantity this is also dimensionless the same way for age and so you will end up with dimensionless quantities. Dimensionless quantities are desirable because you know it helps you reason with it much better. So, the covariance of covariance of z of x z of y it has a name it seems to be the better way what should we call it super Super covariance, better covariance, what do you think it is called? What is it called? Make a guess. Standardized covariance, yes you can pick your word but it so happens that the student of Galton of the regression towards the mean fame was a guy named Pearson and he chose to call this as yeah what is this correlation. Now people came up with you may disagree with that you may say this is one definition of correlation of covariance and I can come up with other ones. And so, there are many definitions of correlation by far this is the most popular it is called the Pearson correlation it is the Pearson's definition of correlation. So, if you just plug it back in here, what you will realize is that this is nothing but 1 over n, the same expectation value of xi minus, now should I use mu x, sorry, should I use mu x now, based on a new thinking, yi minus mu y over each of them over sigma x sigma y. And thus the expression. That's a simple understanding of this expression. So what it does is it makes all data centered. So all the relationships now become centered and close to the center. Isn't it? So you can intuitively see the relationships, what the formula is doing. And guys, this formula, do you develop an intuition now? Is this intuitively obvious what it is doing? And that is co-relation. So your homework is go find all sorts of extraordinary correlations and this term is of course become a part of vocabulary so that even kids nowadays are taught about correlation and correlation is not causation except that every time they think they make it, we all make it, we all make the mistake. Quite often we make the mistake without realizing it. So the more on the guard you are the better it is. You will never get out of making that kind of mistake sooner or later, but you can be on the guard. So that brings us to this. Next time we will deal with the theory of regression. So, I will give you guys a reading exercise. Start reading chapter 2 now. We have a fork in the road guys. At this moment, I would like you guys to form your teams and get into these rooms. I will open up all these rooms. Form your teams and start with the homework. Start by installing two things. One is make sure that you have go to a website called anaconda.org. So, in the world of python it is all snakes, right, anaconda and python and so forth, right. So, go to anaconda.org and download the anaconda python 3.7, right. Install the whole suite on your laptop. The second thing you do is go to our website, our language, download our, install the our language So install these things. Python R Python, R, R studio desktop, these three things you should do. Then collectively what you inside the anaconda navigator fire Jupiter notebook or lab whichever is your personal preference. There are two things Jupiter notebook which is very prevalent and the Jupiter guys now believe that oh no we have a better way of doing things, this is Jupyter lab. And so they are trying to move people over to that, bring this and then there is a GitHub location mentioned in the notes, the ML100. This course, what is the word, is it called SKU or whatever the symbol for this is ML100 right machine learning 100 level university system then you will do 200 and 300 levels right. So ML100 you will find the github project go get the data from that project you will find all the data there start working on it. Yes, yes sigma is in the denominator. Oh my goodness, yes you are right of course it is yes, I missed the summation, very good. Go ahead, I am sorry what is your name? Name? Anand. Naga. Naga, oh yes. You look very familiar, you have been here right? Yeah, okay great. You have a question? Oh no, nice. So, there we go guys. So, do this form groups, you are not going home till you have finished the labs, three labs. Now, I just noticed that I have not going home till you have finished the labs, three labs. Now, I just notice that I have not put up the Galton data set I will just push it to the git repository right now. And it is very interesting guys you are literally walking in the footsteps of giants. You will start with the landmark data of Nightingale, analyze the data right and see how it how you can see patterns in the data. Now that particular rows, the two rows is visualization. You would not be able to do so soon. You know it takes a little bit of visualization skills. Do not try that. But learn to explore the data, summarize the data, do some box plots or whatever it is. Play around with it. Likewise for Galton, for Galton by the way I have given you a comprehensive notebook, you can go and look at that Galton data, right. And then play around with this John's data, John's data I have just told you the data is there, it is the variety of the data, there the problem is very simple. The moment you project it onto the map, it becomes obvious what's going on, the dot map. I want you to do that, to learn that maps are useful things and when you project data onto maps, sometimes the answers are staring you in the face. Use whatever map API you want to use, project it onto that. And for all of them I've given you guys references. Guys do you know the 3 books that I asked you 3, 4 books I asked you to purchase? 4 books. How many of you have bought the yellow jacketed book? Great, one. How many more? Guys, if you do not have it at least if you are in the habit of reading from PDF on a e-reader, do read it though. The other 2 books, the other 3 books that I mentioned in the habit of reading from PDF on an e-reader, do read it though. The other two books, the other three books that I mentioned in the back, you will need to refer to it because I will be referring to them in the lab notes. If you see that, I explicitly tell you chapter and section where solutions to some of the homework is. So, refer to them guys. Go form groups, let us get started and from next time the exploratory data analysis is over as of this, from next time we will get hardcore into regression and gradually the pace of the workshop will pick up. So, I highly advise you, see I was slow because you are entering a completely new field, But do not slacken off, do not stay behind and those of you who are here for the first day, little bit scary or intimidating but keep coming here, that is why we are there. The difference between watching a course on a YouTube or an online video and here is what? I am here to help you guys that is the only reason I am standing here and you are here if you get stuck you ask for help right and I am here and the TAs are here and as you can see they can answer any of your questions right. So use them guys and make appointments with them I will put the slack group I will put you guys all on the slack group you can interact them. You can ask them if you want to come in person. Ask them are you there in the office and then in support vectors. Then if they are there, come by. They are usually here in the afternoons and evenings. Come by and use the resources guys. Use the resources. Nisarg, do you think it's useful to use the resources? Yes. He has experience. He's been attending a lot of the boot camps here. . Yes. That's that. So come by, guys. There is an old saying. I don't know if I said that. A person who asks a question looks foolish for a day. A person who doesn't ask a question, elementary question remains ignorant for life. The whole point here is we are here to not judge you, but to answer every of your questions and help you learn. So, do that, I would not say anything more 9, so you have an hour, hour and a half, hopefully you are here till midnight.