 So, we talked about two metacarpals, there is an epsilon, which is the distance, and there is an endpoint, which decides how many points make the identification of them yeah in or out the concept of the distance function can play a huge role absolutely absolutely so that is an implicit third third hyper parameter that's always assumed for the last thing that is right in fact the next topic after telling you about den clue is precisely the deep implication definitions of distance have we'll come to that okay all right guys so i will now get into an algorithm that is called dead clue and i like it because it makes once again an argument that is so classical theoretical physics kind of argument that you absolutely love it from the moment get go so it basically, I'll give you an intuition here. Imagine that we have just had Diwali. So I'll use Diwali as an intuition for this thing. So Diwali, for those of you who don't know, as I suppose most of you probably do, is a festival of lights. What people do is they light up a lot of lamps, little lamps, oil lamps. So just the background, let me just say, because I'm going to use this. And obviously we just had Diwali two days ago, two, three days ago, Thursday. So Festival of Light, lots of oil lamps. So imagine a little oil lamp, typically you're represented like this, and it sheds light. It is shedding light at a given point. So this is the point at which you imagine there's a oil lamp you would agree that the light at any given point x let me say let me take a point x i no this color is not visible so let me just use this at at a point x i is proportional to, it will decrease with distance, isn't it? The further you go, so suppose this distance is d, right? The further you go, the less the light you will get at point Xi, isn't it? Except that there, the amount of light is 1 over x squared but we won't use one over x square but that is the basic intuition what you say is that based on this intuition you imagine this intuition that from this point let me just call it x naught sorry the force the amount of sorry the force the amount of effect at xi from the point x naught right is equal to some decay function and in fact the decay function that you take because gaussians are so helpful and i am being sloppy guys so i will remove some proportionality constants and so on and so forth so forgive me for not putting all sorts of proportion but what is this e to the minus d square how will it go will it go like this e to the minus d square would you agree that this would be the shape of e to the minus d square? As d increases, it is basically a bell curve, half the bell curve, isn't it? Do we all agree with this? Right? So this is it. It's a good decay function that we have. Now that we have this decay function, we now take this intuition. Suppose you have five points, x1, x2, x3, x4, x5. Right? right and you have another or maybe i'll just make it x6 and let13, x14. Are we together? Now, and then maybe there is another point here, x15. So what you do is, and now let me just separate this area out so you can focus here. Let me do one thing. No, actually, forget it. So are these points clearly visible, guys, on the screen? Yes, no problem. No problem, right? So you take an arbitrary point in space. So let us say I take an arbitrary point. What should I take? Let me take here because I don't have to stretch my hand too much. X right? You realize that from this I will get the influence from every single point, including this, all these points. I won't draw all these points, but from all of these, so I can say that given this point X, I can have F X I X. I can have, right? At this point, I will have the light coming from, in some sense, well, light doesn't decay as a Gaussian, but imagine some funny light. The field, the technical word people use is, it's a scalar field. Or think of it as an influence field. And I believe that's a word people do use for this uh influence field the influence at point at the point x is the influence coming from all the points isn't it that are there in the data instances are we together right so i can write the total influence and I forget what exact notation people use, but let me go with my own notation. If the total influence at the point f x is just a function of where you are. Right. Depending on in this feature space, the total influence as a sum of all the influences. It is a function only of the point where you are sitting isn't it because data points are fixed does that make sense or did i lose you guys imagine that the amount of light at this point x if you, is the sum total of light coming from all the little lamps. The brightness at the point x, how illuminated point x is, it is based on how much light it is essentially gathering or getting from each of the little lamps. If you're trying to read a book there at point x, you're being helped a little bit by the light coming from all these little lamps, isn't it? And so the total light at that point in a metaphorical sense is the sum total of all the lights from these little lamps. It is this. Would you agree? And if you go to some other point y, then maybe you're further off and you may get a different amount of light there from the lamps. It's common sense. If you go too far away, then it gets even less. Right? So, or think of it as a heat field. The further you go, suppose each of these were sources of heat, you would agree that if you want to get warm, you better be close to the sources of heat. The further away you go, the less the heat. Or effective gravity? Or you could think of it as gravity. See, all of these are, take it metaphorically, because in a very technical sense, the decay rates are 1 over r squared and things like that. Is there a directional component? No directional component. That's why. Yeah, so this is important. No directional component no directional component right that is what it why we say it is a scalar field scalar field now what is a field this word this is one of the most beloved words of theoretical physicists field the moment you have field, we light up like a bulb. So what is a field? A field is actually any function that takes value at every point in the space. So given a space here, a feature space, if you can have a function that will have a definitive value at every point in that space, in a very rough sense, that is a field. I mean, they can have a more jargon filled definition, but that's a good intuition for it. So think of the light or the warmth at this point X coming from all these little lamps. That should be good enough. There is no directional antenna to it. There's no directional antenna to it. It's like heat. If you have two fireplaces here you're getting heat from both you're just getting warmed that is it heat is a scalar field scalar means it's a number temperature is a number right luminosity at a point like how much light you're getting uh ambient light is a number just a number So if you take the centroid of those gears and you draw a circle around it. No, no, don't do centroids, forget it. So don't- That radius all around it, you'll get the same light everywhere. We're getting there, not exactly, just hold on. Hold on to that. It's a little bit more subtle than that, but just go with that. So we do understand scalar fields, no directionality, it's just a net warmth. Right, Albert go ahead. So field and space are the same, why do you call it field to the converged? No, no, no, space is just the coordinates, the feature space, but at each feature space there's a measurable value like temperature. If all of these are lamps at different points in the feature space there will be a different amount of heat that you are receiving so a field is different from space itself it expresses the geometry it's the container but at each point of that space there is a measurable value point of that space there is a measurable value that measurable value together forms a field so now comes and you would agree that that is a function purely affects if all the data points are frozen if all the lamps are frozen you agree that if i move from here to there and if i were let's say that these are lamps and you're trying to read a book you go far off you won't be able to read the book you come closer to the lamps you'll be able to read a book you go far off you won't be able to read the book you come closer to the lamps you'll be able to read the book isn't it so far so good guys and now comes a very interesting thing we use an argument which is the opposite of gradient descent it is called the hill climbing hill climbing what does it say so suppose i'm here at this point let me just call this point a which is the point x i feel that my i'm not able to read the book what would be what should be my intuition i want to go towards more light so how would i go towards more light i can look at you know what is the path of steepest what is the shortest path to more light so how would i go towards more light i can look at you know what is the path of steepest what is the shortest path to more light for me it would be you would agree remember we learned about the gradients the path of greatest increase of function is along the gradient, isn't it? So my x next should be where? Should be at x plus some epsilon value times the gradient of the function. Do you see this? This is where I should go. So well, if you really think about it, and now let's ponder over what path that would be. So you realize that there are multiple forces here. One force is pulling it this way. Another force is generally pulling it in this direction. Another force is essentially pulling in this direction, right? And so the net gradient, if you really look at it it will be a path that may basically take it let's let's try to make a path i don't know what it will be so i'm just guessing that you would go straight to you would end up here because if you sit in the center of all of these lamps this is your shortest part to go to a good place to read your book would you agree yes right this is it so you you will keep on finding you'll keep on making little steps and you will go there i'll try to create a visualization of this guys i'll try to so you can see it in a very interactive way. In real time, you can see. You can build a cluster and you can see how this hill climbing takes you to that. So when you end up here, a point at which the gradient vanishes, what will happen at this point? When you have reached a maxima, what will happen to the gradient? Zero. So such a point is called an attractor. It is an attractor for this field, influence field, right? And likewise, if you happen to have started your journey, let us say here, somewhere here, started your journey let us say here somewhere here where would you end up where are you most likely to end up you are most likely to end up somewhere here yeah maybe right on top of x3 or near it somewhere here right which would be at the center and remember remember guys, when you end up here, you don't necessarily end up on an instance of the data, but near it. Like the point of Maxima may not be literally one of the existing data points, right? So this also is an attractor. So will there be multiple attractors over there? Yes, that is the whole point that in your data set you start at random points and keep going there to the attractors and once you get to an attractor so you can do a subtractive process see what you can do is once you find an attractor that you can assume you just intuition shows you that attractor is the center of a cluster isn't it would you agree that your attractor points are the centers in some sense of the cluster they may not be the centroid but they are the centers places of most intensity for that cluster right and so what you can do is suppose you start from a point you find one attractor, and then what you all you have threshold of let me just write it here a threshold of density beyond which you have a cut off so you can draw your circle so when i draw this red circle and pink circle i just said that beyond that it becomes too thin the points are too thin they're too few points right so therefore you have your cluster take that cluster out and its points out then again start somewhere and see where does it take you if you take the pink cluster out then you start at a well you'll end up with the red cluster right and so gradually you'll discover all your clusters what remains whatever remains are What remains? Whatever remains are outliers, right? So whatever remains outliers. Now, why is this a powerful argument? I like this argument because to me, of all of these things, what I like is that it is so straightforwardly driven by intuition, by mathematics, clearly, and an intuition of a force of an influence field that first of all you know that it will converge you will go uh you'll soon discover the clusters isn't it do you notice that there is no notion of epsilon neighborhoods and so forth right the only hyper parameter is it like at what level of thinness do you say okay now i'm beyond my cluster, how do you define the boundary of it, that is not a big like it doesn't completely change your definitions of clusters at most it may change the definitions of your outliers. isn't it. So, that is a big. Those of you who are on zoom, are we getting the point? Yes, I did the point. I just have one question just for understanding sake. Instead of circle, like is that a way, for example, for example, if you have a bunch of lasers sitting in an arc, and then you want to find the center of all those laser points where you have the maximum intensity, is it something that this kind of algorithm can solve? Yes. In fact, the beauty of a dB scan, as we will see in the lab in the afternoon, is these things don't have to be globular like circular like you can have data like this one like this and another one like this let's say you notice that and these may be two different clusters these are called this is the classic half moon data set the beauty of a density-based clustering is it will actually be able to tell them apart. It's a big strength actually that it deals with all sorts of shapes very well. The other point with DENCLU is do you realize that to cluster to find the attractors, you don't have to do the computation with all the points. You can take a reasonable sample of the points and do this exercise, find the attractors isn't it? And then find all the points to the nearest attractor so okay the point is actually an influence of in that attractive space like you say that you go with the point right you could have picked one point which was far away yeah which is not part of that cluster yeah and still throw it away assuming assuming that it's not a one point is not see what happens is that this is why you say that see I started a I ended up with this cluster by throw away I just say now forget about it. don't think about it when you started. Keep it aside that's all. yeah. no longer part of the computation what i'm saying is if you took a point which was not close enough to this speed yeah but it was additive but it was this kind of an outline but you're still included as part of the yeah the part is you do the f of that sigma function right so you're right or do you have to individually go through each point and iterate and make sure they're adding into the light so look at the point y you're asking about the point y see point y will remain once you have found all of the attractors and drawn drawn your circle surround them i'm saying like if that y was somewhere close by over here but far away from the speed how do you know that you whether you should include y or okay yeah this is it so let me make a point z here yeah so the thing is okay so how do you determine the radius of your uh thing the way you do that not the radius what happens is you keep going out to the boundary and at each time you ask what is the density here and density essentially means in a way you make an epsilon neighborhood and see how many enough number of points are there or not right so once it becomes too thin right you say i'm not going to include so if your density is very low then z will get included in that cluster if your density that you need is very high, Z will not get included in the cluster. And so that is the only hyperparameter in the model. That is the gating. Density is the gating factor, right? So based on how dense it is, yeah. So it is, again, think galaxy. At some point you say, right, I've reached the edge of the galaxy. And now the intergalactic cloud is too tenuous for me to really consider it as this region to be a part of the galaxy. So you need to decide some cutoff, isn't it? That's pretty much it. Could you, I don't know if I missed it or like, there are two concepts that you described here, right? One concept is trying to find out the influence of different points on a point yeah and intuitively that will arrive at possible clusters that exist you know you find attractors you'll discover all the attractors and implicitly around in attractors you can now draw a region of dense points. I don't know if you can double-click on that. Okay, so what you do is... Identify what is a zone. What you do is, you can keep sort of creating one intuitive way, one very intuitive ways. Think of a certain density in your mind right that uh the number of points per square inch should be at least this much or per square whatever unit must be this much now start from the center and you start making reasons and say have have i become too thin if i become too thin i'll stop and that's all it is this is how it improves over db scan how does it improve upon db scan see first of all you know that multiple ways it because there is no sensitivity to uh strict sensitivity to epsilon right but it still has a hyper parameter it has a hyper parameter like at what density you stop so now the point is that point is valid the point is yes that hyper parameter remains and that is at the heart of what you define cluster or how how much dense is still good enough for you it often comes from the domain but that remains a weakness it is not sensitive but the clusters that you get at least the main clusters are not sensitive to what you chose as your density as your hyper parameter only the outliers are sensitive to it so for example this point z is it an outlier or not depends upon what is your cutoff of density you got you got that right right so so that is that is the only sort of an aspect in practical terms it doesn't hurt you that much because you are searching for the clusters i see and computation wise to me it seems serious sdb scan very positive it's very cheap it is lightning fast why because i don't need every single point i can just take a sample of points and still do in my influence field right once i have a influence field all i have to do is hill climbing and find the attractors once i found the attractors you realize that i'm done you make a certain region around the attractors any points that fall in the region belong to that cluster, to that attractor. That way it is exploiting the gradient descent pretty well. Exactly, it exploits that, in this case, you would say gradient ascent. Hill climbing. It exploits the hill climbing and the fact that you have a field here and does it. So one of the things that you'll find, scikit-learn doesn't have an implementation of denture right so i give it to you as a project try implementing dental do you see how simple the idea is or try implementing dentle i'll give you a hint guys you'll be able to implement it in some 60 70 80 lines of code It won't be the most optimized, super optimized code. So for example, Google had a paper long, long ago, DENCLU 2.0, which was highly optimized. Then later on, there were further works. I remember seeing a paper in 2016, which was about DENCLU hybridized with expectation maximization and things like that. So there are many, many such bits of work done, but just do a plain and simple implementation of Genqlue. Take this as a project, see if you can do it. And just to bring these ideas home, I'll try to create an animation so that you can literally see that if you just throw a clusters, a data which has clusters, and you start at a random point, you can click at any point in two dimensions and then see how it takes the path of how the force field looks how the sort of influence field looks right and from that it sees scalar fields i typically think of them as potential fields so how the potential field looks and how do you go from there to its maxima or the so-called attractors. Makes for a really nice way to bring the I think the thing home intuition animation is called for I need to sit and do that I'll do that. Isn't this elegant anybody else feels that this is far more elegant that we have to calculate the field at every point? No. Yes and no. Yes and no. See, what happens is that you end up with a function like this. Do you realize that you have a function like this? So at any given point, all you need to know is to compute the gradient there. So you don't need to find the field everywhere. You need to find the field at some point and then start climbing the hill from there you randomly take a point you don't need to find the force field everywhere so long as you have a function that you created it start randomly somewhere and all you need is a force and its gradient see what are the two things that you need here this and this isn't it you need this if you look at this equation where is our hill climbing equation look at this right that's your attractive the top peak is attractive you can sort of you don't even need to ignore if you don't want to ignore it but go go randomly sit somewhere else right and do it see what happens the beauty of this is that one intuition that i'll give you is at the top of the hill that think that there is a lighthouse you're searching for the lighthouses well i'm mixing up my lamps now with lighthouses. Attractors are the centres of the clusters. They are the points of maximum brightness. If you think in terms of light, just the most valid point, where can you read the book, your book, brightest light, that is your attractor. We got to that point. Yeah. Then comes, in the data set, multiple attractors. Yes. What we haven't discussed is the intuition of how do I find one? Yeah. How do I go looking for the remaining and how do i know i have found all yeah so then comes like technical details uh one one way that i do like i don't know if this is yeah you start at different places and you can then find it the other way that i do in fact i don't know if that's absolutely the correct way like what i do is once I found an attractor and it's a cluster right I basically take it out of the equation. and start all over again okay. And then, how do you closure on. Ultimately, what will happen is you will be left with little points which, so what happens is suppose only y point is remaining right in your data set so what happens is you'll gravitate to y but then you look at the density around y and what will be the density around y zero the closure is based on some kind of the sparsity of the remaining that's right all because you know that you're left with just outliers that's the way i do it asif i'm still not understanding what the big f like uh function is like i get what the how the process works i don't understand what that function is okay let me repeat that i'll repeat this guys uh once again so suppose that and again guys i'm using the word light but as a physicist i cringe because light goes one over I'm using the word light, but as a physicist, I cringe because light goes one over R squared. Imagine that this is a little lamp. This is a little light, right? X1, source of light. This is X2, source of light. X3, X4, these are all sources of light. You would agree, all of these, that at any given point, let's say X, what is the light coming from what is the influence let's use the technical word because i think now you guys have gotten the intuition what is the influence of point x1 on x x1 on x is how much is proportional to e to the minus a distance between x1 on x is how much? Is proportional to e to the minus the distance between x1, x squared, leaving aside some proportionality constants. This is it because I use the decay function. The further away you go, this is half the bell curve. I just happen to choose. It is called the kernel, by the way. You can choose other kernels and we'll talk a lot about kernels. is a kernel function these decay functions are called kernel functions so you took some kernel function right or more broadly you can say x i x influence of the xi point on this is some kernel function xi x some decay function something that decreases with distance one monotonically smoothly and monotonically any function you can take but Gaussian is often taken as the standard so would you agree that at the point x1 will influence it to this extent I think yeah yeah yeah that makes sense that's why so now what about x2 so at point x i will get the influence from f1 right which is f2 f k suppose there are k points all around isn't it this one being f x1 x this one being f x2 x and so on and so forth x k x this would be the influence from the kth point so far so good yeah yeah and so what happens if i am looking at the total influence at the point x would it be reasonable to say that this is the sum of all of these yeah yeah yeah i'm seeing that now yeah that is it and the beautiful thing is that is not a function of the points anymore that is just a function of where you sit because the points are frozen isn't it the points the data instances are data instances yeah yeah because and that's why i gave you the metaphor think of it that it is like reading a book and asking where there is more light from all the lamps right you change the location lamps are not moving you change your location the light available there will change isn't it yeah that's it and that's how you should think of the influence field it's a scalar field so one second it's a scalar field obviously light has direction sense so don't look at that but you can think of it as the warmth from the lamp right so uh albert i'll come to your story so there's a very interesting story actually a children's story that's told in india it is called a birbal geek kichari right it is the sort of the cooked food of people so apparently he was a wise prime minister to a king or not a prime minister very courtier to a great king named akbar but there are lots of stories on how akbar would will do foolish things so i suppose i'll'll stop with this story that I think is appropriate, or may not be appropriate, maybe tangential, but for whatever it is, I think a nice time to tell the story. So it turned out that there was a very cold, you know, people were going through a cold winter. were people who were going through a cold winter and Agba just looked at a little pond or lake pond and said my goodness it's so cold the water is freezing cold nobody can nobody can be in this water for more than two minutes right and people said no there are people who for you know for food they're desperate enough and they can do anything uh So then you try it out. So he gave a competition. He says, whosoever can be in this freezing pond all night will get a huge reward. He will not be poor anymore or something to that effect. I don't know how the story exactly goes. So then it so turned out that a poor man came a really hardy one and he suffered through the whole night in that cold water standing in the cold water of the pond and next morning he came out and he says well i'd like to have my prize now so then somebody pointed out that you know what this is not fair because some other courtier who didn't want to want but to give him the prize the poor man the prize pointed out that there was actually a lamp a bright source of light which was far off and he says that this is cheating that guy was not in complete cold he was getting the warmth of that light far off right so? So, well, that's not fair, because you know, how much warmth can you actually get from a light far off? So then, people counted, okay, all right, let's do one thing. Why don't you come to a lunch I'm organizing, a luncheon party that I'm organizing, come, you'll have fun, to the king the king came and people said well you know we are still cooking the food so the king was patient and said all right after a little while king grew very impatient because there was no sight of food and he asked where is the food being cooked and it turns out that in a very very tall pole up there uh 10 feet i mean something like 100 feet high, there was a little pot containing the food to be cooked, khichdi, it's an Indian dish. And at the very bottom of the pole was a tiny little flame. And Bheble said, well, look, I'm cooking the food. And the king said, how possibly can the warmth of this cook that food? And well, the story goes that then people said then how possible but you said it can be right you know that guy got warmed from the lamp and you realized his mistake and so on and so forth it's a good story of course i am reminded of it because it brings home the point you're looking at an influence field think of it as a warmth field right and so how much warmth are you getting from each of the points whatever Whatever it is, it's a quantity, it's a number. And you can sort of look at the gradient of it. You is the path that you would take and where would you end up where you would end up the warmest place are your attractors the path that you would take is the past part of steepest ascent hill climbing path right and all you have to find are this warmest local locally warmest places the peaks, those are your attractors. Around them, you can create your little neighborhoods. Those are your clusters. Warm enough. So one way to say, where does my cluster end? Cluster ends at the point at which it is warm enough, beyond which it is not warm enough. That's one way to think about it. Sort of a, I don't know, a descriptive way to look at it. Asif, if you do gradient ascent though, aren't you going to only hit one extremal? Yeah, and so then you go to some other point and start all over again. Oh I see, that's why you're removing one of the clusters, okay. That's right Now you're getting it That's right. So it's a beautiful Rathik, in fact for you in particular i don't know how many of you will do this project please do this but i think why don't you come back with the solution next week okay i'll try that yeah come bring back your notebook next week i'd like to see you try it try it you may or may not succeed fully but see how far you go a hint it's very short code hint it's very short code let me put a number it will be a hundred lines or less no comments yeah okay yeah without comments here so all right guys so with that we end this topic it is appropriate about an hour gone. Dentlu is lovely you will really love it it doesn't exist in scikit-learn for all you know guys contribute to scikit-learn. If you want to I don't know whether they'll accept it yeah go ahead Albert. So this point one two k those can be random but they're not the point that you want to choose yeah yeah so what happens is set up your experiment take a random if you have a huge data set you can take a random sampling now these are your points these k points here and now you're working with those k points to find the uh attractors uh attractors so it's some form of recursion logic why why recursion you want to find the cluster no no it's not recursive it's iterative you take a k point so let's say your data set size is K when you're starting the learning your data set size is K right and now you have a force field which is the influence of all the k points you do its gradient and then you hill climbing you'll end up with one of the attractors you stop now if you so choose you can just remove the points that are in the cluster of the attractor and then you start all over again from somewhere else or maybe from the same point whatever it is doesn't matter okay but no recursive is will call itself it doesn't call itself any questions guys Any questions, guys? I don't need to discuss it with you, but I guess, in a large data set, the final termination, that logic is complex. You have to be able to say, I'm done searching. So there is always a possibility that somewhere else there is an attractor, and you can go close to it. That is true. So the point is that if you, that's why I use the eliminative process. For me it works, right? I'll have to look at the literature to see if it is strictly correct or not. But okay. See, here's the thing. When you have a massive dataset, right? Can you use the force field argument? Yes, definitely you can use the force field argument. But the beauty of that on the entire data set. But why? The beauty of density-based clustering is if it is really those dense regions, a subsample is good enough. And so when you deal with a subsample, computations are fast. And not only that, you notice that you're working with gradients. So you're not computing the distances to everything right you're just looking at the distances to those Cape I mean set to yeah you can do that yeah then i remove it from the large data set yeah whatever is around that cluster yeah i've taken away all the points i don't want to look at again yes yeah yeah yeah this is it and so you can tell whether something belongs to a cluster or is outlier right come again or is outlier right come again go ahead okay um what's the metric for um knowing when you have hit that tractor gradient will disappear oh okay okay okay yeah yeah at the top of every hill is flat you know yeah yeah the gradient yeah okay at least in the hills behind uh in the what is it our fremont area mission peak mission peak yes and so we're using ascent as opposed to descent because we're going to the top of the hill exactly and the same point remember gradient points to the direction of greatest increase so when you're ascending the hill you go along the gradient not opposite to the gradient it's not the saddle point it is truly the peak from every direction maximum from every direction a saddle point is a point like a horseback where along one direction it's a minima and another direction is a maxima like if you think of a horse, right? Let's say a horse, how does a horse look? Well, this is my poor rendering of a horse. So if you're going along this direction, if you look at it, this point is a minima. But if you look at the circular direction, it is a maxima. In other words, you can fall off the horse, right? You're sitting atop this, this, you can fall off the horse. You're sitting atop this. This point is on top of the horse. So that's why it's called the saddle point. The word itself has come from horses. All right, guys. So let's take a break. We will have another hour of theory and then we'll break for lunch. Let's take 10 minutes and I'll see you in 10 minutes. To summarize, in the previous session, we studied yet another density-based algorithm, DENCLU. We realized that it's a pretty powerful argument based on, it's a field theoretic argument. It says, create an influence field. At any given point, there is an influence coming from all the real data instances, right? And that influence is a scalar field. It's a number, it's a field, it's a value. There's no direction to it. Now, given the field, if you take the gradient, you can take a hill climbing approach to find the shortest path to the peak of that influence, nearby influence. And those peaks are called attractors. Then around the attractors, you can build your certain density region that you can take and say, that's where my cluster ends and that is the only hyper parameter in the model in practice it works quite well so that is the approach now when you look at the influence the question is how do you do influence what is the function any kernel function will do what's a kernel function well that's the topic we are going to talk about shortly but for the sake of this one, take it as any decay function. Means something that slowly decays with distance, right? So like Gaussian, half of a Gaussian is pretty good. One question that someone just asked is, why not one over r, right? That also decays with distance. You could, though people tend not to use one over r because it's computationally a little bit hard. What happens when the distance is 0? 1 over r begins to blow up, right? It tends to go to infinity. Well, of course, then you can say, well, in the denominator, I'm going to add a constant value, alpha. So there are ways you can work. There are many kernel functions you can use. The most popular, obviously, is the Gaussian kernel function that you use. You can play around with some and see, but you should get essentially comparable results. That was DENCLU and a summarization of DENCLU. The homework there was implement DENCLU from scratch. I will give you a hint, guys. Go look at the code where we did linear regression from scratch you remember we did linear regression so we did gradient descent and we did a process of iterating using gradient descent to find minima you realize that this problem is almost identical to that we are not doing gradient descent, the minus will become plus, in other words ingredient descent, we used to do. What was the difference in gradient descent ingredient descent, you would do beta next. is equal to Peter minus alpha gradient of the loss function. gradient of the loss function. Right? Whereas in this hill climb, in this particular one, in the Den Clue, you're using the same argument except that the next point you go to is the previous point plus, and you don't call it a learning rate, people often write it as delta, but it's exactly the same thing, gradient of the force field, right? Do you notice how similar it is? So the code will be very similar. You can take an inspiration from the code and therefore you'll realize that, especially with that code being present, it's a short exercise. Go use something, adapt that code, and you'll quickly be there. All right.