 Let's go through quiz 3. Consider the following plot in the hypothesis space of the relationship between RSS and one of the parameters beta1 for a linear regression model. So we have this plot here. This is of the error surface and now the question asks is the slope at point A at point C and at point B. For this case, let's just go here and we see that at point A as beta1 increases RSSss decreases at point b there's not much change in rss and at point c as beta 1 increases rss increases so because of that we we know that at point a the slope must go down so this is negative at beta at b it is almost approximately zero and at c it is increasing so it is positive so how do you know actually like where do you see that like it's increasing or decreasing how do you actually know at like point a it is decreasing at one point a so it's like this right So, it's like this, right? Yeah. The slope is actually like this. So, where do you see it? So you see that as beta 1 increases, we know that for a small change in beta 1, we know that RSS goes down right we look at 0.5 and at some point uh next to 0.5 we see that uh rss has come down right yeah i mean that intuition is not very clear to me actually so how do you no for a small change in beta 1 let's just take a small change and the curve is like this right so for a small change in beta 1 we see that there's a downwards change in rss right so it's like this so the we get a negative slope because that is the change is negative derivative is delta y by the yeah yeah it's essentially that's that's all it is for small positive delta x you're getting negative delta y so that's why it's negative yeah and then you're rising up on the other side it's a positive and since this has what you call the contour is such that you always have a bowl at the center right the rss can only go down right it can that's that's the reason right it cannot go it can go up but you know that it's going to have this what you call um bowl shape parabola shape yes for the intuition at point b is the local minimum correct yeah so that's why you know you're going up and down so our main reference is going to be sorry yeah yeah especially at point b we know that there is no change yeah there is no change in rss as we move along beta 1 for a very small step and because of that slope is zero so for a we are moving in the direction of the gradient or opposite in the direct opposite to the direction of the gradient opposite to the direction of the way so where is the like the it's pointing down right so that is the direction of the gradient or that's the direction of the error surface so your gradient is different yeah but uh gradient will point in the direction of greatest increase right yeah so for point a where is the greatest increase so we don't look at this curve but rather we look um so gradient is something where we look it's it's mapped on the parameter surface right beta 1 beta naught and it is a vector on this surface and it is not actually marked on in on this curve or anything so in that case we have a bowl like this okay, and then we we talk about the gradient and gradient will have to. it's basically delta RSS. By delta beta not and and then so forth right so it's like something like this. This is the gradient right so and this gradient it has it's marked only on this um parameter surface and if we look at point a and we want to know the gradient it will always point in the direction of the greatest increase so and that would be away away from i think the other way you can look at it is anil yeah say forget can you bring that graph back yeah just look at point a okay assume that there is no minima nothing okay you are just seeing point a yeah just move a little bit right yeah move in any direction right any direction you move over there delta beta one if you move you find what is the difference of the rss right so what happens is if you move in the positive direction the rss reduces so it is negative so the movement is always opposite of that to the derivative which will get you to the minimum so in this case since the derivative is negative and you go minus of that you have to keep increasing beta on the other side if you were to come on c side right and you are starting your journey from there then if you come down the derivative is basically positive so you know that you're going in the opposite direction minus so that's why you have to reduce so you know that you're going in the opposite direction minus so that's why you have to reduce so that's that's essentially the what you call the intuition if you look at it at the big curve you don't know but what you have to do is kind of just concentrate yourself at point a think there's nothing else around right you're just on a hill and you want to go to the ocean how do you go to the ocean? Are you going to go with your feet that gets harder for you to go up or are you going to go down where your knees are going to be easier? If you're on a hill and you want to go to the ocean, wouldn't you go, you know that the ocean is down. That's the way I read it. That's why they're called as contour maps or hill maps or things like that okay i'll let you go okay go ahead i don't know if i explained or confused so okay sorry satchin can you explain it at point c then huh whatever you told just now that yeah intuition can you can come from point c yeah so any point you look over there right just assume that your universe is just around point c correct you take a little bit of a displacement any direction right whether it be the displacement goes delta beta beta one right and if you take it in the positive direction what happens is the slope is going up which means you have to go opposite the the direction that you have to go to the minimize always opposite to the slope of the derivative right so then that's why it tells you that hey you don't go in that direction you have to go down that's why i give the example of ocean right if you are an individual that you have to go to ocean, what does your legs tell you? If you keep climbing up, you know that you're going away, right? Yeah, yeah. It hurts, right? But otherwise, you're going down, then you know that you're in the right direction. That's the way you should think. Like there's a very small person over there at that. Sometimes the books show that small person sitting over there in that the universe, he cannot see anything beyond this whole thing. Yeah, that's all he sees little bit. That's all. And he'd rather slide down. Yeah, yeah, yeah. That's another way to think of it. Thank you. For this question, we're asked to find the type of error for each of these. And in this case, yeah, I have a map here. So here we see that for this particular graph all the points are crowded around the center so if we draw the distribution it would look something like this so look something yeah it will look something like this so in that case we have comparing the other four maps we see that this has a lower spread and because of that it has lower variance and also bias is less because the 0,0 is the actual point so there is not much deviation of the mean from the actual mean and because of that there is low bias error and here we have a large spread and also but the the mean is the mean of the predict i mean uh of of the data points match the mean of the actual point so because of that we see that this is uh this has high variance but low bias here the mean is shifted so there is high bias and high variance here the mean is shifted but comparatively the spread is low because of that there is uh high bias but low variance oh are you using a mouse or something like because we can't see the mouse like uh this is the same issue um this is one note so i was talking about this first and then second okay third and fourth yeah because i can see the mouse and uh i keep forgetting you know mouse is in black color and you're going there on the black color maybe you want to if you change your mouse color to something different okay yeah i i won't be going there anymore so okay yeah uh consider a linear regression model y equals beta x in the equation above we subsume beta non as part of the beta vector and x vector as the augmented vector on as part of the beta vector and x vector as the augmented vector. While the training of the model is in progress let the total error be given by e beta. The equation for a gradient descent step of learning the next values of beta parameters is given by. So we know that beta next is equal to we go just like Sachin said we go in the direction opposite to the gradient right. So we know that beta next is equal to, we go just like Sachin said, we go in the direction opposite to the gradient, right? So we need to go in the direction opposite. And then we have the, I mean, the size of the step depends on the learning rate here. So the answer would be this, okay? If I'm right, yeah. the answer would be this let's just check i'm right yeah so beta minus the current step minus a small step in the negative of in the in the direction opposite to the gradient so the other intuition that i always use with the alpha is essentially do you have an adult versus a child right the adult will have long steps and reach faster versus the kid has smaller smaller steps right so that's essentially the delta thing that kind of so otherwise it's hard to figure out where it most of the time so okay so consider that we are trying to fit a polynomial regression model of degree 20 to a data set d for this data set we draw four samples four different samples a b c d of increasing sample sizes when we fit the polynomial regression to the four samples, we end up with four different models, model A, model B, model C, and model D that capture the relationship between the feature X and response Y. Select all the statements that are true based on the plots given below. Okay. So now they're asking about the variance errors. So in effect, we're only asking what happens in the test case, like in the real world scenario, when we apply these models, what would be the variance errors? When we look at these three, these four samples, we can see that there are more samples here and therefore there must be more error. But that is not the question we are asked when we apply this to the real world with the same data set with different samples what happens so in that case we know that this model seems to be quite off right it has a lot of oscillations and because of that when we apply to a say a data set like this as in sample d it will have a lot of error and that would be a lot of variance errors and so we know that model a has the most variance errors model c has the most variance errors doesn't uh compared compared to a uh c has comparatively lesser variance errors it is slightly more regularized since we have trained it with more data. And model A has most bias errors. That is not true because this is not underfitted but rather overfitted and we will see a lot of variance errors. While training a machine learning model on a dataset D of observations , a point beta in the hypothesis or parameter space corresponds to a specific observation or datum that is on the data space. Error of the model is the hyperboloolic surface, but that is on top of the hypothesis space. A specific instance of a hypothesis or model. So this is the right answer. Okay. During the training of a model, what happens when the learning rate alpha is too high in the gradient descent process? So will heat up the machine and lead to hardware failure? No. Possibly the successive values of beta oscillate around the minima unable to converge any further to a lower model error value. So this is true because if we have, say, a higher. So we do have a large training rate. So we sort of jump like this and then. we'll sort of jump like this and then okay now this one this right now so if i jump like this i'd probably i'll come here and then i'll go back here again and i'll keep jumping around the uh i mean the actual minima i never it would be i wouldn't be able to converge if i don't reduce the learning rate then possibly the true minima may be skipped thus producing sorry what happened yeah possibly the true minima may be skipped thus producing suboptimal parameters that is also i can't see that screen kind of goes back and forth yeah i don't know why yeah now it's fine okay possibly the true minimum may be skipped thus producing suboptimal parameters this is also true as we saw just now then great idea since it will lead to quick convergence always and save computational time and resources this is not true so it might not just it might not lead to uh it might be it might be quick but it will not lead to a good minima So, same question, the correct order of the models with respect to their variance errors. So it's a similar question, but now we are ordering all the four models. So as we saw, A has the most variance errors. B has comparatively less, C has a little bit lesser than that. And then D has the least because it is more regularized and it fits the model more truly to the data. So in this case, we know that D has the least and then comes C and then b and then a okay so this question i guess a lot of people got it wrong it's there in the question the answer is there in the question so consider that we are trying to fit a polynomial regression model of degree 20. so here in the question we've given out that this all these models are of the same degree right they're of the same polynomial degree and same complexity to a data set d from this data set we draw four samples and so this is the same question select all statements that are true based on the plots given below okay so um model a is surely more complex than model d so a lot of people had selected this answer because it looks like it though it looks like model a is more complex but the fact is that this model d has been regularized because there has been more data and because of that it's almost it's almost like a straight line in spite of the fact that this is also a model of complexity 20. so model d is the most effective in capturing the relationship between x and y compared to other models uh that is true model a is surely more complex than model d uh that is not true all the models have the same complexity that is true and this is also not true so let's fill in the right responses yeah of course only one is correct Of course, only one is correct. Two are correct. Oh, which one? Wait, sorry. Model D is the most effective in capturing. That is true. All the models have the same complexity. That is also true because that is right here in the question that all of them have the same complexity it just looks like they don't have the same complexity because of we've taken different sample sizes and because of that it's been regularized and also it's given that all of them have been drawn from the same data set it's given that all of them have been drawn from the same data set okay i think the the key thing to take there is the fact that regularization kicked in in yes d and that's why yeah i got it wrong i kind of didn't discern that yeah that's that that's the point of discussion to confuse you so yeah and the last one okay so now this is the same question and what we are asked is from the plots below one may reasonably infer okay we're asked to infer what we need to do to the complexity we're asked to infer what we need to do to the complexity that the most effective yet simple model is probably a polynomial degree of 10. that's quite random that's not true perhaps a linear regression model of yes polynomial of degree one would be quite effective that is true because as we see when there is more data it looks almost linear so why would we need a degree a higher uh complexity so that would be the right answer uh and this one would be much greater than 20 that is also not so that would be even worse uh the most effective yet simple model is degree 90 yeah and that's just yeah not true through the gradient descent process we are guaranteed to find the optimal parameters for any machine learning model however complex this is not true because we will not if there is a global minima much lower, I mean, we might end up in a local minima and not on the global minima. So this is false. Yeah. I'll add one thing to that. It is true only when the loss surface is convex. Many machine learning problems, in fact, deep neural networks don't have convex loss surfaces. Linear models have that quality and generalized linear models have that quality. That's why you can, with gradient descent, achieve the minima, but in other places, you don't know whether it's absolute minima. Yeah, so that is like, so if the local minima is equal to the global minima, then right? Yeah, see, this is a whole body of research. For many years, for example, in the 90s, we used to worry a lot about simulated annealing, that if you get trapped in a local minima, how do you jump out of it? And you brought in considerations from statistical mechanics and thermodynamics that, you know, the process of annealing metal? Yeah. Yeah. So you take it to a lower and lower energy state because every time you cool it, the crystallization that forms, there are defects. So it's a lower energy state because every time you cool it the crystallization that forms their defects so it's a higher energy state so you anneal it so people thought that we would do a lot of research on annealing and go there today the thinking is different we do have simulated annealing but it's not emphasized so much uh we the general thinking is that there is a deep relationship between the minimas that we are only beginning to get an inkling of. One of the findings that people have is that, and we did that in the last surface paper we covered in ML400, but not with you. What we saw is that they may be interconnected. They may not be the same minima or the same energy level, but they may be interconnected through ravines and so forth. Fascinating set of findings that people are coming out with. It's still a very active area of research at this moment. and how much initialization parameters the random initialization plays, we are finding it's pretty serious. For example, the lottery hypothesis that based on your random initializations, more or less minimize, I mean, sub network is preferred that goes to one minimum. So we won't go there at this moment, but generally to remember that whenever you have a convex model, you have that. That is why in machine learning, when you look at optimization, there is a whole field called optimization theory. In optimization theory, linear optimizers are of course a given. Then convex optimization is a whole topic and we try very hard to make our problems convex. The deep neural network people sort of came and they found that it's not so absolutely necessary. They call this search for convex loss functions to be jokingly they used to call it convexivitis or something like that. So so anyway we don't know all we know is that gradient descent is guaranteed to succeed only if you have a convex loss function so i said that annealing process was that like related to the cosine annealing or or that is just one type of anything a lot of it annealing is a broad topic it's boris boris from physics statistical mechanics you know the annealing of material so we can talk at length about it i mean today is not because there are people here who are doing ml this thing data science course for the first time. So it's probably not appropriate to go in that depth, but maybe for another day. Okay. Okay. The first question, the model that is overly simpler than the ground truth tends to have high, what kind of errors, the options are bias irreducible and variance, the answer is bias errors. And the model that is overly more complex than the ground truth tends to have more variance errors. This is overitting this is underfitting the first one is underfitting okay the second question okay select all statements that are true based on given residual analysis for the polynomial regression hypothesis H of a data set B with predictor variable X and response variable Y. Okay, so let's see these are the three graphs. Okay, yeah, we observe larger training residual errors compared to the test residual errors. The first statement is not actually true we see it is almost equal right so we don't have a big difference here so we observe a larger test residual errors compared to the training residual errors no the training residual errors and the test residual errors are similarly distributed yes true, true. You can see the distribution here, even on the distribution of the residuals, right? You can see the overlap is almost same. There is little difference, that's it. The hypothesis can be very significantly improved by training the model with much more data, not really. We can see the distribution is good, and we can even see this model is pretty well fit. Since there are no pronounced patterns in the residual plot, and there is approximate homoscedasticity, the current model is probably an effective one, and other models will not be significantly better. The second graph shows this homoscedasticity and there is no significant pattern. That's why that statement is true. The model can clearly be improved by reducing its complexity. That is considering a polynomial of a lower degree. No, this is good. A model can be improved by increasing complexity. This will get it overfitting. So we don't want that. The model has overfitted the training data. No. The model has clearly underfitted the training data. No. This is a good model, pretty good model. Okay. Next question. Can you tell me why the other one is not there's a one we said that you can reduce the um improved by reducing its complexity that is considering of a lower degree so how do you know that something lower cannot cannot be good or cannot be good or i don't know if that's is that obvious it's not obvious right but uh uh here you can see the model is pretty good but if we do reduce it see we see that this one looks like a polynomial of degree three uh okay next if we reduce it to two it will be a parabola and obviously that will be a bad fit and then further if we reduce it it will be of it will be linear so it'll be a straight line and even a straight line doesn't seem to fit it properly right you fit a straight line you are assuming that this is a basically uh what you call quadratic right three degree three right you mean a polynomial if you put a straight line if you can see there is extension like there's data if you see x minus 10 and plus 10. do you think a straight line would fit this model there is oh i i don't know there is you know concentration of data in the curve right no so that's so that was not my question was say suppose this was uh degree 10 right and they were like from the earlier thing that you had remember you had those small so rather than 10 if you had say made it eight would that have fitted better that was my more question i think you'd start seeing patterns in the residuals right you will have to try and see. Yeah. Yeah. So I don't know, but what I was thinking that. Okay. Yeah. But since that's homoscedasticity and the distribution is almost Gaussian, right? Normal. We don't say this is the best model. It is a good model right which is there's a lot of variance i mean irreducible error in this model that is that is the takeaway and there even if you try to fit a better model you still like even if you increase it by four you have a lot of data so it will definitely be regularized uh but the point is since the data points are very much scattered there's a lot of irreducible error and there's not much more you can do that's that is the takeaway yeah one more question here on what are we saying later when this residual plot has no pattern right i mean we see a straight line in the center no pat pattern in the sense there is no um obvious say uh there's no bias errors right there we don't see a concentration of points at one side but all this is more related to how the this is probably because of how the training and tests are distributed and and probably because of the curve here but uh it's not related to say a bias errors right so that's what we mean by we don't see any pattern okay no when you see the pattern it is the variance right so it is not the variance like you don't see the variance in the middle graph the homoscedasticity and heteroscedasticity that's the difference right because you see the variance increasing so that is what you see the like that's what is the pattern what you see so in this you don't see the pattern so so it's not biased like it is i think only the variance part here you don't see the variance in the residual flow what i meant was if if if we fit like a model with polynomial degree two we'll see obvious pattern right we'll see we'll see a cluster of points on either side of the this line at this i mean the line at zero so that i meant by pattern but yeah there are two kinds of pattern one is related to variance and one is related to bias so with variance we'll see heteroscedasticity and with the bias we'll see an obvious underfitting and we see points significantly to one side of the one quadrant line yeah yeah okay if you still have doubt of asif sir is that we can ask him to explain he's there yeah so it's clear for him sir i think yes can you we have a few questions on the second graph this graph question to you that uh why do we see this line over here predicted value see yeah let me look at the question select all statements that are true based on the given analysis of that and a data set with the predicted see this is the nature of the data if you uh if you look at the way the data is there along the left graph, just focus on the left graph and just imagine that all the points here collapsing against the wall along the y-axis here collapsing. In your mind, imagine the bell curve that will take shape. Where will it be peaked? Where do you see most of the points here hitting? Most of the points that you see are- Within the two sigma distance, right? Yeah, they are basically around the origin, right? Around zero, but yeah, spread around it. So now you look at this predicted value. Now look at the center graph. And imagine that all of, forget the residual part, the Y axis here in the center is the residual, but ignore the residual part. Just imagine that all of these green points, I mean, all of these points here squashing down, you're projecting down to a bell curve on the x-axis. The bell curve that will develop along the x-axis, would it be very similar to the bell curve that is already there, that is along the wall of the y-axis in the left graph in your mind, right? So reason this thing through, guys, and you'll see that it will be. And so you have a concentration of points here around predicted value zero because in the real data itself there is a huge concentration of points along that place that is what it is so remember when you look for patterns you look at the you keep your eye on the residuals not whether as you move from left to right, the number of points are increasing or decreasing. You look at the band, how much variance you see. So in the center graph, look at the variance in the middle graph with the amounts. Kyle, could you please show? Look at the variance, the width of the errors, width of the residuals along any X value. Sorry, any predicted value, do you see them changing much? Sort of, very mild, not, probably not, right? These are pretty much, it's a uniform with respect to that. That is what you look for. You don't look for the concentration of data at certain points. You look for the band of residuals now you focus only on the residuals so we are focusing on the variance and not the bias right or like both of them see a bias will show up immediately as a huge pattern like you know but when you the variance errors here you when you look at this picture look at the band band of errors. If the band is, which is measured by variance, if that doesn't change, then you seem to be in a good place. So neither of the two should be present. When you build a model, if you see a clear pattern or you see the heteroscedasticity of the residuals, both of those are bad. And if you notice in the lab, I tend to make a point about both. Isn't it? So, and so from that perspective, here there is no pattern except the inherent, you know, centering of the data around the origin, predicted values around the origin. That comes from the fact that data comes to you, original data comes to you like that. Now, if you look at the plot on the left and in your mind's eye projected down to the Y-axis as a marginal distribution, you'll see that it is like that. So that is okay. So now what was the question? Was that the question? That was the question, yeah. All right. Yeah. So you mean to say that the question? That was the question. Yeah. All right. Yeah. So you maybe said the data concentration is zero and zero. So that's why there is a lot of points that's right in the predicted value. Yeah. And in fact, the key things that as you get trained in these things, you know what to look at and what to ignore. that is one thing to ignore because the interpretation not ignore but you look at the left and you know that that is the nature of the data so you say that is fine all right yes thanks that's it yeah so if you have any uh questions for me uh would you like to ask right now because i was going to hit the road to go back home okay there's one more this one yeah data set d of n instances depicting the left plot below. A polynomial regression model is fitted to this data. The error of the model is measured as the mean, okay, that is what is the optimal value of n? See, the optimal value of n is, first of all, the lowest test error, and amongst all the points that exhibit the same low test error which of them is the simplest so when you look at this what would you say at what value do we achieve minima of the test error and it is still a simple model model. 4? Yes. That's right. It's just that when I plotted this, I plotted this with the polynomial of degree 3, but somehow the error for degree 3 is pretty high. And I'm not sure why that's happening. There must be a bug in here. See, if you believe the plot on the right, then the answer is 4. If you look in the curve on the right there are bends in the data two bends in the data because you made it about mean squared error therefore the only product practice is the one on the right but if the only plan if it was about here is this data on the left what would be the optimal end to model with to start with what would be the simplest end to start with then the simplest end to start would be n is equal to three yes okay so in from that perspective but there is a bug in the way there's a bug right i mean like the n is better than two is better than three 3. How can that be? Sometimes it happens. It does happen during training because training starts with random initialization points. But generally, linear models and polynomial is a linear model, it tends not to happen. Almost surely something is screwed up. So run it again. And one more thing which I am noticing is... Kyle, you can show the third question question so where he is coming from right one moment somebody had a question on this question what i am noticing is that uh the training data uh have more on the lower side compared to test data so test data is missing at that end that is quite possible and very very see i didn't notice that but assuming that that is true uh let me i'll have to bring my reading glasses but assuming that that is true that explains see the assumption in a test and train data is iid independent and identically distributed sample points right yes training data set and the test data set they cannot be different distributions if they are different distributions then you will start seeing odd things like this so but it looks like it is like from the same distribution right it does look actually to me it doesn't look very different but yeah my my own guess is there's something odd look at the code and run it again carefully you'll find some little there for such a simple polynomial model of degree three uh learning rate convergence should have been very very it is steep like going down to two it is already coming down but it shouldn't have stopped at two to the test error is too low it shouldn't be this low something if i have to guess most likely you mixed up your twos and threes if you look at the green line and you look look at the on the right hand plot the green end you interchange the the value for two and the plot will then make perfect no i actually took it as a range so i plotted it for range from zero to ten so it's in order only no no i'm gonna yeah i'll check i think that if your data point the same graph if it was reversed the value the error achieves at 2 is actually the error that it would have achieved at n is equal to 3. And the error that it achieves at 3 is the value that it would be 2. Then the function, then the error test error would be also more or less monotonically decreasing at that moment. Right. Like this. So anyway, try it out, see what happens. Maybe you show me the code after this. Uh, I'm going to drive home. Any other question you want my input on? No, that's, that's, that was the only one. So yeah. All right. Bye. Thank you. Okay. So the third question, select all options that are true based on the plot given below. Possibly the optimal value for n is 6. Okay. Here n is the model complexity so the number of bends 6 we don't see right those many possibly the optimum value for n is 5 we don't see those many bends either more data is required for analysis possibly the optimal value for n is 10 so which is not true so we need more data for analysis that's what it says okay and it's just a lot of us selected six yeah okay next question okay yeah yeah this one we just went through it. Yeah, yeah. Fifth one. Okay. Consider a univariant data set D of N instances depicted in the left plot. The polynomial regression model is fitted to this data. The error of the model is measured as mean of squared residuals that's mse what is the optimal value of n so we are trying to find the complexity based on the msc here so here possibly the optimal value for n is eight if you can see at eight the test and the test error is increasing than the training error. So this is not good. Possibly the optimal value for n is 4. At 4, at this point, you can see the test and the training error is similar. But later, the test error is increasing. So at 0.4 is the complexity we have to consider. So possibly the optimal value for n is increasing. So at point four is the complexity we have to consider. So possibly the optimal value for n is four. That's the correct answer. Question six. Select all statements that are true based on the scenario described here of a polynomial model H of a data set D with predictor variable X and response variable Y. The left plot shows the predictions overlaid on the scatter plot of the data. The middle plot shows the residual errors with respect to the predicted values Y hat. The rightmost plot shows the histogram of the residual errors. With respect to the predicted values y hat, the rightmost plot shows the histogram of the residual errors. Let's see the options. Due to underfitting the training data, the model exhibits larger training residual errors compared to the test residual errors. It's not under fit, right? So it is a complex model that's being fit on the data. Due to overfitting the training data, the model exhibits larger test residual errors compared to the training residual errors. This is true. We can see the due to over the test residuals the uh are large than the residuals the training data is increasing so that's why it's true the model can probably improve by training with more data that isn't always an option so that is true the model cannot be improved by increasing or decreasing its complexity we need to decrease the complexity so it's over quitting here in this scenario so this is false the model can clearly be improved by reducing its complexity that is considering the polynomial of a lower degree that is true the model can clearly be improved by increasing its complexity that is false yeah so here there's high variance error so we have to decrease the complexity the next question the three components of prediction error are so what the definition of error so it's the sum of bias error variance error and irreducible the three components are bias irreducible and variance okay the next question okay okay select all statements that are true based on the given residue analysis for the polynomial regression hypothesis H of a data set D with predicted variable X and response variable Y. So blue line is the model X and Y and this is the residual analysis. So let's read the options. The model has underfoot the training data. This is true. The data is more complex than our model. The model has overfilled the training data. That is false. Since there are no pronounced patterns in the residuals plot, there is approximate homoscedasticity. The current model is probably an effective one and other models will not be significantly better. This is false, right? We can see a clear pattern in this data. The model can clearly be improved by reducing its complexity. That is, considering a polynomial of a lower degree, this model is already too simple. So we need to increase the complexity. The next option is right. Okay. In the context of a linear regression model predictions, the presence of heteroscedasticity in the residuals plot may be indicated of the need for a different relationship between the predictors and the response that is being suggested by the model this is true like how we see the previous question right there is a pattern so heteroscedasticity will give us a pattern so we need to build a better model okay the next question consider data set D where the histogram of the target variable Y exhibits a pronounced right skew in the context of a linear regression that is indicated that one must specifically avoid performing a power transformation of the target variable as that will degrade the predictive power of the model learned from this data set if you remember the diamond data set the target variable price was right skewed to you know to do the yeah to correct this we use power transforms and it's in inbuilt log transform so under the hood it is a log transformation so this helps in handling this right skew data so we have to do so the answer is false i think that's it in this quiz yeah that's it yeah that's it.