 Welcome back to the Introduction to Machine Learning ML 100 workshop. This is our lecture number two. This is Thursday, I believe July 21st, I would imagine. Now, am I getting that date right or is it 22nd? 21st. Okay. So I'll just do a very quick review of what we did last time. Last time we went over the course modalities, we said it's a six weeks course. We all agreed that we will divide the saturday into two pieces we will do the theory on thursday evening and we are going to do the lab on saturday morning california time which for people in central time becomes a little bit harder 9 pm to 12 pm at midnight and saturday morning is perhaps better noon to noon to three and for people in India, it becomes 730 in the morning Friday. Friday, which is what it must be there at this moment till 1030 and then the Saturday night 1030 to 130 which will be a little bit harsh, but we live in global. harsh, but we live in global, we are a global class today, this time around. So there'll be a little bit of adjusting from all of us that we have to do. Now, six weeks of theory, labs, homeworks, quizzes, paper reading, social learning, and projects. So there are many aspects to it folks uh try to benefit from all the aspects uh please take help from the teaching assistants i hope if you have those of you who did reach out to the teaching assistants you hopefully were pleasantly surprised how accessible we all are we are always there to help you and as i said we do have an emergency number just as in united states you can call 9-1-1 if there is a emergency if in machine learning you have an emergency call us at 1-855-learn-ai we'll be there anyway um well jokes apart we talked about machine learning. What is machine learning? Why do we use the word machine learning and not artificial intelligence? It's because we don't know what intelligence is in a very quantitative any entity learn, right? And learning in its simplest form, in a more quantitative form, is first to have a measurable way for errors or for the performance of a task, and then to see measurable improvement in the performance of that task, right? As the machine learns, or as the human being learns or the entity learns. If you can quantify the error and you see a reduction in error, you see, you say that learning is taking place. There is a broader definition of learning, which is that learning is the ability to generalize. We took the example of cows and ducks and children in the meadow, in our meadow, and that will be our own special support vectors meadow in which there are only cows and ducks and children trying to understand cows and ducks. Now in that, when a child begins to make less mistakes about whether an animal is a cow or a duck, and for those of you who just joined, the example is framed as follows. There is a meadow, a simplified meadow, in which there is a pond, there's grass and so forth. Some there are some ducks roaming around. And there are some cows roaming around and you are there with children, you show the children and animal and you say, Look, this is a duck. It has a beak, it has webbed feet. It has feathers. It's small. And then you show it this big animal, and you say, look at this big animal with this swishy tail, horns, right, and so forth. And that's a cow, the four-legged animal. So you keep doing that. Now the children, and then you ask the children, you show them an animal they haven't seen before and ask, what is it? Is it a cow or a duck? If the children have not figured out what a cow or duck is, they will make mistakes. They will make far less mistakes the more they get a sense of what a cow or a duck is. Now what we do is we show specific instances of cows and ducks so one easy thing the machine that a child could do and some people have photographic memory they may not understand a cow or a duck at all they may look at the 10 examples of cow that you showed and memorize them and the 10 examples of duck that you showed and memorize them. If you show them exactly that cow or duck, they'll get the answer right. But if you show a new animal, then they wouldn't get it right. Then it is evidence that the child has not learned. It has just memorized those instances, instance memorization. We do it all the time. If you go back and look at your college days their courses that you learn from. And then there were courses that you hated So what did you do you just memorize the important questions which you hope to come in the exam and your past. Right so that's the difference between memorization and learning so if you were to look at the distinction, the distinction is learning, when learning takes place, there is a generalization from examples. You generalize, you form a concept. For example, as a child looking at the duck, gets the grasp of what a duck is, the duckiness of a duck. And likewise, the cowness of a cow, the essence of a cow, what it is. A concept forms in the mind of a child. It's a generalization from the instances. So another way to look at machine learning is, machine learning is the ability to generalize, and generalization is another way to think that it is intelligence. We talked about the fact that if we look at this way, it is a quantifiable way to to measure learning because we can it's great it has one uh thing though it is agnostic to whether the entity that learns is sentient or not is alive or not machines are equally capable of learning as sentient beings. Right? Fishes learn, humans learn, right? Dogs learn, and machines learn. All of these things are capable of learning. From there onwards, we move to a little bit of a history of the field. We talked about the legendary mathematical physicist, Gauss Legendre, who did the work. The first paper on this was Legendre's paper, 1805. Before that was Gauss's paper, 1793, but he did not quite articulate the method of least squares. Legendre did it in a very explicit way. To understand this for the case of regression, of predicting a number, we took another story. This is the story of a young entrepreneur trying to sell ice cream on a beach. The young entrepreneur sees that if you have a warm day, more ice cream sells. If you have less, if you have a cold day, not so much ice creams sell. not so much ice creams sell. So the entrepreneur plots the data and then realizes that there is a linear relationship between the temperature and the amount of ice cream you would sell. Now, why would the entrepreneur want to know that? Because if you have an ice cream shop on the beach, you buy ice cream from a wholesaler. If you buy too much ice cream and it doesn't sell, you lose money. If you buy too little ice cream from the wholesaler, well, then your customers are turned away and you have no ice cream to sell them. So you do that. So when you do that, you need to find what is the real relationship between ice cream and temperature, ice cream sold in temperature. When you plot the data, the eye may indicate that it's sort of a linear relationship, but in higher dimensions or more complex data, you may not know. Now you make a ground, excuse me, you may make a basic assumption that the relationship is linear. Assuming that the relationship is linear, the relationship can be represented by infinitely many lines of different slopes and different intercepts. So which of each line represents a hypothesis? So we talked about two things. We talked about the real space and the hypothesis space. And we talked about two things. We talked about the real space in the hypothesis space, and we talked about quantifying errors. So one way to compute the error is obviously very simple. What is the gap between your predicted amount of ice cream sold and the actual amount of ice cream that was sold? That is the error gap. Now you take the error gap for all the data points across the different temperature values and somehow aggregate those errors to get a composite total error. Now, when you aggregate the error, you have to be a little bit careful because yi minus yi hat, the delta in error could be positive or negative. You have points above the line and below a line and the actual points. So sometimes you overestimate sometimes you underestimate so if you were to just add up the errors you run the risk of ending up with zero error because they're symmetric sometimes so you're looking at the size of the error not its direction so to erase the direction what you need to do is you need to take its absolute value but when you take the absolute value the question, there are many ways to look at the absolute value. I can look at the absolute value. I can look at the square of the absolute value. It's cube, it's fourth power, and so on and so forth. So why a particular way of aggregating? There are so many, many ways of aggregating the error. So what people do generally, if you take the zeroth power, that won't work. If you take the first power, in other words, if you just add up the absolute values, like in this equation here, if you just add up the absolute values, then this equation we are referring to, If k is 1, then it is the sum of absolute error, SAE, right? So let me put the word SAE. And if you take k is equal to 2, it is the sum of squared errors, right? Now, sum of squared errors, these two are the most commonly used measures of error when we are trying to predict a number. In other words, when we are doing regression. So generally, because you want the error measure to be invariant of the data set or sample size, so it is common to take the average to divide the answer by one over n. When you do that, the sum of absolute error becomes mean absolute error. It's mean of absolute errors, but the more technique, the correct English, I suppose would be mean of absolute errors, right? So EI. But people just, it's common for people to forget the off and so forth, and people just call mean absolute error instead of errors, though more technically is the mean of absolute errors. So it's just a language that has stuck. Right, so this is it. We talked about the sigma. We also talked that it is far more common to use the squared errors why we do that was another result that was that was discovered more than 200 years ago by goss and marco it's the goss markov theorem often popularly called the blue theorem a best linear unbiased estimator theorem which basically says that in general the you're better off with a mean squared error. Not always, but quite often. In well-behaved conditions, you're quite better off with the sum squared error. And one thing that I didn't quite do is to give you the intuition of when one should use one and when one should use another. In this world of data science, data is the king. Quite often the situation determines which of the two methods is better. And this is one of the things you will learn in machine learning that a priori, so I'll use the word a priori quite often, a priori means before you see the data. A priori, you can never theorize and say one method is better than the other. Are we together? The data will determine which of the valid methods turns out best. It's called the no free lunch theorem. We'll come to it one day. But generally, the mean squared error is more popular because it tends to work better more often. And that's the Gauss-Markov theorem. But in other circumstances, it is the mean absolute error. In fact, one of the homeworks that I'll give you, I'm about to release it, literally shows you different data sets in which different error measures work better. And you have to develop the intuition why one works better than the other. But I'll give you an intuition. Many of you are parents here. And all of us have been children who have been parented at some point. So one of the advice that people give, I don't know, it is, there are many words to it. Somebody once gave me a very interesting name. He said, it's the principle, it's the benign neglect principle of parenting. It says that don't hover over your kid and point out every mistake. You know they're making mistakes. They're up to mischief. So if they're particularly quiet, it means they're up to some real mischief. If you ever see toddlers quiet, you're in trouble. So well, okay, they're making some, they're up to some mischief and they're making some errors. And this is true as a teacher also. A bad teacher will point out every mistake. A good teacher or a good parent would ignore all the minor mistakes and look the other way. But the moment you make a bigger mistake, then invest a lot of energy either parenting or teaching, that becomes a teachable moment. So there is something like that. I would like to believe that maybe that's a real intuition why the mean squared error tends to work better because what it does is most of the time, the errors tend to be small. If you have a line that really goes to the data, most of the data will be close to your line in two dimensions. So your errors will be small relatively. So the squares will be small, right so their squares will be small but what happens if a number is bigger the square is huge for example a 2 square is 4 but 20 square is 400 right it's drastically bigger isn't it it's drastically bigger or nine square is 81. it gets exponentially bigger so when you when you're learning and you're trying to first minimize the big errors right effectively you you quickly zoom into the right location through the data that's one way of saying it but the problem with this is that when the data has outliers, specific outliers, then those outlier points, which are actually mistakes, they dominate the learning process. Do you see that? If you square the error, then the big errors, the outliers, the data points that are far off, what are outliers? Data points that are far off from the other data points, away from the other data points that will dominate so imagine that you're looking at data like this most of the data is like that and somebody has made a mistake and there is a data point like this now normally ideally you would like to say you would like to say, you would like to draw this line and consider this outlier, this outlier as either an anomaly or something like that, anomaly, and just ignore it. But if you just do some squared error and you're not careful, this point will dominate the learning. Are we together? And it will lead to a line that is perhaps like this, which is suboptimal, isn't it? Or maybe even this, I don't know. We'll have to do this lab to see how far it goes. In fact, it is one of your lab homeworks. Do you see the point point guys? But generally, when you have outliers, they tend to need special treatment. And in the case of our Entreprener and ice cream, something unusual may have happened on that particular day. Maybe a whole school bus came to the beach, and you had an extraordinary amount of ice cream sold. So it is a special case. You don't want your machine learning, machine to learn from that data point. In fact, you want it to be not overemphasized if at all. So that is the problem with just using mean squared error. It becomes susceptible to outliers much more. Whereas when you just take absolute value, then you're keeping things in proportion to the error relatively, right? So that's a distinction between the two, right? So we come now to regress. So the word regression comes from regression towards the mean. Now, today we will talk about that, Galton's paper, regression towards the mean. Now, today we will talk about that, Galton's paper, Regression Towards the Mean. And what is the cause of regression? So we learned that there's regression, there's classification. We focus on regression now. Galton found that children, offsprings of extraordinarily tall parents, tend to be a little less tall. And children of extraordinary short parents tend to be a little bit taller i i believe he first saw it in peas then he saw it in humans and so on and so forth he noticed that it tends to be common in biological phenomena phenomena so where does it come from so that brings us to the concept of the irreducible error irreducible error quantifies that which you don't know. For example, when you sell ice cream on the beach, and as an entrepreneur, you're trying to model it as a function of temperature, there are other things you are not considering. For example, given the same temperature on a weekend, you would sell far more ice cream than you would sell on a weekday. Weekday parents are working, they can't bring their kids to the beach. And weekends they can, holidays they can. So even a given temperature, there would be an error band depending upon what day of the week it is that you can't do. So factors that you don't know, they represent themselves as irreducible error. Even when you have the best method, the best hypothesis, still you have residual error there. The other source of such error says, quite literally instrumentation error, right? So, this happens all the time, by the way. I carry from US a pretty good measuring scale with me so that when I travel through different countries, I know what the weight limits are in different airlines. And I always stay about four or five pounds below that. But whichever way I do, I know that there are certain airports in certain countries who have a weighing scale that will always declare my suitcases to be overweight no matter what right so what do you have you have genuine instrumentation error by design or not you have instrumentation error right and then those of you who stand on the weighing scale every day know that if you stand on the scale and then 20 minutes later you stand on the same scale you magically your weight changes how many of you have seen this right so we see that all the time so you have instrumentation error so those are represented in the irreducible error represented by this epsilon symbol now yeah go ahead Albert so So Gauss invented the SSE or MSE? The same, they each one is just one over n of the other. So now so I must just say that in passing that while regression towards the mean in the particular case of human beings happens, that children of very, very tall parents are less tall. There is also the Flynn effect. Don't confuse with that. Flynn effect says that every successive generation statistically is taller, brighter, more capable than the previous generation. What is today the Olympic world record? In a few years, high school kids would be doing it as their records, right? And we can see it. Just look around at some of the high school records and go back and look at the Olympic records for 25, 30 years ago, and you would see that high school kids are beating the records of 30 years ago that has to do with the fact that we are all better fed well protected well taken care of technology has advanced longevity has increased the human body doesn't go through as much wear and tear and so forth right so that is a different thing but at the individual level regression towards the mean happen so why does it happen? We realize that it happens because there is always a irreducible error. So suppose you have an extraordinarily tall, so imagine that a person is very, very tall. It will be a function of genetics, namely, let us say some genetic causative factor based on the grandparents' height. So grandparents would be tall, but there would be the irreducible error, which will have a bell curve. If by happen chance, this error, whatever it is, whatever the child was fed, the mother was fed, whatever things that you can't account for happened, caused a parent to become excessively tall. It means have this huge epsilon added in the positive direction to the causative height. Then what would happen when that parent has children? You cannot assume that the same random phenomenon, the same random forces would cause even more height increase isn't it in fact the error is likely to be smaller but when you take the causative factor plus a smaller error your actual the the child of the parent now has become shorter than the parent are we seeing the reasoning guys so that is what it is then we learned about gradient descent a pretty interesting concept so there we talked about the dual space the space of the real data and the hypothesis or the parameter space for every hypothesis in the real space aligned a linear relationship there is a point in the parameter space and for every point in the parameter space. And for every point in the parameter space, every hypothesis, we have a certain amount of error. We looked at the error and we realized that those errors, they form a quadratic equation. Remember, we expanded it out and they were a quadratic equation. And they're greater than zero. This quantity is a square of some numbers. Sums of square is by definition greater than zero. And our intuition tells that because of irreducible error, it will be certainly greater than zero. Its shape looks like this. Whichever point in the hypothesis space it achieves the minimum, the optimal point of error, that is the best you can do. It will still be, this is your irreducible error that you can't get rid of, right? This bit of height, you will still have. Now, the question is, suppose I make a random guess, how do I find a path from here to there? So there comes the next part or the next crown jewel of machine learning, namely the gradient descent. So what it says is there is a concept of a gradient, which is a generalization of the derivative. It is represented by this inverted triangle. And we won't go over this because you can review the video. So but for people who are new, please take out time with either me or the TAs, and we will walk you through that. But for people who are new, please take out time with either me or the TAs and we will walk you through that. If you have the gradient, the magical thing with the gradient is if you think of functions, for example, this is a surface, this is a landscape hypothesis space, this is an error surface rising over it. The amazing thing is in the function space or field, mathematicians have a built-in Google map of sorts forever. If they want to go home, namely the point of minimum of a function, all they need to do at that point is take out this magic compass, which doesn't tell not sort, but it tells which way is the gradient pointing. And whichever way the gradient is pointing, go the other way around. Walk opposite to it. And if you keep walking opposite to the gradient, you will essentially reach home, right? But you will reach home only if there is one home, there's one minima. If your surface is what is called convex, right? So this is a convex surface. now you say inside is concave but if you look like this is convex in the common language but actually the way mathematicians think they are they look at this surface as convex they say any surface is convex like this surface is convex because if you take any two points and you connect any two points with a segment then the part with the part of the surface that is under that is there between these will always be on one side of the segment right so? So this is a convex surface. On the other hand, this is not a convex surface. Why is that? Because the curve goes back and intersects the segment, right? So we talked about that. This is non-convex. And we need to remember that non-convex. So one of the problems in machine learning is that how do you learn or how do you go to the minimum when the surface happens to be non-convex and we talked about this i believe i showed you some highly non-convex surfaces where was that maybe i'll type it in again Maybe I'll type it in again. Let me do that. It turns out that in machine learning, you don't always have convex surfaces. Yes. So I would just like to show you. We talked about this surface that in machine learning, quite often you get lost surfaces like this, error surfaces like this. Well, I'm using the word error and loss interchangeably, but there's actually a subtle difference, and we'll come to that. So this is a minima here where my mouse is. Can you see where my mouse is? We want to reach here, but along the way there are many traps, there are many ridges and valleys, little, little valleys around this surface that you can get trapped in. So one of the questions is how do we do that? And that brings us to the whole architecture and machinery of this beautiful subject we'll deal with it it also answers the question why can't i set dy dx to zero in calculus in high school calculus you learn that i can set just the dy dx to zero and get to the minima why do i need to do this gradient descent the reason for that has to do with the fact that if you do it you'll find that they're in they're practically infinitely many points at which dy dx is zero. Horrendously many points, right? And so that won't serve you. You need a systematic way to take you to a minimum. Now, in the case of linear regression, the beautiful thing with linear regression is one of those cases where your error surface is really like a bowl, right? It's convex. So you can say I could have said dy dx to zero and found the optimal point. And that is actually what is done. In practice, when you have linear regression libraries, they do a direct close form solution. They don't actually do gradient descent because you know for sure that if there is a point where the error vanishes, it is the right answer. So you do close form solutions. We talked about all of that. And so remember that gradient always points in the direction of maximum ascent, steepest growth. And if you want to climb up a hill, follow the gradient. If you want to go quickly into the valley, go opposite to the gradient right so that's the journey right and i illustrated this with an example in one dimension if you take this function and i'll just quickly review this you have a function this function if you look at this point the slope is negative why because when you take a small positive step, you fall. The function decreases. Decrease in function means negative slope. Because slope by definition is the amount of increase in a function for unit step forward. A tiny, by the way, unit step, not in terms of giant, don't take giant steps. Unit step means, imagine a millipede, right? Making a, with its tiny legs, making one tiny step forward. So when you take one unit tiny step forward, how much did the function increase? That is slope. If it decreased, well, that is a negative increase, and so negative slope. So at this point, it is positive. B, it is positive. At A, it's negative. but if you want to go home to the green point what should you do at a at a you should go if you want to go here you want to go again in the if this because the slope is negative you want to move forward positive amount you want to add so you want to add a negative of the slope scale down by a factor you don't want to take a giant step you take a little bit of a step. This is called the learning rate. And remember, you are a little millipede or centipede. You're taking tiny little steps. Likewise, at B, also it turns out that the same thing works. Because you want to go in the opposite direction, you would do a thing like this. And so the net result is is it turns out that this equation and this equation are exactly the same equation and so this is this becomes the celebrated uh equation of gradient descent in its simplest form right and what is in one dimension true it is true in higher dimension right so if i were to write it as a vector i would write it as next is equal to x minus alpha gradient of x with respect to x right but we are not in the x space now let's go to the parameter space so in the parameter space you would say beta vector, beta next, is equal to beta minus alpha gradient of the error surface, and gradient of the error surface. And this is actually the machine learning. This is how machines learn by taking tiny step, not in the real space, but in the hypothesis or the parameter space. So this is the the celebrated gradient descent step right folks i hope you have reviewed the video or you have watched the video this is important this is therefore the summary of what we learned the last time any questions before we proceed the last time any questions before we proceed uh yes uh as if uh if i may ask uh do we maximize the learning rate to get to gradient descent no it turns out oh you mean the alpha right the alpha learning you don't maximize there is a problem that happens it's a very good question and we are sort of jumping the gun we'll do gradient descent in great detail at some point but let me show you what happens if you make giant steps you see me making giant steps what happens What happens? Am I reaching the minima? No. So what happens is if you take giant steps, if you are a big foot, you won't reach the minima. You'll just be hopping all around the minima, isn't it? So that's the problem. That's the reason you don't keep your learning rate too big. But then on the other hand, if you keep it too small, you'll be creeping your way towards the minima, isn't it? So one of the very, very interesting topics in machine learning has always been what should the learning rate be? You can treat it in the beginning courses, in this course, you can treat it just a hyperparameter of the model. Play around with it, see what works. But there is more to it. As you advance, you go to ML 400, you'll realize that this is a whole topic in itself. It's called the rate schedule, learning rate scheduler. And they're very powerful and intelligent theories and methods on how to adapt the learning rate at different stages of the learning right but we won't go there at this moment just assume that you have to choose it judiciously you can't make it too big too small okay see if i can ask a question see um when you the minima, how do you know if it's a local minima or the global minima? You wouldn't know if you take just tiny steps. At a certain point, you have to take a little bit bigger step to see if you're getting into complicated things. So remember, we are, you know, first let's crawl, walk, then run. So that principle. But your question is very valid and very deep. The thing is, in the case of linear regression, there is only one minima. If you reach the minima, you're done. Because there was only one. Right? But when you get to more complicated surfaces, like for example, when you get to a surface like this, the question becomes more interesting. How do you get get out of a local minimum? How do you even know that you're trapped in a local minimum? And what do you do? And there are beautiful, beautiful methods to it. Some of it coming from actually statistical physics and material science, simulated annealing and things like that. And we will deal with that. But for that, wait till ML 400. You are three courses away from it at this moment. We'll come to that in due time. So at this moment, Raj, for the sake of this course, just assume that if the gradient vanishes, you're home. No worries, thanks. Yes. Any other questions guys, before we continue? Yes, if so, what if the curve was reversed? Like instead of y equal to x square, let's say y equal to minus x square, where you know there is no global minima or local minima to start with oh see see here's the thing suppose you have a function like this well in machine learning you won't because error loss functions are usually positive but suppose you have a function that we say gx right so instead of minimizing what you can do this is a maximization problem right or just take minus gx you'll end up inverting g and it will now become a minimization problem right just change the sign and we can so in machine learning and traditionally most of these libraries for no particular reason these libraries are all tuned to minimize functions knowing that if you ever want to maximize take the negative of it got it that's it so that is that so guys any more questions because now it's my turn to ask questions all right so i'll tell you a fact and tell me what do you think happens? So pay attention to this, guys. At one time in my neighborhood, there is this university, University of California, Berkeley, right? Their sports team in their infinite wisdom decided to do something unusual. So now when you teach people, one of the first things you are taught, you learn, I mean, you internalize as an educator is to give positive feedback. We know that as parents to the children, we should give positive feedback. When they do things right, we should let them know that they're doing well. We should be rather reserved negative feedback for exceptional occasions, not often minimize that. So not everybody agrees with the theory. Some people believe that that is coddling the generation and spoiling the young, right? There are old sayings like spare the rod, spoil the kid, and things like that in various cultures, something or the other is there. So there's an alternate school of thought that says nothing helps so much in teaching people anything, whether kids or grownups, as a good, nice stick to whip people with. And you have seen that. You have worked for many managers who use that, who are always using a whip to scare people into working or being productive, because they feel that is how you improve people. Now, people have different ways of looking at it. The overwhelming scientific data, it turns out, is in favor between these two different hypotheses. It is in favor of positive feedback, positive reinforcement. Now that is what the data says, but people obviously obviously nobody has to agree with the data right we live in very interesting times when data may say one thing but somebody else might believe is the president or won the election and whatnot right so you see that in the u.s so there was one group some people always feel that being strict is the right way. So the sports team decided here that every time a player does badly, they're going to absolutely rain down on that person. And just trash the day light of that person, not physically, but metaphorically just rain down on the person and see if things improve. And then they reported that, well, they found that if they rain down on the person or the players, the next day those players did better. This is a real thing, by the way. And so they got so excited with their finding, they thought they had some very good finding. They went so far ahead as to publish their results. So, and this is what I heard actually, and which is ironic considering that Berkeley is one of the best places to do mathematics. Then a similar story is associated with Israel's Air Force. So you have Air Force pilots, the training pilots who train you, or training instructors who train you on how to fly a plane. Now, usually flying a plane, when you are doing that, it is a bit of a high stress activity. No matter how many hours you have spent in the simulator, when you're actually in the simulator when you're actually in the cockpit of a fighter jet or a plane then it's a different game you're in an airplane you have an instructor next to you and you're flying and you make too many mistakes and the instructor may die with you right so it's a bit of a tense situation and so people were flying and learning and so they decided that now when instructor decided that what they will do is enough of coddling. Anytime a pilot flies badly or makes a lot of mistakes, they will absolutely rain down on the person. Are we together? And what they noticed is that that led to extraordinary results. They tabulated the results. And what they found is every time they shouted at a guy, the very next day, the performance of the guy improved. Clear data. They too published the results. That's how we know about it. Now, so how many of you would vote and say, yes, that is the way to do it. Now is the time to bring out that stick and walk up to your kid who has been annoying you. Right. Or I'm joking, of course, don't actually do that. How many of you would subscribe to the theory that giving very strong negative feedback was the reason or causes better performance the next time or actually leads to improvement in performance or is the cause of improvement in performance okay how many how many disagree go ahead somebody is speaking hina go ahead Okay, how many disagree? Go ahead. Somebody is speaking. Hina, go ahead. I don't know. Does this mean that it improves the performance by coming to a local minima and not we never reach the global minima? No, no, no. Forget about minimum. Forget your mathematics. Just think in basic sense. How would you argue? Imagine you're in a court of law or you're talking to common people sense, how would you argue? Imagine you're in a court of law, or you're talking to common people, which way are you leaning? To give positive feedback, or there is actual value in giving negative, instant negative feedback? We would never know until we compare it to even better performance. Does a positive reinforcement lead to an even better performance? We would never know until we compared it to a better performance. Yes, and that spoke the journalist amongst us. Very good. Anybody else? Yeah, I believe that it depends on the activity, but if you are inventing something, then negative feedback is not going to help. The encouragement will help there. But if you are going to do a repetitive job, it only needs to be tuned better, then probably this will help. good point anybody would like to come up with a counter argument to the uh to these things like for example anybody can prove what can you point out to what is the flaw in this line of reasoning anyone articulate it well. Hina, you did it partially. Fear of losing employees is not good enough. If you know in your heart that you should trash them, but you're not trashing because they leave. That means that in your view, they'll never develop, they'll never grow. You need a consistent study that accounts for all the factors, not just that one time. Yes, a consistent study, all of you are saying, that needs, that accounts for many factors. Anybody else would like to hazard a guess? Guys, this is the time to use your imagination, come up with explanations. Speak up, please. It goes to the heart of what we are going to talk today. Another thing, what was or how many things change? Was the talking the only thing that changed? Yes, the only factor. The student pilots did badly. They were called into a room. They were absolutely, you know, given a piece of the instructor's mind in very uncertain terms. And next day their performance improved. Kate. Do they have all the instances where they had poor performance, no feedback or positive feedback and then what the performance was the next day? Kate's thing is that did we also look at the case where some poor performance were given no feedback or positive feedback, positive reinforcements and what happened to them right and yes you guys are all close to the right answer but i want somebody to articulate it in crisp language in in a lot in a in a logically in a in completely defensible way how would you say it the the function for uh for the football team would be different with the function for the pilots. They are two different stories, but the same thing happened. Shouting led to better performance. Chander has written it down in the chat for everyone. I'll just read it. Okay, yes. It was an example of regression towards the mean. Absolutely right. I just taught you regression towards the mean. So let me explain that. It's an example of regression towards the mean and another concept that I'm going to explain. So how do you see, guys? Regression towards the mean is one of the most really one of the most non-intuitive things that we know in a great statistician stigler wrote a book the i believe it's called the six pillars of statistics or five pillars or i've forgotten how many pillars but one of the pillars is regression towards the mean and human mind has a very tough time understanding that see what happens is imagine that you have some pilots who did badly right who did horribly bad they did horribly bad for a whole variety of reason the guy may have not slept well the previous night, may have drunk a little bit, may just be having the body, may be having aches, the body has its ups and downs. For all you know, his girlfriend had just dumped him that morning. Right? Right? Or many, many things may be happening to the person's life. Or there's so many factors that you don't know about. That caused the pilot to have a particularly bad day. And we all have good days and bad days. How often have you woken up and gone to work and realized that today, just nothing seems to work? Isn't it? It happens. And then some days you go to work and whatever you touch works and you suddenly feel that your IQ must have jumped 30 points while you were sleeping. Right? It happens to all of us. We don't know. There's a variability built in and that is the epsilon. On the days when the variability is hugely negative, you're having a really bad day, you get shouted at, but the next day, the variability may by random chance be in the other direction, right? So whether you were shouted at or not, you don't know because the next day you would have done better anyway. So if you really want to say that because of the shouting, the performance improved, the right way to do that would have been to break up into a control group. And that's why in medical, we always do a control group and psychology and medicine and economics also. And nowadays we do that. So you have a control group. Don't shout at a group. Divide it randomly. Some people you don't shout at. some people you shout at. Better still, some people you give some positive feedback, some people you talk to at all, some people you shout at and next morning you see what you will see generally. And so people have repeated such studies is that they all improve, right? Invariant of whether you said positive things, negative things, or didn't talk to them at all. The extremes are pulled in. It's regression towards the mean. Are we seeing that? But believe it or not, it's very hard for the human mind to sequence. But sequentiality in time dimension does not imply causation. All your life in statistics, you must have heard the phrase, correlation is not causation. That is true, we'll come to that. But one of the cardinal mistakes we all make is we think if event B happened after event A, B is likely the cause of A, especially if somebody can make a persuasive argument. As in this case, the improvement in performance in those pilots is because they were shouted at. Or these football players is because they were shouted at. If you read the newspaper guides, and I invite you to do that, within a week, you will be able to pull up examples where people have written papers, written articles, where they have mixed sequentiality with causation, whereas what really was happening was regression towards the mean. And sequentiality is not causation. See, I came to Silicon Valley in 1999. And there was a dot-com boom. And billionaires were manufactured. I must be the cause. So the absurdity of sequentiality is right there. Just because B follows A doesn't mean that a caused b are we together yeah go ahead what were the outliers right some people might be really good so those people should be remote from this particular situation some people will always perform much better than others no no, no, they are there. See, there is a baseline value. So they are the high level, let's say that they perform at 90. But within 90 score out of 100, they will fluctuate between 95, 98 to 80, 85. Everybody has random fluctuations, right? So we all have error bars associated with it. So that is important, guys. So the point is, We all have error bars associated with it. So that is important guys. So the point is, remember, sequentiality is not causation. Do not infer causation from it. And quite often, there are many, many things are true, right? If you look for that, for example, if you're in the United States, and I'm sure in every democracy, if the economy booms, whoever is the president or the prime minister immediately takes credit for it. If the economy sinks, it was the cumulative effect of the mistakes by his predecessor. Have you seen that? Right. So this happens every time. Right. This is a mistake. So the next thing we will talk about is correlation and causation. Causation means A causes B. Right. Now, without defining what correlation is. And today we'll have a more precise definition of correlation. So the second half will go into statistical concepts rigorously. defining what correlation is. And today we'll have a more precise definition of correlation. So the second half, we'll go into statistical concepts rigorously, but at this moment, let's be with stories. So there are many, many things that happen in life that people ascribe to causation. Even researchers do. Right. So I'll give you some very interesting examples. Suppose, so they found in the US, for example, that there was a therapy at one time that was very popular. It was called hormone replacement therapy for women. So women have a process called menopause. And if you take hormone replacement therapy, generally you stay perked up. You stay, you look younger, you stay younger, you stay more active. It was supposed to be the miracle thing, right? You generally feel good, right? You don't feel old and so forth. And nowadays, of course, there's hormone replacement therapy for men also. You generally feel good. You don't feel old and so forth. And nowadays, of course, there's hormone replacement therapy for men also. Now, when it came out, it was advertised as the miracle thing because they found that people who were taking the hormone replacement, the more stronger dosages they were taking or more regularly they were taking, the better their general heart health right so what do you conclude from that what the research has concluded is that yeah this correlation means that this hormone replacement therapy in some ways that we don't understand improves the heart health, the coronary health, right? And it was literally marketed at least in the Western hemisphere as the magic thing, right? Makes you younger, makes your heart grow better and so forth. makes you younger, makes your heart grow better, and so forth. In the complete absence of any scientific or biological causative discovery, researchers had no way to explain why A caused B, but they felt that A caused B. So I want you to now, with the discussion that we are having, can you argue against it? There is a correlation. There was a correlation based on how regularly you were taking hormone replacement and how your health was, or between people who took hormone replacement at all, women who took hormone replacement and their cardiovascular health versus women who did not and their cardiovascular health. So would it not be fair to give credit? Perhaps credit is due to give credit to the hormone replacement. Anybody would like to agree with that or contest that? You could try the placebo and see if that works because the patients knew they were taking something. That is one way, have a control group, very good. But how could you just refute this study on its merit without doing any further experiment? Maybe because they thought that, you know, they're taking the miracle medication psychologically. They were thinking that something is helping. Induce psychosomatic response. There was an induced psychosomatic response. Very good. And I can see your marketing and advertising background come in here. Yeah. Very good. Anyone else would like to hazard a guess? Just trying to find a link. If you're taking hormone replacement therapy, you feel active for longer, maybe they're exercising a lot more, and that's improving their heart health so you are at the causative aspect that it will basically do something that will make your heart better it will change your lifestyle you feel good you are more active yeah uh anyone yeah um I think I think the people who took uh the hormone replacement therapy were already more concerned about their health so they might have done other things to improve their heart health other than take HRT people who took the hormone replacement therapy were already more concerned about their health. So they might've done other things to improve their heart health other than take HRT. Very good, very good, Andrew. So in other words, you haven't control for factors. How about the fact that hormone replacement might have been taken by a biased sample, a sample that began healthier. Andrew, oh, sorry, Albert. So are there examples of people who are not successful? Only maybe positive results were reported. No, no, the study was not, it was not like sort of, there was no malicious intent there, right? Anybody else would like to hazard a guess? I guess everybody loves to sell their logic actually, even if there is no logic. Yes, I mean, obviously, this is a great, great marketing opportunity. And pharma makes huge money from that. But I'm claiming that as a data scientist, see, I'm training you guys to think correctly. Can you refute the argument on its head right away? What is that was not the end result that they wanted actually. Oh, they definitely wanted that end result, get a good cardiovascular. What was the age group of the women who took it? By construction, you can imagine that these are women who are entering menopause. When do women enter menopause? I have no idea. 51. 51 is the average age. that these are women who are entering menopause when do women enter menopause i have no idea 51 is the average age yeah so so guys i will let you ponder over this question and i'll give you an explanation in a little bit but i'll tell you a different story But I'll tell you a different story. In US, as you know, a lot of the history of this country has been that the settlers came, and they often in the South especially, they had huge tobacco plantations. It was big business. The country changed, but tobacco remained big business. I don't know if it is still big. I think it's still big business. So you have tobacco plantation in fact that's how if my understanding is right that's how a lot of people were brought from africa and from india and so forth to work on the foundations so tobacco gradually as biological and medical sciences advanced, there was a general realization that people who smoke, they also tend to have lung cancer more often. There's more incidents of lung cancer in smokers than in non-smokers. So in the beginning, there were lawsuits and people trying to get smoking stopped, tobacco banned. And they weren't succeeding because tobacco is a big industry and they would bring their gazillions of lawyers. And this is a real history of the country, of the United States. It was hard to win against them. They would always have some, they said the evidence is insufficient. Evidence is, when the evidence is insufficient, it's easy to poke holes in it and they could easily poke holes in it. But gradually, evidence began to mount. The legitimate scientists in research labs are beginning to see increasing evidence that this is really true. When people smoke a lot, they have significant incidence of cancer. So what did tobacco do? They said, oh boy, there's evidence mounting against us. So we need to open our own labs. So they opened specialized labs where they hired specialized scientists who did very specialized experiments, whose only conclusion was that smoking is beneficial for health. Right? And no matter how much you smoke, it doesn't cause cancer. There's no data that shows cancer in their labs. And so they would produce counter evidence, but it went on and gradually the evidence began to mount quite a bit. Then at some point there was again a lawsuit and the big tobacco said, this type is hard. There's too much evidence against us and there were all these correlation charts showing look at the correlation the number of cigarettes that you smoke in this the group the cohort that smokes daily four cigarettes a day has this incidence of cancer whereas the one that smokes one a day has a slightly lesser the one doesn't smoke at all has no a very very low incidence of cancer. So you have a correlation. So then they had to defend. And so how would you defend? Anyone has an idea? How would you defend? Yeah, I would say simply the user doesn't know how to smoke. He smoked the wrong way. Yeah, possibly. It's as simple. If you're an amateur, you're bound to do the mistake. Okay, so then you can say that, okay, now it's the responsibility of the tobacco companies to educate users, right? But they didn't do that. What else? How would you argue against it? And the argument is actually beautiful. So at that moment, the big tobacco thought they need to get big guns. So one of the greatest statisticians is a statistician named Fisher. So what Fisher? Okay, I'll remember his name is escaping my mind, a British. They flew him from England, right? And knighted, I mean, see, when you have sir attached, you're knighted or something like that. You have gotten the queen has put some title on you. He flew in. And by the way, if you look into the books, we will learn one of his algorithms. We'll learn quite a few things that we ascribe to this Fisher. He came in and he says, what's the problem? He says, you know, evidence is there, all these correlations. And they seem to show that smoking and tobacco use, and there is oral cancer and there's lung cancer and so forth. He says, no problem. Goes to the court. They say, they bring up the people bring up all this chart, he says, I completely agree with it. And well, if you agree, then we have one isn't it? The other side is one he says no, absolutely not. He says, all you have to do is turn the charts a little bit, rotate it a little bit. And as you can clearly see, smoking causes people to to i mean cancer causes people to smoke right when people have cancer the way he positioned it is when people have cancer they are suffering right and cigarette is a great tobacco helps alleviate that pain, right? Suits the nerves. So what about the people who, well, don't have cancer? Well, he claimed that they have latent cancer somewhere in the body. They are in pain, and so therefore they gravitate to smoking, and this tobacco is doing great public service. They're getting pain alleviation for a big problem, right? So do you see how a correlation can go either way? Do you see that? From pure correlation, you cannot, and I believe this is a very good thing because while obviously he had a devious intention, it did bring out one point that the scientific community was not making a strong argument. Correlations are not enough. Later on, we had more precise understanding of how exactly tobacco leads to cancer. We know the chemical pathway better. You have to create the causative chain scientifically, in laboratory, demonstrate it, and then you have evidence. Pure correlation is not evidence because you can actually turn it upside down and argue the other way around. So what A may cause B, in this particular case, tobacco may cause cancer, cancer may cause tobacco with equal validity. You can't contradict it. Just because you feel it's not right is not argument enough. It may be true. If you notice a similar argument is being made for weed and for other drugs also legalizing other drugs today with different degrees of validity weed has been shown to have genuine medical benefits so it's a slightly different topic but now i'll go back and ask you guys the other question. But now I'll tell you a story that is even more ridiculous. More case studies. Let's learn through case studies today. In US, there is a big breakfast industry. Most people on earth, when they wake up in the morning, their mom and dad have cooked something nice in the morning, their mom and dad have cooked something nice in the kitchen. In India, it is usually a nice Uttapam or Idli or dosha or paratha. True, isn't it? In the Western hemisphere, especially in the United States, at one point, the breakfast industry took over. And so the convention was you would open this breakfast and out would pop colored loops and all sorts of multicolored, sugar-coated, total starch, horrible things. And they showed with validity, they showed that people who have a nice, good breakfast, who don't skip breakfast, they tend that people who have a nice good breakfast, who don't skip breakfast, they tend to be slimmer, right? And have generally better health. So there was a whole belief that, you know, you need to take your breakfast very seriously. Even now, you go to any health site, and you'll find some guy or the other advocating this wisdom you must have seen that and it is all based on this old study now could you poke holes into this i'll let you think about how you would poke holes but i'll end with a really obnoxious example obnoxious because I hope you'll remember. This happens to be true. I didn't know where I read it, but it's so obnoxious that it's stuck in my mind. India and China, they have something interesting correlating them. The population growth curve of India, apparently I'm told, matches closely the population growth curve of donkeys in China. So unless you feel that activities in India is influencing the donkeys in China or vice versa, how would you explain the correlation? So think about it. Why is there a correlation? So think about it. Why is there a correlation? Right? Can we therefore conclude that one is influencing the other? They could be independent. They could be altogether independent and yet there's a pretty good correlation. Another, but and now and a final correlation that I'll tell you, if you look at the temperature curve in some city, you know, the sun is shining, it'll go up, then clouds will come, it'll go down, then maybe rain comes, it goes down even further, then sun again starts shining, it goes up a little bit or whatever. You take temperature, you take humidity, et cetera, you'll get some stochastic curve. You get some curve. If you look into the stock market, more or less amongst the thousands of stocks, you'll be able to find some company's stock which closely matches that curve for that day. So did the temperature here and what was happening here in your city affect the stock price or the other way around? What happened? Why are they so closely looking like the same curve? More or less? Naturally occurring populations. No, no, it is financial market. You see some companies exactly like that. Yeah, but it's one company amongst 5000 or 10,000 companies. That error is bound to happen. Close. Yes. Basically random. Yeah, chance. Yeah. So, so yeah, good point. So, let's let's draw some lessons from it. Correlation can be pure accidental. I'll call it adventitious correlation. They're able to go and repeat the experiment for the next day and at least the next 100 days or so. Right. Then you wouldn't see that. Unfortunately, that complete stop won't do so well. So this clearly is an example where it is unrelated. Isn't it? Right. So now let me, by the way, there was one more story I wanted to give, and I'll leave that as a puzzle and give you a break to think over. And I want you all to discuss amongst yourself and come back with answers. The next story is, suppose you have taken a few people to las vegas and you have given them a hundred dollars to gamble some will win some some most people will win some lose some right or maybe give them a thousand dollars these days with inflation 100 doesn't mean much right so let's say you gave them a thousand dollars and they played the markets after a little while at the end of the, there will be some winners and some losers. Some people will be big winners and some will be big losers. Isn't it? Now what you do is you take the really big winners, because they really seem to know how to win, isn't it? Because they have come back with big moves. Next day, you again give them a thousand dollars. What do you expect? So think about that problem because that's how, by the way, traders are hired. Any trader who does well for a given amount of time immediately becomes a star trader and all the trading houses want that person. And ponder over what happens to such traders. It's real life. These things happen. So let's take a break. We have been talking now for the better part of an hour. It's time for a break. I'll give you guys a short break of exactly 10 minutes. Ponder over this, guys. Don't take it passively. Come up with answers. Because if you think about it and ponder over it, then when I explain the theory, because now I'm getting into statistical theory, it will all make sense. So 10 minutes break, guys. All right, guys. So I posed a few puzzles. Let's take the easiest of them. If you take the people who were extraordinarily successful in Las Vegas on a given day, how many of you vote that they really, like, there are people who are either lucky or who have figured out the system the next day also they'll make money. Any any takers for that anybody with experience. Okay, so I know that I haven't played poker myself but I know a friend who does, and depending on the game you play at the casino, you might have different chances of winning. Poker is one where skill actually matters. So you have to make sure that the people who won big weren't all playing poker. Okay, let's take poker out of the equation. Okay, yeah. So if poker is out, then I'd argue it's pretty much random. And the next day, you're likely to see most of them earn less or lose less or like earn less than they won and also lose less than the people previously also lost yes so i'll illustrate this with an example guys and this is how actually a famous paper did it. Imagine a box. And so now we are getting mathematical. How many of you play a game? When I was a kid, it used to be called the bagger tail. What you would do is imagine a horizontal surface like that and there would be all sorts of pins or obstructions, but judiciously placed. And what you would have is let me put bins, obviously, many more pins in here. I have underrepresented the number of pins and lots and lots of bins. Right. So what happens is from the top you drop a ball a marble now the marble can will go and hit the first one it goes and hits and after or it will hit something right once it hits this it will gravity is pulling it down. It may go this way. It may go this way. Right? Then it will hit something here, which may cause it to go this way or this way, let's say. Right? And it may have gone here. It may have gone. So you're pulling it. It's randomly falling at whichever direction it is. At the end of it, what will happen is, the most high, so you will see an interesting, if I were to just exaggerate, the marbles that have accumulated here. When you drop a lot of marbles, would you agree that it makes common sense that in the center would be most marbles? Because there's no reason why there should be more on the left or more on the right, isn't it? That random chance will keep pushing them to a distribution like that. Does it make sense? So now take the same game and let us say the winners, you impose a game on it. You say the people who are here are winners. These marbles are winners. These guys are losers. And once again, you have a second round to this game. You pour these things through a funnel into yet another set of marbles sorry pins pinheads and here are your pins here these marbles these marbles that are there as I apply when they come and start falling here do you expect them to all accumulate in this region X or do you expect to again see a uniform distribution sort of a bell curve distribution you normal says that because there's no reason why you pour this you replicate the same situation above and below and you should see different results so what has happened think about what has happened to these marbles their location has regressed most of them have regressed towards the mean isn't it from being outliers they have been pushed inside and anywhere in sometimes severely inwards they have become losers does it make sense guys just do this thought experiment and there's a lovely word in a research paper that it was called that is one of your readings so kyle we need to release the second paper for reading a famous research paper so a great mathematician showed this just with this simple example. Now there's more to it, the fact that it's a bell curve, we expect it, but why it is, we'll come to that later. What it shows, regression towards the mean is very obviously there. Now, what is the causative? Because in this case, the causative factor is practically zero, right? It's this thing. Now, when you send a bunch of random people to play games, in a casino, most of them will win some lose some, they are like this. Occasionally, if they win, they move to the right. If they lose, they move to the left, they feel they have 5050 chance, but actually not 5050. Because house is a leak. It keeps taking some money out of the system that's how the house wins eventually but you do that so you most people would have lost some one sum some people would have lost a lot and won a lot but if you make them repeat the next day they are not going to be winners and you see how you can demonstrate this right this is a fact, by the way. Have you ever walked into a bank that will show you the investment schemes, the investment funds? Walk into any bank, here in California at least, and say, I want to invest money. And all of a sudden, they'll become your best friends and they'll show you all these wonderful portfolios on how well they have managed money there's many money managers and they'll show you that from this period to this period this particular fund did very well it had 20 growth it had 15 growth and so on and so forth then you come out feeling that you don't know much about money but these guys live and breathe and think financial strategy so is it a good idea to give them your money most people do by the way no yeah the why why not because just just like historical evidence shows you should do it but they cannot do it for long it's just one good year you know if you do enough stocks you can always find a collection of them some little fund which has done well for a short period of time right generally you base some heuristics that oh the tech will do better so you just go create a bundle of them and for a while you go it begins to look that these guys are geniuses right but actually that is that is exactly this situation next time around the next few years everybody is puzzled i don't know why my fund is not doing so well right but while it's not doing so well as promised the fund managers are always getting their one percent two percent three percent of your portfolio whether your stock goes up or down have you seen that you keep losing money so i call it the mathematical idiocy tax if you are mathematically illiterate these guys will take your money one way or the other why because there is no you know the the financial markets are extraordinarily efficient i think how you made that point they're extraordinarily efficient right and as being extraordinarily efficient unless you have an unfair advantage you can you have powerful machines to do high frequency trading or you have inside information there there is no way, fair way, that you can beat the indices, beat that. In fact, there is an experiment done, it's called the random, I think the random darts monkey experiment. The thought experiment is that a monkey throws darts onto a board with lots of stocks written. I don't know if they physically get a monkey to do it or it's just figurative with randomly you pick a stock and you follow. No, they actually made the monkey to pick the stocks. Oh, they actually made them. And it beat the market continuously. It beats the market continuously. Exactly. So what happens is that because it's random it's actually closer to the index funds that the dow jones industrial average or nasdaq or something much more likely to be closer whereas these money managers are human beings who all have biases based on experience their experience said that they ended up in this area, because they have certain theories that will lead to their winning, time and time again, they fail, right? In fact, no one has ever beaten that random darts from monkey experiment. No one has beaten that, right? You can do this experiment. Take kids, put their finger on random stocks, good or bad, you just take it create an index out of it sufficiently many follow the index and you see uh if these uh all of this snake oil salesmanship that these banks do has any merit in them in it or not right so something to learn from that guys which is that this is an illustration of what? This is the clearest illustration of regression towards the mean. Remember, here I said that y is equal to fx, the causative factor, plus epsilon. In this particular experiment, the causative factor is practically missing. The people who won in casino, they all won because of the epsilon factor. It is all random, not causative. But if you talk to them, they say, I use this and that strategy and there was a cause to it. Right? So if you know that it is random, you know that they will regress towards the mean. Right? This is it. Now, let's go back and ask this correlation thing we realize that if the day's temperature can easily have a correlation with some stock is adventitious there is no head and tail to it you shouldn't't read into it. Right? But then there's the other extreme where perhaps there is a relationship and you need to study more. For example, if you look at you put a kettle of water on the fire, and you keep measuring the temperature of the water, and the amount of time that has passed, you will find a fairly strong correlation between temperature and time that has passed, the time that the kettle has been on the fire. Would that be reasonable? That if you look at the temperature of the water and with certain margin of error, this is the time on fire for the kettle and this is the time on fire for the kettle and this is the temperature you would find would you be would you be convinced that the results would be like this and after that it plateaus off because water beyond boiling point won't go up but at least in the beginning you do see a positive correlation so not all correlations are advantageous. The other extreme is a correlation may indicate a causation. Now, if you think about the causation, more temperature can't cause you to put kettle on the fire. Temperature is the effect, not a cause. The only thing that you can control is how long you keep the kettle on the fire. So your inclination should be to find out if putting more kettles on the fire, you see the temperatures increase and you can put control experiments, put some kettle in the refrigerator, put some kettle on the normal place. And with time you see the temperature doesn't rise, but on a fire, it does tend to rise. So then you can start going deeper and soon you will discover that there is a rich and beautiful theory of thermodynamics and statistical mechanics in physics right so there is real cause causative see so i'll write may imply, may indicate, and this is the operative word, possible causation. It does not prove causation. It may indicate possible causation. So these are two extremes. They're completely random, advantageous, or there is some possible underlying causation. The underlying causation is of course the heat energy. The fire contains heat. That heat is transmitted to the water. The water temperature rises, right? Now, there is a third case which I came to, which, what are the stories did I tell about correlation? Oh, the donkey population. It turns out that the Chinese donkey population, donkeys tend to pay particular attention to how Indian population is growing. Why would that be? attention to how Indian population is growing. Why would that be? So that is when... Go ahead. I don't know. I could be wrong. They both naturally are cutting populations without any population control on them. So it's not... But the tiger population in india has been decreasing human population is increasing but our tiger population is decreasing our elephant population is decreasing the pandas in china are decreasing so you can't argue that because of natural expansion, the population should be increasing. I don't think you can compare tigers and pandas with donkeys, right? Donkeys are used, they are bred to carry the burden. So if the economy increases, they need to have some- You're close, you're getting to it. Yes, that's a very good way- There is a need for that. So that's why they are bred like that. Why are they correlated? Just random. I don't think there is a correlation. Wait. Does China breed donkeys to ship to India? No, it doesn't. Okay. The mystery deepens. to India? No, it doesn't. Okay. The mystery deepens. So see guys, I'll give you an explanation of what it is. Sometimes both of these are effects of an underlying latent cause. A latent cause is causing both of these to happen in two different scenarios. So I'll give you a possible plausible explanation, see if it rings with you. Both India and China were British colonies. Under British colonies, they were practically plundered and when both these countries became free in the 1945 and 47 respectively, they were, to put it blandly, land of starving beggars. I've seen that. My grandparents have seen that poverty and I have seen poverty. I come from one of the poorest parts of India. I've seen unbearable poverty. People who are skeletons around me in my own family. So India and China both had to rebuild a country which was in countries which were in shambles, where there was famine, there was starvation. And from there, they had, once they are freed of colonialism, they rebuilt these countries, each country, the government, whatever we may say, and we may criticize the governments, they have done an exceptionally good job in both these countries, after the, in the post-colonial world, to bring their population up. Today, if you go to India, and I can say that I go to India often, when I go to railway stations, I don't see a sea of beggars that I have to walk in the midst of to cross from one platform to another. I don't see lots of beggars sleeping on the platform. I don't see lots of beggars sleeping on the platform i don't see lots of beggars sleeping on the road generally i find well-fed people right they may not have the fanciest cars they may not be having the latest iphone pro but they are people who are broadly speaking not starving same is true for china they have. So it is when natural resources, when are available, when food is available in both these countries, what happens is everything is well fed. We get well fed as human beings, our dogs get well fed, our donkeys get well fed, our cows get well fed. All of them get well fed, our cows get well fed, right? All of them get well fed, isn't it? Even our cats and dogs, I mean, wild animals who steal our food get well fed, isn't it? And so when there are natural resources, as standard Malta's dynamics, what do you expect? Population to grow. Population grows when natural resources are available. And so the population of India, it is no surprise, is correlated with not only the population of China, but you can pick any animal in India, any domesticated animal and so on and so forth. You would probably see the correlation. So what is the correlation here? What is the causation here? It is the way these countries have managed to essentially rise from gashes, right? And they have had very parallel trajectories of economic growth, which is responsible for this. So that is the third way of looking at correlation. So that is the in-between part when when correlation has a latent or underlying cause right so this is number one adventitious this is it is one is actually causing the other this This is number three. Something else is causing both of this, isn't it? And there is a number four also. Now let's go back to our lovely American breakfast of Froot Loops, right? And sugared whatever, wheat and whatever that are marketed as healthy dishes and if you pick up any cereal box in america they will say healthy american health association and there's a big heart symbol saying how it will improve your heart right i don't know if you have seen that i actually picked up a cereal box at home and noticed that it was true i it was there why do you think that is true do you think really that those fruit loops and those sugary starch sugary carbs are beneficial for your health they'll make you lose weight and get healthier what is going on why is there a correlation there uh no but i think since to eat breakfast you have to get up early in the morning. And if you get up early in the morning, then it makes a sense on your health because you will be doing some exercises or something. Yes, partly, maybe, maybe. Anything else people can come up with? Well, it may depend whom you fed. If you fed really, really hungry people, then of course their health will improve. What is a starting point? If you fed really healthy people, maybe it won't affect so much. Maybe they go over overboard and you know again a clue raj yeah we see in our own neighborhood since you and i live in the same neighborhood a lot of homeless people do you think they wake up in the morning and have those lovely fruit loops with milk probably not not. Probably not. What about the janitor, the people, the actual salt of the earth, the people who are actually keeping this world going, your mechanic, your driver, your janitor, your gardener, your construction worker. Do you think they actually live here in Silicon Valley or can afford to? No. They all commute. They commute long distances to come here. When do you think they leave home to be here at work? Early. Very, very early in the morning. Do you think that these poor people who are really the salt of the earth the real hard-working people get any chance whatsoever to have breakfast a decent breakfast they grab what they can and they run to get into their car and start or their commuting vehicles commutes and trains and start coming to work, right? There is, the confounding factor is of people who are poorer, who cannot in this country, at least, afford good nutrition. You probably know that people, you go further from the city, you end up with what are called food deserts. You literally find no good grocery store with healthy food there. All you find are the 7-Elevens and the overpriced places where it is not food. It is processed junk that they live on. Who, by and large, can afford all of these expensive seals the well-off reasonably well-off right who have time who have leisure who come home after the 20-minute commute and go go for a walk or a jog or like you and me raj take our dog for a walk right so what do you expect? This is also the popular thing. I mean, it buys those fruit cereals and whatever, because it's affordable. It's available in the groceries and we can afford it. So therefore, the confounding factor is that we are healthier than the people who work very hard, barely get good food at all. We are generally healthier. And these cereals, this junk, sugary, starchy junk is a factor that is actually screwing our health, not improving it, as common sense would tell any scientist. Isn't it but nonetheless it manifests itself as though there's a correlation between having that and the and health right that the people so the observed data was that people who have good breakfast tend to be healthier, slimmer, right? But they just happen to be more affluent people. They are not people who are, you know, just struggling to keep alive, commuting long distances and working hard. They are not the people who are, you know, living in the bushes behind your house. And that's the difference. using the same argument now explain what happened to that hormone replacement therapy why is it that there's observed data that hormone people who are taking hormone replacement tend to have healthier hearts they're went off they went off. They're went off. It's a discretionary, it's an optional procedure, right? Most health insurances won't cover it, right? Or you have to buy a pretty good insurance to get coverage for it in the United States. HRT is the privilege of the settled people, well-off people. You go, you don't have a health insurance or you have a crappy health insurance, go try asking, trying to get a hormone therapy. You won't get it, right? But being, I mean, well-off, does it mean their heart is also healthy? Or is that? Yeah, it does. See, what has happened is, no, it doesn't. But the paradoxical thing is, they are more well-off people amongst the healthier because in this country you need leisure to exercise even if you want to the poor people unfortunately have no leisure they wake up in the morning start commuting by the time they come home they're totally tired they have to sit and help the kids with the homework cook dinner whatever they can or get whatever food they can and they sleep. There is no leisure. So where's the time to improve your health? Other thing is the food they eat is hardly food. It is processed, very low grade, very unhealthy food, because that's all they can afford. Try going to McDonald's every day in America. In India, I know McDonald's is a prestige thing. You dress up well and wear a tie and go to McDonald's. I think in India, it's kind of reverse. It's reverse now, is it? Yeah, yeah. I mean, if you're only wealthy, then you go have junk food. Oh, yeah, that is right. you wear a tie and be healthy wear fancy clothes designer clothes and go designer jeans and go to mcdonald's or court and so forth in the u.s is the reverse the healthy people go to whole food right and buy organic locally grown food right the unhealthy the the rest of us go to whatever grocery we can find, whatever food we can find. And America is notorious for the so-called food deserts. The vast tracts of America actually has no healthy food at all available. There's no grocery store at all. So they live on junk food. McDonald's are everywhere. And I don't want to single out McDonald's, all of these, Taco Bell or whatever it is. Yeah. Back, breakfast burritos and this and that are everywhere. You go to 7-Eleven, you'll get a preservative ridden, you know, some junk or sugary junk, Slurpees. And people need energy to just go to work. They don't realize that those are just empty calories. They all have vitamin deficiencies. They have severe deficiencies. They are people, America is the land where homelessness is at an epidemic level at this moment. They use disparity between the rich and the poor. So in other words, we are not talking about American system here. Unfortunately, I tend to be on the people call me left wing. So I shouldn't speak much. Confounding factors are there. Whenever you hear a study like that that doesn't make common sense, like good breakfast is better, will slim you down. And by the way, breakfast in America is just Froot Loops, right, or there's junk cereals. Take it with a huge grain of skepticism. Ask, what are the confounding factors? When you say balanced breakfast. Yes. You don't think healthy, you think balanced. Balanced breakfast, of course. Now, that's a great legal say, right? Because the balance means you also take a banana with it. Yeah, yeah. So now for the hormone replacement therapy, the same argument applies. And people have studied though, by the way. They found that this was true. The people who were taking hormone replacement generally were healthier, right? Well-off people. And so of course their heart wasn't. So the causation was the other way around. Do you see that? Here, there is a causation. Being healthy well-off is more likely to cause you to go take hormone replacement therapy. Do you see that, guys? Well, it turned out later on that it actually increases your chances of cancer. So I think hormone replacement therapy is more or less phased out. Yeah, especially in Marin County. Marin County. We also saw that breast cancer rates skyrocketed because they were all able to afford the hormone therapy. Hormone replacement, yes. They had a concrete population that they could prove they had this unfortunate effect. Yes, so Kate has mentioned the story for the rest of your remote I'll mention. There is a county here called the Marin County. It is like, you know, it's it is like you know it's the destination you know you have made it in life when you live in marine county and if you don't live in main county you have ways to go right so those people are all well off very rich very well settled and it turned out that they had a pretty high usage of hormone replacement therapy usage of hormone replacement therapy. And there was a very high incidence of breast cancer. Almost it became the epicenter of cancer in the Bay Area. And a lot of research has been done. And now of course, HRT is in disrepute. You don't do that unless you absolutely need it, right? So anyway, guys, these are stories to bring home certain points the hardest lesson the lesson these are hard lessons guys these are simple in the data science you will learn a lot of things very sophisticated things but i wanted to take some time out to get your grounding in statistics some of the greatest people in this field data scientists like stigler have pointed out that the human mind seems incapable of grasping it. When you explain it like that, they will all say yes, yes. But after a little while, we'll all go and make the same mistakes. So if you want to help yourself, instill into your mind that regression towards the mean often explains many things to which people give a causative explanation. the mean often explains many things to which people give a causative explanation. Also, correlation is not causation. We know that. That's a clich. But then there are gradations to it. Right? So, for example, if a guy says, I really studied hard and my grades came out, I got an A grade. You cannot say that correlation is not causation just because you you studied and the likes of you studied it doesn't mean it was not the reason you got a it may be the reason sometimes there may be a possible causation causations express as correlation but correlation does not prove causation that's a way to do that. Then there may be an underlying cause that's causing it, both of these things, correlations to happen. Or there may be confounding factors. Confounding factors are so prevalent. Most studies that you hear about health and nutrition, consider it with a pillar of salt, generally. consider it with a pillar of salt, generally. Just take the studies of five years ago and the study of today, and one would contradict the other. They would go in opposite directions. It's a fact quite often. So not always. I mean, you can't disparage your entire field, but a lot of it. Why? Because it's very hard. Human beings are complex. There are a lot of confounding factors, and it's hard to account for all the confounding factors. So all of that being there, now we will get down to brass tacks. It's nine o'clock. Today, I plan to have an extended session, guys. Are we all willing to go a little bit more till 10.30? Half an hour more? I'm okay. Okay. All right, guys. So we have reached a place at which we'll bring it down to statistics. So suppose you have some data. So we will use notation now. Let me just call it super fast. Or let's use some funny words a hypersonic flight flight over the statistical land the statistical land. Imagine that you are, well, the hypersonics are not yet there. Let's say supersonic. You are in, what was that airplane called that did supersonic flight from here to London? It was the Concorde. Concorde, Concorde. So we are on a Concorde and we are flying over the statistical land right, obviously, you can only get a very, very high level view of what it is. Srinivasan Parthasarathy, So in this view, but we'll still grasp a lot if you sort of pay attention let's just say that there is data so i'll use the symbol always for data, it is conventional to use this symbol d this do you notice this fancy scripted d scripted or calligraphic d this is uh quite common many textbooks use this and i will follow this convention d is for data set what is a data set a data set is a data set? A data set is a collection of datum by data instances. Are we together? Let's take some simple data, for example, consider in practical terms, height of sample of people. I use the word sample, what does sample mean? Whenever you use the word sample, you're acknowledging that you're you're not looking at the height of all the people in the world that's somewhat impractical right so if you take a measuring stick and go around the world measuring people's heights you won't succeed while you are still measuring the heights some people will die some new ones will be born and in some dangerous places you might get killed right so anyway i'm making it a fun but the point is it's never practical so not not ever quite often it's not practical quite often it is not practical to measure an entire population. When you cannot do that, you really can't do that easily. Sometimes it's just not possible to begin with. So, for example, if I ask you that, let's say that you have a certain topography, and I ask you how much iron is there in the different rocks in this region? What is the average amount of iron, right? Or what's the iron for every square meter or cubic meter of rock or so forth? It's not practical to basically dig up all the rocks, pass it through your scientific instrument, measure the iron, and then somehow restore the rocks you have destroyed you can't till the whole earth so it is not you you essentially have to practically take some samples right so samples are subsets of the population subsets of the population. So now samples are subsets. We understand subsets. They are parts of the, in simple language, they are parts of the population. Once you take the parts of the population, now you go measure. So you happen to pick, let's say, take a population. You took about 30 students 30 people you measured their heights can you draw some conclusion about the human the entire human population what is the risk here the sample of a sample says say that again yeah and uh hurry i am saying that the size was too low so what is right size you have seven and a half billion human beings on earth what would be the right size ample size uh to be true it should be basically the representation of the whole seven and of people coming down to let's say how it is a with heterogeneous and every subset of every kind of guy how many types of subsets you can make you're getting into this whole thing of how to sample in such a way that the sample is representative of the whole yeah so it's a good that is a question so that speaks to an important topic, bias in samples. Bias in a sample is when the sample is not representative of the whole population. Why does it happen? For example, if you're not careful, it happens all the time. You're looking for people, you might just pick colleagues in your office, measure their heights and come to the conclusion that most people are their heights are between five and a half five feet three inches to well if you're in software you don't often get very tall people but broadly speaking six foot three inches or something like that right you might miss the fact that there are children in the world who are tiny tots, isn't it? So you got wrong, even the range of values. So bias is there in the sample. How do you create representative samples? And there are a lot of theories or methods creating stratified sampling. You go to every, you know that people are divided by race, certain races at all certain or not, you go measure by race, then you get into complication because then comes anthropologists who tell racism, ethical, and literally a racist concept. It has no scientific basis. So then you scratch your head and say, What do I do now? So you go to different geographical regions and start measuring, taking some people from there. Right? You can try different things stratified sampling you can do but it's still very hard but even if you could go i'm going to make a statement even if you could get a truly un a biased sample your results will still be can be wrong and in fact are guaranteed to be wrong for certain key statistics so think of the statistics that you learned about so given a sample made up of elements let's say x1 x2 xn all of whom take so you often call them random variable like x is a random variable height for example in the language of statistics you would say height is a random variable it can take various values right so you take certain values you go get a sample what are the you if i ask you to describe the sample you cannot you cannot go on enumerating that one guy was this tall, another guy was this tall, another guy was this tall, people will get bored. They say, okay, so what have you learned? When we try to extract the essence of the data, we tend to use something, a language, we create something called a statistic. a language, we create something called a statistic. The statistic is a measurable, a quantifiable or quantified way to describe the sample data. The data, I'll just use the word data. Are we together? So what are the examples of statistics? One statistic could be range. Min, max. See, what is the shortest person? That is a statistic, singular. Max is another statistic. Range is another statistic from here to there, isn't it? So each one of them conveys some statistic you gather it becomes descriptive statistics of the data so now you notice that it is a plural and now you know why you end the word with the s statistics means there are many different statistics that you put together to get a sense of the data in a quantitative manner. Then we are familiar with some if you're not tell me mean slash average people often use this subtleties involved here, but actually, let me avoid the word. And mode, mode is the most common median. If you sort all the values, the middle value, median, you may remember something called standard deviation. So let's go through each of the statistics and see if we understand what it means. What would the min be? Like, suppose I give you the height as 3, 7, 9, 11, 4, 2, 8. Let's say that this is your data set. D is this. Can we tell what the min is? What is the min statistic? Please speak up, guys, remote. Two. Two is the min. What is the max? 11. 11. 11. What is the range? Two to 11. Two to 11, isn't it? What is the median? 2 to 11. 2 to 11, isn't it? What is the median? And let me throw in just for good measure, one more number, 3, 7, and sneak in a 7 at the end also. What is the median? 7. So if you put these numbers in a row two three um whatever it is four seven seven seven eight nine so the middle guy looks to be somewhere here right this is your middle so let's say median seven what about mode what is mode seven sorry three times it got repeated so it got repeated three times so this is the mode this is it now what is the average what is the mean mean is you add up all of these numbers summation of Xi over whatever number is the average. So now, what is the standard deviation? Standard deviation is represented by X-I. It is equal to X-I. So mean is represented by mu. So you notice that once again, we are following the convention that observables are roman letters like xi measurements of height how many samples did how many points are there cardinality of your data set is a number n but mu you can't go and pick mu off the table mean of the table it's a it's it's a derived quantity isn't it so we use greek letters for it mu and sigma mu is the mean sigma is defined as if you remember what is it defined as guys is this fair Is this fair? Yeah. Sigma squared is this, right? The standard, this is called variance. Variance is, people in machine learning tend to use the word variance more than standard deviation. Variance is square of standard deviation. Deviation, right? Standard deviation. So each of these is a statistic and they all help describe the data set, isn't it? Now, there is more to it. It turns out that there is a concept in, we can generalize beyond mean and variance to go to the next level, which is the concept of moments. Moments. But before I do that, I will talk about something. So suppose data. There is one thing it's called the z value or standardization or normalization people offer the diatization normalization depending upon who you talk to they'll use these words interchangeably and sometimes they'll say one is different from the other but i will call it z value is defined as xi minus mu over sigma. Now, what in the world it is? Let's look at this. Let's xi. Let's do that. What is the mean? By the way, could one of you please quickly calculate the mean? 26, 37, 41, 41, 43, 51, 58. 58, 1, 2, 3, 4, 5, 6, 7, 8, 9. 58 divided by 9. 6.4. 6.4. So guys, when I subtract from the value, a value of 6.4, what am I, the mean, what am I telling? How far above or below the mean it is? Isn't it? This. And when I scale it with the sigma, sigma is a measure of how spread out the data is. That is why it's called standard of variance how spread out the values are like if you have values that are spread out here like this imagine a data set like this versus a data set which is like this right all the individual elements are tightly in in it you say low variance high variance or high standard deviation are we together guys because data is literally spread out the same data is so for example if it was not seven but seven million or things like that then the range of the data is large right the and the spread is large and spread of the core part of the data is large, right? And the spread is large and spread of the core part of the data is a measure of variance, very hand-wavingly. So if you scale the data by variance, you're pulling everything down to essentially a similar scale. And then if you look at only how far above or below the average it is, you get something called a z value. So we learned of standardization of data. This is an important concept. Standardization is standard or normal, etc. I won't use the word. z i is equal to xi minus mu over sigma. Now, one of the things we do, you'll realize that machine learning, it is never a good idea to work with raw data. Very, very often. I mean, you have to at least consider, should I standardize the data? You can't ignore it. Maybe you don't. Maybe it doesn't require it. But it has to be a conscious choice. You have to think about it. It is like you wake up in the morning and you brush your teeth. A data scientist sees the data and first thing, brushing the teeth is equivalent to standardizing the data. Are we together, guys? So go ahead. So the ZI is a list of elements. Exactly. So it has as many elements as there are the sample size so each value is replaced by its z value but then you might have to take it oh yeah perfectly like 777 all the three sevens will become the same z value whatever it is so you eliminate those values no no you keep them all you're doing so let me illustrate this guys when i do x1 x2 xn we are we are not changing the cardinality of the data set we are just creating a denormalized let's say standardized which every value z1 z2 all of them are replaced you create another data set, which is the standardized version of this, comprised of the z's. Are we together? So that is an important step. Once you do that, it turns out that now we will talk about something called the expectation value. Expectation value of a variable is a little bit sophisticated thing but i will today keep it for you i will deliberately slightly simplify it i can give you the more formal definition the more formal definition would involve uh bringing in this probability right so let me give you a formal aside but ignore it for the time being probability distribution so what is the probability for a value xi to be possible right so you see a value xi you see a guy who is seven foot four inch. He's very unlikely to be that, isn't it? The probability that human beings are that tall is relatively low compared to five foot eight for men and five foot six for women. So there is a probability associated with it. So if you take a number and you subtract the mean just to see how far it is deviation from this mean and then you multiply it by the probability of a xi right so i will remove the i because it is generally like it's a continuous variable dx dx in the case of continuous variable this is defined as the expectation value of x right and sort of the this is the expectation value right this is the mean value of this number but we will ignore this and for the time being forget about the p's and so on and so forth so what we will do is and by the way this e is written with a double e typically it's called the expectation value value of x right x being the height of people so expectation value is very intuitively the mu right if you take off intuitively the the e of x as if one error you have done you have put a minus mu it shouldn't be inside the integral uh this integral yeah the mu will come out of its own no the mu is the x i mean it's the expected value your oh xp x integral is the oh yes yes yes you're right absolutely correct yes x px that will so intuitively when you're just looking at x px this will become the mean it will be it will result to the mean but now let us define another concept which i will call standardized moment chanda thanks for pointing that out. Dice moment. So for that, we will create another concept called standardized mean. What is the standardized mean or the moment about the mean? It is called the moment about the mean so now that we have mu what you can do is this is defined as something very interesting it is moments about the mean of degree k okay mu k uh i don't know we can make it a subscript or superscript it is the expectation value of x minus mu to the power k by the way expectation value you often put in square bracket guys the e with the square bracket this is part of the language let me just emphasize this you will often find this notation and a square bracket what it means is that go find the average of this thing the squares or the kth power not squares the kth power right now you can work out what it will mean for k is equal to 1 k is equal to 2. you can convince yourself that the moment about the mean for degree one would be when k is equal to one, what would it be? For k, so for example, for k is equal to one, what will it be? Mu one would be expectation value of x minus mu. And that will be expectation value of, it turns out out expectation value of x minus expectation value of mu which is mu because mu doesn't change and this is mu and so what will it be zero right so moment about the mean the first the first moment is zero right now you can do the second moment, the third moment, and so on and so forth. So now comes... Sorry, as if... What is a moment again? I didn't grasp it properly. Moment is defined as this mathematically. But what is it? I mean... I'm coming to the intuition. That's the whole point. Of course we come up with some very abstract thing. And you scratch your head and what are these guys up to? Why are they creating these weird expressions? So we'll see that in a moment. See, in reality, it works backward. People have intuition, and from there, they abstract out some mathematics. But we'll start here, in the interest of time, with the thing. Likewise, in a way, the standard, the kth degree, I will say sigma of the kth degree is given by some expression. And by the way, the same thing in continuous variable if you want to write minus infinity to infinity, x minus mu k right bx right this is the continuous and ignore the infinite part of it but you can see that this is essentially it if x has a certain probability and so on and so forth associated with it you can ignore it this is the expectation value of x minus mu uh let's say i would say square this to the uh okay how should i write it um this to the power two it is the square root okay weird thing square root to the power k, weird. Take this square, go to the power k. So we are going to now say that the real moment, and now comes this weird expression, the actual kth degree moment for which, I wish I'll notice the big tilde on top of it. And this is sort of the literature people often use. The kth moment, standardized moment, is defined as the ratio of the kth moment about the mean, standardized moment about the mean, and the standard deviation around the mean of the kth Sigma K right, this is what it comes to so let's see what it means in real life. R. Vijay Mohanaraman, Ph.D.: For case equal to one. R. Vijay Mohanaraman, Ph.D.: You know that the numerator what will happen, you are looking at expectation value of X minus new. R. Vijay Mohanaraman, Ph.D.: Right. value of x minus mu right itself divided by this whole square root business to the power one expectation value of x minus mu square to the power one it doesn't matter because this will go to zero right so what is the answer zero do you agree because why is this because we just convinced ourselves this is zero e this is the same as e x minus mu and this is mu so mu minus mu is equal to zero so denominator doesn't matter it goes to zero isn't it so you say first standardized moment of the data therefore would be this what about k is equal to 2 do you want to play that out and see what happens it is let's again plug it into the equation x minus mu square right expectation value and bottom is what square root of expectation value x minus mu square and to the power square so that this square will kill out the square root right and this will be equal to one because numerator and denominator are the same isn't it right so you say that the standardized moment the the second degree moment of the data will be like that things get interesting when you go to the third and the fourth degree. Raja Ayyanar? And that answers your question Raj what in the world is this whole business and why do we consider this weird mathematical concept seriously so let's see what happens with the third degree. Raja Ayyanar? You have expectation value of X minus new square. of x minus mu square uh no cube cube right remember third power divided by what in the world are we dividing it by expectation value of x minus mu square square root well square root to the power three right and you can convince yourself that this is what what is this? What is the expectation value of X minus mu? This is sigma, isn't it? The standard deviation. Right. So basically, you're putting the standard deviation here. So you're saying standard deviation cube expectation value of X minus mu cube over sigma cube, minus mu cube over sigma cube, which is the same as expectation value of x minus mu over sigma cube. And do you notice that our z came in? Z value came in, right? So what we are basically saying in simpler terms is it is nothing but expectation value of z cube of the data standardized values cubed of the data right that is the third moment this actually has an interpretation it is called the skewness it measures the skewness in the data in the data as if don't you think there is an n missing no there is no n missing expectation value by definition is 1 over n right this is expectation value of c what is the expectation value of this x 1 minus mu squared no no when you convert it into that sigma cube i thought there is an n missing no no that's what i'm explaining why it is not missing so you have x n minus mu squared the n of these right and you divide it when you do the expectation value you divide it by 1 over n right this is your expectation value or average in a simple common sense term right so there's already a 1 over n factor built in and this is by definition sigma this is how you define literally sigma square s right if you look i mean square root of this a square root of this which is this term here is and then it will be sigma right so this is it so what we are saying is the third order now you can generalize from this to the fourth order right k is equal to four i won't go through the rest of the derivation you know that this would be expectation value of x minus mu over sigma to the fourth power right or simple terms are big e big e z to the fourth power so you see the elegance if you use z as your notation right you're just looking at powers of z the the elegance if you use z as your notation right you're just looking at powers of z the the standardized moments are powers of z right that is why you thought the z yes you get the yeah and its expectation values are the moments the standardized moments now say that again Standardized moments. Now, say that again. It turns out there is a meaning to this one also, kurtosis. And what kurtosis, so I'll explain to you what skew and kurtosis are. What do they measure? The second moment and the third moment, what do they measure? The interpretation is actually quite in quite obvious once you see it so sometimes data shows itself as let's say look at the three data sets along x-axis one data rises up and is like this. Right? Another data is like this. And another data is like this. A, B, C. What can you, how does b differ from a and c? B is normal. It's not symmetric. Normal. This is symmetric. You don't know whether it is normal. There are many curves that look like this that are symmetrical, right? By the way, it's one of the fallacies to believe that every symmetric distribution is normal. It isn't actually. It could be log normal. It could be a Laplacian. There's a whole family. It could be a beta function. There's a whole family of transcendental and exponential functions which can all mimic a symmetric distribution. So never just assume it's a bell curve. So never just assume it's a bell curve. In fact, there is a very great math professor who has written a classic paper, lovely reading. He asked the question, are normal distributions normal? The reason bell curve is considered normal is because we think we find it everywhere. Heights are normally distributed, et cetera, et cetera. And generally you ascribe something called a center limit theorem, which I'll explain right now, as the causation why bell curves are everywhere. But he asked this question, are they really everywhere? And he makes very persuasive arguments to claim that actually many other distributions are very often masquerading or masking themselves as bell curves in real life. So it is not as you think. So let's use the word symmetric. Given a symmetric distribution, what can you tell about A versus C? How do they differ? They're stressed on one side. That's right. So I'll give you a mnemonic to remember. Whenever you see this, think of a duck. You know, we love ducks and cows. Think of a duck. Think of this as the beak of a duck. And give it an eye. In A, duck A is looking towards right or left. duck a is looking towards right or left guys speak up which way is a looking the duck a right the duck is looking towards the right what positive direction this is negative direction or positive direction what about this the middle guy this is a hard duck it's not looking anywhere isn't it it's not looking anywhere, isn't it? It's probably looking at you, right? What about the duck C? It's looking left. Looking left. Left or negative direction. Would you agree with this? Simple, right? Convention being this is positive, or negative direction. Would you agree with this? Simple, right? Convention being this is positive, this is negative in a coordinate system. So you say that it turns out magically that this curve you say has positive or right Q. or right skew. And this guy has negative or left, his words are used interchangeably, skew. And this has no skew it's symmetric by definition symmetry is the opposite of skew right skew breaks symmetry you don't have symmetry are we making sense and it turns out that your k is equal to 3, the third standardized moment is literally the mathematical expression that will quantify how much the skew is. Lovely, isn't it? So all you have to do is just k is equal to 3. In that equation. That is it. Just take the z values and raise it to the third power and find its expectation value you will get this cube are we together now what about the fourth power if third one has some interpretation maybe the fourth one also has some interpretation it turns out the fourth one also has a name. It is called kurtosis. What in the world does kurtosis measure? It turns out what it measured, people had a pretty strong debate about. There were many interpretations of what the fourth moment meant, fourth standardized moment, fourth standardized moment meant intuitively. What in the world is it measuring? Remember, it's a statistic. What exactly is the meaning of this statistic? So there were many interpretations, but I think the final word came around 2014, as recently, when somebody pointed out a very simple intuition he said that see if you take the fourth power of anything so suppose ZI to the fourth power, ZJ to the fourth power, and Zn to the fourth power. Some of these numbers are bigger than the other. Now, in your mind, and these are all deviations from the normal, from the mean, isn't it? So what will happen for a value that is close to the mean and inline our data point relatively close to the mean its power could be let's say that it is three units away from the mean. So, three to the power four and let's say that another unit is an outlier. Outlier means it is 100 units away from the mean right. So, 100 to the power 4 now guys i try to right and by the way so okay so there is one more catch to it i said z value so z values won't take three well so let me take it this way i apologize z values what happens is they take values from minus three to plus three plus threes are outliers right most values are close to zero why because you did xi minus mu over sigma you scaled it the data right z i sorry i should have been careful uh so suppose the mean is 6.4 look at your data and did anyone compute the standard deviation, guys, in the data set that we considered a little bit ago? You can find the standard deviation is what, approximately 3? Could somebody please plug it in and check in the computer? If I have to guesstimate, I would say, let's say the standard deviation is 3. So for each of the values, if you look at this, let's say the standard deviation is 3, right? So for each of the values, if you look at this, for this 7 minus 6.4, which is the mean, divided by 3, right? Is 0.6 divided by 3 is 0.2 right this would be uh 3.6 point 3.4 divided by 3 is 1.1 do you see that these are all small values isn't it these values are small but if you have an outlier its value will be like more like three four extreme outliers 2.5 those are outliers because outliers and this is a fact take it as a fact that most inliners have values in this interval close to zero right fractional values so what will happen when you take a fractional number even 0.9 and you take the fourth power of it let's take that this is 0. let's say 9 to the fourth power and this happens to be let's say 3 to the fourth power and this happens to be 0.1 to the fourth power right you realize that this will practically disappear, right? And this will become 0.something like 6, 4, isn't it? Approximately 6, 5 or something like that. And this 3 to the power of 4. 3 squared is 9. 9 squared is 81, right? So what is happening? This value overwhelms all the other values. You might as well ignore the smaller values and you may just look at the outlier values. Look mostly at outliers, looks mostly at outlier looks mostly at outliers so if there are no outliers the kurtosis will be small if they are big outliers kurtosis will be big right some people call it the heavy tail effect like if the tail is heavy lots of outliers are there big heavy tail right heavy tail some people call it heavy tail effect like if the tail is heavy lots of outliers are there big heavy tail right heavy some people call it heavy tail means there are lots of outliers sitting there then that is measured by high kurtosis high kurtosis tells you how significantly outliers are present in your data and as you know we live in the world of long tail distributions. Like for example, most books don't sell much but some books go on selling gazillions of copies. Right. So this is called the cartosis. Yeah, heavy tail. many descriptive statistics today. And this is the only class in statistics that we'll have. We will use this now to actually make progress in the next 45 minutes. So guys, from a perspective, the core idea is start with the Z value. It is the core, standardize the data, right? You wake up in the morning, brush your teeth, look at the data and you go standardize it. Think of it like that. You must do it. Most of the time you should do it. Sometimes you need not do it. Sometimes it may even be counterproductive, but that's rare. But this is it. Then there is a concept of expectation value. Expectation value is essentially averaging that power for discrete numbers, for continuous, you have to bring in a distribution. We'll forget about it. Now, we realize that there is this concept, mu k and sigma k, but ultimately what it comes to is the ratio. The ratio is mu k over sigma k, a little bit complicated mathematical expressions but basically in simplest terms the the kth moment standardized moment is expectation value of the z k right that is one easy way to remember it right the average of the kth powers so ask if you said k is equal to four is uh kurtosis skew skewness skew is k is equal to 3 and kurtosis is k is equal to 4 k is equal to 3 a third moment so now you see the usefulness of the concept of moments Wait, a third moment. So now you see the usefulness of the concept of moments, isn't it? So each moment describes something. Now what the fifth moment describes, I have no idea. But if you figure out the interpretation, let me know. But it is a descriptive, I can't put every obvious intuition on it. But I'm sure people have tried and I may just be ignorant. I may just not be knowing about it. So this is statistics, guys. Now comes a final result in statistic that we'll use, and it's about the only last piece of statistic. It is a profound result. It's a crown jewel of statistics. It's called the center limit theorem. Center limit theorem. So guys, I'll do this and then we'll take a break and then we'll start with the machine learning proper. The center limit theorem says that for me to explain the center limit theorem, I need to create the concept of a probability distribution. There's a concept called probability distribution or probability density let's say density distribution density is implicit wow that's a big big word but i call it one bucket of sand right so suppose you have one bucket of sand you spread it like this, you you you put it on the X axis right whatever values your random variables can take, for example, height. Well, cannot be zero for human beings, they say the height starts at I don't know one foot for people babies. for people babies or and goes up to what eight foot who knows something like this this is your age so then the more the more people you find at a given point at a given height value let's say five feet five and a half feet the more grains of sand you put there so what happens is as you keep distributing the sand and remember you have only one bucket of sand to put so what you will so here is one way to do it you first create the histogram you know what a frequency plot is every time you find a human being put a value there and then create a frequency plot and then make sure that your sample size is very very large so you get some distribution like this now divided by the number of people so suppose here you had access like okay at this height i found nine million people out of let's say um 20 mil like 200 like i don't know 20 million i'm just taking some random numbers 25 million population sample size uh n is equal to this so one rough way that people do is when sample sizes are large you can divide this value each of these height things divide by height things, divide by n. When you divide by n, you scale down all of them, right? So each of them becomes a fraction, right? And so what happens is that you end up with something called a probability density distribution. It's as simple as that, right? So you end up with some distribution and these values will never go up to one. In fact, the area under it will be one. The area px dx will be one, right? Or if you look at discrete discrete values the summation of all of these p x i's will be one based on discrete or continuous so which makes sense right so let's say that people come in only two sizes a three foot and six foot let's take an example a three foot people there are 20 of them six foot people there are them. Right? So would it be fair to say that you draw a histogram and 30 foot is 20 and this is 10. 3 feet, 6 feet. These are only two values. Right? 20, 10. If I divide it by the total, what will I get? I will get, what is the total? N is equal to 30. Two-third and one-third, right? Three-fifth, one-third. Would it be fair to say that these numbers represent the probability, if you randomly picked a human being, two-third probability that it will be three-fif will be three feet isn't it and one-third the probability that the person would be six foot would that be fair to say that right it would be fair and so what you have done is whenever you convert a histogram you normalize it by dividing by n, you get a probability. You get probabilities. In continuous form, you get explicit. I mean, in discrete form, you get explicit values. Now generalize it to continuous, right? So you get probability density. So now here is one intuition that I have. The fact that the area under the curve or the fact that they all need to add up to one, I look at it this way. You get one bucket of sand. You need to distribute it fairly to be representative of the data. So children make little sand piles, isn't it? You made a sand pile and a sand pile, but your total sand pile has to be the one unit of one bucket of sand right likewise height of people in reality is not just these two values is spread over a space whatever the min max ranges you would agree that the area under this the probability probability of finding a particular height excite if I integrate over all of the xi values right this of course has to be one right is because I have one unit sand I'm just spreading it around so if you think of probability density is a way one bucket of sand is spread that's actually a powerful intuition and when we go deep into machine learning, and we are talking about such things as Wasserstein distance and Wasserstein GAN, actually, those of you who attended my ML400 must be familiar with these words I used. They all derive their intuition from this. In fact, Wasserstein distance is if i have a pile of sand that looks like this and a pile of sand that looks like differently how how much material do i have to shift to go from a to b it is called the optimal transport problem there are many ways i can do it the bad ways would be take all the sand first put it in one bucket in one giant pile and then spread it to look like this bad idea because this shape a and b they approximately look alike you want to just move in the minimum amount of sand to make a transition into b that's sort of the optimal it's a big theory by the way one of the hottest topics these days It's a big theory by the way, it's one of the hottest topics these days. Optimal transport and so Wasserstein distance measures how different are two distributions right and so forth. So we'll keep that for later but at this moment we do that probability distribution. So now we come to our crown jewel for today which is the center limit theorem and for statistics the moment you see the beauty and power of it, it will completely astound you, right? So let me bring that, and then we'll talk about biased and unbiased estimators. So there's a very interesting thing. No matter the distribution of your data, whether it is like this, whether it is symmetric, whether it is like this, right? Whether it is like this whether it is symmetric whether it is like this right whether it is like this doesn't matter whichever way you look so this is your underlying distribution of the data whatever it is for example if you look at the income of people in your company it looks like this by the way most of us are common, ordinary people. We earn within a range. And then there are the rich executives, right, or the upper management, which earns somewhere here in the US at least. So well, this, by the way, is a fact. This is well studied in economics. So there are many distributions of data. But here is something. You take a sample of people, any sample, and we will start with the average, the mean. So you take sample S1, it will have a mean mu1. You take sample S2, it will have a mu mean mu2 you take sample s3 it will have a mean s3 now you realize that each of your samples can be pretty biased right for example so let's take one curve any one curve i'll just deliberately take the curve that skewed that is uh do you see the skew maybe i'll make this queue even more pronounced that is like this okay you agree that this doesn't look symmetric i'll make it even more unsymmetric how about this right and this hill i'll make it smooth i'm trying to make it look different on the two sides would you agree that they look different on the two sides or did i end up making something symmetric hopefully not right so uh now or maybe let's make it pronouncedly like this okay how about this this is very asymmetric the probability distribution of some random variable x height height of people what is the probability that people are of this height think of the histogram simply put samples are if that's probability distribution so basically if you took the whole population and you put measured their heights right they will look like they will look like a histogram similar to this up to a scale right that's one way of thinking about it right or in this particular case if you look at a very very very large company of employees right ibm or something like that but then their salary distribution let's say may look like this. Proprietary distribution, as I said, up to a scale, is essentially histogram. Now here's one interesting thing. You take some random people. They may have been, it turns out that by accident, the data is biased. You ended up going to upper management. You ended up on the wrong floor of the corporate building. And they are all sitting there there sipping their lattes right and preparing for their champagnes in the evening or while they're discussing some i don't know big things i'm joking right and then by chance another time you ended up on a second floor where all the minions are there like us drones working at it and then some somebody goes and gets a sample that is spread out like this so you realize that if you take the mean the means will not be true means because you know that the samples are biased or you put in no effort to make unbiased samples. Are we together? Just go take random samples. And if you just by happen chance, there will always be some bias in the samples. Would you agree guys? Remotely, those of you who are there, you would agree that there'll be some bias in the samples. So if you compute the means, you don't really expect the means to be correct representation of the entire population isn't it the means wouldn't represent the whole population would it guys no no it wouldn't you say because each of the means is biased because you expect the data underneath to be biased. But here comes a beautiful, beautiful fact of statistics, the center limit theorem. It says no matter what the underlying distribution is, I'll say this because this statement needs to be spelled out, no matter how the underlying distribution, probability distribution, if we write the word probability distribution looks. Can I use a more intuitive word, data distribution? How the data is distributed? Distribution looks. All the mu i's so you know your mu 1 mu 2 mu thousand right if you plot the mean if you just plot the mu's, you will notice something absolutely beautiful emerge. Unbelievably, they will all have a beautiful, the mu's will have a beautiful bell curve distribution. This is it. All the mu's will collectively, well well the formal word is normal distribution now think for a moment how amazing it is you can start with all sorts of weird distributions but if you keep sampling data from the distribution or take little samples of the data of the population those mus will form a bell curve and the next amazing fact is that the peak now in a bell curve what happens the mean median mode are the same mean median mode are the same. It's a very interesting distribution, isn't it? The most frequent, the median, and the average are the same. This value will actually tend to the population true mean. Isn't that amazing? Yeah. The effective mean of the means will be the true mean of the population. However crazy the distribution. Now, what is the intuition behind it? See, each sample has a bias. It introduces an error in the mean, right? But those errors tend to cancel each other out. And so you end up with a mu. The mean of means is close to the population mean. That is the center limit theorem. Now I'll pause here because I just introduced you to something called an unbiased estimator if you go through this process mu mean we say is an unbiased estimator in in other words the the mu of mu the average of the samples will tend to be pretty good representation of the population mean. Are we together? So this is estimator means estimate. A mean is an estimation. Think of it as a statistic. So unbiased statistic. Are we together? Because it will tell you the right answer. But then why are we making such a big deal about this mean and this unbiasedness? It turns out it's not true for other things. For example, if you look at variance, there is a problem with variance. The problem with variance is that, let's say that the underlying distribution is whatever. Again, go to the same distribution do you realize that the variance of all of this is limited right the you know variance measures the variability but if every time you take a small sample, its variability will be less than that of the population. Isn't it? Almost always, the value of variance will be less than that of the population. This population variance will be greater than any of the sample variances. Isn't it? We're assuming that we're not taking random samples because no no but if you take random samples you are very unlikely to always hit the tail points with the sufficient population you're unlikely to hit the tail points you will hit some you'll pick up some points from the from in between somewhere right you're not likely to pick up all the tail points in such a way that the variance of the sample will be the same as the variance of the population so the point is the sample variances will always be smaller than the population variance so what do you say if they are always smaller then you can go about averaging the variances. But will they ever represent the true variance of the population? No, because each of the values is smaller than the real population variance. Guys, are we following me? The variance of the variance square of the standard deviation, or just look at the picture. If each of the standard deviation or just by pick just look at the picture if each of the variance is smaller than the population let's say that sigma one let's say square is less than the actual let me just call it uh population population sigma variance sigma 2 also is less than Sigma population squared so on and so forth so when I add all of them in average you would agree that this will still remain much smaller than the population variance it's not going to change right so what have we done samples samples will always underestimate the variance. Does this fact come through, guys? Right? And so what happens is, while the definition, so what happens is that, so now comes a fact, guys. When you take a sufficiently big sample or you take a sample of sample like you take the mean of samples irrespective mu will be unbiased the mean of sample will be reflective of population more or less up to error bar right but sigma square and therefore sigma standard deviation will be sample will always underestimate population variance, population sigma, isn't it? Sigma square of the population. That's quite an interesting fact, just looking, thinking about it it isn't it you say therefore that variance is a biased estimator this is this is a so this is now you understand why we say mean is unbiased when you look at samples because just looking at a good enough sample you get a good sense of the mean but looking at a sample you don't get a good sense of the variance do you see that right this is biased when you're looking at the sample so what happens is that for variance and therefore for standard deviation there is actually people have figured out and the mathematics the reasons are a bit mathematical we won't go into for a population for all data population let's say that you know you line up all of humanity together right then you know that there is no bias ultimately is the population so sigma population squared would be the average of the xi minus mu squared the average of them that makes sense isn't it oh i forgot my summation symbol one actually let me write it neatly that's because these are nouns so this makes sense guys right this is literally the definition as you learned in the school books trouble is in machine learning in data science most of the time we have only samples all right so for samples sigma sample square is and here is the thing you realize that it underestimates so instead of dividing by n what people do is they divide by n minus 1 now n minus 1 will be a smaller denominator means the value increases or decreases increases so what you do is when you're dealing with sample you just boost it a little bit you boost it a little bit and it turns out that this is just the right amount of boosting boosting so n goes to n minus one boosting to make sigma sample people say it's and make it unbiased close to unbiased unbiased right right or more or more representative or more representative of the population. So you're acknowledging that no matter what, when you take a sample, there are always things on this or that side of the sample quite often, right? So, I mean, of the sample in the population. So it's a biased estimator variance. You should remember that so these terms keep coming up. Biased and unbiased estimator, and so on and so forth. So we have covered a large statistical territory today, guys, I noticed it's 10 past 10, so I would like to finish it. Today is the only time we will do statistics and we are done. As I said, we were flying rather fast. We were in a Concorde, isn't it? And in a Concorde, we flew over the entire descriptive statistical land. And we found some remarkable things. Let's see what we learned today in a more formal sense we learned about where where did we start we learned of the concept of what is a statistic like when you say chemistry you don't say chemistries but when you study statistics it always come as a plural so now you know because a statistic is a measure a description of the data right we talked about population and sample a data set could be either the population or a sample of the population samples can be biased or unbiased right when it is unbiased is representative of the data the small samples are almost never representative of the data for the simple reason that how would you it's very hard to make like for example if you pick only two people to measure the average height of humanity are you likely to get a good sense of the humanity's height now right so take a large enough sample and try your try your level best to be as unbiased as you can in the sample. But more than that, people have realized that taking more samples is better. Take lots of samples, don't just take one sample. Take lots of samples because their center limit theorem is your friend. We talked about Z value or standardization of the data. We learned about once you have standardization, we understood what variance means, what mean means, what mode means. Variance is just literally the spread. When a basic example is when you have kids, or when the kid is sleeping, all the toys are in a pile low variance then the kid wakes up and toys are all over the room they all spread out high variance right this is it if you look at the x the coordinate along the coordinates along any one of the walls they're not all over the place right they're spread out that is variance of the walls, but they're not all over the place, right? They're spread out. That is variance of the data. So the Z value is pretty rude. And at the end of the day, there's a concept of moments, standardized moments, but the standardized moment is essentially your, comes from your Z value in simplified form.'s the powers of the z value first second third fourth the third is skewness what in the world is skewness it shows which way your distribution is bending right is it looking right if you think always think of your distributions as ducks which way is the duck looking the beak If the beak is going in the positive direction, it's right skewed. Or in the right direction, it's right skewed. If it is going in the left direction, it's left or negatively skewed. And if the duck is staring straight at you, it turns out that all this mathematical gymnastics that we did beautifully relates to our intuition of skew. It turns out it measures to what extent or which direction is the duck looking. If you want to know that, look at the third moment, third standardized moment. Then comes kurtosis, which is like how spread out outliers they are in the data. It is not about skew, but the outliers or the quantity of outliers there, or how heavy the tails are. That is the kurtosis. It's the fourth moment of the data. Then we learned about the fact, this remarkable thing in statistics, a crown jewel. And guys, the more you think about this center limit theorem, the more awestruck you would be at its sheer elegance and power. It shows its presence just about everywhere. Read about it, that's your homework. Learn more about it. We'll do a lab or so about it. You take, what it says is something absolutely remarkable. It says, however crazy your distribution You take what it says is something absolutely remarkable. It says, however crazy your distribution or however crazily you have put the sand, right? Spread out the sand and you can do it in multiple dimensions. But crazy looking sand castles you have built with that one bucket of sand doesn't matter. If you take lots of samples and you keep taking their mean, those mean values will form a bell curve, number one, and the mean of that bell curve would be the true mean of the population, irrespective of the distribution. Very, very insightful thing. Then, oh, by the way, I did not mention to you one remarkable, one extra thing about the skewness, and I would like to do that. See what happens is, look at this. Where is the mode? In a right skew, where is the mode? This is the mode, right? Where is the mean? Because it has a long tail, the mean is here. Isn't it? And where is the median value? Somewhere here. So in a right skew, mode is less than median, is less than median is less than mean right in this way in a left skew the opposite will be true mode is here let me use green colors mode is here the mean will be here it's symmetric The mean will be here. It's symmetric. Right? It is just the mirror symmetry of this. And this is the median. So mean will be greater than median is greater than mode. Oh, mode. No, hang on. What did I do wrong? No, no, no. Mean is less than, sorry, what silly thing I did. Mean is less than, is less than the mode, as you can see in this picture here. Right. So this is just a fact as I'm summarizing for today. Asif, also about the expression for covariance and correlation. We'll take it up to next time because we take it as part of the linear regression. We're intimately connected, so we'll do it next time. Today, I think. Would you guys be willing to stay another hour? No, no, no, of course not. Covariance and correlation, the mathematical thing, because that gets into linear regression. So regression and covariance correlation, the mathematics is next time. So the beautiful thing is you can center limit Kerem. Guys, please go study it. It's a crown jewel. economics i i know one economy in india there's this economist who has written quite a few books uh haricharan das or somebody india unbound if you have read those books so i think it was him or somebody else who said when he first learned of the center limit theorem in his mba he just rushed to the library because he couldn't believe that something like this could be true so that's all you require center limit so now the unbiased so mean we consider unbiased estimator because with sufficiently large sample size or with a sample of with a lot of sample sizes lots of samples is always better you have the power of center limit with you the estimates you'll get will be unbiased means your sample estimates will reflect your population estimates but not so for variance for reasons that we showed variances will always be less than the population variance. So one way to compensate is you put this n minus 1. See, guys, you may have wondered why in books of data science when you open it up, you find this n minus 1. So now you know why. It also nominates your difference between actual population versus sigma. Yeah, people use different symbols but i'm just using sigma sample and sigma population okay so with that guys uh we end today we uh i'll keep maybe 10 minutes for qa any questions guys was it all overwhelming did the concord go very fast or was it one of the quizzes uh no correlation we still have to wait for correlation causation the correlation and covariance all right guys um i don't know how many of you are still with me yeah as if why it's only n minus one why it can't be n minus 2 or n minus 3 i give that to you as a homework okay does it do anything have to do with degrees of freedom i'm not answering okay got it I said one question. Go ahead. Will the mean of the variance sample variance? Yeah. Population variance? No, no, it will always be less than that. If each of the variances is less than the population, so the mean of the variance will also be less than the population. That is why it is called a biased estimator right because variances samples never tell you about the correct variance and so you can correct it a little bit by changing the denominator by sort of shrinking the denominator a little bit to boost the value to boost the variance up a little bit it turns out that is just the right amount of it if you do n minus one are you being a reasonably good sample size huh let's start so why it is go ahead you know do we do n minus one to give leeway to the last sample that it will compensate nothing no there is not a last element it isn't like that it isn't like that the cause is not that but why don't you guys take that as a homework find out why n minus one why not uh why not n minus 100 or n minus whatever right why not something else y and minus one i'll leave that as a homework for you to figure out and asif is there any way to know like how much sample size is big enough from let's say i know the population size so uh jocular way of saying no sample size is big enough that but in real life you you work with whatever size you get see guys here's the thing when you deal with physical data engineering data often you have lots of data you have the luxury of taking large sample sizes but in domains like rare diseases sample sizes are like five right and you are supposed to infer something with five patients right you know that it's too small a sample but beggars can't be choosers or as in my school somebody used to say if beggars for horses, what is it? If wishes were horses, beggars would ride. So if you can wish for more data, but unfortunately, real life situation is many, many times you don't have enough data. So you should ask for the biggest sample size and sort of compromise with whatever you get. Does that answer you, Hari? Yeah, I thought there is some mathematical formula where you can determine, okay, these many number of sizes, okay. Here's a new aspect that I use. For sufficiently large population sizes, I tend to take the square root of n. Okay, square root of n. OK, square root of n. Minimum threshold for myself. So suppose you're talking about people, and there are 10,000 of them. I would not make any definitive statements without a lot of cautionary statements about bias, unless I had at least 100 fairly random samples, representative 100 people or 100 items, data instances. There are various ways to calculate how good your sampling is to do that. Yeah, there are. So here's the thing, guys. There are some techniques. There's some heuristics, some ways of looking at it. But I would say that in real life, in practical life, you should try to get the biggest sample that you can get your hand on. But then we live in the world of big data. It doesn't mean that you chomp through a petabyte of data saying, now I have a big enough sample. That brings us to other aspects, the real life computational aspect, and their algorithms. For example, you can find the median of a vast population of data without actually calculating the median or looking at it. So there's the Boyer-Moore theorem and so on and so forth methods. They're lovely, lovely algorithms in machine learning, which are specific to big data. Someday, which are specific to big data. Someday, someday we'll talk about it. I think for small size data for central in the tier and to apply at least the minimum of 30 samples. Yeah, people do say, see, Kyle, those are numbers. Those are heuristic. You can't, I mean, you can't put a magic number. These are experience talking. Common sense says that below 30, what will you do, right? It doesn't, how would you, like, out of, if you have only 30 data points, how many samples, frankly, can you take out of it? How much bootstrapping can you do, right? can you take out of it? How much bootstrapping can you do? Right? So you often sample from the sample. That's a reality. So we'll come to all these topics, bootstrapping and so forth in due time. It's one of the topics, but let's again learn to walk before we run. Hey, Asif, can you please explain the usage of probability mass function and how it differs from the density one? Yes. See, what did we do? Look at this case of people who have only two heights, 3 feet, 6 feet. So remember, we made two sand pillars. First of all, we made a histogram 20 and 30, 20 and 10, isn't it? Then when we divided it by 30 total number of people, we got two third and one third, discrete numbers, isn't it? We put two third of the sand at three feet, we put one third of the sand at six feet. Let me mark it as six feet, isn't it? This is probability mass function. But when values are continuous, in reality, people don't come in just two sizes, only clothes come in two sizes or three sizes. Human beings come with a spectrum of weight and our height, and our height keeps changing, isn't it? We time, we grow, we shrink. Certainly with weight, we grow and shrink all the time. So when it is a continuous distribution, it is a probability density. So continuous is density. Discrete is mass. Okay. That's the difference between the two. So Siddhartha and Ankur, how did you find the... Area under the curve for both of them. No, for mass function, these are discrete blocks. Like with sand, imagine you're sitting at the beach and making discrete pillars. But for continuous variable, it's literally as nicely making a hill of various shapes. That is the probability density. So this is density, mass, probability mass, probability density. So the area under the curve for both would be one. Area under the curve will be one by definition. But look here in the histogram, there were 30 people, 23 feet, 10, 6 feet. If I divide it by the total, I get the proportion. In simple terms, proportion is probability. When you look at it, proportion is probability. So two-thirds proportion of people are three feet. So therefore, probability of if you randomly pick a guy and ask how tall he is going to be, three feet or six feet, you would say two-thirds chance that he'll be three feet, one-third chance that he'll be six feet does that agree with your intuition yeah that is it now take it to continuous domain generalize add different values now what would happen if you had 3.5 and just think of these as very tiny tiny little pillars sitting here right with values between this this this this this and so forth all right guys any any other anybody else any question before we end uh yeah go ahead yes yes if so in galton's paper i read one statement which said that daughter's height is proportional is mostly dependent on father's height and son's height is mostly dependent on mother's height like he did not give any proof but he made that statement after that 1.7 and he yeah there are many nuggets in that paper but uh for for our, we will focus only on the regression towards the mean. Dr. G R Narsimha Rao, He does have certain observations like that I don't know how whether they were later validated or not, maybe they were so why don't you do that you have the data data is available, I believe it's one of our homeworks you can see how closely that is true. closely that is true. Maybe almost surely it's true. Now Dalton student was guess who? It was Pearson, the guy who created the definition of correlation. And so our next topic will be Pearson. Alright guys, if no one else is asking questions, we'll stop. Siddharth and Ankur, please stay back.