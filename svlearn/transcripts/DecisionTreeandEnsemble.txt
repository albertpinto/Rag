 🎵 so news we are through with setting up our environment today we'll go straight into topics this topic that I'm giving to review it is chapter 8 trees of the textbook so if you look into this your textbook ISLR, you will find this mentioned. So use that for review. It's very easy to understand. So this set of algorithms that go by the name of decision trees, they are called, or they are also called classification and regression trees classification and regression trees card that's where the word C a T comes classification and regression trees so this is interesting it is the first nonlinear method that we are learning in our sequence if you remember ml100 we focused only on linear methods read we did linear regression we did logistic regression which which is a classifier that makes linear decision boundaries we did linear discriminant analysis. Again, it made straight decision boundaries quadratic discriminant analysis. It made sort of quadratic decision boundaries. Sajeevan G. But we didn't go anything more complex than that. Now we are going to do supervised learning that is classification and regression using more powerful techniques in this particular workshop decision tree is a good segue into it. It is the simplest one. It gives me a strong intuition. It's very interpretable tree as an algorithm is very interpretable. In some sense you can say it's more interpretable than even linear regression. So that is its virtue. When decision trees came about historically, they were considered so remarkable that some people got carried away and they began saying that all of machine learning or data mining is just decision trees. You don't need anything else. With decision trees, you can do classification, you can do . And the rest is sort of classic and you can forget about it. Which is, as you will learn when we go along that's not true remember the no freelance theorem that i mentioned no one algorithm is so good that it outperforms every other algorithm so uh just be mindful of that and with the with that preface we'll get started uh decision trees from a programmatic perspective is very straightforward like any class or regressor. Scikit-learn has excellent support for it. R has excellent support for it, multiple libraries and then you have support in many other libraries also. So for example if you're doing a Spark machine learning you will have support for it at scale right big data scales you have support for it so it just emphasizes the ubiquity and importance of decision trees now the question is what are decision trees i'll motivate decision trees using an example i will take a sort of oversimplified version of the San Francisco Peninsula the bay the SF Bay in the peninsula so if you look at the peninsula let us say that this is the Golden Gate this is the north side this is the sea and you have this land that sort of curves like this and then obviously at some point this goes and curves back to make the bay now when we look at this peninsula here if you observe the way the the buildings are and the way it is laid out it has a very well defined geometry you will find that you have how you have high-rise commercial district here then it is followed by a green belt which is the SF Park and it is followed then by roughly speaking this is your residential areas lots of residential area so I'll just make the houses to look like this roughly speaking data is like this and you have also some buildings commercial areas here all along this commercial areas are there and you have this residential areas sometimes some of the residential areas are abutting the I'll just make it like this diamond shape to show that you have residential areas but it isn't quite like that sometimes you find some commercial areas I suppose I'll just throw it in some here and I'll put some residential areas here now if you were to were asked this question the question we want to ask is I take any point on the peninsula so let me say I'll take a point in white color let us say you take an arbitrary point here. Let me call this point A. Let me call this point B. Let me call this point C. B and C. If you put your finger here at A and I ask you, which region is it? Is that point likely to have a commercial building. Is it likely to have trees or is it likely to have a residential building. You would say, well, it is obvious it should be a commercial. Now if I say create a classifier such that for a given place. Let's say that you have coordinate system here. this is your x1 and this is your x2 coordinates so every point a has associated with x1 a x2 a the coordinate systems of this can you write a mapping says that given a point X you can map it to one of the three things either it is this or it is this or it is a tree it is like a I'm sorry it is a tree can you take every point and map it to one of the three classes what do we call this sort of activities algorithm that can do that what do we call it classification classification these are this is classification and an algorithm is a classifier that can do this mapping so what we are asking for is a function such that given a point X right FX belongs to this set of commercial residential and tree. Let me scroll down a little bit. Tree. So that's how we pose the problem. Now let's go and look at this picture here and ask how would you do that? So one of the algorithms that is quite intuitive, it says that suppose we did this we took let me pick a color that we haven't used more colors let's take big bold red suppose you did this Oh, this red doesn't show very well. Well, yellow we have taken. What can I use? For some reason red doesn't out something. Okay. And that too doesn't show. All right, I'll just use white here for whatever reason this color. So one thing you could do is you could just say that suppose I draw a line here. I can declare everything to this site as commercial and I can declare everything to this side as something else right are we together guys non-commercial like I can declare it to be let us say I can declare it to be residential if you do that you would be doing pretty good on the left-hand side i can declare it to be residential if you do that you would be doing pretty good on the left hand side but you'll be doing not so good on the on the right hand side are we together guys so you say well that isn't good enough what we can do next is draw another line here now we have divided this space into three boxes but a one box contains a one set of region let's say that this is a this is a region here this is one region it contains the point a another region contains a point B another region contains a point C and now if you do that what you could do is you could say that the region a is commercial that is fine this region is all trees right this reason you can declare to be trees and then you would be making some mistakes if you declare it to be trees you would be making some mistakes and here what is the majority here the majority are residential so you can declare this this thing to be residential you would say well that seems to be getting somewhere can we do can we do better and in order to do better you may then want to draw a third line you see this line so let me call these lines one second partition the third partition so if you draw a line here now we can be more precise we can say this side the lower side and this area is residential and this upper area here is commercial commercial now once again we notice that there's a mistake here. These regions should be commercial and not trees. So you may want to draw a one more decision boundary somewhere around as let's say here and when you do that now you can say that this region is again commercial. So guys, are we getting an intuition of what we are doing? What we are doing is we are taking this entire space, this rectangle that would capture this peninsula, and we are partitioning it gradually into smaller and smaller regions so that a region ideally should contain all the data points belonging to only one type or one class like for example here all these points any point here represents a commercial district here represents a park here represents the residential area here represents the again the commercial district in the commercial district are we together guys do we do we see the concept so this intuition let us formalize what you what we have done is we have taken the big rectangle if we call this the big rectangle are not the big complete rectangle of which the peninsula is a part first time we divided R naught into two parts we divided it into R 1 and R 2 isn't it and then we divided this further into one more region, the R2, we divided further into, let me call it, this is, let me leave this as R1. And we divided this further into R21, R22, isn't it? And then if you look back at it, the third division we it and this this I'll call the fourth division number four and the third division we did is we partitioned our R3 into apart so then we went like this we went from here to a situation where this was our one this was r21 this again we partition like this so that we had r221 r222 and then finally from here so i am we are recursively at each stage you notice that we are just adding one more partitioning of one of the regions so going back it is r1 one more partitioning of one of the regions so going back it is our one are now this we leave alone are two to one by the way I'm just giving these numbers to two these numbers don't mean say mean anything you could have just called them ABCD if you so wish and then we did one more partitioning. This was R, what was this? Oh, this was R2. I should have done, yeah, R21, 2, 1, 1, let us say, R22, 2, 1, 2, right? Because R21, we are splitting. So at the end of it, we end up with how many regions? We end up with one, two, three, four, five. So we can represent this as a tree structure. We can say you start with R0 and the first partitioning was if you notice R1 and R2. So we went from R21 and R22 and the R dot we further partition into R211 and R212. R221, R222. And so you notice that these are all regions, all of these regions they add up to, if you sum these regions, they will all add up to R naught. The same is true of this, these regions, if you add up all these regions, they all at any given level, they all add up to the full region, the R naught. So this is called in in programming this sort of hierarchical structure is called a tree now if you think about this problem you'll realize that you could have divided this region in many many ways but there is one way of dividing it into into sub regions that is perhaps the best but even then it may not be perfect like for example you notice that there are mistakes here so you never try to achieve perfection and here there are mistakes and so forth you will still be left with some mistakes you don't want to grow a tree so big or so fine grained that there are no mistakes you stop somewhere at some point you stop so to summarize suppose you have what we have done is decision tree algorithm works like this start with the whole region the whole feature space and we can generalize it to a multi-dimensional feature space, but it's much easier to understand it in two dimension as R0. Then this is the starting point. This is where you initialize. to what you do is find the best cut point and the cut point is interesting how do you find the cut point let's go back to the picture see this picture shows that we should have done a move this as the first cut point but a machine is blind it doesn't see the way we can see so what it will have to do it will have to scan the whole of this axis x1 axis and it will have to scan the whole of the x2 axis to find the best cut point right now the definition of best we still have to figure out. But let us say that there is a definition of the best. And so it searches along the y axis and along the x axis or the x1 and x2 axis and finds the best point to cut such that somehow it makes the best possible split. having cut that it again cuts again at the next best place and then again and again and at each point what you do is find the best cut point on one of the sub regions, search for the best sub region to split next and the best axis in that sub region and the best axis in the sub region what do I mean by that let's let's go up and see in this picture first we split here we ended up with two regions how did we decide to find this as the next split point you could have tried any of those in this sub region you could have gone with R2 you could have gone with any of these lines horizontally or vertically so you're still scanning the axes to find the best cut point having found the best cut point. Having found the best cut point, you have three regions and now you have to check for each of the regions what is the best cut point and whether at any moment you are just going to split one of the regions. So you have to find which region is the best candidate for a split and then go and split that region so the tree grows or this regions grow they add regions one region at a time because you will find a box one region and that box you will split when you split that box you'll end up with two boxes so suppose you are at seven boxes and you have found some box let us say the third box and you split it now you have you have taken away three but you have added two new boxes so minus one plus two which is the same as plus one so you always add one new region every time you split but it leaves the question what is how do we decide the big question that remains is how do we decide decide the split point split point right and along with it is also the question that like you can choose a point to split based on what criteria what are you trying to improve right so what is the criteria criterion to improve upon like what is it that you say that if I split here it would be much better than if I split somewhere else are we together right so you want to look for the best split points so we will think about this criteria that we will use to find the best split point so when you think about this we can do it two ways we can first think in terms of regression and how we do it for regression and then we can think how we do it for classification are we together so now to deal with regression let's take a slightly simpler simpler problem awesome so I don't rub color wants to be then she is writing all right guys so now suppose we are solving a regression problem remember regression is y hat is some function of FX right and then of course Y itself is some function of FX plus the irreducible error. That's our definition. This y hat belongs to r, it's a number, and x is of course a point in the feature space, and you're searching for some sort of a function that will do this. So now I'll take an example that may make it easier to understand. Let me do that. I'll take a slightly different example. Suppose that you are in a cold Arctic forest, the tundra or something like that. And on one side, you have lots of trees, lots of trees. On the other side, let us say that there is a house there has a fire right it has a fire inside perhaps there is cooking or for heating I heat heating fire I don't mean in a negative sense the house is not burning it is just a fireplace either a fireplace or a kitchen inside it and imagine that it is late night and it's it's cold so what would happen in a cold place at late at night and the rest of it is field open field so when which of these three places is likely to be the coldest? Inside the house open field or in the forest and the far in the forest Open field open field open. Yes, and which place is likely to be the warmest Forest our house When it is forest or house but logically if you say that when there are more trees it tends to be more cooler because a lot of like you know the argument is, trees moderate the temperature, which means that in warm, hot places, trees will bring a degree of coolness. And in very cold places, trees will bring a degree of warmth. The idea is that heat is not escaping from open field, heat is escaping into the atmosphere. Trees will trap the air, it will act as a cover and it will prevent heat loss okay right from the ground it sort of acts as an insulator right so you would say that this open field will be coldest now suppose i ask you this question again bring about a coordinate system let's say x1 and x2 and guys if you have questions do ask it and notice all of you are on mute but remember you can all ask questions I ask you this my target variable is temperature y is temperature you have to predict the temperature at any given point X which is a combination of x1 x2 any given point let us say this point you have to tell what the temperature is right so let us again treat it as a decision tree problem or one easy way to find the temperature would be to find the average temperature across so suppose you have temperatures you have been given training data the training data has points here it has points here in the house and everywhere right so these are your training data points and suppose you are asked the temperature in the absence of any learning you can basically say hey let's take the average temperature of all the data points so what you would do you would add up all the yi and a 1 over n and you would call that to be your y hat your prediction that would be a pretty reasonable prediction because at least by taking the average of all the temperatures you are not saying that it is it is hot as Africa or something like that there's Arizona or something like that you are still saying it is arctics isn't it so the first improvement or result that you get is you can say just take the average temperature of the region R naught itself So if you do that now you will have a lot of errors, isn't it? Because what is the sum squared? What is the measure of errors if you remember for regression? It was y I minus y I had The prediction it was the square of this do you remember guys this was the error but now what is why I had why I had is basically y bar right it is the average this is y bar let me just call it y bar by the way this is statistical notation when you put a bar over something, you often refer to it as the average. Predictions wear a hat. Just to remind you, the terminology, hat means prediction bar implies average the average so at this particular case of of course, that is also your why had for the whole region. Now you can do better than that. The next thing you can do it is you can say, Hey, can I reduce this error. This error is there. Can I, the question that you ask is, can I split R naught into sub regions such that my error goes down because if you can answer yes to it you would say you are learning isn't it learning is a reduction in error so when you go back up and the first boundary that you might want to put would be something like this let's put this boundaries in actually let me see if I can make it fatter yes they should do. First, no, blue. You would agree that if I split like this, I'll put the forest on one side and the open field and house on the other. And then if I will get two regions, let us say this region now becomes R1, this region, the forest becomes R2, let us say. Now, the R2 seems to be a pretty pure region. It's mostly made up of forest. Now, I do this. For each of the region, once again, I find the average. So, this would be, I would find the average of R2. That would be the prediction in R2 any point in R2 the prediction that I will make is again sum of all the points I belonging to R2 right summed over I why I let me put it in a more formal notation I belonging to R2 and one over number of points that is there in the R2 right the average here in this region and when I do that and likewise for R1 I can take the average of all these points so would you believe me if I say that clearly now the errors will reduce because for each point for example a point in the forest the temperature is likely to be much closer to the average of the forest rather than the global average does that statement look plausible guys anyone yes the forest error will be zero almost yeah almost zero it will be much lower right on the other hand on the R1 side yes there are errors for example but it would still be an improvement upon taking the average now you're looking at the open field in the and the house right so you can say that the error on both the sides will improve and the total error will go down so that split is worth making that's how you decide to make this split and you find the point here, the split point. It could have been like this direction or it could have been this direction. You scan the axes and you find that point that gives you a maximum reduction in error, right? Total error. Let me just say total error. Like that. Now you say, well, that is good. I can continue this process. The next split perhaps that you may want to make is you can say, hey, what can I do further? Maybe the second split I can make is along this direction because then this field becomes a pure field open field and I'll get better results and here the average of this I could do and then the last thing that you might want to make is like this and let's sort of stop there and accept the rest of the errors here so what have you done you have broken it up into one two three four right if you were to a market suppose i call this r11 this is r1 then this would be r12 and then this would be one two one and r one two two so again you can write it as R naught got into R one and R two, R one got broken up into R one one and R one two, which got broken up into one to one and R one to two. Do you see that guys? You have a decision tree. And so what is the prediction? The prediction for any given point will always be the average of the region that the point belongs to. Isn't it? Now that average value may not be perfect, but that's how decision trees work. Now, the temptation here is that you can keep on dividing to get to more accurate answers if you want. In this particular problem, I've posed a simplified problem. So it works. But so suppose you can say, well, you're not close to the house because the house is warm. There can be some further regions where it will be a little warmer than the rest of the open field and so on and so forth. So you can keep on growing the tree if you wish to get better and better accuracy. And generally, that leads to overfitting. Right. So one of the problems that we'll deal with is how do you deal with overfitting in a tree. But before I do that, let me Now use the decision trees to do classification problems. How would you use this to classify right so let me again just use instead of San Francisco let me use this simpler diagram of a forest and a thing just because we can argue with this perhaps a little bit quicker so I'll just redraw this thing here here are my trees of no trees come again I didn't hear that I have a question yes yes yes of course please do ask a question so when you are not like do you just like force every single point to like find the average how do you like how do you think when I'm finding the yes unfortunately this algorithm is very sort of in a way well in the way that I've explained it's sort of brute force you have to go scanning for it fortunately what happens is that the mathematics makes it easy when you are scanning this direction right you you look at, see, it's a continuous, slow, improving function. You can take derivatives and you can use arguments of gradient descent and so forth in finding the best split points. So those techniques are still applicable. So while it looks rather dreadfully expensive to go and scan every point, but what happens is the mathematics makes it easy. So along each of the axis, you can quickly zero into the point. Right, which will give you a good split because the error sort of reduces up to a point and then it starts increasing in this direction. So you know that the minimize here. direction so you know that the minima is here likewise if you go in this direction you will realize that say minima is here now the only thing you have to do is compare this minima with this minima and decide which is a better minima to split on does that answer your question so think about it this way see you have an error let me elaborate it so you have a certain error if you split at this point just look as as it is a function of derivative of the error with respect to x1 as you go along this direction you'll realize that this error will decrease and then start increasing again like in this simplified situation that i've given you will be able to find the point of cut points quite easily other thing you can do is discretize the many many techniques that you can do to quickly find the To quickly find the split points Yes Sorry, I would like you to scroll up a little bit to the previous example and the algorithm. I have a question there. Okay, hang on. Let me scroll up. You mean this forest? Yes, the forest. Okay. So, no, not the forest. Not the forest. The previous one. You want to go back to San Francisco. All right. Yeah, the San Francisco. Yeah one that you want to go back to san francisco all right yeah the san francisco yeah so so in this number three you have said for each of this region right sub region search for the best sub region so based on that local uh local minima principle right the minimum error you are getting in these sub regions right so i could have when i'm going through that right most probably it is like a looping through each of the sub regions and trying to find the local minima, which is giving me better accuracy. Right. So in each of these, I could have I could have done what is called the region be fast as opposed to region C, right. It's not that I have to select all of the region so what you have to do all of the sub regions yeah yes you have to find the best split point in all the sub regions and then ask if I were to do that split what is the reduction in error and then pick that region to split which gives you the maximum reduction in error okay because yes because because below in the algorithm number three of written you have to find the best sub region and within that we have to find the I understood it you know instead of finding it's not finding the best sub region but it is more like which of the sub regions I have to reduce the errors yeah which of the sub regions I have to reduce the errors. Yeah, which of the sub regions if I split the error reduction will be the highest. Highest. Okay. Okay. That's a way to that's fine. And so this brings up an interesting point. I might as well mention it. See when the decision trees came out, the computers were not insanely smart. They used to be, you know, all this 8086 and all of that, different versions of that. So decision trees in those days were considered to be a computational beast. Very much like today, we consider deep neural networks to be a computational beast. So at every generation of hardware, you find that the machine learning algorithms are pushing the limit always. And they run, they take a long runtime and so forth. So the decision trees used to take a very long time to run. So this word, CART, classification and regression tree, it started out, people started coming up with versions up to four, 4.5. And the way I remember it, the people who are doing this this open source at some point they decided they wanted to make a commercial version of it so the next improvement they didn't reveal they instead made it into a commercial product or something like that happened I vaguely remember and then well I guess there was a bit of history to that. So decision trees, the compute much of the effort was in trying to somehow make it faster. Jay Shahzad- And because there's more to it. I've just taught you half the journey. The other half is Jay Shahzad- Something called pruning the decision tree, which is to get rid of the overfitting and I'll come to it in a moment after I've done the classification part of so I've done the classification part of so so there was so there was that and they were quite effective compared to linear regression logistic etc in many many situations decision trees are very effective even today they are very effective and a lot of domains especially medical and biological etc they're there even today swear by decision trees it's a it's really powerful it's very intuitive. You can see what is happening. But today- Yeah, the cancerous regions in India. Yeah, that's right. And today we live in the world of computational plenty compared to the late 1980s, early 1990s. This is the years of plenty. So today decision trees don't take that much time compared to other algorithms it actually solves the problem very very fast computers are insanely fast these days but then of course we have other algorithms that bring it to its knees we have the the dql networks and support vector machines or even today computational beasts and they slow it down so we'll come to all of that that gradually. So now let me go back to classification now. How would you deal with a classification problem? So let me erase some space and write it down that this year classification now. How would you do classification? Not very different. Let's go back and build, bring back our Arctic forest. Oops, what just happened? Arctic forest. Okay. And here we have, and then we have this little house, lonely little house out there there we bring it in the forest this this is looking quite a bit like Hansel and Gretel isn't it so you know the story and this is the field open field now let's change the problem. We are not finding the temperature of a given place. We are asking the question, is it a field point, house point, or inside the house, or in the field, or in the forest? So this is the question. and so in the beginning you could start with this you could say well let us take all the data points that we have and let's look at the target variable and look at the majority there majority in our training set so our is the majority trees open field or house let us say that you come to the conclusion that is the open tree the open field is the majority let's say for the sake of argument we will say this so now what you do is your first model are not that when the regions are not split your prediction always is open field. Let me just use open field. Oh, house edge and forest F. So you always make a prediction of that. Well, when you make the prediction of that, what will happen? You will have a certain number of errors, isn't it? So what you can do is you can find the proportion that you got right and the proportion of it number of houses in the data point how is place number of trees in the data point over the total total this is forest and what will this signify this will signify the proportion of errors. Would you agree, guys? Right? So you take the majority class. Let's say here the majority class would be an open field over the n total. This is the proportion of correct answers. Would you agree that this is pretty much self-evident, right? If you declare everything to be open field, all you need to do is look at the number of answers you get correct divided by the total. That's a proportion of correct answers. So let me call it proportion of O. You have proportion of O, you have proportion of houses and proportion of open field. Are we together? And so what you can do is you can see, I want to reduce this error. Total error is this. In each region, you look for the non-majority part. And in this particular case is this two total error would be pH plus PF as we said or proportion these two proportions put together that's your total error would you agree this is the way to quantify error it turns out that proportions actually are not very well behaved objects and it is we use some things that are not so intuitive in the beginning instead of trying to quantify error just as proportion you do something differently you create two different measures that are known one of them is called Ginny after an Italian mathematician Ginny who literally discovered the formula for that. And the other is the Shannon's, the concept, the entropy. Well, entropy has been there, known to physicists for more than 100 years. Who was it? Maybe it was Gibbs or Thomson who created the concept of entropy more than 100 years ago, I forget. But anyway, these two concepts we'll use. So Gini index is this given a class proportion of a given class in a given region let me in a given region so i'll assume that whatever region we are looking at that region times one minus let me just say i for class d i 1 minus, let me just say i for class, d i, right, in whatever region they belong to. And for each of the regions, so suppose you're not in R0, you're in R1, R2, sum over all the regions. You just find this. So this total is the Gini index. Now, let's try to understand what Gini looks like. So proportion, would you agree that proportion will be, will have this property? Proportion of any class will be between zero and one. Would you agree guys? Yes. So if the class is pure, if the region is completely pure, then of course all the points will belong to one class, and none of the points will belong to the other class. So one proportion will be 1, the other proportion will be 0. Now let's look at numbers that are in this interval. Think about what happens if you multiply P with 1 minus P right we can plot this function out when you plot this function out you notice a interesting behavior at 0 what when P is 0 what is that what is the total 1 0 0 it is 0 at the same time the other limit is one when p is equal to one what's the answer now zero zero it is again zero so it's an interesting curve that sort of goes like this right these sort of curves are very very interesting actually um and in machine learning the moment you see something like that uh you you sort of if you are mathematically trained your fingers begin to tickle you know you you get a nice warm fuzzy feeling because now you can do all sorts of magical things with these things things that rise up from zero and fall back to zero at one right so the other thing this is the genie thing now entropy entropy is defined as something very similar but a little bit the formula is a little unlikely I like what you would have thought it is P times natural log of P and of course you put a negative sign and I'll explain why a negative sign. So what happens is, suppose the proportion is zero. What would happen to this quantity? Anybody would like to venture? If proportion is zero, entropy would be? It would also be zero. And if proportion is one, what would be the value? Zero. Because log of one is zero. But for all of the values, log of half would be what? It would be a negative. Log of half is a negative number, right? One over two. And so you multiplied by another negative number just to make it into a positive quantity, entropy. Entropy is actually a measure of disorder. The higher the entropy, the more disorder there is, or simply put, the more impurity, the more mix up of the classes in the region. So if you have a region of high entropy, it means you can't quite tell whether that point is a house or an open field or something like that. So entropy. Ashok, a quick question. At zero, actually, isn't it indeterminate log of zero multiplied by zero outside, zero into minus infinity? That's right. And so the mathematical convention is the 0 trumps. Whenever you multiply anything with 0, it trumps, and it becomes 0. I thought the 0 by 0, it has the indeterminate. I'll define it. Yeah, yeah. So see what happens is that it is like this. When p is equal to 0, you're multiplying zero times log of zero. This is minus infinity Right. And you say that this is equal to Okay, okay. That's how you do it. Or another way to think about it is that see That if you if you take the limit of epsilon a very small This expression can be thought of as a limiting quantity If you want to be mathematically more rigorous those of you Island tends to zero of epsilon Ln epsilon so what will happen? This you can rigorously prove that this limit by the way the way to prove this rigorously is you can use the L'Hopital rule yeah I love so that's what I was about to say actually because it's a long P by 1 by P which is infinity by infinity in the internet so all on P will become okay okay I don't want to bring the kind of mathematical jargon but if you do that and so it's a and who is this person asking this question this is a good question biology very good question Balaji. So now what happens is that this function actually behaves a little like, how should I put it? No, let me be more accurate and not just to give you an intuition. I hope, well, my drawing is terrible, but you see that the entropy E and the Gini G, both of these functions look very similar, isn't it? They're very similar and they both measure, they are measures of the measure, the degree of impurity or disorder. People in this literature talk about impurity means how pure are the regions they have only a point of one class like impurity degree of impurity and that's why they call impurity index impure beauty index right so the most popular index used to be for the longest time, a Gini impurity index used to be impurity index. So now you can try to reduce the Gini impurity index and use that and find out what split will give you the greatest Gini you know lowering of the index and for entropy the literature for entropy is very much influenced by theoretical physics and in entropy we don't talk so much about with entropy well the usage of the word impurity has been less common people often talk about disorder right but in the literature of decision trees the word impurity sort of stays right but you'll often see some people use the word disorder right because entropy is a measure of disorder so the more the pure a region is the less these indices and now I've glossed over a bit of mathematics when you do the split what you look at is it is called the information gain IG if you this textbook actually doesn't go into that mathematics but it's what doing because you most more detailed books will go into that mathematics but it's worth doing because your most more detailed books will go into that what it means is that you whatever you want to take suppose you have a region r i and r i is being burst out in r j r k so what you do is you take the whatever measure you have let me just say genie or impurity. Let me just use the word I for impurity. I of RI minus sum of, like if you were to split it, I of RJ, let me just call it I, well, I impurity. I am, let me use the word word impurity of region I minus the sum of the the impurity that remains after you do the split so I am J here in this particular case plus I am K right so does this make sense you look at the initial impurity and then the final impurity after you have done the split and the difference between the two is essentially given the mathematical term information gain. And if you're using entropy, then it is literally the definition of information gain, but people use the same thing even for Gini index. So the word has stayed. So what do you look there for? In the language of information gain, you look for that split point that gives you the maximum information gain. Does that make sense guys? Could I review it once again? Yeah, I think it's a little bit difficult. So there's a disorder and it's decreasing and the information gain, I'm unable to put it in. Yes, let's do that. So we realize that in any region, there will be a proportion of the majority and a proportion of the minority. So, for example, the open field, the house and the forest. So if you, let's say that on average, there is more open field and these are your mistakes. These data points are your mistakes. So suppose your total impurity in the beginning is based on either Gini or entropy, you will come up with some value. You can use a summation over P 1 minus P which is the Gini definition or you can use the entropy definition right to find the and again you can do summation over okay let me put it here summation over is equal to summation over all the regions. So, and all the classes, all the I's also. So you can find the entropy or you can find the Gini, it doesn't matter. Let's just use the word impurity index. So up to impurity index, do we understand? Irrespective of whether- So P is the count of the number of uh it's like an area under that region right no no no so suppose yeah it's very simple simpler than that suppose i have this region it has uh let me just say 15 data points for open space for O, two data points for house, right? And six data points for trees. Are we together? In this region, like if you look at your training data, you realize that the training data that belongs to this region this is the way it decomposes so you say that if you add up these points 1723 how many data points there are 23 data points are there right so the proportion of open points is 15 over 23 proportion of houses a 2 over 23 proportion of trees is equal to 6 over 23 so far so good guys now you ask this question which is the majority well here open points are the majority isn't it yes and so if you were to ask how many mistakes do you make you would just say 6 plus 2 8 8 over 23 are the mistakes right that's the proportion of mistakes so this is the concept of proportion now what you do is you don't use raw proportion you instead create these measures so what you would do is to find the Gini index you would do a 15 over 23 times 1 minus 15 over 23 plus 2 by 23 1 minus 2 by 23 plus 6 by 23 1 minus 6 by 23 do you see that so this will be the genie genie impurity you see how simply is just simple arithmetic coming from this data I hope does this make sense guys so I just can you give us an intuition like if there is so there is a bigger chunk of open space and very small chunk of non openopen data points yeah i mean by data by data points will the genie be close to zero or yeah it will be closer to zero so the more pure region is that's why it's called the impurity index the more homogeneous a pure region is the lower the genie because the impurity that's why you use the word impurity index means if a region has only open space let's say there are no trees or houses so for that region the genie will be you know you know yes right that's how you that's how you look at it so the bigger the genie the more impurities and so more ripe it is to split okay all right you can now think about that is a potential for splitting and what is the information gain suppose you have a region let me just call it our eye and you have to split it into let's say somewhere into RJ and RK so the thing is there was a impurity originally. This is the original impurity of RI. And if you, anywhere you split and create RJ, RK, there will be the impurities now of the sub regions. Now RI has gone and it has been replaced by RJ and RK. So you, when you add up the impurity of Rj and Rk The one thing that you must have is that number should be less than this isn't it? Otherwise splitting is pointless I think so you add the genie index for Rj and Rk Right, right So you add it up? That's why this plus symbol and your basic common sense says that there is no point in splitting unless the total of the total impurity of the sub regions is less than the original impurity of the full region right so the impurity of ri should be more than the impurity of the two sub regions otherwise splitting it is pointless. Does that make sense guys? Because what are you trying to do? I'll give you an example. Suppose you have this region and let us say that this is a trees, trees, trees, and before you split or after you so here's a thing this is all open space 1 2 3 4 5 6 7 and 10 points are there so now look at the genie before and after let's do this particular example okay let me actually draw this example out to illustrate the point example of how it works here Here is that same example, a three trees and seven points, five, six, seven. Right? So now let's look at the original space R zero. Let's compute the Gie impurity for R 0 let us compute and see what it comes out to be so how many trees are there proportion of tree is would anybody like to volunteer looking at this picture and a proportion of uh open spaces right so now let us compute the genie the original genie impurity index impurity of the zeroth of the entire region it is equal to pt 1 minus pt plus p 0 p o 1 minus PT plus P 0 PO 1 minus PO right and so what is that 3 10 by 7 10 plus 7 10 3 which is basically 2 times this is it so what it means is a 42 over 100 right which is approximately half which is pretty large right it's a lot of impurity so let us say 42 percent impurities there now let us see what happens if we can reduce this impurity what happens if we divide this by this vertical line and now we are left with region let me call it RA and RB right or left and right left is more intuitive I suppose region on the left and the region on the right right so now let's look at region on the left impurity of RL now in RL look at the thing what is the proportion of our trees one one isn't it so you say proportion of tree is equal to zero and likewise the impurity of R to the right once again if you look to this what do you see here it is purely open space isn't it all the data is very cleanly split so here you would have proportion of trees equal to zero proportion of open space is equal to one isn't it and so you ask this question what is the impurity of this PT 1 minus PT here plus P o 1 minus P o you would agree that both of them equal to zero and likewise the same applies here zero zero so now what happens impurity of the the the impurity that you are left with after the split is I am after split is equal to I am to the left plus I am to the right and that is equal to zero isn't it and what was the original impurity original impurity was I am zero was 42 percent isn't it and so you ask this question is it worth splitting you say very much so and in fact visually you can see that it is worth splitting. But how did we decide on this perfect split point? Let us see what would have happened if we had chosen a different split point. Suppose I had chosen, just for the sake of argument, this split point. Can we repeat the computation and see what happens? This region to the right becomes pure, to the left becomes impure isn't it yeah right and in fact we can see the impurity of it it becomes half and half it's pretty bad right and so there would still be some improvement in impurity so what would happen is for red line, for red, it would be r left. The impurity would be the proportions are half, 1 minus half plus 0. Right? And for the right one, it would be 0. So this is equal to 1 fourth. That is equal to 25%. So the thing is, for red line line if you chose red line as your split point you are going from 42% to 25% for white line you're going from 42% to 0% so which of the two split points would you prefer? And the second one, the information gain is 42. Yeah, the first one, the white split point, right? You would take that. Yeah, yeah, yeah. I mean, yeah, okay. For the red one, half into one minus half. Again, you have to plus half into one minus half. you have to plus half into one minus half oh yes half plus one minus half so it will come to actually this right which that will be 50 exactly so actually this is a very good point so you have gone from a situation which was 42 percent and you have made it you have just screwed it up and made it and you have made it you have just screwed it up and made it 50% well that is counterproductive isn't it there is no point in splitting if you want to pick the red line you want to pick the white line to split so good but I think you have gone like almost close to the middle but still you went up in genie it's very confident you do yes that is that is it Ginny can go up the max it can achieve is half and you achieve the max why did you achieve the max if you look at it carefully why did you achieve the max because you ended up with a region that is perfectly disordered exactly half and half trees and trees and open spaces isn't it does this make sense and now you see why you actually ended up creating more disorder and so this is how you use it too so what do you want to do you want to look at the gap between before and after the before value and the after value the difference between the two and the difference between the two is called information gain The term is it is before minus after And the bigger this number is the better the split Asif sorry here Just not the You made it half, right? It's 1 by 2 into 1 by 2, that is 1 by 4. The other side is 0, so it's going to be 1 by 4. proportion of tree is half proportion of open spaces is also half so when you add up the two terms half one minus half plus the other half one minus the other half right is it one fourth plus one for the member the expression is PT 1 minus PT plus P open space 1 minus sorry 1 minus open space right so this is it so half and half that's where this addition comes from are we together do you see that honey yes yes okay so this is it guys it's a very simple algorithm you look for information gain at which point should I split to get maximum information gain for classification? And in regression, which point should I split on to get maximum reduction in the error, the sum squared error, which we are familiar with? Are we together? That is it. And so you can find the best split points and you can keep on dividing. Now comes one problem. Being one point. See? One point. You realize that if every point is boxed in as a region, all the regions will be pure isn't it so suppose you have three points all you have to do is divide it like this and now suppose this is tree you declare it to be tree if this is house you declare it to be house and if this is open space you declare it to be open space okay so you realize that you'll end up with absolutely pure regions if you box each each point as a sub region and that is the danger of a decision trades that you end up over fitting because if you don't stop or you don't have a good criteria for stopping the splitting process you can go on splitting and the only time it will stop is when every point becomes a region so typically what you do is you keep some number lower bound lower bound say 10 points 10 points or 100 points whatever pick your number and you say that if if a region region contains less than that cut. Let me put the cutoff as cutoff. Less than cutoff. Then you don't split it anymore. It is already too sparse. Are we together? So you do that and so it prevents you from making a tree that is very deep. While that is good, it turns out that even if you do that, your data tends, your tree tends to overfit the data quite a bit. And that was a problem with trees. Now, let's take a break. And after that, I'll explain how to deal with overfitting and how do you cure it actually partially cure it it turned out after many many years that you it is very very hard to cure overfitting and station trees to have a tendency to remain a problem many times, not always, but many times it remains a problem. And so that will take us to the next set of algorithms, which help you not have that problem. But let us deal with it after a break. So before I go into the break, let me summarize what we learned today so we learned that decision trees are are created by taking the entire feature space and partitioning it one partition at a time such that information gain keeps happening for classification and sum squared error keeps reducing for regression right so long as you keep doing that you you build this uh decision trees now when you look at information gain for regression it's very easy some squared error but when you look at and by the way just for regression so what is the value you predict for any region? You just predict the average of the values in that region. You find all the trading data points that belong to that region and you take the average of them and you say, well, that's the predicted value. Classification, you're trying to identify whether it's a tree, open space or house. The way you do that, majority wins. In any region, whichever is the majority is the answer for that region. Well, it leads to errors. This proportion of errors, a proportion of each class for a region helps you determine impurity measure. There are two good impurity measure. There are two good impurity measures, GINI and entropy. For the longest time GINI was the default. If you look back at the history of decision trees, GINI used to be used most of the time. After some time, people realize that you get some improvement quite often by using entropy. Improvement is not much, but it tends to give you improvement. Not always. Sometimes Gini tends to do better. So it becomes a hyperparameter of the model, whether you use Gini or entropy, one of the two. Either of the two will get the job done. You can use. And so what do you do? the job done you can use and so what do you do for classification you find the point along each of the axes and you look at each of the regions and you say what is the best split point for this region and if I were to split along this read this split point for this region what would be the information gain then you ask the same question for all the other regions and whichever region splitting gives you the highest information gain, you go and split that region into two. And so you keep on doing this process till your regions all have no more than the cutoff number of points. It may have less than this is the cutoff is hundred So they may contain less than hundred points, but no more than that Right and then you say I'm done. I'm done building the tree now these trees tend to have a problem which is overfitting and These trees tend to be very like sort of fine-grained very deep trees So the second activity we need to do is solve the problem of overfitting. We need to prune the tree. Now how do you prune the tree? Well it's very similar to the way you would prune the tree in your garden. You need to take off some branches. So we will learn about that. Let's do that after the break. Any questions so far before we call the break in? I had a question. So from a very higher level understanding, you're doing cuts which are perpendicular and horizontal, even in the San Francisco region. So can't it be at an angle? I mean, could you put the question there? Actually, there's a whole body of research. So what I'm teaching you is the standard decision tree people have asked this question that what if we split along arbitrary directions random directions and there are some papers that have shown that sometimes splitting along arbitrary directions can give you better results and so on and so forth. But you see, once you have an algorithm like that, then it becomes a cottage industry. Lots and lots of research paper come that do adaptations of it. That is one adaptation, one change, one variant of it. Maybe the number of regions might decrease with an angle, but attend, this should be sufficient. Generally what happens is that you can do that, but you will also incur the cost of computational cost and so forth. What happened is decision trees were very well investigated at one point. Even now, I'm sure that some researchers are writing papers and decision trees they are in fact but the the locus of attention has moved away from decision trees to the algorithms the rest of the algorithms that you learn in this workshop and later so now decision tree is no more considered the hottest algorithm or the most powerful it is considered actually one of the simpler algorithms but a highly interpretable one and the interpretability is something you can draw out the regions you know you can show you can make this diagram let me say this sort of you know when you make out the regions into pieces like this like this blue a colored tree then it becomes easy for people to understand any point belongs to one of the regions and each region has a certain class associated with it let's say if you are doing classification so you can just look it up and tell okay but the class value for this point is this because it belongs to this region. So very interpretable, very simple. The computational cost with modern computer, modern processes is considered not worth even considering it's straightforward. Unless you have extremely high dimensional spaces, then of course it's still a problem because you're searching through many, many dimensions, axes but that is that so that's decision trees let me call in a 10-minute break guys it's 836 according to my computer 837 actually so let's make it 15 minutes so let's call it 840 so 855 actually it should be regroup at 855 that's is that enough or should I make it 9 o'clock 9 is good 9 is okay 9 is better all right so let's meet at 9 o'clock i'm going to pause the recording now all right guys so what we learned so far is that you can build a tree using information gain the summary is information gain can help you build a tree. But this tree can be too deep. It can be, it can overfit the data. Overfitting the data is never good because what the algorithm is doing is essentially, roughly speaking, memorizing your points, that each of these points what it is and not good so how do you remove overfitting I'll give you the intuition guys so suppose you have a region you're split like this I'm just making some random splits to illustrate the point so let's take this splits here and as you can see I've deliberately split it in many many places to illustrate what we are going to do now this is your decision tree during construction. And now each of these regions, they have less than a hundred points. So whatever you cut off number of points as 10 points or something like that. What you do is you ask yourself this question, which of these two regions can i merge so that my uh you know on validation data uh a holdout data set so what you do is you take your training data and you hold out some part of it you use a certain methods, K-fold or whatever it is, on the validation set, you actually get an improvement in accuracy. You get better predictive power. So you might decide that it could be, for example, getting rid of this particular thing. So it may become like this. So now this region, you notice that we have gotten a non rectangular region. It's a region that is L-shaped. Then after some time you might realize that what you need to erase is this guy. For example, the second region that you need to merge is like this. And you continue this process. As you continue this process, you'll realize after some time that you end up with all sorts of non-rectangular regions at this time. So you might end up with this, for example, as a region. And these regions are built by merging adjacent regions. So you say that in the decision tree of merging nodes and when you do that and you look for the weakest links or weakest branches or split points so that you can merge them in such a way that your model improves. When you do that, you eventually end up with, general relatively simpler trees for example you might if I were to illustrate this point you might end up with something like this a decision tree like this so now this decision tree is much simpler and you called it the prune tree and I won't go into too many details it's a the way to do that is to find regions that improve it what you do is you replace your cost function like for example y minus y hat I square was an error function what you do is you change your loss function by a parameter you introduce an extra error point a cost which is the number of nodes in the tree itself you penalize it you say that the the more nodes there are the more the errors right so you you you basically are saying that I'm going to optimize in such a way that I am trying to get the smallest tree that is giving me the maximum reduction in error so if I'm only trying to reduce the errors then I can get a very deep big tree but on the other hand if I also put a penalty factor that says too many notes in the tree is bad too big a tree is bad how big the tree is is this and that is bad so then there is a balancing act between these two if you try to minimize this this stays large if you try to minimize this too much then this begins to grow up so you have to find an optimal point in between where you go and stop. And so you end up with a prune tree. We will do a lab in which we'll see the effect of the prune tree on data. So prune decision trees is what you do. When you prune the tree, interestingly, you don't reverse your backtrack. You know, you split, split, split, you get a tree. But once you have split and gotten a tree, when you try to go back to it, you don't reverse path. You actually prune in a different path. As you can see, you prune by using a different heuristics for pruning, and you end up with a decision tree, which you could not have drawn on the way down if you remember on the way down all the regions were rectangular you could not have gotten a non rectangular region whereas now going back up when you merge the no branches you end up with non rectangular regions in your in your decision tree, which is considered pretty good actually, it leads to good results. So that is about decision trees. However, decision trees have a problem. So this is all that there is to the theory of decision trees. I would like to take some questions now. Any questions guys feel free to ask questions are you guys hearing me or not no we are hearing you yeah so on the prune pruning and in discipline we have to maintain any ways to do it yeah they're are mathematically here take a stand right what you do is there is a whole there is a whole bit of mathematics okay i won't go into the reason is it's not really worth going into we are going to do more sophisticated algorithms at one time pruning the tree used to be a huge cottage industry how best you can do it after a little while you reach a point of diminishing returns and the better way to do is not to use a decision tree but to use lots of them and that's the next topic yes if in practical examples where would you think this is applicable decision trees Oh any time you want to do classification or regression decision tree should certainly be one of your choices because if you keep decision tree as one of your choices you have the advantage that if the model remains interpretable assuming that you get a good model it remains interpretable so see this question is you never know given a situation which algorithm will do best. That's sort of the new freelance theorem. So you should try out all the algorithms and that's one of the practical, you know I named this course, this workshop, the practical methods. You'll realize at the end of the day what I'm trying to tell you is that you can have some gut feeling that in this situation this will work, but you still need to validate it. And decision trees are very general purpose algorithms. They work both for classification and regression. Whether they are suitable to your problem or not, you'll only come to know after you build, after you use it, not before that. only come to know after you build after you use it not before that okay that makes sense yeah this was trying to figure out some any practical examples in the market that is how decision tree was used decision like for example she was you have been to the previous workshops and so forth think of it the breast cancer data you can apply a decision tree California housing prices you should apply a decision tree and all these situations decision tree applicable and they are widely used like when you say where should I use decision trees and are they used in the industry ubiquitously almost any problem set you go to somebody would have tried to solve it with decision trees and decision trees are quite effective so okay and they are a favorite of a class of people simply because they are highly interpretable if you can manage the overfitting problem they're very interpretable this is like easy to interpret, much more simpler to explain compared to some of the other that we're going to learn, which will be complex to explain. Exactly. So for example, a support vector machine is interpretability is very hard there for the common man, right? The moment you try to interpret, you get into a lot of mathematics. At the same time, the same is true for other algorithms like gradient boosting, quantum power, and so forth. Neural networks is almost hopeless. But decision trees are lovely. They can solve pretty complex problems and they're interpretable, which explains the huge popularity. The popularity of algorithms, all this after the linear algorithms, like linear regression and logistic regression and so forth, I would say decision tree is the next most popular algorithm. When linear doesn't work, people's first go-to is decision trees, When linear doesn't work, people's first go-to is decision trees because they're simple. And then you always try more sophisticated algorithm. And if those outperform the decision tree by a wide margin, then you give up on decision tree. But if you notice that their performances are comparable to decision trees, you always stay with the decision tree because it's very interpretive. Are we together? That makes sense. stay with the decision tree because it's very interpretive so that's that now any questions guys so what are the key concepts we learned we learned about impurity measures the genie and entropy we learned about information gain. We learned about pruning the tree after growing it. And when we do the labs, you'll find that it's quite simple and it is a very good interpretation. Decision trees visually are very, very appealing. So we'll use that the now I'll move on to a new topic I'll introduce it today and we'll cultivate it much more in the next next Monday the topic that we'll talk about is ensembles ensemble methods or ensemble methods. So when you think of ensembles, you might think of orchestra or something like that where there are a lot of people playing different parts of the music. And it's sort of like that, you know, you're in a big orchestra, then harmony comes because each musician is playing the same music on a different instrument isn't it one is playing the flute one is playing the violin and so on and so forth and obviously not one a few a few people are playing the flute a few people are playing the violin maybe the piano and so on and so forth and but it is in a very ordered process at the end of it, what you get is harmony, you get beautiful music so that you won't get that beauty that harmony with just one instrument. Sajeevan G. And there is something of that to be said about these new methods they are reflective of a concept that I will just talk about in my mind when I think about it I think of wisdom of crowds so wisdom of crowds is a big topic but wisdom of clouds applied to algorithms of machine learning algorithms makes for ensemble methods of learning so let me explain what I mean with a simple example. Right? See, by the way, just as a tangential discussion going off, the word wisdom of crowds has gotten, got a lot of attention about 10, 15 years ago. There was a book literally called The Wisdom of Crowds. I encourage you to purchase it and read it. It had quite a bit of influence. So there are quite a few stories associated with the wisdom of crowds. Let me tell you some stories just to motivate it because we have limited time and next time we'll go into the technical aspects of it. See, there was a great statistician named Galton who whose way of thinking about data and he's obviously at the father of all this data science subject one of the key people in this pursuit more than a hundred years ago he was roaming around England rural England and he came upon a weekly fair so both in India and in Europe they used to be this custom of a fair in which the various vendors will come and sell their vegetables and they would sell their you know animals cows and whatever sheep and whatever. So, and then there would be some, I don't know, entertainment and so forth, merry-go-round and so forth. We are all familiar with fairs. So, and a market, weekly market. In India, it used to be, even now in the Northeast, the word people use is hot. So, something like that so you go to you went to that and then he noticed something which I think it will feel pretty gross actually so there was a butcher and the butcher was selling meat let's say he was selling I believe being England I would guess it must be a sheep but I may be wrong a sheep so I wasn't a pig I don't remember which one so the question was he wanted to drum up business so he gamified his shop what he did is he would in the beginning in the morning he would show an animal and you could you could put some amount let's say a shilling you could buy a ticket and on the ticket you could guess the weight of that animal but it wasn't the weight as you saw it it would be the weight of the animal after it had been slaughtered drained cleaned and hung up and skinned and hung up as meat for the butcher to sell. So obviously there's an involved process because a sheep is furry and all of that let's say. So people would put all sorts of numbers into the ticket and the idea was that the butcher would keep all that money together as a jackpot. Obviously he would keep a cut and whosoever's answer turned out to be closest to the observed value after the animal had been slaughtered and hung up, cleaned and hung up, that person would get the jackpot. So obviously, it's very exciting the moment you create something like this. A lot of people will come, and they'll bet, and so on, and so forth. And there's always the temptation of the jackpot so people did that he then after the game was over and the winner had taken the jackpot all those tickets used to be just lying around on the floor so Galton being a vague data driven person and observant he picked up those tickets and what he and he would make a table of all the values that people entered. He observed something quite remarkable, actually. He observed that time and again, the average of those values was uncannily close to the winning number, to the actual weight of the animal. And he verified this again and again and again. In fact sometimes they, if you had taken the average you would have won, you would have beaten the winner and so forth. So it was a remarkable discovery and it also had a lot of consequences. For example, those were the days when this whole thing, whether everybody should, whether you should have true democracy in which everybody could vote is the right answer, or should vote belong only to the educated people and the intelligentsia and so forth, all of those debates. So obviously it sort of fell into that. And he noted the point that the crowd, individually, they were making guesses, but together as a group, they could guess the answer with uncanny accuracy. It was the wisdom of the crowds. Now, this class I'm doing here virtually, but if you were in the physical class some of you may remember that at this stage I show you a jar of stones anybody remembers that yeah multicolored and I would ask you to guess how many stones there are in the jar and everybody's guess would be different but if you take the average of the values you notice that the average is uncannily close to the right answer and a jar of stones is hard to sort of get the count of because you know it's three-dimensional and you can't it's opaque you can just see that filled with stones but you can't tell how many stones there are and yet almost every single time the average would be near the winning answer near the correct answer even though the variation would be I would typically have about nine hundred and two somewhere between ninety two hundred and two I might still wouldn't know how many stones I would put but in that range But the answers that people would range from like 30 all the way to 250, typically. Very wide of variation of answers. And yet the average of them used to be uncannily close to the right answer. So this concept is now today called collective intelligence or wisdom of crowds. There are many such stories. I'll just today to end the class I'll tell you two interesting stories. Many of us lose keys. I lose keys all the time. You know I lose my key, I lose my ID card or my driving license or something. And it's a bit of a nuisance when you have a habit of losing things. The absent-mindedness is a bother, but not much harm is done after some time I find it. Well, sometimes losing can that one fine day, the US Navy managed to lose a whole nuclear submarine. Now, how in the world do you lose a big nuclear submarine? Well, the way it worked is that there was a big submarine, which was out at sea in the big Pacific Ocean. And the Pacific Ocean is huge. If you ever look at it in the globe, you'll realize that, well, being the ocean, obviously there are no landmarks. It is just flat and it just stretches out seemingly endlessly. Well, something went wrong with this nuclear submarine so that the last ping or the last message that it had sent was when people took that value and they wanted to search for the nuclear submarine, they had no idea because a submarine does of course move and they wouldn't have an idea where to go look for it in the neighborhood. You had to search, I believe, I forget I forget the number 100 square miles or thousand square miles or something like that a huge area could be searched and obviously that kind of area in the sea where there are no landmarks is difficult to search for especially in the deep pacific so they were searching everywhere apparently and they weren't getting anywhere and a nuclear submarine is not something that you can stop searching it is obviously of national security importance so you have to keep searching for it so there was a ship a sailor a Navy people on ships and there was a mathematician sailor and he had a bright idea he he created a jackpot he said to the, let's for a dollar guess where that submarine is, the coordinates of that submarine. And whosoever's answer comes out to be the best, we will give the jackpot to that person. Well, what do people do on ships when they get bored? As you know, drinking and gambling is pretty common. you know, drinking and gambling is pretty common. And nobody likes, I mean, you really love betting, isn't it? Especially a harmless bet like this. So well, of course, they all jumped for it. A jackpot was created. And he systematically took the data and from that analyzing it, he came up with certain coordinates for for the submarine that it's worth checking there. Apparently, the way I heard it, I think it's there in the Wisdom of Crowd books. He mentioned that to the powers that be, the admirals and whatever, and said, why don't we look here? And those people pooh-poohed it, said that just a bunch of ignorant sailors betting upon it, or cadets betting upon it, is not going to come up with the right answer. So it wasn't taken that seriously, as I hear the story, but that submarine a few months later was actually found. And when it was found, it was uncannily close to where this mathematician sailor had pointed to in fact if they had started right there and gone down they would have almost immediately seen the submarine at the bottom of the sea so it's amazing how we look at problems each one of us makes a different guess, but collectively, somewhere there, the intelligence is there, we come up to the right answer. It's a little hard to describe, but actually, if you think about it mathematically, here's one way I tend to answer it. So suppose I ask you to guess the number of stones. Let's say that this is the right number. Let's say 100 is the number of stones. So what will happen is, a lot of people will guess on both sides of it. So in everybody's answer, there will be some information and some error, some bit that is actually correct and some biased some degree somebody is optimistic somebody is pessimistic and so forth and on the average what will happen to the average of the errors the average of the errors will cancel out but the information content will remain so what will happen is when you take the average of all of these things they will all peak around around the correct answer so wisdom of crowds has been actually quite an interesting thing there has been a lot of studies quite amazing studies some of them are quite uncanny and are very hard to explain for example when there was a Challenger disaster, the shuttle disaster, there were five companies that were contractors for, or three companies, I don't know, some ordinary, three or five companies, which were contractors for NASA giving the parts. So the moment the Challenger disaster happened, all five stocks tanked because people felt that these contractors will be held responsible. And yet something very interesting happened. Four of the companies, their stocks actually recovered. The fifth company stock didn't recover so much. Now the Challenger disaster, it's a post-mortem. The root cause analysis took months. It was actually the Nobel Prize winner, Richard P. Feynman, who discovered the real cause. It was just a seal, an O-ring, a gasket, which had failed at low temperatures. But that took a long time. It is very uncanny that the financial market somehow had decided to blame the company that turned out to be the maker of that O-ring. And people have studied it a lot, I suppose, people who do economics and MBA. They have studied it a lot to find out what actually happened. Nobody seems to have a very clear answer, but somehow collectively, the collective wisdom came to the conclusion that most likely it is this company and they were right so there is a lot of that now that is all interesting how does it how does all the stories come around to what we are going to learn hey Asif yes so this error is this does this error also include irreducible errors or just irreducible errors it does include and the point with irreducible errors is they always the the mean of the irreducible errors is zero yeah okay so you wouldn't think here you just say that individuals when they are making guess uh they're it's partly what they don't know and partly they optimize exactly exactly okay that's how they get mixed up yeah now how does it relate to machine learning and to algorithms i'll give that with a simple example let us say that you took a bunch of kids to the zoo with a simple example. Let us say that you took a bunch of kids to the zoo and to a meadow and a very simplified meadow that I keep referring to. Imagine a meadow in which there are only two kinds of animals, the cows and their ducks and the teacher is trying to tell the children about cows and ducks. So the teacher being highly educated adult is pointing out that the cow is big and ducks. So the teacher being highly educated adult is pointing out that the cow is big and has a swishy tail and has horns on his head, is heavy and and so on and so forth, all the characteristics of a cow. And then the teacher is also explaining all the characteristics of a duck, you know the feather, the feathers, the the wings the web feet the beak the small size small weight and all of that the behavior but imagine that these are first kindergarten children so what will happen is for them it would be information overload they won't quite catch on to all of those things so one child may remember one or two features, one or two facts. For example, one child may remember that cows are big and they have swishy tails, right? Or that ducks are small and they have feathers. So little small things. They won't remember the whole large collection of features that distinguishes cows from ducks. Some other child may have noticed onto something else. May notice the fact that cows don't have beaks, ducks have beaks. Another child may have noticed that cows have hooves and ducks have webbed feet. So each child may have picked up something, a subset of the information. You use the word weak learners each child you can say is a weak learner weak learner and then comes a remarkable fact if you ask a child pointed to an animal and say is it a coward duck and the children are still learning the child will make mistakes to different degrees they'll be able to tell a cow from a duck using their features so one may use the size but size is not very useful when you're looking at a cow from a large distance it might look like a duck right a web the child who looked at the web feed would just be guessing because from a distance, you can't tell whether it's hooves or web feet and things like that. So each of the child will make a small mistake, will have a certain error rate, a different error rate based on the features they're looking at. But the remarkable thing is if you take the majority of what the children are saying, so suppose they are, let's take a number, 50 children. And you ask the children, what is it, a cow or duck? And then you take the majority of the answers. Well, to get a majority, let's be a little bit clever. We don't want 25, 25. Let's say that there are 51 students. So you will always get a majority. You get a majority and you look at the majority and you take the majority answer as the correct answer aggregated over all the students you will those children and what you'll observe is quite remarkable that while individually each of the child is a weak learner but does have a high error rate but collectively the wisdom of the crowd kicks in the collective intelligence kicks in and the children are getting the answers with remarkable accuracy and that's a very counter-intuitive fact because each of the children as i deliberately mentioned is a kindergarten child right so it's a weak learner it's not a very powerful intellect that can absorb all the facts that the teacher is saying distinguishing a cow from a duck nonetheless this this collection this class of children or this group of children together are very smart they almost always get the answer right so therein lies the message that we capitalize in ensemble methods so in ensemble methods and sample and let me just say ensembles the key ingredients is you take weak learners learners be many of them the then comes the things that are implicit that I didn't mention but I should mention each learner different learners are looking at different things different aspects one child looks at the web feed and something else different learners are looking at different subset of features. Just a small subset of features. And you can even do, like, they are given different samples, may even be given, be getting different, because let's say each child is roaming around in a different part of the middle different samples of data later now comes a fact that is important to know implicit to this is they're looking at different you know that these children are not talking to each other one is looking at web feet another is looking at at, let's say, the size of the animal. Right. And it is important that they're independent. So in other words, the learners are not correlated So, for example, the moment you talk about wisdom of crowds and you bring it to the non-mathematicians, they'll immediately tell you that there is no wisdom of crowds. There is the stupidity of the mobs, right? And quite often they will be right. So what happened? What happens is, let's take the case of elections. In any democracy, the ideal condition is that there are candidates and each citizen thinks about what each candidate is offering to the country, what the agenda is, deeply thinks about it, independently comes to a conclusion and picks a candidate. That is the way democracy in its ideal form should work. If that were true, democracies would not tend to bring in the kinds of leadership they invariably bring up, the sort of idiotic leadership quite often that emerges in most democracies time and again. So what happens in reality? Where did the theory fail in my view and this is a subjective perspective and i would argue that i'm fairly convinced of that and i'll let you decide whether you agree in democracies this process of election is not giving the candidates and then people making independent decisions there is a whole process of campaigning in which the media, the newspapers you read, the television you watch, etc. is trying to influence you. Each candidate is trying to influence. So based on which channel of the television you watch, they give you selective facts and they give opinions. And most people get influenced by the opinions of the so-called pundits, the intellectuals on that channel. So if you listen to Fox, you will have one sort of opinion. If you listen to MSNBC, you'll have the diametrically opposite sort of beliefs and facts. And in every every country it goes on like that in fact if you it is a remarkable thing that newspapers came in existence not for the pure journalistic purpose that we think they should be for today they were actually meant as quality political propaganda vehicles surprising actually a lot of people don't realize that. And so that has always been a problem. Journalism has evolved and it tries for impartiality but almost never succeeds. And so all of these media outlets, they have their biases. And then people talk to each other in the offices and you know that most people in California will lean left most people in I don't know Mississippi or somewhere may lean right you ask yourself why are they really uncorrelated learners are they making independent decisions no so the flaw with wisdom of crowds is when the learners are correlated it becomes instead of wisdom of crowds it becomes the stupidity of the mobs. And that is the downfall of democracy. I mean, somebody very wisely said that democracy. Is the worst form of government, except that every other form of government is worse than this. And so you, I mean, it is the best that we know of we don't know of anything that's better than this but that is no argument to say that it is actually a good system and we all know that politically we all know that and we all know elections are coming this year so the the amount of coverage and machinery to influence our opinions is going into high gear it It's really mounting up now. And we'll see what happens. But generally speaking, the kind of person you would have picked if you had no influence is quite different from the person you end up picking because of all the influence that is there, all the propaganda that is there. So that's the fall of democracy. It's always been and is there. And the same that is there so that's the fall of democracy it's always been and is this and the same thing is true in machine learning so one of the things is that you don't want the wisdom of crowds to become the stupidity of the mobs so you need to keep bullies away inherently you need a mechanism to keep bullies who can dominate thinking who can dominate neutralized and these things now I'm giving you as a flavor just motivational talk but you'll realize that these things have mathematical meanings and we'll deal with it next time so that is an important criteria let me just call it e and then f is just aggregate the results let's say average or majority so if i want to know what is the weight of that sheep you can just take like that galton did took the average of the rates right as the correct answer if you want to figure out whether something is a coward that you ask the children and whatever the children say as a majority you take that to be the correct answer to aggregate to predict aggregate to predict or get the answer or get answers aggregate to predict and get answer so these are the steps that you use an ensemble let me recapitulate you actually so the first thing is weak learners people say that well you know if you create an ensemble or a collection of weak learners wouldn't it be far better to create a collection of strong learners right and paradoxically but mathematically it is more obvious but paradoxically unless you see why and why weak learners are better actually taking a collection of strong learners is a terribly bad idea people have tried that in real life also they sometimes will get a bunch of experts to opinionate on a topic and come to a decision and they have studied that if you make if you only take experts what happens and if you take people who are not experts who know we're intelligent knowledgeable willing to think independently and you take a bunch of those and you give them all the information to think over time and time again you notice that actually the latter class comes out the winner quite often sometimes expert the expert wins. So for example, you know, if I were to ask you some very technical problem, for example, something to do with particle physics, right? At certain high energy interactions, what sort of particles will be produced? So, well, you can't take ordinary people and ask them to guess because it takes practically 10 years of training, mathematical training, before they can even understand what the question being asked is. And somebody who has been through 10 years of training is inherently already an expert. Right. So there are situations where it doesn't work, but quite often actually it works remarkably well and you see it all around us. Encyclopedia Britannica was the collection of the writings of the best experts on any topic. Great professors would sit down and write those articles, each of the articles, knowledge articles in Encyclopedia Britannica. They were absolutely a pleasure to read. I remember spending many a happy afternoons in my childhood, literally pouring over the articles of the Encyclopedia Britannica. Beautiful language, lots of facts. And then came Wikipedia, where anybody can go and who feels that they know enough can go and update a topic or write about a topic. People have done a lot of in-depth studies of which has more errors and they have found that on average the errors on Wikipedia is not more than the errors in Encyclopedia Britannica. In fact, they were very comparable and in fact Encyclopedia Britannica had slightly greater error rate. And it is for a reason today everybody has heard of wikipedia we all visited and there are very few people who have the encyclopedia britannica or read about it in fact the last printed volumes were in the late 90s or maybe 2005 is when the last printing happened and the editions were older and after that it hasn't been printed to my knowledge I don't know does anybody here own encyclopedia Britannica if you haven't I would highly suggest at some point get a volume of it all of them put together is a bit expensive it will cost you a few hundred dollars a few hundred dollars or a thousand dollars but uh get a volume it would be inexpensive ebay or something like that and try reading articles from that and you would be absolutely fascinated by the depth of scholarship behind each article and yet we find today that everybody goes to Wikipedia and a lot of information is there on Wikipedia is mostly accurate why because behind every article there's a lot of debate there are people who are debating ideas there they're saying no this is not correct I this is not well stated and they are arguing over it. And finally, what comes out is the collective expression of what they all think. And so the articles evolve in Wikipedia. So I will stop here. I don't want to go into the technical aspects of ensembles. Now you may say, where is ensemble used in practice? They're used everywhere but the algorithms that fall under this categories are many actually but the ones most people are familiar with are a random forest and a gradient boosting like XG boost and other boost and things like that people are very familiar with cat boost and so forth so in practical terms we will do all of that and on next Monday we will continue the theory of ensembles they used everywhere if you go to Kegel by now I hope all of you have accounts on Kegel you look at the competitions you'll be shocked at how many many competitions are won by people just using ensemble methods. In fact, once you learn the whole theoretical aspects of ensemble, the question you would be left asking is, is there ever a situation when you should not use ensembles? And we'll come to that. It turns out that it is much better to use a lot of learners and aggregate their wisdom rather than just use one algorithm. And with those words, I will conclude and I'll take questions now.ご視聴ありがとうございました